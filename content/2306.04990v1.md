---
title: 2306.04990v1 Multi-Architecture Multi-Expert Diffusion Models
date: 2023-06-05
---

# [Multi-Architecture Multi-Expert Diffusion Models](http://arxiv.org/abs/2306.04990v1)

authors: Yunsung Lee, Jin-Young Kim, Hyojun Go, Myeongho Jeong, Shinhyeok Oh, Seungtaek Choi


## What, Why and How

[1]: https://arxiv.org/abs/2306.04990 "[2306.04990] Multi-Architecture Multi-Expert Diffusion Models - arXiv.org"
[2]: https://arxiv.org/pdf/2306.04690 "arXiv:2306.04690v1 [astro-ph.GA] 7 Jun 2023"
[3]: https://arxiv-export-lb.library.cornell.edu/abs/2306.04990 "[2306.04990] Multi-Architecture Multi-Expert Diffusion Models"

Here is a summary of the paper[^1^][1]:

- **What**: The paper proposes a novel approach called **Multi-architecturE Multi-Expert (MEME)**, which consists of multiple experts with specialized architectures tailored to the operations required at each time-step interval of a diffusion model.
- **Why**: The paper aims to address the limitation of existing diffusion models that employ denoisers with the same architecture, without considering the optimal operations for each time-step noise. The paper claims that this leads to diffusion models requiring a large number of parameters for their denoisers and being inefficient at handling different frequency ranges at each time-step noise.
- **How**: The paper introduces a multi-expert strategy that assigns denoisers with different architectures to different noise intervals. The paper uses self-attention operations for low-frequency components (low-pass filters) and convolutions for high-frequency features (high-pass filters). The paper also proposes a dynamic routing mechanism that adaptively selects the best expert for each time-step noise. The paper evaluates the proposed approach on various image generation tasks and compares it with large competitors in terms of both generation performance and computational efficiency.


## Main Contributions

[1]: https://arxiv.org/abs/2306.04990 "[2306.04990] Multi-Architecture Multi-Expert Diffusion Models - arXiv.org"
[2]: https://arxiv.org/pdf/2306.04690 "arXiv:2306.04690v1 [astro-ph.GA] 7 Jun 2023"
[3]: https://arxiv-export-lb.library.cornell.edu/abs/2306.04990 "[2306.04990] Multi-Architecture Multi-Expert Diffusion Models"

According to the paper[^1^][1], the main contributions are:

- The paper proposes a novel approach called **Multi-architecturE Multi-Expert (MEME)**, which consists of multiple experts with specialized architectures tailored to the operations required at each time-step interval of a diffusion model.
- The paper introduces a **dynamic routing mechanism** that adaptively selects the best expert for each time-step noise based on a learned score function.
- The paper demonstrates that MEME **outperforms large competitors** in terms of both generation performance and computational efficiency on various image generation tasks, such as unconditional image generation, class-conditional image generation, and super-resolution.
- The paper provides **ablation studies and analysis** to validate the effectiveness of the proposed approach and to understand the behavior of different experts at different noise intervals.

## Method Summary

[1]: https://arxiv.org/abs/2306.04990 "[2306.04990] Multi-Architecture Multi-Expert Diffusion Models - arXiv.org"
[2]: https://arxiv.org/pdf/2306.04690 "arXiv:2306.04690v1 [astro-ph.GA] 7 Jun 2023"
[3]: https://arxiv-export-lb.library.cornell.edu/abs/2306.04990 "[2306.04990] Multi-Architecture Multi-Expert Diffusion Models"

Here is a summary of the method section of the paper[^1^][1]:

- The paper first reviews the background of diffusion models, which are generative models that learn to reverse a diffusion process that gradually adds noise to a data sample until it becomes pure noise. The paper explains how diffusion models use a sequence of denoising steps to generate samples from noise, and how the denoising steps are parameterized by neural networks.
- The paper then introduces the main idea of **Multi-architecturE Multi-Expert (MEME)**, which is to use multiple experts with different architectures to handle different noise intervals in the diffusion process. The paper argues that this can improve the efficiency and performance of diffusion models, as different architectures can be more suitable for different frequency ranges at each time-step noise.
- The paper describes the details of the proposed approach, which consists of three components: 1) a set of experts with specialized architectures, such as self-attention and convolution, that are designed to handle low-frequency and high-frequency components respectively; 2) a dynamic routing mechanism that adaptively selects the best expert for each time-step noise based on a learned score function; and 3) a training procedure that optimizes the parameters of the experts and the score function jointly using a variational lower bound on the log-likelihood.
- The paper provides some analysis and insights on the proposed approach, such as how the experts behave differently at different noise intervals, how the score function reflects the suitability of each expert, and how the dynamic routing mechanism balances the trade-off between exploration and exploitation. The paper also discusses some extensions and limitations of the proposed approach, such as how to handle conditional generation and how to deal with mode collapse.


## Pseudo Code - High level

Here is a possible high-level pseudo code for the paper:

```
# Define a set of experts with different architectures
experts = [SelfAttentionExpert(), ConvolutionExpert(), ...]

# Define a score function that takes a noise level and an expert index as inputs and outputs a scalar score
score_function = ScoreFunction()

# Define a diffusion model that takes a data sample and outputs a sequence of noise levels and denoised samples
diffusion_model = DiffusionModel()

# Define a loss function that computes the variational lower bound on the log-likelihood
loss_function = VariationalLoss()

# Define an optimizer that updates the parameters of the experts and the score function
optimizer = Optimizer()

# Loop over the training data
for data_sample in training_data:

  # Get the sequence of noise levels and denoised samples from the diffusion model
  noise_levels, denoised_samples = diffusion_model(data_sample)

  # Initialize the loss to zero
  loss = 0

  # Loop over the time steps
  for t in range(len(noise_levels)):

    # Get the current noise level and denoised sample
    noise_level, denoised_sample = noise_levels[t], denoised_samples[t]

    # Compute the scores for each expert using the score function
    scores = [score_function(noise_level, i) for i in range(len(experts))]

    # Normalize the scores using a softmax function
    probabilities = softmax(scores)

    # Sample an expert index from the probabilities using a categorical distribution
    expert_index = sample_categorical(probabilities)

    # Get the selected expert from the experts list
    expert = experts[expert_index]

    # Compute the prediction of the selected expert for the denoised sample
    prediction = expert(denoised_sample)

    # Compute the loss for the current time step using the loss function
    loss_t = loss_function(prediction, data_sample)

    # Accumulate the loss over time steps
    loss += loss_t

  # Update the parameters of the experts and the score function using the optimizer
  optimizer.update(loss)
```


## Pseudo Code - Detail

Here is a possible detailed pseudo code to implement the paper:

```
# Define the hyperparameters
num_experts = 4 # The number of experts
num_layers = 12 # The number of layers for each expert
hidden_size = 256 # The hidden size for each layer
num_heads = 8 # The number of heads for self-attention
kernel_size = 3 # The kernel size for convolution
dropout_rate = 0.1 # The dropout rate for each layer
num_steps = 1000 # The number of diffusion steps
beta_min = 0.0001 # The minimum noise level
beta_max = 0.02 # The maximum noise level
learning_rate = 0.0001 # The learning rate for the optimizer

# Define a function that computes the noise level for a given time step
def get_noise_level(t):
  return beta_min + (beta_max - beta_min) * t / (num_steps - 1)

# Define a function that adds Gaussian noise to a data sample
def add_noise(data_sample, noise_level):
  return data_sample + sqrt(noise_level) * random_normal(data_sample.shape)

# Define a function that applies layer normalization to a tensor
def layer_norm(tensor):
  # Compute the mean and standard deviation of the tensor along the last dimension
  mean = reduce_mean(tensor, axis=-1, keepdims=True)
  std = reduce_std(tensor, axis=-1, keepdims=True)
  # Normalize the tensor using the mean and standard deviation
  normalized_tensor = (tensor - mean) / (std + epsilon)
  # Return the normalized tensor
  return normalized_tensor

# Define a function that applies a feed-forward network to a tensor
def feed_forward(tensor, hidden_size):
  # Apply a linear transformation to the tensor with hidden_size units and ReLU activation
  tensor = linear(tensor, hidden_size, activation="relu")
  # Apply dropout to the tensor
  tensor = dropout(tensor, dropout_rate)
  # Apply another linear transformation to the tensor with the same size as the input and no activation
  tensor = linear(tensor, tensor.shape[-1], activation=None)
  # Apply dropout to the tensor
  tensor = dropout(tensor, dropout_rate)
  # Return the tensor
  return tensor

# Define a function that applies self-attention to a tensor
def self_attention(tensor, num_heads):
  # Split the tensor into query, key, and value tensors along the last dimension
  query, key, value = split(tensor, num_heads, axis=-1)
  # Compute the attention scores by multiplying the query and key tensors and scaling by the square root of the hidden size
  scores = matmul(query, transpose(key, -2, -1)) / sqrt(hidden_size)
  # Apply a softmax function to the scores along the last dimension
  probabilities = softmax(scores, axis=-1)
  # Compute the attention output by multiplying the probabilities and value tensors
  output = matmul(probabilities, value)
  # Concatenate the output tensors along the last dimension and apply a linear transformation to restore the original size
  output = linear(concat(output, axis=-1), hidden_size)
  # Apply dropout to the output tensor
  output = dropout(output, dropout_rate)
  # Return the output tensor
  return output

# Define a function that applies convolution to a tensor
def convolution(tensor, kernel_size):
  # Apply padding to the tensor along the spatial dimensions
  tensor = pad(tensor, [(kernel_size - 1) // 2] * 2 * len(tensor.shape[2:]))
  # Apply a convolution operation to the tensor with hidden_size filters and ReLU activation
  tensor = conv(tensor, hidden_size, kernel_size, activation="relu")
   # Apply dropout to the tensor
   tensor = dropout(tensor, dropout_rate)
   # Apply another convolution operation to the tensor with hidden_size filters and no activation
   tensor = conv(tensor, hidden_size, kernel_size, activation=None)
   # Apply dropout to the tensor
   tensor = dropout(tensor, dropout_rate)
   # Return the tensor
   return tensor

# Define a class that represents an expert with a specific architecture
class Expert:

   # Initialize the expert with an architecture name and a list of layer functions
   def __init__(self, name, layers):
      self.name = name # The name of the architecture (e.g., "self-attention" or "convolution")
      self.layers = layers # The list of layer functions (e.g., [self_attention] * num_layers or [convolution] * num_layers)

   # Define a function that applies the expert to a denoised sample and returns a prediction
   def __call__(self, denoised_sample):
      # Loop over the layers
      for layer in self.layers:
         # Apply the layer function to the denoised sample and add a residual connection
         denoised_sample = denoised_sample + layer(denoised_sample)
         # Apply layer normalization to the denoised sample
         denoised_sample = layer_norm(denoised_sample)
      # Return the prediction
      return denoised_sample

# Define a class that represents a score function that takes a noise level and an expert index as inputs and outputs a scalar score
class ScoreFunction:

   # Initialize the score function with a linear layer
   def __init__(self):
      self.linear = Linear(num_experts, activation=None) # A linear layer that maps the noise level to a vector of scores

   # Define a function that takes a noise level and an expert index as inputs and outputs a scalar score
   def __call__(self, noise_level, expert_index):
      # Apply the linear layer to the noise level and get the vector of scores
      scores = self.linear(noise_level)
      # Return the score corresponding to the expert index
      return scores[expert_index]

# Define a class that represents a diffusion model that takes a data sample and outputs a sequence of noise levels and denoised samples
class DiffusionModel:

   # Initialize the diffusion model with a set of experts and a score function
   def __init__(self, experts, score_function):
      self.experts = experts # The set of experts with different architectures
      self.score_function = score_function # The score function that selects the best expert for each time-step noise

   # Define a function that takes a data sample and outputs a sequence of noise levels and denoised samples
   def __call__(self, data_sample):
      # Initialize an empty list for the noise levels
      noise_levels = []
      # Initialize an empty list for the denoised samples
      denoised_samples = []
      # Loop over the time steps from 0 to num_steps - 1
      for t in range(num_steps):
         # Compute the noise level for the current time step using the get_noise_level function
         noise_level = get_noise_level(t)
         # Add the noise level to the noise_levels list
         noise_levels.append(noise_level)
         # Add Gaussian noise to the data sample using the add_noise function
         noisy_sample = add_noise(data_sample, noise_level)
         # Compute the scores for each expert using the score_function
         scores = [score_function(noise_level, i) for i in range(num_experts)]
         # Normalize the scores using a softmax function
         probabilities = softmax(scores)
         # Sample an expert index from the probabilities using a categorical distribution
         expert_index = sample_categorical(probabilities)
         # Get the selected expert from the experts list
         expert = experts[expert_index]
         # Compute the prediction of the selected expert for the noisy sample
         prediction = expert(noisy_sample)
         # Compute the denoised sample by subtracting the prediction from the noisy sample
         denoised_sample = noisy_sample - prediction
         # Add the denoised sample to the denoised_samples list
         denoised_samples.append(denoised_sample)
      # Return the sequence of noise levels and denoised samples
      return noise_levels, denoised_samples

# Define a function that computes the variational lower bound on the log-likelihood for a given prediction and data sample
def variational_loss(prediction, data_sample):
   # Compute the mean squared error between the prediction and data sample
   mse = reduce_mean((prediction - data_sample) ** 2)
   # Compute the log-likelihood lower bound using the formula from https://arxiv.org/abs/2006.11239
   log_likelihood_lower_bound = -0.5 * (log(2 * pi) + beta_min + mse / beta_min)
   # Return the negative log-likelihood lower bound as the loss
   return -log_likelihood_lower_bound

# Define an optimizer that updates the parameters of the experts and the score function using gradient descent
optimizer = GradientDescentOptimizer(learning_rate)

# Define a set of experts with different architectures using self-attention and convolution functions
experts = [Expert("self-attention", [self_attention] * num_layers), Expert("convolution", [convolution] * num_layers), ...]

# Define a score function using the ScoreFunction class
score_function = ScoreFunction()

# Define a diffusion model using the DiffusionModel class with the experts and score function as inputs
diffusion_model = DiffusionModel(experts, score_function)

# Loop over the training data
for data_sample in training_data:

  # Get the sequence of noise levels and denoised samples from the diffusion model by calling it with data_sample as input