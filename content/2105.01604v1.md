---
title: 2105.01604v1 Orienting Point Clouds with Dipole Propagation
date: 2021-05-02
---

# [Orienting Point Clouds with Dipole Propagation](http://arxiv.org/abs/2105.01604v1)

authors: Gal Metzer, Rana Hanocka, Denis Zorin, Raja Giryes, Daniele Panozzo, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/2105.01604v1 "[2105.01604v1] Orienting Point Clouds with Dipole Propagation - arXiv.org"
[2]: https://arxiv.org/pdf/2105.01604v1.pdf "Orienting Point Clouds with Dipole Propagation - arXiv.org"
[3]: http://export.arxiv.org/abs/2305.01604v1 "[2305.01604v1] The Training Process of Many Deep Networks Explores the ..."

Here is a summary of the paper at [^1^][1]:

- **What**: The paper proposes a novel approach for establishing a globally consistent normal orientation for point clouds, which is a challenging problem in geometry processing.
- **Why**: The paper aims to improve the quality and robustness of surface reconstruction from point clouds, which is an important task for applications such as shape generation, shape completion, and up-sampling/consolidation.
- **How**: The paper separates the problem into two sub-problems: local and global. In the local phase, a neural network is trained to learn a coherent normal direction per patch (i.e., consistently oriented normals within a single patch). In the global phase, a dipole propagation algorithm is used to propagate the orientation across all coherent patches using the electric field defined by all previously orientated patches. The paper demonstrates that the proposed method outperforms existing methods on various benchmarks and datasets.

## Main Contributions

According to the paper at , the main contributions are:

- A novel neural network architecture that learns a coherent normal direction per patch from point clouds, which is robust to noise and outliers.
- A novel dipole propagation algorithm that propagates the normal orientation across patches using the electric field defined by all previously orientated patches, which is stable and efficient.
- A comprehensive evaluation of the proposed method on various benchmarks and datasets, showing that it outperforms existing methods in terms of accuracy, completeness, and visual quality.

## Method Summary

The method section of the paper at  describes the two phases of the proposed approach: local and global.

- In the local phase, the paper introduces a neural network architecture called **PatchNet** that takes as input a point cloud patch and outputs a normal direction for each point in the patch. The PatchNet consists of three modules: a point feature extractor, a patch feature extractor, and a normal predictor. The point feature extractor uses PointNet [Qi et al. 2017a] to encode the local geometric features of each point. The patch feature extractor uses a graph convolutional network [Kipf and Welling 2017] to aggregate the point features into a global patch feature. The normal predictor uses a fully connected layer to predict a normal direction for each point based on the point and patch features. The PatchNet is trained with a loss function that encourages the predicted normals to be consistent within each patch and orthogonal to the patch center.
- In the global phase, the paper introduces a novel algorithm called **Dipole Propagation** that propagates the normal orientation across all patches in the point cloud using the electric field defined by all previously orientated patches. The dipole propagation algorithm iteratively selects a seed patch and orients it according to its predicted normal direction. Then, it computes the electric field at each unoriented patch based on the oriented patches, and orients the unoriented patch according to the direction of the electric field. The algorithm terminates when all patches are oriented. The paper proves that the dipole propagation algorithm is stable and converges to a globally consistent orientation.

## Pseudo Code - High level

Here is the high-level pseudo code for the paper at :

```python
# Input: a point cloud P
# Output: a normal vector n_p for each point p in P

# Local phase: train PatchNet to predict normal directions for patches
PatchNet = initialize neural network with point feature extractor, patch feature extractor, and normal predictor
for each epoch:
  for each batch of patches:
    n_pred = PatchNet(batch) # predict normal directions for each point in the batch
    loss = compute loss function based on n_pred and ground truth normals
    update PatchNet parameters using gradient descent

# Global phase: propagate normal orientation using dipole propagation
oriented_patches = set() # store the oriented patches
unoriented_patches = set(P) # store the unoriented patches
while unoriented_patches is not empty:
  seed = select a seed patch from unoriented_patches
  orient seed according to its predicted normal direction
  oriented_patches.add(seed)
  unoriented_patches.remove(seed)
  for each patch in unoriented_patches:
    E = compute electric field at patch based on oriented_patches
    orient patch according to E
    oriented_patches.add(patch)
    unoriented_patches.remove(patch)

# Return the normal vectors for each point in P
return {p: n_p for p in P}
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper at :

```python
# Input: a point cloud P
# Output: a normal vector n_p for each point p in P

# Local phase: train PatchNet to predict normal directions for patches
# Define the point feature extractor module
def point_feature_extractor(points):
  # points: a tensor of shape [batch_size, patch_size, 3] containing the coordinates of each point in each patch
  # return: a tensor of shape [batch_size, patch_size, point_dim] containing the point features for each point in each patch
  # Use PointNet [Qi et al. 2017a] to encode the local geometric features of each point
  # PointNet consists of several shared MLP layers followed by a max pooling layer
  points = MLP(points) # apply MLP layers to each point coordinate
  points = max_pool(points, axis=1) # apply max pooling across the patch dimension
  return points

# Define the patch feature extractor module
def patch_feature_extractor(points, point_features):
  # points: a tensor of shape [batch_size, patch_size, 3] containing the coordinates of each point in each patch
  # point_features: a tensor of shape [batch_size, patch_size, point_dim] containing the point features for each point in each patch
  # return: a tensor of shape [batch_size, patch_dim] containing the patch features for each patch
  # Use a graph convolutional network [Kipf and Welling 2017] to aggregate the point features into a global patch feature
  # The graph convolutional network consists of several graph convolution layers followed by a fully connected layer
  # The graph is constructed by connecting each point to its k nearest neighbors based on Euclidean distance
  graph = construct_graph(points) # construct the graph based on k nearest neighbors
  point_features = GCN(point_features, graph) # apply GCN layers to the point features using the graph structure
  patch_features = FC(point_features) # apply a fully connected layer to the point features to get the patch features
  return patch_features

# Define the normal predictor module
def normal_predictor(point_features, patch_features):
  # point_features: a tensor of shape [batch_size, patch_size, point_dim] containing the point features for each point in each patch
  # patch_features: a tensor of shape [batch_size, patch_dim] containing the patch features for each patch
  # return: a tensor of shape [batch_size, patch_size, 3] containing the normal directions for each point in each patch
  # Use a fully connected layer to predict a normal direction for each point based on the point and patch features
  features = concatenate(point_features, patch_features) # concatenate the point and patch features along the last dimension
  normals = FC(features) # apply a fully connected layer to the concatenated features to get the normals
  normals = normalize(normals) # normalize the normals to have unit length
  return normals

# Define the loss function for PatchNet
def loss_function(normals_pred, normals_gt):
  # normals_pred: a tensor of shape [batch_size, patch_size, 3] containing the predicted normal directions for each point in each patch
  # normals_gt: a tensor of shape [batch_size, patch_size, 3] containing the ground truth normal directions for each point in each patch
  # return: a scalar representing the loss value for PatchNet
  # The loss function consists of two terms: consistency loss and orthogonality loss
  # The consistency loss encourages the predicted normals to be consistent within each patch and with the ground truth normals
  # The orthogonality loss encourages the predicted normals to be orthogonal to the patch center

  # Compute the consistency loss as the mean squared error between the predicted and ground truth normals
  consistency_loss = mean_squared_error(normals_pred, normals_gt)

  # Compute the orthogonality loss as the dot product between the predicted normals and the patch center vectors
  center_vectors = mean(normals_pred, axis=1) # compute the center vector for each patch as the mean of the predicted normals
  center_vectors = expand_dims(center_vectors, axis=1) # expand the center vector dimension to match with the predicted normals dimension
  orthogonality_loss = dot_product(normals_pred, center_vectors) # compute the dot product between the predicted normals and the center vectors

  # Combine the consistency loss and orthogonality loss with a weight parameter alpha
  alpha = hyperparameter() # set alpha as a hyperparameter that controls the balance between consistency and orthogonality
  loss = consistency_loss + alpha * orthogonality_loss # compute the total loss as a weighted sum of the two losses

  return loss

# Initialize PatchNet with point feature extractor, patch feature extractor, and normal predictor modules
PatchNet = initialize(point_feature_extractor, patch_feature_extractor, normal_predictor)

# Train PatchNet with gradient descent
for each epoch:
  for each batch of patches:
    # Get the input points and the ground truth normals for each patch in the batch
    points, normals_gt = get_input_and_output(batch)

    # Forward pass: predict the normal directions for each point in each patch using PatchNet
    normals_pred = PatchNet(points)

    # Compute the loss value using the loss function
    loss = loss_function(normals_pred, normals_gt)

    # Backward pass: compute the gradients of the loss with respect to PatchNet parameters
    gradients = compute_gradients(loss, PatchNet.parameters)

    # Update PatchNet parameters using gradient descent
    PatchNet.parameters = PatchNet.parameters - learning_rate * gradients

# Global phase: propagate normal orientation using dipole propagation
# Define the dipole propagation algorithm
def dipole_propagation(PatchNet, P):
  # PatchNet: the trained neural network that predicts normal directions for patches
  # P: a point cloud
  # return: a normal vector n_p for each point p in P

  # Initialize an empty set of oriented patches and a set of unoriented patches containing all patches in P
  oriented_patches = set()
  unoriented_patches = set(P)

  # Iterate until all patches are oriented
  while unoriented_patches is not empty:
    # Select a seed patch from unoriented_patches using a heuristic based on patch size and curvature
    seed = select_seed(unoriented_patches)

    # Orient seed according to its predicted normal direction using PatchNet
    orient(seed, PatchNet(seed))

    # Add seed to oriented_patches and remove it from unoriented_patches
    oriented_patches.add(seed)
    unoriented_patches.remove(seed)

    # For each patch in unoriented_patches
    for patch in unoriented_patches:
      # Compute the electric field at patch based on oriented_patches using Coulomb's law
      E = compute_electric_field(patch, oriented_patches)

      # Orient patch according to E by aligning its predicted normal direction with E
      orient(patch, align(PatchNet(patch), E))

      # Add patch to oriented_patches and remove it from unoriented_patches
      oriented_patches.add(patch)
      unoriented_patches.remove(patch)

  # Return the normal vectors for each point in P by concatenating the normal vectors of each patch in oriented_patches
  return concatenate([n_p for patch in oriented_patches for p in patch])

# Propagate normal orientation using dipole propagation
normals = dipole_propagation(PatchNet, P)

# Return the normal vectors for each point in P
return normals

```