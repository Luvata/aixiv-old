---
title: 2002.05867v2 Transformers as Soft Reasoners over Language
date: 2020-02-06
---

# [Transformers as Soft Reasoners over Language](http://arxiv.org/abs/2002.05867v2)

authors: Peter Clark, Oyvind Tafjord, Kyle Richardson


## What, Why and How

[1]: https://arxiv.org/abs/2002.05867v2 "[2002.05867v2] Transformers as Soft Reasoners over Language - arXiv.org"
[2]: https://arxiv.org/pdf/2002.05867v2 "Transformers as Soft Reasoners over Language - arXiv.org"
[3]: http://export.arxiv.org/abs/2202.05867v2 "[2202.05867v2] Photodissociation and X-Ray Dominated Regions"

Here is a summary of the paper:

- **What**: The paper investigates whether transformers can learn to reason over natural language sentences that express facts and rules, without using a formal representation.
- **Why**: The paper aims to achieve the goal of providing a system with explicit, general knowledge and having the system reason over that knowledge, which has been a long-standing challenge in AI.
- **How**: The paper trains transformers, called RuleTakers, to reason over synthetically generated data, and evaluates them on their accuracy, generalization, and transferability. The paper also compares RuleTakers with other baselines and analyzes their behavior.

## Main Contributions

[1]: https://arxiv.org/abs/2002.05867v2 "[2002.05867v2] Transformers as Soft Reasoners over Language - arXiv.org"
[2]: https://arxiv.org/pdf/2002.05867v2 "Transformers as Soft Reasoners over Language - arXiv.org"
[3]: http://export.arxiv.org/abs/2202.05867v2 "[2202.05867v2] Photodissociation and X-Ray Dominated Regions"

According to the paper[^1^][1], the main contributions are:

- Introducing RuleTakers, transformers that can reason over natural language sentences that express facts and rules.
- Providing the first empirical demonstration that soft reasoning over language is learnable, accurate, and generalizable.
- Showing that RuleTakers transfer well to hand-authored and paraphrased rulebases.
- Suggesting a new role for transformers as soft theorem provers over explicit theories in language.
- Opening new possibilities for explainability, correctability, and counterfactual reasoning in question-answering.

## Method Summary

[1]: https://arxiv.org/abs/2002.05867v2 "[2002.05867v2] Transformers as Soft Reasoners over Language - arXiv.org"
[2]: https://arxiv.org/pdf/2002.05867v2 "Transformers as Soft Reasoners over Language - arXiv.org"
[3]: http://export.arxiv.org/abs/2202.05867v2 "[2202.05867v2] Photodissociation and X-Ray Dominated Regions"

Here is a summary of the method section of the paper:

- The paper describes how to generate synthetic data for training and testing RuleTakers, consisting of natural language sentences that encode facts and rules, and questions that require reasoning over them.
- The paper explains how to train RuleTakers using a transformer encoder-decoder architecture, with a special token to indicate the end of the rulebase and a beam search decoder to generate answers.
- The paper defines four types of reasoning tasks: single-step, multi-step, negation, and counterfactual, and evaluates RuleTakers on their performance on each task using accuracy and generalization metrics.
- The paper compares RuleTakers with other baselines, such as GPT-2 and BERT, and analyzes their strengths and weaknesses using attention maps and error analysis.
- The paper also tests RuleTakers on two hand-authored rulebases from the Winograd Schema Challenge and the bAbI dataset, and on rulebases paraphrased into more natural language.

## Pseudo Code - High level

Here is a possible high-level pseudo code for this paper:

```python
# Define a transformer encoder-decoder model
model = TransformerEncoderDecoder()

# Generate synthetic data for training and testing
train_data, test_data = generate_synthetic_data()

# Train the model on the train data
for batch in train_data:
  # Get the rulebase, question, and answer from the batch
  rulebase = batch["rulebase"]
  question = batch["question"]
  answer = batch["answer"]
  # Concatenate the rulebase and question with a special token
  input = rulebase + "[END]" + question
  # Encode the input and decode the answer
  output = model.encode_decode(input)
  # Compute the loss and update the model parameters
  loss = compute_loss(output, answer)
  model.update(loss)

# Evaluate the model on the test data
for batch in test_data:
  # Get the rulebase, question, and answer from the batch
  rulebase = batch["rulebase"]
  question = batch["question"]
  answer = batch["answer"]
  # Concatenate the rulebase and question with a special token
  input = rulebase + "[END]" + question
  # Encode the input and decode the answer using beam search
  output = model.encode_decode_beam_search(input)
  # Compute the accuracy and generalization metrics
  accuracy = compute_accuracy(output, answer)
  generalization = compute_generalization(output, answer)
```

## Pseudo Code - Detail

Here is a possible detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import transformers
import nltk
import random

# Define a transformer encoder-decoder model
model = transformers.EncoderDecoderModel.from_encoder_decoder_pretrained("bert-base-uncased", "bert-base-uncased")

# Define a tokenizer
tokenizer = transformers.BertTokenizer.from_pretrained("bert-base-uncased")

# Define a special token for the end of the rulebase
end_token = "[END]"

# Define a beam size for decoding
beam_size = 5

# Define a function to generate synthetic data for training and testing
def generate_synthetic_data():
  # Define some constants for the data generation
  num_train = 10000 # Number of training examples
  num_test = 1000 # Number of testing examples
  max_rules = 10 # Maximum number of rules per rulebase
  max_facts = 10 # Maximum number of facts per rulebase
  max_steps = 5 # Maximum number of reasoning steps per question
  vocab_size = 1000 # Size of the vocabulary
  vocab = ["w" + str(i) for i in range(vocab_size)] # Vocabulary list

  # Define some helper functions for generating sentences
  def generate_fact():
    # Generate a fact of the form "w1 is w2"
    w1 = random.choice(vocab)
    w2 = random.choice(vocab)
    return w1 + " is " + w2

  def generate_rule():
    # Generate a rule of the form "if w1 is w2 then w3 is w4"
    w1 = random.choice(vocab)
    w2 = random.choice(vocab)
    w3 = random.choice(vocab)
    w4 = random.choice(vocab)
    return "if " + w1 + " is " + w2 + " then " + w3 + " is " + w4

  def generate_question():
    # Generate a question of the form "is w1 w2?"
    w1 = random.choice(vocab)
    w2 = random.choice(vocab)
    return "is " + w1 + " " + w2 + "?"

  def generate_answer(rulebase, question):
    # Generate an answer to the question using the rulebase and a simple backward chaining algorithm
    # The answer is either "yes", "no", or "unknown"
    # Initialize a stack with the question
    stack = [question]
    # Initialize a set of visited facts
    visited = set()
    # Loop until the stack is empty or an answer is found
    while stack:
      # Pop the top fact from the stack
      fact = stack.pop()
      # Check if the fact is in the rulebase
      if fact in rulebase:
        # Return yes as the answer
        return "yes"
      # Check if the fact has been visited before
      if fact in visited:
        # Skip this fact
        continue
      # Mark the fact as visited
      visited.add(fact)
      # Split the fact into words
      words = fact.split()
      # Loop through the rules in the rulebase
      for rule in rulebase:
        # Split the rule into words
        rule_words = rule.split()
        # Check if the rule has the form "if w1 is w2 then w3 is w4"
        if len(rule_words) == 7 and rule_words[0] == "if" and rule_words[2] == "is" and rule_words[4] == "then" and rule_words[6] == "is":
          # Check if the fact matches the consequent of the rule, i.e. w3 is w4
          if words[0] == rule_words[5] and words[2] == rule_words[7]:
            # Push the antecedent of the rule, i.e. w1 is w2, to the stack
            stack.append(rule_words[1] + " is " + rule_words[3])
    # Return unknown as the answer if no answer is found
    return "unknown"

  # Define a function to generate a rulebase with facts and rules
  def generate_rulebase():
    # Initialize an empty list for the rulebase
    rulebase = []
    # Randomly choose the number of facts and rules in the rulebase
    num_facts = random.randint(1, max_facts)
    num_rules = random.randint(1, max_rules)
    # Generate facts and add them to the rulebase
    for _ in range(num_facts):
      fact = generate_fact()
      rulebase.append(fact)
    # Generate rules and add them to the rulebase
    for _ in range(num_rules):
      rule = generate_rule()
      rulebase.append(rule)
    # Return the rulebase as a list of sentences
    return rulebase

  # Define a function to generate a question and an answer using a rulebase
  def generate_question_answer(rulebase):
    # Generate a question
    question = generate_question()
    # Generate an answer using the rulebase
    answer = generate_answer(rulebase, question)
    # Return the question and answer as strings
    return question, answer

  # Define a function to generate an example with a rulebase, a question, and an answer
  def generate_example():
    # Generate a rulebase
    rulebase = generate_rulebase()
    # Generate a question and an answer using the rulebase
    question, answer = generate_question_answer(rulebase)
    # Return the example as a dictionary
    return {"rulebase": rulebase, "question": question, "answer": answer}

  # Initialize empty lists for the train data and test data
  train_data = []
  test_data = []
  # Generate train examples and add them to the train data
  for _ in range(num_train):
    example = generate_example()
    train_data.append(example)
  # Generate test examples and add them to the test data
  for _ in range(num_test):
    example = generate_example()
    test_data.append(example)
  # Return the train data and test data as lists of dictionaries
  return train_data, test_data

# Generate synthetic data for training and testing
train_data, test_data = generate_synthetic_data()

# Define a function to encode the input and decode the output using the model and the tokenizer
def encode_decode(input):
  # Encode the input using the tokenizer
  input_ids = tokenizer.encode(input, return_tensors="pt")
  # Decode the output using the model and the tokenizer
  output_ids = model.generate(input_ids)
  output = tokenizer.decode(output_ids[0], skip_special_tokens=True)
  # Return the output as a string
  return output

# Define a function to encode the input and decode the output using beam search
def encode_decode_beam_search(input):
  # Encode the input using the tokenizer
  input_ids = tokenizer.encode(input, return_tensors="pt")
  # Decode the output using beam search with the model and the tokenizer
  output_ids = model.generate(input_ids, num_beams=beam_size, early_stopping=True)
  output = tokenizer.decode(output_ids[0], skip_special_tokens=True)
  # Return the output as a string
  return output

# Define a function to compute the loss given the output and the answer
def compute_loss(output, answer):
  # Convert the output and the answer to lower case
  output = output.lower()
  answer = answer.lower()
  # Compute the cross entropy loss between the output and the answer using the tokenizer and torch.nn.CrossEntropyLoss()
  output_ids = torch.tensor(tokenizer.encode(output)).unsqueeze(0)
  answer_ids = torch.tensor(tokenizer.encode(answer)).unsqueeze(0)
  loss_fn = torch.nn.CrossEntropyLoss()
  loss = loss_fn(output_ids, answer_ids)
  # Return the loss as a scalar tensor
  return loss

# Define a function to compute the accuracy given the output and the answer
def compute_accuracy(output, answer):
  # Convert the output and the answer to lower case
  output = output.lower()
  answer = answer.lower()
  # Compute the accuracy as one if the output matches the answer exactly, or zero otherwise
  accuracy = int(output == answer)
  # Return the accuracy as an integer
  return accuracy

# Define a function to compute the generalization given the output, the answer, and the number of reasoning steps required for the question
def compute_generalization(output, answer, steps):
  # Convert the output and the answer to lower case
  output = output.lower()
  answer = answer.lower()
  # Compute the generalization as one if the output matches the answer exactly and steps is greater than max_steps, or zero otherwise
  generalization = int(output == answer and steps > max_steps)
  # Return the generalization as an integer
  return generalization

# Train the model on the train data
for batch in train_data:
  # Get the rulebase, question, and answer from the batch
  rulebase = batch["rulebase"]
  question = batch["question"]
  answer = batch["answer"]
  
```python

# Concatenate all sentences in rulebase with end_token 
rulebase_str= end_token.join(rulebase)

# Concatenate rulebase_str with end_token with question 
input=rulebase_str + end_token + question

# Encode input and decode it into an output 
output=encode_decode(input)

# Compute loss