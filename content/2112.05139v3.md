---
title: 2112.05139v3 CLIP-NeRF  Text-and-Image Driven Manipulation of Neural Radiance Fields
date: 2021-12-06
---

# [CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields](http://arxiv.org/abs/2112.05139v3)

authors: Can Wang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao


## What, Why and How

[1]: https://arxiv.org/abs/2112.05139v3 "[2112.05139v3] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural ..."
[2]: https://arxiv.org/pdf/2112.05139v3 "arXiv:2112.05139v3 [cs.CV] 2 Mar 2022"
[3]: https://arxiv.org/pdf/2112.05139v3.pdf "arXiv.org e-Print archive"

Here is a summary of the paper:

```
What: The paper presents CLIP-NeRF, a multi-modal 3D object manipulation method for neural radiance fields (NeRF) that allows editing NeRF using either a short text prompt or an exemplar image.

Why: The paper aims to overcome the challenges of editing NeRF, such as the lack of intuitive tools, the multi-view dependency, and the difficulty of bridging the gap between natural language or images and the implicit representation of NeRF.

How: The paper introduces a disentangled conditional NeRF architecture that allows individual control over both shape and appearance. It also designs two code mappers that take a CLIP embedding as input and update the latent codes to reflect the targeted editing. It also proposes an inverse optimization method that projects an input image to the latent codes for manipulation.
```

## Main Contributions

[1]: https://arxiv.org/pdf/2112.05139v3 "arXiv:2112.05139v3 [cs.CV] 2 Mar 2022"
[2]: https://arxiv.org/abs/2112.05139 "[2112.05139] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural ..."
[3]: http://export.arxiv.org/abs/2112.05009v3 "[2112.05009v3] Timelike and spacelike kernel functions for the hadronic ..."

Some of the contributions of this paper are:

- A disentangled conditional NeRF architecture that allows individual control over both shape and appearance of NeRF.
- Two code mappers that take a CLIP embedding as input and update the latent codes to reflect the targeted editing.
- A CLIP-based matching loss to ensure the manipulation accuracy.
- An inverse optimization method that projects an input image to the latent codes for manipulation.
- An intuitive interface for interactive editing.

## Method Summary

[1]: https://arxiv.org/pdf/2112.05139v3 "arXiv:2112.05139v3 [cs.CV] 2 Mar 2022"
[2]: https://arxiv.org/abs/2112.05139 "[2112.05139] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural ..."
[3]: https://arxiv.org/abs/2112.07746 "[2112.07746] CEM-GD: Cross-Entropy Method with Gradient ... - arXiv.org"

Here is a summary of the method section of the paper:

```
The method section of the paper consists of four subsections: 3.1 Disentangled Conditional NeRF, 3.2 Code Mappers, 3.3 Inverse Optimization, and 3.4 Implementation Details.

- In 3.1, the paper introduces a disentangled conditional NeRF architecture that allows individual control over both shape and appearance of NeRF. It also describes how to perform shape conditioning via applying a learned deformation field to the positional encoding and deferring color conditioning to the volumetric rendering stage.
- In 3.2, the paper designs two code mappers that take a CLIP embedding as input and update the latent codes to reflect the targeted editing. It also explains how to train the mappers with a CLIP-based matching loss to ensure the manipulation accuracy.
- In 3.3, the paper proposes an inverse optimization method that accurately projects an input image to the latent codes for manipulation. It also discusses how to handle occlusion and missing regions in the input image.
- In 3.4, the paper provides some implementation details, such as the network architectures, the training settings, and the evaluation metrics.
```

## Pseudo Code - High level

[1]: https://arxiv.org/pdf/2112.05139v3 "arXiv:2112.05139v3 [cs.CV] 2 Mar 2022"
[2]: https://arxiv.org/abs/2112.05139 "[2112.05139] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural ..."
[3]: https://arxiv.org/pdf/2112.03178v1.pdf "arXiv.org e-Print archive"

Here is a high-level pseudo code for the paper:

```
# Input: a text prompt or an exemplar image
# Output: a manipulated NeRF

# Step 1: Encode the input into a CLIP embedding
clip_embedding = CLIP.encode(input)

# Step 2: Initialize a disentangled conditional NeRF with shape and appearance codes
shape_code = random_init()
appearance_code = random_init()
nerf = DisentangledConditionalNeRF(shape_code, appearance_code)

# Step 3: Update the shape and appearance codes using the code mappers
shape_code = ShapeCodeMapper(clip_embedding, shape_code)
appearance_code = AppearanceCodeMapper(clip_embedding, appearance_code)
nerf.update(shape_code, appearance_code)

# Step 4: Render the manipulated NeRF from a novel view
image = nerf.render(view)

# Step 5: Optionally, project an input image to the latent codes for manipulation
if input is image:
  shape_code, appearance_code = InverseOptimization(input, nerf)
  nerf.update(shape_code, appearance_code)
  image = nerf.render(view)

return image
```

## Pseudo Code - Detail

[1]: https://arxiv.org/pdf/2112.05139v3 "arXiv:2112.05139v3 [cs.CV] 2 Mar 2022"
[2]: https://arxiv.org/abs/2112.05139 "[2112.05139] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural ..."
[3]: https://arxiv.org/abs/1701.05139v3 "[1701.05139v3] Distributors and the comprehensive factorization system ..."

Here is a detailed pseudo code to implement the paper:

```
# Input: a text prompt or an exemplar image
# Output: a manipulated NeRF

# Step 1: Encode the input into a CLIP embedding
clip_embedding = CLIP.encode(input)

# Step 2: Initialize a disentangled conditional NeRF with shape and appearance codes
shape_code = random_init()
appearance_code = random_init()
nerf = DisentangledConditionalNeRF(shape_code, appearance_code)

# Step 3: Update the shape and appearance codes using the code mappers
# Define the shape code mapper network
shape_code_mapper = MLP(clip_embedding_dim, shape_code_dim)
# Define the appearance code mapper network
appearance_code_mapper = MLP(clip_embedding_dim, appearance_code_dim)
# Define the CLIP-based matching loss function
def clip_matching_loss(nerf, clip_embedding, view):
  # Render the nerf from the given view
  image = nerf.render(view)
  # Encode the image into a CLIP embedding
  image_embedding = CLIP.encode(image)
  # Compute the cosine similarity between the clip embeddings
  similarity = cosine_similarity(clip_embedding, image_embedding)
  # Return the negative similarity as the loss
  return -similarity
# Define the optimizer for the code mappers
optimizer = Adam(shape_code_mapper.parameters + appearance_code_mapper.parameters)
# Define the number of training iterations
num_iters = 1000
# Train the code mappers using gradient descent
for i in range(num_iters):
  # Sample a random view for rendering
  view = sample_view()
  # Update the shape and appearance codes using the code mappers
  shape_code = shape_code_mapper(clip_embedding, shape_code)
  appearance_code = appearance_code_mapper(clip_embedding, appearance_code)
  nerf.update(shape_code, appearance_code)
  # Compute the CLIP-based matching loss
  loss = clip_matching_loss(nerf, clip_embedding, view)
  # Backpropagate the loss and update the parameters
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()

# Step 4: Render the manipulated NeRF from a novel view
image = nerf.render(view)

# Step 5: Optionally, project an input image to the latent codes for manipulation
if input is image:
  # Define an occlusion mask for the input image
  mask = get_occlusion_mask(input)
  # Define an inverse optimization loss function
  def inverse_optimization_loss(nerf, input, mask, view):
    # Render the nerf from the given view
    image = nerf.render(view)
    # Compute the masked L2 distance between the input and the rendered image
    distance = mask * (input - image) ** 2
    # Return the sum of the distance as the loss
    return distance.sum()
  # Define an optimizer for the latent codes
  optimizer = Adam(shape_code.parameters + appearance_code.parameters)
  # Define the number of optimization iterations
  num_iters = 1000
  # Optimize the latent codes using gradient descent
  for i in range(num_iters):
    # Compute the inverse optimization loss
    loss = inverse_optimization_loss(nerf, input, mask, view)
    # Backpropagate the loss and update the latent codes
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    # Update the nerf with the optimized latent codes
    nerf.update(shape_code, appearance_code)
  # Render the manipulated NeRF from a novel view
  image = nerf.render(view)

return image

```