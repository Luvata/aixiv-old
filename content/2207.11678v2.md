---
title: 2207.11678v2 Quad-Net  Quad-domain Network for CT Metal Artifact Reduction
date: 2022-07-12
---

# [Quad-Net: Quad-domain Network for CT Metal Artifact Reduction](http://arxiv.org/abs/2207.11678v2)

authors: Zilong Li, Qi Gao, Yaping Wu, Chuang Niu, Junping Zhang, Meiyun Wang, Ge Wang, Hongming Shan


## What, Why and How

[1]: https://arxiv.org/abs/2207.11678 "[2207.11678] FD-MAR: Fourier Dual-domain Network for CT ... - arXiv.org"
[2]: https://lib-arxiv-013.serverfarm.cornell.edu/abs/2207.11678v2 "[2207.11678v2] Quad-Net: Quad-domain Network for CT Metal Artifact ..."
[3]: https://arxiv.org/pdf/2207.11678.pdf "arXiv.org"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a Fourier dual-domain network for CT metal artifact reduction, called FD-MAR.
- **Why**: The paper aims to address the problem of streak-like artifacts in CT images caused by high-density objects such as metal implants and dental fillings, which can affect the diagnosis and treatment of patients. The paper also aims to overcome the limitations of existing methods, such as poor performance in the sinogram domain, secondary artifacts in the image domain, and the requirement of precise metal masks.
- **How**: The paper explores fast Fourier convolution for MAR in both sinogram and image domains, and designs a network that consists of two sub-networks: a Fourier sinogram restoration network and a Fourier refinement network. The former can fill in the metal-corrupted region in the sinogram by leveraging global context information, while the latter can refine the reconstructed images by exploring image-wide context information. The paper optimizes FD-MAR with a composite loss function that combines L1 loss, perceptual loss, and structural similarity loss. The paper evaluates FD-MAR on various datasets and compares it with state-of-the-art methods, showing its superiority in terms of quantitative metrics and visual quality. The paper also demonstrates that FD-MAR does not require precise metal masks, which is beneficial for clinical applications.

## Main Contributions

[1]: https://arxiv.org/abs/2207.11678 "[2207.11678] FD-MAR: Fourier Dual-domain Network for CT ... - arXiv.org"
[2]: https://lib-arxiv-013.serverfarm.cornell.edu/abs/2207.11678v2 "[2207.11678v2] Quad-Net: Quad-domain Network for CT Metal Artifact ..."
[3]: https://arxiv.org/pdf/2207.11678.pdf "arXiv.org"

According to the paper[^1^][1], the main contributions are:

- **The first Fourier dual-domain network for MAR**: The paper proposes FD-MAR, a novel network that exploits fast Fourier convolution for MAR in both sinogram and image domains, and achieves state-of-the-art performance on various datasets.
- **The first Fourier sinogram restoration network**: The paper designs a sub-network that can restore the metal-corrupted region in the sinogram by using Fourier convolution layers, which can capture sinogram-wide context information and are robust to the metal trace.
- **The first Fourier refinement network**: The paper develops a sub-network that can refine the reconstructed images by using Fourier convolution layers, which can explore image-wide context information and reduce secondary artifacts.
- **The first MAR method that does not require precise metal masks**: The paper demonstrates that FD-MAR can work well without precise metal masks, which are usually difficult to obtain in clinical practice. This makes FD-MAR more practical and applicable for real-world scenarios.

## Method Summary

[1]: https://arxiv.org/abs/2207.11678 "[2207.11678] FD-MAR: Fourier Dual-domain Network for CT ... - arXiv.org"
[2]: https://lib-arxiv-013.serverfarm.cornell.edu/abs/2207.11678v2 "[2207.11678v2] Quad-Net: Quad-domain Network for CT Metal Artifact ..."
[3]: https://arxiv.org/pdf/2207.11678.pdf "arXiv.org"

Here is a summary of the method section of the paper[^1^][1]:

- The paper introduces the problem formulation of MAR and the basic idea of Fourier convolution, which can capture global context information by using complex-valued kernels and fast Fourier transform (FFT).
- The paper presents the architecture of FD-MAR, which consists of two sub-networks: a Fourier sinogram restoration network (FSRN) and a Fourier refinement network (FRN). FSRN takes the corrupted sinogram and the metal mask as inputs, and outputs a restored sinogram. FRN takes the reconstructed image from FSRN and the metal mask as inputs, and outputs a refined image.
- The paper describes the details of FSRN, which has four components: a Fourier convolution layer, a Fourier attention module, a Fourier fusion module, and a Fourier reconstruction layer. The paper explains how each component works and how they are connected to form FSRN.
- The paper describes the details of FRN, which has three components: a Fourier convolution layer, a Fourier attention module, and a Fourier refinement layer. The paper explains how each component works and how they are connected to form FRN.
- The paper introduces the composite loss function for FD-MAR, which combines L1 loss, perceptual loss, and structural similarity loss. The paper explains the rationale and the benefits of each loss term.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the Fourier convolution layer
def FourierConv(x, W):
  # x: input feature map
  # W: complex-valued kernel
  # Apply FFT to x and W
  x_hat = fft(x)
  W_hat = fft(W)
  # Perform element-wise multiplication in the frequency domain
  y_hat = x_hat * W_hat
  # Apply inverse FFT to y_hat
  y = ifft(y_hat)
  # Return the output feature map
  return y

# Define the Fourier attention module
def FourierAttention(x):
  # x: input feature map
  # Apply a global average pooling layer to x
  s = gap(x)
  # Apply a fully connected layer to s
  z = fc(s)
  # Apply a softmax layer to z
  a = softmax(z)
  # Perform element-wise multiplication between x and a
  y = x * a
  # Return the output feature map
  return y

# Define the Fourier fusion module
def FourierFusion(x1, x2):
  # x1: input feature map from the corrupted region
  # x2: input feature map from the uncorrupted region
  # Concatenate x1 and x2 along the channel dimension
  x = concat(x1, x2)
  # Apply a Fourier convolution layer to x
  y = FourierConv(x, W)
  # Return the output feature map
  return y

# Define the Fourier reconstruction layer
def FourierRecon(x):
  # x: input feature map
  # Apply a Fourier convolution layer to x with a kernel size of 1x1
  y = FourierConv(x, W)
  # Return the output feature map
  return y

# Define the Fourier sinogram restoration network (FSRN)
def FSRN(s, m):
  # s: corrupted sinogram
  # m: metal mask
  # Apply a Fourier convolution layer to s and m separately
  s1 = FourierConv(s, W1)
  m1 = FourierConv(m, W2)
  # Apply a Fourier attention module to s1 and m1 separately
  s2 = FourierAttention(s1)
  m2 = FourierAttention(m1)
  # Divide s2 and m2 into corrupted and uncorrupted regions according to m2
  s2_c = s2 * m2
  s2_u = s2 * (1 - m2)
  m2_c = m2 * m2
  m2_u = m2 * (1 - m2)
  # Apply a Fourier fusion module to s2_c and s2_u separately
  s3_c = FourierFusion(s2_c, s2_u)
  s3_u = FourierFusion(s2_u, s2_c)
  # Concatenate s3_c and s3_u along the channel dimension
  s3 = concat(s3_c, s3_u)
  # Apply a Fourier reconstruction layer to s3
  r = FourierRecon(s3)
  # Return the restored sinogram r
  return r

# Define the Fourier refinement network (FRN)
def FRN(i, m):
   # i: reconstructed image from FSRN 
   # m: metal mask 
   # Apply a Fourier convolution layer to i and m separately 
   i1 = FourierConv(i, W1) 
   m1 = FourierConv(m, W2) 
   # Apply a Fourier attention module to i1 and m1 separately 
   i2 = FourierAttention(i1) 
   m2 = FourierAttention(m1) 
   # Concatenate i2 and m2 along the channel dimension 
   i3 = concat(i2, m2) 
   # Apply a Fourier reconstruction layer to i3 
   f = FourierRecon(i3) 
   # Return the refined image f 
   return f

# Define the composite loss function for FD-MAR 
def CompositeLoss(f, g): 
   # f: refined image from FRN 
   # g: ground truth image 
   # Compute the L1 loss between f and g 
   L_L1 = mean(abs(f - g)) 
   # Compute the perceptual loss between f and g using a pre-trained VGG network 
   L_perceptual = mean(abs(VGG(f) - VGG(g))) 
   # Compute the structural similarity loss between f and g using SSIM function 
   L_ssim = mean(1 - SSIM(f, g)) 
   # Combine the three loss terms with weights alpha, beta, and gamma 
   L = alpha * L_L1 + beta * L_perceptual + gamma * L_ssim 
   # Return the composite loss L 
   return L

# Define the FD-MAR network
def FD-MAR(s, m):
  # s: corrupted sinogram
  # m: metal mask
  # Apply FSRN to s and m to get the restored sinogram r
  r = FSRN(s, m)
  # Apply a filtered back-projection (FBP) algorithm to r to get the reconstructed image i
  i = FBP(r)
  # Apply FRN to i and m to get the refined image f
  f = FRN(i, m)
  # Return the refined image f
  return f
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
from skimage.metrics import structural_similarity as ssim

# Define the Fourier convolution layer class
class FourierConv(nn.Module):
  # Initialize the layer with input and output channels and kernel size
  def __init__(self, in_channels, out_channels, kernel_size):
    super(FourierConv, self).__init__()
    # Initialize the complex-valued kernel with random values
    self.W = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size, 2))
    # Initialize the padding size based on the kernel size
    self.padding = (kernel_size - 1) // 2
  
  # Define the forward function of the layer
  def forward(self, x):
    # x: input feature map of shape (batch_size, in_channels, height, width)
    # Apply FFT to x along the last two dimensions and add a dimension for complex values
    x_hat = torch.fft.fft2(x, dim=(-2, -1)).unsqueeze(-1)
    # Apply FFT to W along the last two dimensions
    W_hat = torch.fft.fft2(self.W, dim=(-2, -1))
    # Perform element-wise multiplication between x_hat and W_hat in the complex domain
    y_hat = torch.complex.mul(x_hat, W_hat)
    # Apply inverse FFT to y_hat along the last two dimensions and remove the dimension for complex values
    y = torch.fft.ifft2(y_hat.squeeze(-1), dim=(-2, -1))
    # Return the output feature map of shape (batch_size, out_channels, height, width)
    return y

# Define the Fourier attention module class
class FourierAttention(nn.Module):
  # Initialize the module with input channels and reduction ratio
  def __init__(self, in_channels, reduction=16):
    super(FourierAttention, self).__init__()
    # Initialize the fully connected layer with input and output dimensions
    self.fc = nn.Linear(in_channels, in_channels // reduction)
    # Initialize the softmax layer
    self.softmax = nn.Softmax(dim=1)
  
  # Define the forward function of the module
  def forward(self, x):
    # x: input feature map of shape (batch_size, in_channels, height, width)
    # Apply a global average pooling layer to x along the last two dimensions
    s = F.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)
    # Apply a fully connected layer to s with ReLU activation
    z = F.relu(self.fc(s))
    # Apply a softmax layer to z
    a = self.softmax(z).unsqueeze(-1).unsqueeze(-1)
    # Perform element-wise multiplication between x and a
    y = x * a
    # Return the output feature map of shape (batch_size, in_channels, height, width)
    return y

# Define the Fourier fusion module class
class FourierFusion(nn.Module):
  # Initialize the module with input channels and output channels
  def __init__(self, in_channels, out_channels):
    super(FourierFusion, self).__init__()
    # Initialize the Fourier convolution layer with input and output channels and kernel size of 3x3
    self.FourierConv = FourierConv(in_channels * 2, out_channels, 3)
  
  # Define the forward function of the module
  def forward(self, x1, x2):
    # x1: input feature map from the corrupted region of shape (batch_size, in_channels, height / 2 , width / 2)
    # x2: input feature map from the uncorrupted region of shape (batch_size, in_channels , height / 2 , width / 2)
    # Concatenate x1 and x2 along the channel dimension 
    x = torch.cat([x1,x2], dim=1)
    # Apply a Fourier convolution layer to x 
    y = self.FourierConv(x) 
    # Return the output feature map of shape (batch_size , out_channels , height / 2 , width / 2) 
    return y

# Define the Fourier reconstruction layer class 
class FourierRecon(nn.Module): 
   # Initialize the layer with input channels and output channels 
   def __init__(self , in_channels , out_channels): 
      super(FourierRecon , self).__init__() 
      # Initialize the Fourier convolution layer with input and output channels and kernel size of 1x1 
      self.FourierConv = FourierConv(in_channels , out_channels , 1) 
  
   # Define the forward function of the layer 
   def forward(self , x): 
      # x: input feature map of shape (batch_size , in_channels , height , width) 
      # Apply a Fourier convolution layer to x 
      y = self.FourierConv(x) 
      # Return the output feature map of shape (batch_size , out_channels , height , width) 
      return y

# Define the Fourier sinogram restoration network (FSRN) class
class FSRN(nn.Module):
  # Initialize the network with input channels, output channels, and reduction ratio
  def __init__(self, in_channels, out_channels, reduction=16):
    super(FSRN, self).__init__()
    # Initialize the Fourier convolution layer for the sinogram with input and output channels and kernel size of 3x3
    self.FourierConv_s = FourierConv(in_channels, out_channels, 3)
    # Initialize the Fourier convolution layer for the metal mask with input and output channels and kernel size of 3x3
    self.FourierConv_m = FourierConv(in_channels, out_channels, 3)
    # Initialize the Fourier attention module for the sinogram with input channels and reduction ratio
    self.FourierAttention_s = FourierAttention(out_channels, reduction)
    # Initialize the Fourier attention module for the metal mask with input channels and reduction ratio
    self.FourierAttention_m = FourierAttention(out_channels, reduction)
    # Initialize the Fourier fusion module for the corrupted region with input channels and output channels
    self.FourierFusion_c = FourierFusion(out_channels, out_channels)
    # Initialize the Fourier fusion module for the uncorrupted region with input channels and output channels
    self.FourierFusion_u = FourierFusion(out_channels, out_channels)
    # Initialize the Fourier reconstruction layer with input channels and output channels
    self.FourierRecon = FourierRecon(out_channels * 2, in_channels)
  
  # Define the forward function of the network
  def forward(self, s, m):
    # s: corrupted sinogram of shape (batch_size, in_channels, height, width)
    # m: metal mask of shape (batch_size, in_channels, height, width)
    # Apply a Fourier convolution layer to s and m separately
    s1 = self.FourierConv_s(s)
    m1 = self.FourierConv_m(m)
    # Apply a Fourier attention module to s1 and m1 separately
    s2 = self.FourierAttention_s(s1)
    m2 = self.FourierAttention_m(m1)
    # Divide s2 and m2 into corrupted and uncorrupted regions according to m2
    s2_c = s2 * m2
    s2_u = s2 * (1 - m2)
    m2_c = m2 * m2
    m2_u = m2 * (1 - m2)
    # Apply a Fourier fusion module to s2_c and s2_u separately
    s3_c = self.FourierFusion_c(s2_c, s2_u)
    s3_u = self.FourierFusion_u(s2_u, s2_c)
    # Concatenate s3_c and s3_u along the channel dimension
    s3 = torch.cat([s3_c, s3_u], dim=1)
    # Apply a Fourier reconstruction layer to s3
    r = self.FourierRecon(s3)
    # Return the restored sinogram r of shape (batch_size, in_channels, height, width)
    return r

# Define the Fourier refinement network (FRN) class
class FRN(nn.Module):
  # Initialize the network with input channels, output channels, and reduction ratio
  def __init__(self, in_channels, out_channels, reduction=16):
    super(FRN, self).__init__()
    # Initialize the Fourier convolution layer for the image with input and output channels and kernel size of 3x3
    self.FourierConv_i = FourierConv(in_channels, out_channels, 3)
    # Initialize the Fourier convolution layer for the metal mask with input and output channels and kernel size of 3x3
    self.FourierConv_m = FourierConv(in_channels, out_channels, 3)
    # Initialize the Fourier attention module for the image with input channels and reduction ratio
    self.FourierAttention_i = FourierAttention(out_channels, reduction)
    # Initialize the Fourier attention module for the metal mask with input channels and reduction ratio
    self.FourierAttention_m = FourierAttention(out_channels, reduction)
    # Initialize the Fourier reconstruction layer with input channels and output channels
    self.FourierRecon =