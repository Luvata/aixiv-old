---
title: 2305.20030v2 Tree-Ring Watermarks  Fingerprints for Diffusion Images that are Invisible and Robust
date: 2023-05-21
---

# [Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust](http://arxiv.org/abs/2305.20030v2)

authors: Yuxin Wen, John Kirchenbauer, Jonas Geiping, Tom Goldstein


## What, Why and How

[1]: https://arxiv.org/pdf/2305.20030v2.pdf "Tree-Rings Watermarks: Invisible Fingerprints for Diffusion Images"
[2]: https://github.com/chaowentao/cv-arxiv-daily "GitHub - chaowentao/cv-arxiv-daily"
[3]: https://arxiv.org/abs/2305.20030v2 "[2305.20030v2] Tree-Ring Watermarks: Fingerprints for Diffusion Images ..."

Here is a summary of the paper:

- **What**: The paper introduces a novel technique called **Tree-Ring Watermarking** that robustly fingerprints diffusion model outputs[^1^][1].
- **Why**: The paper aims to prevent potential harm from AI-generated content by watermarking the outputs of generative models with a signal that is invisible to humans and yet marks the image as machine-generated[^1^][1].
- **How**: The paper embeds a pattern into the initial noise vector used for sampling, which is structured in Fourier space so that it is invariant to convolutions, crops, dilations, flips, and rotations. The watermark signal is detected by inverting the diffusion process to retrieve the noise vector, which is then checked for the embedded signal[^1^][1]. The paper demonstrates that this technique can be easily applied to arbitrary diffusion models, including text-conditioned Stable Diffusion, as a plug-in with negligible loss in FID[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/2305.20030 "Tree-Ring Watermarks: Fingerprints for Diffusion Images that are ..."
[2]: https://www.nature.com/articles/s41467-021-23627-6 "The influence of decision-making in tree ring-based climate ..."
[3]: https://www.nature.com/articles/s41559-016-0008 "Improved tree-ring archives will support earth-system science"

According to the paper[^1^][1], the main contributions are:

- The paper proposes a novel technique called **Tree-Ring Watermarking** that robustly fingerprints diffusion model outputs with a signal that is invisible to humans and yet marks the image as machine-generated.
- The paper embeds a pattern into the initial noise vector used for sampling, which is structured in Fourier space so that it is invariant to convolutions, crops, dilations, flips, and rotations.
- The paper demonstrates that this technique can be easily applied to arbitrary diffusion models, including text-conditioned Stable Diffusion, as a plug-in with negligible loss in FID.
- The paper shows that the watermark is semantically hidden in the image space and is far more robust than watermarking alternatives that are currently deployed.

## Method Summary

[1]: https://www.semanticscholar.org/paper/Tree-Ring-Watermarks%3A-Fingerprints-for-Diffusion-Wen-Kirchenbauer/ba8a0780ff1a5607311367d6a7515e2ee28739aa "Tree-Ring Watermarks: Fingerprints for Diffusion Images that are ..."
[2]: https://twitter.com/jonasgeiping/status/1664379589034950659 "Jonas Geiping on Twitter: \"How can you watermark the output of a ..."
[3]: https://en.wikipedia.org/wiki/Dendrochronology "Dendrochronology - Wikipedia"

Here is a summary of the method section of the paper:

- The paper describes the **diffusion sampling process** and how it can be inverted to retrieve the initial noise vector from a generated image[^1^][1].
- The paper introduces the **Tree-Ring Watermarking** technique, which consists of three steps: embedding, sampling, and detection[^1^][1].
- The paper explains how to **embed** a watermark pattern into the initial noise vector by adding a sinusoidal signal with a specific frequency and phase[^1^][1].
- The paper shows how to **sample** an image from a diffusion model with a watermarked noise vector, which subtly influences the entire sampling process and results in a model fingerprint that is invisible to humans[^1^][1].
- The paper describes how to **detect** the watermark signal by inverting the diffusion process to retrieve the noise vector, which is then checked for the embedded signal using a correlation test[^1^][1].
- The paper discusses the **robustness** of the watermark against common image manipulations, such as cropping, resizing, rotation, compression, and filtering[^1^][1].
- The paper evaluates the **performance** of the watermark on various diffusion models, including text-conditioned Stable Diffusion, and compares it with existing watermarking methods[^1^][1].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Embed a watermark pattern into the initial noise vector
def embed_watermark(noise_vector, frequency, phase):
  # Create a sinusoidal signal with the given frequency and phase
  signal = sin(2 * pi * frequency * noise_vector + phase)
  # Add the signal to the noise vector
  watermarked_noise_vector = noise_vector + signal
  return watermarked_noise_vector

# Sample an image from a diffusion model with a watermarked noise vector
def sample_image(watermarked_noise_vector, diffusion_model):
  # Initialize the image as the watermarked noise vector
  image = watermarked_noise_vector
  # Loop over the diffusion steps from the last to the first
  for t in reversed(range(diffusion_model.num_steps)):
    # Apply the reverse diffusion update to the image
    image = diffusion_model.reverse_update(image, t)
  return image

# Detect the watermark signal from a generated image
def detect_watermark(image, diffusion_model, frequency, phase):
  # Initialize the noise vector as the image
  noise_vector = image
  # Loop over the diffusion steps from the first to the last
  for t in range(diffusion_model.num_steps):
    # Apply the forward diffusion update to the noise vector
    noise_vector = diffusion_model.forward_update(noise_vector, t)
  # Compute the correlation between the noise vector and the sinusoidal signal
  signal = sin(2 * pi * frequency * noise_vector + phase)
  correlation = corr(noise_vector, signal)
  # If the correlation is above a threshold, return True (watermark detected)
  if correlation > threshold:
    return True
  # Otherwise, return False (watermark not detected)
  else:
    return False
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import torch
import torchvision
import matplotlib.pyplot as plt

# Define some constants
pi = np.pi # The value of pi
threshold = 0.5 # The correlation threshold for watermark detection
frequency = 0.1 # The frequency of the watermark signal
phase = 0 # The phase of the watermark signal

# Load a pre-trained diffusion model (e.g., Stable Diffusion)
diffusion_model = torch.hub.load('openai/Stable-Diffusion', 'model')

# Define the forward and reverse diffusion update functions
def forward_update(noise_vector, t):
  # Get the diffusion parameters for the current step
  alpha_t = diffusion_model.alphas[t]
  sqrt_alpha_t = torch.sqrt(alpha_t)
  sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)
  # Apply the forward update to the noise vector
  noise_vector = sqrt_alpha_t * noise_vector + sqrt_one_minus_alpha_t * diffusion_model.predictor(noise_vector, t)
  return noise_vector

def reverse_update(image, t):
  # Get the diffusion parameters for the current step
  alpha_t = diffusion_model.alphas[t]
  sqrt_alpha_t = torch.sqrt(alpha_t)
  sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)
  # Apply the reverse update to the image
  image = (image - sqrt_one_minus_alpha_t * diffusion_model.predictor(image, t)) / sqrt_alpha_t
  return image

# Define the watermark embedding function
def embed_watermark(noise_vector, frequency, phase):
  # Create a sinusoidal signal with the given frequency and phase
  signal = torch.sin(2 * pi * frequency * noise_vector + phase)
  # Add the signal to the noise vector
  watermarked_noise_vector = noise_vector + signal
  return watermarked_noise_vector

# Define the image sampling function
def sample_image(watermarked_noise_vector, diffusion_model):
  # Initialize the image as the watermarked noise vector
  image = watermarked_noise_vector
  # Loop over the diffusion steps from the last to the first
  for t in reversed(range(diffusion_model.num_steps)):
    # Apply the reverse diffusion update to the image
    image = reverse_update(image, t)
    # Clip the image values to [0,1] range
    image = torch.clamp(image, 0, 1)
  return image

# Define the watermark detection function
def detect_watermark(image, diffusion_model, frequency, phase):
  # Initialize the noise vector as the image
  noise_vector = image
  # Loop over the diffusion steps from the first to the last
  for t in range(diffusion_model.num_steps):
    # Apply the forward diffusion update to the noise vector
    noise_vector = forward_update(noise_vector, t)
    # Clip the noise vector values to [-1,1] range
    noise_vector = torch.clamp(noise_vector, -1, 1)
  # Compute the correlation between the noise vector and the sinusoidal signal
  signal = torch.sin(2 * pi * frequency * noise_vector + phase)
  correlation = torch.corrcoef(noise_vector.flatten(), signal.flatten())[0,1]
  # If the correlation is above a threshold, return True (watermark detected)
  if correlation > threshold:
    return True
  # Otherwise, return False (watermark not detected)
  else:
    return False

# Generate a random noise vector of shape (3,256,256) with values in [-1,1] range
noise_vector = torch.rand(3,256,256) * 2 - 1

# Embed a watermark pattern into the noise vector
watermarked_noise_vector = embed_watermark(noise_vector, frequency, phase)

# Sample an image from the diffusion model with a watermarked noise vector
image = sample_image(watermarked_noise_vector, diffusion_model)

# Display the generated image
plt.imshow(torchvision.transforms.ToPILImage()(image))
plt.show()

# Detect the watermark signal from the generated image
result = detect_watermark(image, diffusion_model, frequency, phase)

# Print the result of watermark detection
if result:
  print("Watermark detected!")
else:
  print("Watermark not detected!")
```