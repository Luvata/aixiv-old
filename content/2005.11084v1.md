---
title: 2005.11084v1 Point2Mesh  A Self-Prior for Deformable Meshes
date: 2020-05-12
---

# [Point2Mesh: A Self-Prior for Deformable Meshes](http://arxiv.org/abs/2005.11084v1)

authors: Rana Hanocka, Gal Metzer, Raja Giryes, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/pdf/2005.11084v1.pdf "Point2Mesh: A Self-Prior for Deformable Meshes - arXiv.org"
[2]: https://arxiv.org/abs/2005.11084 "[2005.11084] Point2Mesh: A Self-Prior for Deformable Meshes - arXiv.org"
[3]: http://export.arxiv.org/abs/2202.11084v1 "[2202.11084v1] Artificial Viscosity -- Then and Now"

Here is a summary of the paper:

- **What**: The paper introduces Point2Mesh, a technique for reconstructing a surface mesh from an input point cloud using a self-prior that is defined automatically from the input point cloud[^1^][1] [^2^][2].
- **Why**: The paper aims to overcome the limitations of traditional reconstruction approaches that rely on explicit priors that encode the expected shape properties, such as smoothness or symmetry, which often fail in non-ideal conditions such as unoriented normals, noise and missing parts[^1^][1] [^2^][2].
- **How**: The paper proposes to optimize the weights of a deep neural network that deforms an initial mesh to shrink-wrap a single input point cloud. The network uses shared local convolutional kernels that are optimized globally across the entire shape, which encourages local-scale geometric self-similarity across the shape surface. The paper shows that this self-prior converges to a desirable solution and is robust to non-ideal conditions[^1^][1] [^2^][2].

## Main Contributions

The paper claims to make the following contributions:

- It introduces Point2Mesh, a novel technique for reconstructing a surface mesh from an input point cloud using a self-prior that is defined automatically from the input point cloud.
- It demonstrates that the self-prior encapsulates reoccurring geometric repetitions from a single shape within the weights of a deep neural network, and that it can handle complex shapes with varying topology and geometry.
- It shows that Point2Mesh outperforms state-of-the-art methods on several benchmarks and is robust to non-ideal conditions such as unoriented normals, noise and missing parts.

## Method Summary

[1]: https://arxiv.org/pdf/2005.11084v1.pdf "Point2Mesh: A Self-Prior for Deformable Meshes - arXiv.org"
[2]: https://arxiv.org/abs/2005.11084 "[2005.11084] Point2Mesh: A Self-Prior for Deformable Meshes - arXiv.org"
[3]: http://export.arxiv.org/abs/2103.11084v1 "[2103.11084v1] 3DMNDT:3D multi-view registration method based on the ..."

Here is a summary of the method section of the paper:

- The paper proposes a two-stage approach for reconstructing a surface mesh from an input point cloud using a self-prior that is defined automatically from the input point cloud[^1^][1] [^2^][2].
- The first stage is to deform an initial mesh to fit the input point cloud using a deep neural network that learns shared local convolutional kernels that are optimized globally across the entire shape. The network takes as input the initial mesh and the point cloud, and outputs a deformation field that is applied to the mesh vertices. The network is trained by minimizing a loss function that measures the distance between the deformed mesh and the point cloud, as well as a regularization term that prevents overfitting[^1^][1] [^2^][2].
- The second stage is to refine the deformed mesh by applying a Laplacian smoothing operation that preserves the geometric features of the shape. The paper also introduces a post-processing step that removes spurious faces and vertices from the reconstructed mesh[^1^][1] [^2^][2].
- The paper evaluates the performance of Point2Mesh on several benchmarks and compares it with state-of-the-art methods. The paper also conducts ablation studies to analyze the effect of different components of the method[^1^][1] [^2^][2].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a point cloud P and an initial mesh M
# Output: a reconstructed mesh M'

# Stage 1: deform the initial mesh to fit the point cloud using a self-prior
# Define a deep neural network f that takes M and P as input and outputs a deformation field D
# Define a loss function L that measures the distance between M + D and P, and a regularization term R that prevents overfitting
# Train f by minimizing L + R
# Apply D to M to get a deformed mesh M*

# Stage 2: refine the deformed mesh by applying Laplacian smoothing
# Define a Laplacian operator L that computes the difference between each vertex and its neighbors
# Define a smoothing parameter alpha that controls the amount of smoothing
# Update each vertex v of M* by v = v - alpha * L(v)
# Get a refined mesh M'

# Post-processing: remove spurious faces and vertices from M'
# Define a threshold T that determines whether a face or a vertex is spurious
# For each face f of M':
#   If the area of f is smaller than T, remove f from M'
# For each vertex v of M':
#   If the degree of v is smaller than T, remove v from M'
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a point cloud P and an initial mesh M
# Output: a reconstructed mesh M'

# Stage 1: deform the initial mesh to fit the point cloud using a self-prior
# Define a deep neural network f that consists of three modules: encoder, decoder and sampler
# The encoder takes M and P as input and outputs a latent code z
# The decoder takes z as input and outputs a deformation field D
# The sampler takes P as input and outputs a subset of points S that are uniformly distributed on the surface of P
# Define a loss function L that consists of three terms: chamfer distance, normal consistency and edge length
# The chamfer distance measures the symmetric distance between M + D and S
# The normal consistency measures the alignment between the normals of M + D and S
# The edge length measures the deviation of the edge lengths of M + D from the average edge length of M
# Define a regularization term R that consists of two terms: orthogonality and sparsity
# The orthogonality measures the deviation of the convolutional kernels from being orthogonal
# The sparsity measures the deviation of the latent code z from being sparse
# Train f by minimizing L + R using gradient descent
# Apply D to M to get a deformed mesh M*

# Stage 2: refine the deformed mesh by applying Laplacian smoothing
# Define a Laplacian operator L that computes the difference between each vertex and its neighbors weighted by their inverse distances
# Define a smoothing parameter alpha that controls the amount of smoothing
# Update each vertex v of M* by v = v - alpha * L(v)
# Get a refined mesh M'

# Post-processing: remove spurious faces and vertices from M'
# Define a threshold T that determines whether a face or a vertex is spurious
# For each face f of M':
#   If the area of f is smaller than T, remove f from M'
# For each vertex v of M':
#   If the degree of v is smaller than T, remove v from M'
```