---
title: 2207.08134v1 Editing Out-of-domain GAN Inversion via Differential Activations
date: 2022-07-09
---

# [Editing Out-of-domain GAN Inversion via Differential Activations](http://arxiv.org/abs/2207.08134v1)

authors: Haorui Song, Yong Du, Tianyi Xiang, Junyu Dong, Jing Qin, Shengfeng He


## What, Why and How

[1]: https://arxiv.org/abs/2207.08134v1 "Editing Out-of-domain GAN Inversion via Differential Activations"
[2]: https://arxiv.org/pdf/2207.08151v1.pdf "arXiv:2207.08151v1 [cs.GT] 17 Jul 2022"
[3]: http://export.arxiv.org/abs/2206.08134v1 "[2206.08134v1] Simple shear in nonlinear Cosserat micropolar elasticity ..."

Here is a summary of the paper based on the search results:

- **What**: The paper is about editing out-of-domain GAN inversion via differential activations[^1^][1].
- **Why**: The paper aims to tackle the problem of reconstructing real-world images faithfully using a pretrained GAN model, which is challenging due to the distribution mismatch between training and real-world data[^1^][1].
- **How**: The paper proposes a novel GAN prior based editing framework that consists of two phases: composition and decomposition. In the composition phase, a differential activation module is used to detect semantic changes and generate a coarse reconstruction by blending the original and edited images. In the decomposition phase, a GAN prior based deghosting network is used to separate the final fine edited image from the coarse reconstruction[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/2207.08134 "Editing Out-of-domain GAN Inversion via Differential Activations"
[2]: https://link.springer.com/chapter/10.1007/978-3-031-19790-1_1 "Editing Out-of-Domain GAN Inversion via Differential Activations - Springer"
[3]: https://link.springer.com/content/pdf/10.1007/978-3-031-19790-1_1.pdf?pdf=inline%20link "Editing Out-of-Domain GAN Inversion via Differential Activations - Springer"
[4]: https://deepai.org/publication/editing-out-of-domain-gan-inversion-via-differential-activations "Editing Out-of-domain GAN Inversion via Differential Activations"

According to the search results, the contributions of this paper are:

- It proposes a novel GAN prior based editing framework to tackle the out-of-domain inversion problem with a composition-decomposition paradigm[^1^][1] [^2^][2] [^3^][4].
- It introduces a differential activation module for detecting semantic changes from a global perspective and generating a coarse reconstruction by blending the original and edited images[^1^][1] [^2^][2].
- It presents a GAN prior based deghosting network for separating the final fine edited image from the coarse reconstruction[^1^][1] [^2^][2].
- It exhibits superiorities over the state-of-the-art methods, in terms of qualitative and quantitative evaluations, and validates the robustness and flexibility of the method on both scenarios of single attribute and multi-attribute manipulations[^1^][1] [^2^][2] [^3^][4].

## Method Summary

[1]: https://arxiv.org/abs/2207.08134 "Editing Out-of-domain GAN Inversion via Differential Activations"
[2]: https://link.springer.com/chapter/10.1007/978-3-031-19790-1_1 "Editing Out-of-Domain GAN Inversion via Differential Activations - Springer"
[3]: https://github.com/HaoruiSong622/Editing-Out-of-Domain "GitHub - HaoruiSong622/Editing-Out-of-Domain"
[4]: https://deepai.org/publication/photo-realistic-out-of-domain-gan-inversion-via-invertibility-decomposition "Photo-Realistic Out-of-domain GAN inversion via Invertibility ... - DeepAI"
[5]: https://link.springer.com/content/pdf/10.1007/978-3-031-19790-1_1.pdf?pdf=inline%20link "Editing Out-of-Domain GAN Inversion via Differential Activations - Springer"

Here is a summary of the method section based on the search results:

- The method section describes the proposed GAN prior based editing framework, which consists of two phases: composition and decomposition[^1^][1] [^2^][2].
- In the composition phase, the method introduces a differential activation module for detecting semantic changes from a global perspective, i.e., the relative gap between the features of edited and unedited images[^1^][1] [^2^][2]. The module generates a Diff-CAM mask that indicates the regions where editing attributes are activated[^1^][1] [^2^][2]. The mask is then used to blend the original and edited images to obtain a coarse reconstruction that preserves the out-of-domain content[^1^][1] [^2^][2].
- In the decomposition phase, the method presents a GAN prior based deghosting network for separating the final fine edited image from the coarse reconstruction[^1^][1] [^2^][2]. The network consists of two branches: a deghosting branch that removes the ghosting effect caused by blending, and a refinement branch that enhances the quality of the edited image[^1^][1] [^2^][2].
- The method section also provides details on the network architectures, loss functions, implementation details, and evaluation metrics[^1^][1] [^2^][2] [^3^][3].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a real image x and a pretrained GAN model G
# Output: an edited image y with desired attributes

# Composition phase
# Invert x to a latent code w using an encoder E
w = E(x)
# Edit w along the attribute directions to obtain w'
w' = edit(w)
# Generate an edited image x' using G
x' = G(w')
# Extract features of x and x' using a feature extractor F
f = F(x)
f' = F(x')
# Compute the differential activations between f and f'
d = diff(f, f')
# Generate a Diff-CAM mask m using d
m = cam(d)
# Blend x and x' using m to obtain a coarse reconstruction r
r = blend(x, x', m)

# Decomposition phase
# Input r to a deghosting network D
# Output a deghosted image g and a refined image y
g, y = D(r)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a real image x and a pretrained GAN model G
# Output: an edited image y with desired attributes

# Composition phase
# Define an encoder E that maps x to a latent code w
E = Encoder()
# Define an attribute direction dictionary A that contains the semantic directions for editing
A = load_attribute_directions()
# Define an edit function that modifies w along the attribute directions specified by a vector v
def edit(w, v):
  for i in range(len(v)):
    # Get the i-th attribute direction and weight
    a = A[i]
    w = w + v[i] * a
  return w
# Define a feature extractor F that extracts features from x and x'
F = FeatureExtractor()
# Define a diff function that computes the differential activations between f and f'
def diff(f, f'):
  # Compute the L2-norm of f and f' along the channel dimension
  n = norm(f, axis=1)
  n' = norm(f', axis=1)
  # Compute the relative gap between n and n'
  d = abs(n - n') / (n + n' + epsilon)
  return d
# Define a cam function that generates a Diff-CAM mask m using d
def cam(d):
  # Resize d to the same size as x
  d = resize(d, size(x))
  # Normalize d to [0, 1]
  d = normalize(d)
  # Apply a threshold to d to obtain a binary mask m
  m = threshold(d, t)
  return m
# Define a blend function that blends x and x' using m
def blend(x, x', m):
  # Apply Gaussian smoothing to m
  m = smooth(m)
  # Blend x and x' using m as alpha channel
  r = x * (1 - m) + x' * m
  return r

# Decomposition phase
# Define a deghosting network D that consists of two branches: a deghosting branch D_g and a refinement branch D_r
D_g = DeghostingBranch()
D_r = RefinementBranch()
# Define a deghost function that removes the ghosting effect from r using D_g
def deghost(r):
  # Input r to D_g and output a deghosted image g
  g = D_g(r)
  return g
# Define a refine function that enhances the quality of g using D_r
def refine(g):
  # Input g to D_r and output a refined image y
  y = D_r(g)
  return y

# Main procedure
# Invert x to a latent code w using E
w = E(x)
# Edit w along the attribute directions to obtain w'
w' = edit(w, v) # v is a vector that specifies the desired attributes
# Generate an edited image x' using G
x' = G(w')
# Extract features of x and x' using F
f = F(x)
f' = F(x')
# Compute the differential activations between f and f'
d = diff(f, f')
# Generate a Diff-CAM mask m using d
m = cam(d)
# Blend x and x' using m to obtain a coarse reconstruction r
r = blend(x, x', m)
# Deghost r using D_g to obtain a deghosted image g
g = deghost(r)
# Refine g using D_r to obtain a refined image y
y = refine(g)
```