---
title: 2012.08673v2 A Closer Look at the Robustness of Vision-and-Language Pre-trained Models
date: 2020-12-09
---

# [A Closer Look at the Robustness of Vision-and-Language Pre-trained Models](http://arxiv.org/abs/2012.08673v2)

authors: Linjie Li, Zhe Gan, Jingjing Liu


## What, Why and How

[1]: https://arxiv.org/abs/2012.08673v2 "[2012.08673v2] A Closer Look at the Robustness of Vision-and-Language ..."
[2]: https://arxiv.org/pdf/2012.08673v2 "A Closer Look at the Robustness of Vision-and-Language Pre ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2208.08673v2 "[2208.08673v2] Identifying incoherent mixing effects in the coherent ..."

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper is about evaluating and enhancing the robustness of vision-and-language (V+L) pre-trained models, such as ViLBERT and UNITER, on various tasks and datasets that challenge different aspects of robustness.
- **Why**: The paper aims to investigate how robust these pre-trained models are against linguistic variation, logical reasoning, visual content manipulation, and answer distribution shift, which are common sources of difficulty and error for V+L models.
- **How**: The paper conducts a comprehensive evaluation of existing pre-trained models on 9 diverse VQA datasets that cover each type of robustness. The paper also proposes MANGO, a generic and efficient approach that learns a multimodal adversarial noise generator in the embedding space to fool pre-trained V+L models and improve their robustness. The paper shows that MANGO achieves new state of the art on 7 out of 9 robustness benchmarks.

## Main Contributions

According to the paper, the main contributions are:

- The first comprehensive study on V+L robustness, covering 4 generic types of robustness and 9 diverse VQA datasets.
- A systematic evaluation of existing pre-trained V+L models on these datasets, revealing their strengths and weaknesses in different aspects of robustness.
- A novel and generic approach, MANGO, that learns a multimodal adversarial noise generator in the embedding space to enhance model robustness across diverse tasks and datasets.
- A new state of the art on 7 out of 9 robustness benchmarks, surpassing existing methods by a significant margin.

## Method Summary

The method section of the paper consists of two parts: the evaluation framework and the MANGO approach.

- The evaluation framework describes how the authors select 9 diverse VQA datasets that cover 4 types of robustness: linguistic variation, logical reasoning, visual content manipulation, and answer distribution shift. The authors also explain how they fine-tune and evaluate existing pre-trained V+L models on these datasets using standard metrics such as accuracy and consistency.
- The MANGO approach describes how the authors design a multimodal adversarial noise generator that learns to add perturbations to the image and text embeddings of pre-trained V+L models in order to fool them. The authors also explain how they use random masking on the image and text inputs to promote more diverse adversarial embeddings, and how they optimize the noise generator using a min-max objective. The authors show how MANGO can be applied to any pre-trained V+L model and any VQA dataset to improve model robustness.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Evaluation framework
for each dataset in [VQA-Rephrasings, VQA-LOL, VQA-Introspect, GQA, IV-VQA, CV-VQA, VQA-CP v2, GQA-OOD]:
  for each model in [ViLBERT, LXMERT, UNITER]:
    # Fine-tune the model on the dataset
    model = fine_tune(model, dataset)
    # Evaluate the model on the test set
    accuracy, consistency = evaluate(model, dataset)

# MANGO approach
for each dataset in [VQA-Rephrasings, VQA-LOL, VQA-Introspect, GQA, IV-VQA, CV-VQA, VQA-CP v2, GQA-OOD]:
  for each model in [ViLBERT, LXMERT, UNITER]:
    # Initialize a noise generator for image and text embeddings
    noise_generator = NoiseGenerator()
    # Train the noise generator to fool the model
    for each batch in dataset:
      # Get the image and text inputs
      image, text = batch
      # Randomly mask some regions in the image and some tokens in the text
      image_masked, text_masked = mask(image, text)
      # Get the image and text embeddings from the model
      image_embed, text_embed = model.encode(image_masked, text_masked)
      # Add noise to the embeddings using the noise generator
      image_noise, text_noise = noise_generator(image_embed, text_embed)
      # Get the logits from the model with noisy embeddings
      logits = model.decode(image_noise + image_embed, text_noise + text_embed)
      # Compute the loss and update the noise generator parameters
      loss = compute_loss(logits, batch)
      noise_generator.update(loss)
    # Fine-tune the model with MANGO on the dataset
    model = fine_tune(model, dataset, noise_generator)
    # Evaluate the model on the test set
    accuracy, consistency = evaluate(model, dataset)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import libraries
import torch
import torchvision
import transformers
import numpy as np

# Define constants
NUM_DATASETS = 9 # Number of VQA datasets
NUM_MODELS = 3 # Number of pre-trained V+L models
NUM_EPOCHS = 10 # Number of epochs for fine-tuning and MANGO training
BATCH_SIZE = 32 # Batch size for training and evaluation
LEARNING_RATE = 1e-4 # Learning rate for fine-tuning and MANGO training
MASK_PROB = 0.15 # Probability of masking a region or a token
NOISE_DIM = 256 # Dimension of the noise vector
NOISE_SCALE = 0.1 # Scale factor for the noise

# Load the datasets
datasets = [load_dataset(name) for name in ["VQA-Rephrasings", "VQA-LOL", "VQA-Introspect", "GQA", "IV-VQA", "CV-VQA", "VQA-CP v2", "GQA-OOD"]]

# Load the models
models = [load_model(name) for name in ["ViLBERT", "LXMERT", "UNITER"]]

# Define the loss function
def compute_loss(logits, batch):
  # Get the ground truth answers from the batch
  answers = batch["answers"]
  # Convert the answers to one-hot vectors
  answers_onehot = torch.nn.functional.one_hot(answers, num_classes=logits.size(-1))
  # Compute the cross entropy loss between the logits and the answers
  loss = torch.nn.functional.cross_entropy(logits, answers_onehot)
  return loss

# Define the evaluation function
def evaluate(model, dataset):
  # Set the model to evaluation mode
  model.eval()
  # Initialize the accuracy and consistency metrics
  accuracy = 0.0
  consistency = 0.0
  # Loop over the test set of the dataset
  for batch in dataset.test_set:
    # Get the image and text inputs from the batch
    image, text = batch["image"], batch["text"]
    # Get the logits from the model
    logits = model(image, text)
    # Get the predicted answers from the logits
    predictions = torch.argmax(logits, dim=-1)
    # Get the ground truth answers from the batch
    answers = batch["answers"]
    # Compute the accuracy as the percentage of correct predictions
    accuracy += torch.mean((predictions == answers).float())
    # Compute the consistency as the percentage of consistent predictions across different rephrasings or augmentations of the same question-image pair
    consistency += compute_consistency(predictions, batch)
  # Normalize the accuracy and consistency by the number of batches
  accuracy /= len(dataset.test_set)
  consistency /= len(dataset.test_set)
  return accuracy, consistency

# Define the masking function
def mask(image, text):
  # Randomly mask some regions in the image by setting them to zero
  image_masked = image.clone()
  num_regions = image_masked.size(1)
  mask_indices = np.random.choice(num_regions, size=int(num_regions * MASK_PROB), replace=False)
  image_masked[:, mask_indices] = 0.0
  # Randomly mask some tokens in the text by replacing them with [MASK] token
  text_masked = text.clone()
  num_tokens = text_masked.size(1)
  mask_indices = np.random.choice(num_tokens, size=int(num_tokens * MASK_PROB), replace=False)
  text_masked[:, mask_indices] = tokenizer.mask_token_id # Assume tokenizer is a transformers tokenizer object
  return image_masked, text_masked

# Define the noise generator class
class NoiseGenerator(torch.nn.Module):
  def __init__(self):
    super().__init__()
    # Initialize a linear layer for image noise generation
    self.image_noise_layer = torch.nn.Linear(NOISE_DIM, IMAGE_DIM) # Assume IMAGE_DIM is a constant for image embedding dimension
    # Initialize a linear layer for text noise generation
    self.text_noise_layer = torch.nn.Linear(NOISE_DIM, TEXT_DIM) # Assume TEXT_DIM is a constant for text embedding dimension
  
  def forward(self, image_embed, text_embed):
    # Generate a random noise vector for each image and text embedding in the batch
    noise_vector = torch.randn(image_embed.size(0), NOISE_DIM).to(image_embed.device)
    # Generate noise for image embeddings using the image noise layer
    image_noise = self.image_noise_layer(noise_vector) * NOISE_SCALE
    # Generate noise for text embeddings using the text noise layer
    text_noise = self.text_noise_layer(noise_vector) * NOISE_SCALE
    return image_noise, text_noise

# Evaluation framework
for i in range(NUM_DATASETS):
  # Get the current dataset
  dataset = datasets[i]
  for j in range(NUM_MODELS):
    # Get the current model
    model = models[j]
    # Fine-tune the model on the dataset
    model = fine_tune(model, dataset, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE)
    # Evaluate the model on the test set
    accuracy, consistency = evaluate(model, dataset)
    # Print the results
    print(f"Dataset: {dataset.name}, Model: {model.name}, Accuracy: {accuracy}, Consistency: {consistency}")

# MANGO approach
for i in range(NUM_DATASETS):
  # Get the current dataset
  dataset = datasets[i]
  for j in range(NUM_MODELS):
    # Get the current model
    model = models[j]
    # Initialize a noise generator for image and text embeddings
    noise_generator = NoiseGenerator()
    # Train the noise generator to fool the model
    for epoch in range(NUM_EPOCHS):
      # Loop over the training set of the dataset
      for batch in dataset.train_set:
        # Get the image and text inputs from the batch
        image, text = batch["image"], batch["text"]
        # Randomly mask some regions in the image and some tokens in the text
        image_masked, text_masked = mask(image, text)
        # Get the image and text embeddings from the model
        image_embed, text_embed = model.encode(image_masked, text_masked)
        # Add noise to the embeddings using the noise generator
        image_noise, text_noise = noise_generator(image_embed, text_embed)
        # Get the logits from the model with noisy embeddings
        logits = model.decode(image_noise + image_embed, text_noise + text_embed)
        # Compute the loss and update the noise generator parameters
        loss = compute_loss(logits, batch)
        noise_generator.update(loss) # Assume noise_generator has an update method that performs gradient descent
    # Fine-tune the model with MANGO on the dataset
    model = fine_tune(model, dataset, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE, noise_generator=noise_generator)
    # Evaluate the model on the test set
    accuracy, consistency = evaluate(model, dataset)
    # Print the results
    print(f"Dataset: {dataset.name}, Model: {model.name}, Accuracy: {accuracy}, Consistency: {consistency}")
```