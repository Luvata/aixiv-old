---
title: 1709.05424v2 NIMA  Neural Image Assessment
date: 2017-09-06
---

# [NIMA: Neural Image Assessment](http://arxiv.org/abs/1709.05424v2)

authors: Hossein Talebi, Peyman Milanfar


## What, Why and How

[1]: https://arxiv.org/abs/1709.05424 "[1709.05424] NIMA: Neural Image Assessment - arXiv.org"
[2]: https://arxiv.org/pdf/1709.05424v2.pdf "arXiv.org e-Print archive"
[3]: http://export.arxiv.org/abs/2208.05424v2 "[2208.05424v2] Physics-Constrained Climate Downscaling"

Here is a summary of the paper:

- **What**: The paper proposes a method for predicting the distribution of human opinion scores for image quality assessment using a convolutional neural network (CNN).
- **Why**: The paper aims to address the limitations of existing methods that only predict the mean opinion score, which does not capture the subjective nature of image quality perception. The paper also wants to provide a tool for optimizing photo editing/enhancement algorithms without requiring a reference image.
- **How**: The paper uses a CNN that is pretrained on object recognition tasks and fine-tuned on image quality datasets such as AVA and TID2013. The paper modifies the last layer of the CNN to output a vector of 10 values that represent the probability distribution of the opinion scores from 1 to 10. The paper evaluates the performance of the method using various metrics such as Earth Mover's Distance (EMD), Spearman's rank correlation coefficient (SRCC), and Pearson's linear correlation coefficient (PLCC). The paper also demonstrates some applications of the method such as image ranking, style transfer, and tone mapping. [^1^][1]

## Main Contributions

[1]: https://arxiv.org/abs/1709.05424 "[1709.05424] NIMA: Neural Image Assessment - arXiv.org"
[2]: https://arxiv.org/pdf/1709.05424v2.pdf "arXiv.org e-Print archive"
[3]: http://export.arxiv.org/abs/2208.05424v2 "[2208.05424v2] Physics-Constrained Climate Downscaling"

Some of the contributions of this paper are:

- It proposes a novel method for predicting the distribution of human opinion scores for image quality assessment using a convolutional neural network (CNN).
- It shows that the predicted distribution can be used to compute various quality metrics such as mean opinion score (MOS), standard deviation (STD), and cumulative probability (CP).
- It demonstrates that the method can achieve high correlation with human perception and outperform existing methods on various datasets such as AVA, TID2013, and LIVE.
- It presents some applications of the method such as image ranking, style transfer, and tone mapping, and shows that the method can improve the quality of the output images. [^1^][1]

## Method Summary

[1]: https://arxiv.org/abs/1709.05424 "[1709.05424] NIMA: Neural Image Assessment - arXiv.org"
[2]: https://arxiv.org/pdf/1709.05424v2.pdf "arXiv.org e-Print archive"
[3]: http://export.arxiv.org/abs/2208.05424v2 "[2208.05424v2] Physics-Constrained Climate Downscaling"

Here is a summary of the method section of the paper:

- The paper uses a convolutional neural network (CNN) that is pretrained on object recognition tasks such as ImageNet and Places365, and fine-tunes it on image quality datasets such as AVA and TID2013.
- The paper modifies the last layer of the CNN to output a vector of 10 values that represent the probability distribution of the opinion scores from 1 to 10. The paper uses a softmax activation function and a cross-entropy loss function for training the network.
- The paper uses various data augmentation techniques such as random cropping, flipping, rotation, and color jittering to increase the diversity and robustness of the training data.
- The paper evaluates the performance of the method using various metrics such as Earth Mover's Distance (EMD), Spearman's rank correlation coefficient (SRCC), and Pearson's linear correlation coefficient (PLCC). The paper compares the method with existing methods such as BRISQUE, CORNIA, DIIVINE, and NIQE on various datasets such as AVA, TID2013, and LIVE. [^1^][1]


## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the CNN model with pretrained weights from object recognition tasks
model = CNN(pretrained=True)

# Replace the last layer with a 10-unit layer with softmax activation
model.fc = nn.Linear(model.fc.in_features, 10)
model.fc.activation = nn.Softmax(dim=1)

# Define the cross-entropy loss function
criterion = nn.CrossEntropyLoss()

# Define the optimizer and learning rate scheduler
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

# Load the image quality datasets such as AVA and TID2013
train_loader, val_loader, test_loader = load_datasets()

# Train the model for a fixed number of epochs
for epoch in range(num_epochs):
  # Set the model to training mode
  model.train()
  # Loop over the training batches
  for inputs, labels in train_loader:
    # Apply data augmentation techniques such as random cropping, flipping, rotation, and color jittering
    inputs = augment(inputs)
    # Move the inputs and labels to the device (CPU or GPU)
    inputs = inputs.to(device)
    labels = labels.to(device)
    # Zero the parameter gradients
    optimizer.zero_grad()
    # Forward pass
    outputs = model(inputs)
    # Compute the loss
    loss = criterion(outputs, labels)
    # Backward pass and optimize
    loss.backward()
    optimizer.step()
  # Set the model to evaluation mode
  model.eval()
  # Loop over the validation batches
  for inputs, labels in val_loader:
    # Move the inputs and labels to the device (CPU or GPU)
    inputs = inputs.to(device)
    labels = labels.to(device)
    # Forward pass
    outputs = model(inputs)
    # Compute the loss and metrics
    loss = criterion(outputs, labels)
    emd = compute_emd(outputs, labels)
    srcc = compute_srcc(outputs, labels)
    plcc = compute_plcc(outputs, labels)
  # Print the loss and metrics for the current epoch
  print(f'Epoch {epoch}, Loss: {loss}, EMD: {emd}, SRCC: {srcc}, PLCC: {plcc}')
  # Adjust the learning rate according to the scheduler
  scheduler.step()

# Test the model on the test set and compare with existing methods
test_model(model, test_loader)
compare_with_baselines(model, test_loader)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import pandas as pd
from scipy.stats import wasserstein_distance, spearmanr, pearsonr

# Define the CNN model with pretrained weights from object recognition tasks
# The paper uses two models: MobileNet and InceptionResNetV2
# Here we use MobileNet as an example
model = torchvision.models.mobilenet_v2(pretrained=True)

# Replace the last layer with a 10-unit layer with softmax activation
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)
model.classifier[1].activation = nn.Softmax(dim=1)

# Define the cross-entropy loss function
criterion = nn.CrossEntropyLoss()

# Define the optimizer and learning rate scheduler
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

# Define the device (CPU or GPU) to run the model on
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define the data augmentation techniques such as random cropping, flipping, rotation, and color jittering
augment = transforms.Compose([
  transforms.RandomResizedCrop(224),
  transforms.RandomHorizontalFlip(),
  transforms.RandomRotation(15),
  transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),
  transforms.ToTensor(),
  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

# Define the function to load the image quality datasets such as AVA and TID2013
def load_datasets():
  # Load the AVA dataset from https://github.com/mtobeiyf/ava_downloader
  # The AVA dataset contains about 255k images and their mean opinion scores from 1 to 10
  # We use the mean opinion scores as labels and convert them to integers from 0 to 9
  ava_df = pd.read_csv('AVA_dataset/AVA.txt', sep=' ', header=None)
  ava_df[12] = ava_df[2:12].idxmax(axis=1) - 2
  ava_df = ava_df[[1,12]]
  ava_df.columns = ['image_id', 'label']
  
  # Load the TID2013 dataset from http://www.ponomarenko.info/tid2013.htm
  # The TID2013 dataset contains 25 reference images and their distorted versions with different types and levels of distortions
  # The dataset also provides the mean opinion scores and standard deviations for each distorted image
  # We use the mean opinion scores as labels and convert them to integers from 0 to 9 using a linear mapping function
  tid_df = pd.read_csv('TID2013/mos_with_names.txt', sep='\t', header=None)
  tid_df.columns = ['mos', 'image_id']
  tid_df['label'] = ((tid_df['mos'] - tid_df['mos'].min()) / (tid_df['mos'].max() - tid_df['mos'].min()) * 9).astype(int)
  
  # Concatenate the two datasets and shuffle them
  df = pd.concat([ava_df, tid_df], ignore_index=True)
  df = df.sample(frac=1).reset_index(drop=True)
  
  # Split the dataset into train (80%), validation (10%), and test (10%) sets
  train_size = int(len(df) * 0.8)
  val_size = int(len(df) * 0.1)
  
  train_df = df[:train_size]
  val_df = df[train_size:train_size+val_size]
  test_df = df[train_size+val_size:]
  
  # Define the custom dataset class that loads the images and labels from the dataframes
  class ImageQualityDataset(torch.utils.data.Dataset):
    def __init__(self, df, transform=None):
      self.df = df
      self.transform = transform
    
    def __len__(self):
      return len(self.df)
    
    def __getitem__(self, idx):
      image_id = self.df.iloc[idx]['image_id']
      label = self.df.iloc[idx]['label']
      
      # Check if the image is from AVA or TID2013 and load it accordingly
      if image_id.isdigit():
        image = Image.open(f'AVA_dataset/images/{image_id}.jpg')
      else:
        image = Image.open(f'TID2013/reference_images/{image_id}')
      
      # Apply the transform if specified
      if self.transform:
        image = self.transform(image)
      
      # Return the image and label as tensors
      return image, torch.tensor(label)
  
  # Define the transform for the validation and test sets
  # No data augmentation is applied, only resizing, center cropping, and normalization
  val_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
  ])
  
  # Create the dataset objects for the train, validation, and test sets
  train_dataset = ImageQualityDataset(train_df, transform=augment)
  val_dataset = ImageQualityDataset(val_df, transform=val_transform)
  test_dataset = ImageQualityDataset(test_df, transform=val_transform)
  
  # Create the data loader objects for the train, validation, and test sets
  # Use a batch size of 32 and shuffle the train set
  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
  val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)
  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)
  
  # Return the data loader objects
  return train_loader, val_loader, test_loader

# Define the function to compute the Earth Mover's Distance (EMD) between two distributions
def compute_emd(outputs, labels):
  # Convert the outputs and labels to numpy arrays
  outputs = outputs.cpu().detach().numpy()
  labels = labels.cpu().numpy()
  
  # Initialize an empty list to store the EMD values
  emd_list = []
  
  # Loop over the outputs and labels
  for output, label in zip(outputs, labels):
    # Create two discrete distributions from the output and label
    # The output is already a probability distribution of length 10
    # The label is a single integer from 0 to 9, so we create a one-hot vector of length 10
    output_dist = output
    label_dist = np.zeros(10)
    label_dist[label] = 1
    
    # Compute the EMD between the two distributions using the wasserstein_distance function from scipy.stats
    emd = wasserstein_distance(output_dist, label_dist)
    
    # Append the EMD value to the list
    emd_list.append(emd)
  
  # Return the average EMD value over the list
  return np.mean(emd_list)

# Define the function to compute the Spearman's rank correlation coefficient (SRCC) between two distributions
def compute_srcc(outputs, labels):
  # Convert the outputs and labels to numpy arrays
  outputs = outputs.cpu().detach().numpy()
  labels = labels.cpu().numpy()
  
  # Initialize an empty list to store the SRCC values
  srcc_list = []
  
  # Loop over the outputs and labels
  for output, label in zip(outputs, labels):
    # Create two discrete distributions from the output and label
    # The output is already a probability distribution of length 10
    # The label is a single integer from 0 to 9, so we create a one-hot vector of length 10
    output_dist = output
    label_dist = np.zeros(10)
    label_dist[label] = 1
    
    # Compute the SRCC between the two distributions using the spearmanr function from scipy.stats
    srcc = spearmanr(output_dist, label_dist)[0]
    
    # Append the SRCC value to the list
    srcc_list.append(srcc)
  
  # Return the average SRCC value over the list
  return np.mean(srcc_list)

# Define the function to compute the Pearson's linear correlation coefficient (PLCC) between two distributions
def compute_plcc(outputs, labels):
   # Convert the outputs and labels to numpy arrays
   outputs = outputs.cpu().detach().numpy()
   labels = labels.cpu().numpy()
   
   # Initialize an empty list to store the PLCC values
   plcc_list = []
   
   # Loop over the outputs and labels
   for output, label in zip(outputs, labels):
     # Create two discrete distributions from the output and label
     # The output is already a probability distribution of length 10
     # The label is a single integer from 0 to 9, so we create a one-hot vector of length 10
     output_dist = output
     label_dist = np.zeros(10)
     label_dist[label] = 1
     
     # Compute the PLCC between the