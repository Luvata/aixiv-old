---
title: 2207.14288v1 Rewriting Geometric Rules of a GAN
date: 2022-07-15
---

# [Rewriting Geometric Rules of a GAN](http://arxiv.org/abs/2207.14288v1)

authors: Sheng-Yu Wang, David Bau, Jun-Yan Zhu


## What, Why and How

[1]: https://arxiv.org/abs/2207.14288v1 "[2207.14288v1] Rewriting Geometric Rules of a GAN - arXiv.org"
[2]: http://export.arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv"
[3]: https://arxiv.org/pdf/2207.14288v1.pdf "arXiv.org e-Print archive"

Here is a summary of the paper:

```
What: The paper proposes a method to edit a generative adversarial network (GAN) by changing the geometric rules of its outputs, such as stretching, bending, or twisting objects.

Why: The paper aims to enable users to create novel and diverse visual content that goes beyond the data distribution and everyday experience, without the need to collect a large-scale dataset or train a new model from scratch.

How: The paper uses a low-rank update to a single model layer to reconstruct edited examples, and a latent space augmentation method based on style-mixing to prevent overfitting. The paper also shows how edited models can be composed to achieve aggregated effects, and presents an interactive interface for users to create new models through composition. The paper evaluates the method on various test cases and applications, such as latent space interpolation and image editing.
```

## Main Contributions

[1]: https://arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv.org"
[2]: http://export.arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv"
[3]: https://arxiv.org/pdf/2207.14288v1.pdf "arXiv.org e-Print archive"

The paper claims to make the following contributions:

- A method to edit a GAN by applying a low-rank update to a single model layer to reconstruct edited examples with desired geometric changes.
- A latent space augmentation method based on style-mixing to prevent overfitting and improve the diversity and quality of the edited model outputs.
- A demonstration of how edited models can be composed to achieve aggregated effects, such as combining stretching and bending operations.
- An interactive interface for users to create new models through composition by editing and selecting model outputs.
- An evaluation of the method on various test cases and applications, such as latent space interpolation and image editing, and a comparison with recent GAN fine-tuning methods.

## Method Summary

[1]: https://arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv.org"
[2]: http://export.arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv"
[3]: https://arxiv.org/pdf/2207.14288v1.pdf "arXiv.org e-Print archive"

Here is a summary of the method section:

```
The method consists of three main steps: editing, updating, and augmenting.

Editing: The user edits a few original model outputs with desired geometric changes, such as stretching, bending, or twisting objects. The user can also select some unedited outputs as references. The edited and reference outputs are then fed into an encoder network to obtain their latent codes.

Updating: The method applies a low-rank update to a single model layer (the style layer) to reconstruct the edited and reference outputs. The low-rank update is computed by solving a least-squares problem that minimizes the reconstruction error and the Frobenius norm of the update matrix. The updated model can then generate new outputs with similar geometric changes as the edited ones.

Augmenting: To prevent overfitting and improve the diversity and quality of the updated model outputs, the method proposes a latent space augmentation method based on style-mixing. The method randomly mixes the latent codes of two different outputs, one from the original model and one from the updated model, and feeds them into the updated model. The style-mixing operation can be applied at different resolutions to control the level of geometric changes.
```

## Pseudo Code - High level

[1]: https://arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv.org"
[2]: http://export.arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv"
[3]: https://arxiv.org/pdf/2207.14288v1.pdf "arXiv.org e-Print archive"

Here is a high-level pseudo code for the paper:

```
# Input: a GAN model G, a set of edited outputs E, a set of reference outputs R
# Output: an updated GAN model G'

# Step 1: Editing
# Encode the edited and reference outputs into latent codes using an encoder network
Z_E = encode(E)
Z_R = encode(R)

# Step 2: Updating
# Apply a low-rank update to the style layer of G to reconstruct E and R
U = solve_least_squares(G, Z_E, Z_R, E, R) # U is the update matrix
G' = update_style_layer(G, U) # G' is the updated model

# Step 3: Augmenting
# Randomly mix the latent codes of two different outputs, one from G and one from G', and feed them into G'
for i in range(num_samples):
  z_1 = sample_from(G) # z_1 is a latent code from the original model
  z_2 = sample_from(G') # z_2 is a latent code from the updated model
  z_mix = style_mix(z_1, z_2) # z_mix is a mixed latent code
  x_mix = G'(z_mix) # x_mix is an output from the updated model with mixed style
  save(x_mix) # save the output for evaluation or application
```

## Pseudo Code - Detail

[1]: https://arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv.org"
[2]: http://export.arxiv.org/abs/2207.14288 "[2207.14288] Rewriting Geometric Rules of a GAN - arXiv"
[3]: https://arxiv.org/pdf/2207.14288v1.pdf "arXiv.org e-Print archive"

Here is a detailed pseudo code to implement the paper:

```
# Input: a GAN model G, a set of edited outputs E, a set of reference outputs R
# Output: an updated GAN model G'

# Step 1: Editing
# Define an encoder network E that maps an output image x to a latent code z
E = Encoder()

# Encode the edited and reference outputs into latent codes using E
Z_E = E(E)
Z_R = E(R)

# Step 2: Updating
# Define the style layer of G as S, which is a linear transformation of z
S = Linear()

# Define a function F that takes a latent code z and returns the output image x using G
F = lambda z: G(S(z))

# Define a function L that computes the reconstruction loss between two images x and y
L = lambda x, y: mean_squared_error(x, y)

# Define a function U that computes the low-rank update matrix for S by solving a least-squares problem
U = lambda Z_E, Z_R, E, R: argmin_U sum(L(F(Z_E + U), E) + L(F(Z_R + U), R)) + lambda * norm(U)

# Compute the update matrix U using Z_E, Z_R, E, and R
U = U(Z_E, Z_R, E, R)

# Update the style layer S by adding U to its weight matrix W
W = W + U

# Update the model G by replacing S with the updated style layer
G' = replace_style_layer(G, S)

# Step 3: Augmenting
# Define a function M that randomly mixes two latent codes z_1 and z_2 at different resolutions r
M = lambda z_1, z_2, r: concatenate(z_1[:r], z_2[r:])

# Sample some latent codes from the original model G and the updated model G'
Z_G = sample_from(G, num_samples)
Z_G' = sample_from(G', num_samples)

# Mix the latent codes from Z_G and Z_G' using M and feed them into G'
for i in range(num_samples):
  z_1 = Z_G[i]
  z_2 = Z_G'[i]
  r = random(0, len(z_1)) # r is a random resolution index
  z_mix = M(z_1, z_2, r) # z_mix is a mixed latent code
  x_mix = G'(z_mix) # x_mix is an output from the updated model with mixed style
  save(x_mix) # save the output for evaluation or application
```