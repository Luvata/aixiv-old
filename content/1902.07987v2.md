---
title: 1902.07987v2 Learning representations of irregular particle-detector geometry with distance-weighted graph networks
date: 2019-02-08
---

# [Learning representations of irregular particle-detector geometry with distance-weighted graph networks](http://arxiv.org/abs/1902.07987v2)

authors: Shah Rukh Qasim, Jan Kieseler, Yutaro Iiyama, Maurizio Pierini


## What, Why and How

[1]: https://arxiv.org/pdf/1902.07987v2.pdf "Learning representations of irregular particle-detector geometry with ..."
[2]: https://arxiv.org/abs/1902.07987 "[1902.07987] Learning representations of irregular particle-detector ..."
[3]: http://export.arxiv.org/abs/1902.07987 "[1902.07987] Learning representations of irregular particle-detector ..."

Here is a summary of the paper:

- **What**: The paper introduces two new graph network architectures, GarNet and GravNet, to deal with irregular-geometry detectors in particle reconstruction tasks.
- **Why**: The paper aims to overcome the limitations of existing methods that rely on fixed detector geometries or regular grids, and to exploit the full detector granularity and sparsity in a flexible and efficient way.
- **How**: The paper applies the new architectures to a toy model of a highly granular calorimeter, inspired by the CMS endcap calorimeter for the High-Luminosity LHC phase. The paper compares the performance of the new methods with alternative approaches, such as PointNet and Dynamic Graph CNN, on clustering energy depositions, which is the basis for calorimetric particle reconstruction. The paper shows that the new methods offer equally performing or less resource-demanding solutions with less underlying assumptions on the detector geometry.

## Main Contributions

The paper claims to make the following contributions:

- It proposes two new graph network architectures, GarNet and GravNet, that use distance-weighted aggregation functions to learn representations of irregular-geometry detectors.
- It demonstrates the applicability of the new architectures to a realistic particle reconstruction task on a toy model of a highly granular calorimeter.
- It provides a quantitative comparison of the new methods with existing approaches, such as PointNet and Dynamic Graph CNN, on clustering energy depositions.
- It shows that the new methods can generalize to other detectors and geometries without requiring additional tuning or preprocessing.

## Method Summary

[1]: https://arxiv.org/pdf/1902.07987v2.pdf "Learning representations of irregular particle-detector geometry with ..."
[2]: https://arxiv.org/abs/1902.07987 "[1902.07987] Learning representations of irregular particle-detector ..."
[3]: http://export.arxiv.org/abs/1901.07987v2 "[1901.07987v2] Stein Variational Online Changepoint Detection with ..."

Here is a summary of the method section of the paper:

- The paper describes two new graph network architectures, GarNet and GravNet, that use distance-weighted aggregation functions to learn representations of irregular-geometry detectors.
- GarNet layers aggregate information from neighboring nodes based on a learned distance metric and a fixed number of nearest neighbors. GravNet layers use a gravitational analogy to assign weights to neighboring nodes based on their distance and mass (a learned scalar feature).
- The paper applies the new architectures to a toy model of a highly granular calorimeter, where each cell is represented by a node with features such as position, energy, and time. The paper uses simulated data of particle interactions with different types and energies.
- The paper defines the clustering task as assigning each node to one of K clusters, where K is unknown and varies for each event. The paper uses a softmax function to assign cluster probabilities to each node, and a learned scalar feature to predict the number of clusters.
- The paper trains the models using a loss function that combines cross-entropy for cluster assignment and mean squared error for cluster number prediction. The paper uses gradient-based optimization with Adam and early stopping.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define GarNet layer
def GarNet(input_features, num_neighbors, num_aggregators):
  # Compute pairwise distances between nodes
  distances = pairwise_distance(input_features)
  # Find the nearest neighbors for each node
  neighbors = find_nearest_neighbors(distances, num_neighbors)
  # Compute distance weights using a learned metric
  weights = distance_weights(distances, neighbors)
  # Aggregate features from neighbors using a learned linear transformation
  aggregated_features = linear_aggregation(input_features, neighbors, weights, num_aggregators)
  # Concatenate input and aggregated features
  output_features = concatenate(input_features, aggregated_features)
  return output_features

# Define GravNet layer
def GravNet(input_features, num_neighbors):
  # Compute pairwise distances between nodes
  distances = pairwise_distance(input_features)
  # Compute mass features using a learned linear transformation
  masses = linear_mass(input_features)
  # Compute gravitational weights using a learned metric and mass features
  weights = gravitational_weights(distances, masses)
  # Aggregate features from neighbors using a learned linear transformation
  aggregated_features = linear_aggregation(input_features, neighbors, weights, num_neighbors)
  # Concatenate input and aggregated features
  output_features = concatenate(input_features, aggregated_features)
  return output_features

# Define the model architecture
def model(input_nodes):
  # Apply GarNet or GravNet layers to input nodes
  hidden_nodes = GarNet(input_nodes, num_neighbors=10, num_aggregators=4) or GravNet(input_nodes, num_neighbors=16)
  # Apply nonlinear activation function
  hidden_nodes = relu(hidden_nodes)
  # Apply batch normalization
  hidden_nodes = batch_norm(hidden_nodes)
  # Apply dropout
  hidden_nodes = dropout(hidden_nodes)
  # Repeat the above steps for a desired number of layers
  ...
  # Apply a final linear transformation to get cluster probabilities and cluster number prediction
  cluster_probs, cluster_number = linear_output(hidden_nodes)
  return cluster_probs, cluster_number

# Define the loss function
def loss(cluster_probs, cluster_number, true_labels, true_number):
  # Compute cross-entropy loss for cluster assignment
  ce_loss = cross_entropy(cluster_probs, true_labels)
  # Compute mean squared error loss for cluster number prediction
  mse_loss = mean_squared_error(cluster_number, true_number)
  # Combine the two losses with a weight factor
  total_loss = ce_loss + weight * mse_loss
  return total_loss

# Train the model using gradient-based optimization
def train(model, data, optimizer):
  # Loop over the data in batches
  for batch in data:
    # Get the input nodes and the true labels and number of clusters
    input_nodes, true_labels, true_number = batch
    # Forward pass the model to get the predictions
    cluster_probs, cluster_number = model(input_nodes)
    # Compute the loss
    loss = loss(cluster_probs, cluster_number, true_labels, true_number)
    # Backward pass the model to compute the gradients
    gradients = backward(loss)
    # Update the model parameters using the optimizer
    optimizer.step(gradients)
    # Optionally apply early stopping based on validation loss
    ...
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import tensorflow as tf

# Define GarNet layer
class GarNet(tf.keras.layers.Layer):
  def __init__(self, num_neighbors, num_aggregators):
    super(GarNet, self).__init__()
    # Initialize the parameters for distance metric and linear aggregation
    self.distance_metric = tf.Variable(tf.random.normal(shape=[1]))
    self.linear_aggregation = tf.keras.layers.Dense(num_aggregators)

  def call(self, input_features):
    # Compute pairwise distances between nodes using Euclidean distance
    distances = tf.norm(tf.expand_dims(input_features, axis=1) - tf.expand_dims(input_features, axis=0), axis=-1)
    # Find the nearest neighbors for each node using top-k operation
    _, neighbors = tf.math.top_k(-distances, k=num_neighbors)
    # Compute distance weights using a learned metric and softmax function
    weights = tf.math.exp(-self.distance_metric * distances)
    weights = tf.gather(weights, neighbors, batch_dims=1)
    weights = tf.nn.softmax(weights, axis=-1)
    # Aggregate features from neighbors using a learned linear transformation and sum operation
    features = tf.gather(input_features, neighbors, batch_dims=1)
    features = self.linear_aggregation(features)
    aggregated_features = tf.math.reduce_sum(features * weights, axis=-2)
    # Concatenate input and aggregated features
    output_features = tf.concat([input_features, aggregated_features], axis=-1)
    return output_features

# Define GravNet layer
class GravNet(tf.keras.layers.Layer):
  def __init__(self, num_neighbors):
    super(GravNet, self).__init__()
    # Initialize the parameters for mass feature and gravitational weight
    self.mass_feature = tf.keras.layers.Dense(1)
    self.gravitational_weight = tf.Variable(tf.random.normal(shape=[1]))
    # Initialize the parameters for linear aggregation
    self.linear_aggregation = tf.keras.layers.Dense(num_neighbors)

  def call(self, input_features):
    # Compute pairwise distances between nodes using Euclidean distance
    distances = tf.norm(tf.expand_dims(input_features, axis=1) - tf.expand_dims(input_features, axis=0), axis=-1)
    # Compute mass features using a learned linear transformation and sigmoid function
    masses = self.mass_feature(input_features)
    masses = tf.nn.sigmoid(masses)
    # Compute gravitational weights using a learned metric and mass features
    weights = self.gravitational_weight * masses * tf.transpose(masses) / (distances + 1e-3)
    # Aggregate features from neighbors using a learned linear transformation and sum operation
    features = self.linear_aggregation(input_features)
    aggregated_features = tf.math.reduce_sum(features * weights, axis=-2)
    # Concatenate input and aggregated features
    output_features = tf.concat([input_features, aggregated_features], axis=-1)
    return output_features

# Define the model architecture
class Model(tf.keras.Model):
  def __init__(self):
    super(Model, self).__init__()
    # Define the number of layers and hidden units for each layer
    self.num_layers = 4
    self.hidden_units = [64, 128, 256, 512]
    # Define the number of neighbors and aggregators for GarNet layers
    self.num_neighbors_garnet = [10, 10, 10, 10]
    self.num_aggregators_garnet = [4, 4, 4, 4]
    # Define the number of neighbors for GravNet layers
    self.num_neighbors_gravnet = [16, 16, 16, 16]
    # Define the dropout rate for each layer
    self.dropout_rate = [0.2, 0.2, 0.2, 0.2]
    # Define the weight factor for cluster number loss
    self.weight_factor = 0.01
    # Define the list of layers for the model
    self.layers_list = []
    
    # Loop over the number of layers
    for i in range(self.num_layers):
      # Choose between GarNet or GravNet layer randomly
      if np.random.rand() < 0.5:
        # Add a GarNet layer with the corresponding parameters
        self.layers_list.append(GarNet(self.num_neighbors_garnet[i], self.num_aggregators_garnet[i]))
      else:
        # Add a GravNet layer with the corresponding parameters
        self.layers_list.append(GravNet(self.num_neighbors_gravnet[i]))
      # Add a nonlinear activation function (ReLU)
      self.layers_list.append(tf.keras.layers.ReLU())
      # Add a batch normalization layer
      self.layers_list.append(tf.keras.layers.BatchNormalization())
      # Add a dropout layer
      self.layers_list.append(tf.keras.layers.Dropout(self.dropout_rate[i]))
    
    # Add a final linear layer to get cluster probabilities and cluster number prediction
    self.output_layer = tf.keras.layers.Dense(K + 1)

  def call(self, input_nodes):
    # Loop over the list of layers and apply them to the input nodes
    hidden_nodes = input_nodes
    for layer in self.layers_list:
      hidden_nodes = layer(hidden_nodes)
    # Apply the output layer to get the logits
    logits = self.output_layer(hidden_nodes)
    # Split the logits into cluster probabilities and cluster number prediction
    cluster_probs = tf.nn.softmax(logits[:, :-1], axis=-1)
    cluster_number = tf.nn.sigmoid(logits[:, -1])
    return cluster_probs, cluster_number

  def loss(self, cluster_probs, cluster_number, true_labels, true_number):
    # Compute cross-entropy loss for cluster assignment
    ce_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(true_labels, cluster_probs)
    ce_loss = tf.math.reduce_mean(ce_loss)
    # Compute mean squared error loss for cluster number prediction
    mse_loss = tf.math.squared_difference(true_number, cluster_number)
    mse_loss = tf.math.reduce_mean(mse_loss)
    # Combine the two losses with a weight factor
    total_loss = ce_loss + self.weight_factor * mse_loss
    return total_loss

# Load the data from a file or generate it using simulation
data = load_data(file_name) or generate_data(parameters)

# Initialize the model and the optimizer
model = Model()
optimizer = tf.keras.optimizers.Adam(learning_rate)

# Train the model using gradient-based optimization
def train(model, data, optimizer):
  # Loop over the data in batches
  for batch in data:
    # Get the input nodes and the true labels and number of clusters
    input_nodes, true_labels, true_number = batch
    # Use gradient tape to record the gradients
    with tf.GradientTape() as tape:
      # Forward pass the model to get the predictions
      cluster_probs, cluster_number = model(input_nodes)
      # Compute the loss
      loss = model.loss(cluster_probs, cluster_number, true_labels, true_number)
    # Get the gradients from the tape
    gradients = tape.gradient(loss, model.trainable_variables)
    # Update the model parameters using the optimizer
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    # Optionally apply early stopping based on validation loss
    ...
```