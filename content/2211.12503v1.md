---
title: 2211.12503v1 Is the Elephant Flying? Resolving Ambiguities in Text-to-Image Generative Models
date: 2022-11-13
---

# [Is the Elephant Flying? Resolving Ambiguities in Text-to-Image Generative Models](http://arxiv.org/abs/2211.12503v1)

authors: Ninareh Mehrabi, Palash Goyal, Apurv Verma, Jwala Dhamala, Varun Kumar, Qian Hu, Kai-Wei Chang, Richard Zemel, Aram Galstyan, Rahul Gupta


## What, Why and How

[1]: https://arxiv.org/abs/2211.12503 "[2211.12503] Is the Elephant Flying? Resolving Ambiguities in Text-to ..."
[2]: https://arxiv.org/pdf/2211.12503v1.pdf "Abstract - arXiv.org"
[3]: http://export.arxiv.org/abs/2201.12503v1 "[2201.12503v1] Polygon recutting as a cluster integrable system"

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper studies ambiguities that arise in text-to-image generative models and proposes a framework to mitigate them by soliciting clarifications from the user.
- **Why**: The paper argues that ambiguities can lead to misinterpretation and miscommunication in natural language and can result in undesired outcomes and poor user experience in text-to-image generative models. The paper also claims that ambiguities can pose a challenge for fairness of the underlying models.
- **How**: The paper curates a benchmark dataset covering different types of ambiguities that occur in text-to-image generative models, such as syntactic, semantic, and underspecification ambiguities. The paper then develops a framework that leverages natural language inference and common-sense knowledge to detect ambiguities in the prompts given to the systems and to generate clarifying questions for the user. The paper evaluates the framework using automatic and human metrics and shows that it can generate more faithful images aligned with human intention in the presence of ambiguities.

## Main Contributions

According to the paper at , the main contributions are:

- A novel benchmark dataset for studying ambiguities in text-to-image generative models, covering different types of ambiguities and diverse domains.
- A framework for mitigating ambiguities in text-to-image generative models by detecting ambiguities and soliciting clarifications from the user using natural language inference and common-sense knowledge.
- An extensive evaluation of the framework using automatic and human metrics, demonstrating its effectiveness in generating more faithful images aligned with human intention in the presence of ambiguities.

## Method Summary

[1]: https://arxiv.org/abs/2211.12503 "[2211.12503] Is the Elephant Flying? Resolving Ambiguities in Text-to ..."
[2]: https://arxiv.org/pdf/2211.12503v1.pdf "Abstract - arXiv.org"
[3]: http://export.arxiv.org/abs/2201.12503v1 "[2201.12503v1] Polygon recutting as a cluster integrable system"

Here is a summary of the method section of the paper at [^1^][1]:

- The paper presents a framework for mitigating ambiguities in text-to-image generative models by detecting ambiguities and soliciting clarifications from the user.
- The framework consists of three main components: an **ambiguity detector**, a **clarification generator**, and an **image generator**.
- The **ambiguity detector** takes a prompt as input and determines whether it is ambiguous or not using natural language inference and common-sense knowledge. It also identifies the type and source of ambiguity (e.g., syntactic, semantic, or underspecification).
- The **clarification generator** takes an ambiguous prompt as input and generates a clarifying question for the user based on the type and source of ambiguity. It also provides a set of possible answers for the user to choose from.
- The **image generator** takes a prompt and an optional clarification as input and generates an image using a pre-trained text-to-image generative model. It also ensures that the image is consistent with the clarification if provided.


## Pseudo Code - High level

Here is the high-level pseudo code for the paper at :

```python
# Input: a prompt p
# Output: an image i

# Define an ambiguity detector AD
# Define a clarification generator CG
# Define an image generator IG

# Check if the prompt is ambiguous using AD
a = AD(p)

# If the prompt is ambiguous, generate a clarifying question and possible answers using CG
if a:
  q, ans = CG(p)

  # Ask the user to choose an answer from the possible answers
  print(q)
  print(ans)
  c = input("Please choose an answer: ")

  # Generate an image using IG with the prompt and the clarification
  i = IG(p, c)

# If the prompt is not ambiguous, generate an image using IG with the prompt only
else:
  i = IG(p)

# Return the image
return i
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper at :

```python
# Input: a prompt p
# Output: an image i

# Define an ambiguity detector AD
# Define a clarification generator CG
# Define an image generator IG

# Define a natural language inference model NLI
# Define a common-sense knowledge base KB
# Define a text-to-image generative model T2I

# Define a set of ambiguity types T = {syntactic, semantic, underspecification}
# Define a set of ambiguity sources S = {pronoun, modifier, noun, verb, preposition}

# Define a function to detect ambiguity using NLI and KB
def AD(p):
  # For each type t in T
  for t in T:
    # Generate a set of alternative interpretations I_t for p based on t
    I_t = generate_interpretations(p, t)

    # For each interpretation i in I_t
    for i in I_t:
      # Use NLI to check if i entails p
      e = NLI(i, p)

      # If i does not entail p, return True and t as ambiguous and type
      if not e:
        return True, t

  # For each source s in S
  for s in S:
    # Generate a set of alternative meanings M_s for p based on s
    M_s = generate_meanings(p, s)

    # For each meaning m in M_s
    for m in M_s:
      # Use KB to check if m is plausible for p
      pl = KB(m, p)

      # If m is not plausible for p, return True and s as ambiguous and source
      if not pl:
        return True, s

  # If no ambiguity is detected, return False and None as ambiguous and type/source
  return False, None

# Define a function to generate clarifying questions and possible answers using NLI and KB
def CG(p):
  # Get the ambiguity status and type/source from AD
  a, ts = AD(p)

  # If the prompt is ambiguous
  if a:
    # Generate a clarifying question q based on ts
    q = generate_question(p, ts)

    # Generate a set of possible answers ans based on ts
    ans = generate_answers(p, ts)

    # Return q and ans
    return q, ans

  # If the prompt is not ambiguous, return None and None as q and ans
  else:
    return None, None

# Define a function to generate images using T2I
def IG(p, c=None):
  # If a clarification is provided
  if c:
    # Concatenate the prompt and the clarification with a separator token
    pc = p + "[SEP]" + c

    # Generate an image i using T2I with pc as input
    i = T2I(pc)

  # If no clarification is provided
  else:
    # Generate an image i using T2I with p as input
    i = T2I(p)

  # Return i
  return i

# Check if the prompt is ambiguous using AD
a = AD(p)

# If the prompt is ambiguous, generate a clarifying question and possible answers using CG
if a:
  q, ans = CG(p)

  # Ask the user to choose an answer from the possible answers
  print(q)
  print(ans)
  c = input("Please choose an answer: ")

  # Generate an image using IG with the prompt and the clarification
  i = IG(p, c)

# If the prompt is not ambiguous, generate an image using IG with the prompt only
else:
  i = IG(p)

# Return the image
return i

```