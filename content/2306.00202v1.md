---
title: 2306.00202v1 Building Manufacturing Deep Learning Models with Minimal and Imbalanced Training Data Using Domain Adaptation and Data Augmentation
date: 2023-06-01
---

# [Building Manufacturing Deep Learning Models with Minimal and Imbalanced Training Data Using Domain Adaptation and Data Augmentation](http://arxiv.org/abs/2306.00202v1)

authors: Adrian Shuai Li, Elisa Bertino, Rih-Teng Wu, Ting-Yan Wu


## What, Why and How

[1]: https://arxiv.org/pdf/2306.00202.pdf "Building Manufacturing Deep Learning Models with Minimal ... - arXiv.org"
[2]: https://arxiv.org/abs/2304.00202 "Improving Fast Adversarial Training with Prior-Guided Knowledge"
[3]: http://export.arxiv.org/abs/2306.00202 "[2306.00202] Building Manufacturing Deep Learning Models with Minimal ..."

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a novel domain adaptation (DA) approach to build manufacturing deep learning models with minimal and imbalanced training data using domain adaptation and data augmentation.
- **Why**: The paper addresses the problem of labeled training data scarcity for a target learning task by transferring knowledge gained from an existing source dataset used for a similar learning task. The paper also addresses the problem of imbalanced target datasets by using an autoencoder-based data augmentation approach.
- **How**: The paper combines the DA approach with the data augmentation approach to train deep learning models for defect detection from images. The paper evaluates the proposed approach using image data for wafer defect prediction and shows its superior performance against other algorithms.

## Main Contributions

[1]: https://arxiv.org/pdf/2306.00202.pdf "Building Manufacturing Deep Learning Models with Minimal ... - arXiv.org"
[2]: https://arxiv.org/abs/2304.00202 "Improving Fast Adversarial Training with Prior-Guided Knowledge"
[3]: http://export.arxiv.org/abs/2306.00202 "[2306.00202] Building Manufacturing Deep Learning Models with Minimal ..."

According to the paper at [^1^][1], the main contributions are:

- **A novel DA approach** that works for scenarios where the source dataset and the target dataset have same or different feature spaces. The approach leverages a pre-trained model from the source domain and fine-tunes it on the target domain with a novel loss function that balances the source and target distributions.
- **An autoencoder-based data augmentation approach** that generates synthetic samples for the minority classes in the target domain to address the class imbalance problem. The approach uses an autoencoder to learn a latent representation of the target data and then samples from the latent space to create new samples.
- **A comprehensive evaluation** of the proposed approach using image data for wafer defect prediction. The paper compares the proposed approach with other algorithms and shows its superior performance in terms of accuracy, precision, recall, and F1-score when the number of labeled samples in the target domain is significantly small and the target domain is imbalanced.

## Method Summary

[1]: https://arxiv.org/pdf/2306.00202.pdf "Building Manufacturing Deep Learning Models with Minimal ... - arXiv.org"
[2]: https://arxiv.org/abs/2304.00202 "Improving Fast Adversarial Training with Prior-Guided Knowledge"
[3]: http://export.arxiv.org/abs/2306.00202 "[2306.00202] Building Manufacturing Deep Learning Models with Minimal ..."

Here is a summary of the method section of the paper at [^1^][1]:

- The paper proposes a **domain adaptation (DA) approach** that consists of two steps: **feature alignment** and **label alignment**. Feature alignment aims to reduce the feature distribution discrepancy between the source and target domains by using a pre-trained model from the source domain and fine-tuning it on the target domain with a novel loss function that balances the source and target distributions. Label alignment aims to assign pseudo labels to the unlabeled target samples by using a confidence threshold and a voting mechanism.
- The paper also proposes an **autoencoder-based data augmentation approach** that generates synthetic samples for the minority classes in the target domain to address the class imbalance problem. The approach uses an autoencoder to learn a latent representation of the target data and then samples from the latent space to create new samples. The approach also uses a discriminator to ensure that the synthetic samples are realistic and consistent with the original data distribution.
- The paper evaluates the proposed approach using image data for **wafer defect prediction**. The paper uses two datasets: one from a public benchmark (SECOM) and one from a real-world wafer manufacturing company (WAFER). The paper compares the proposed approach with other algorithms, such as transfer learning, few-shot learning, and self-training, and shows its superior performance in terms of accuracy, precision, recall, and F1-score when the number of labeled samples in the target domain is significantly small and the target domain is imbalanced.

## Pseudo Code

Here is a possible pseudo code to implement the paper at :

```python
# Import libraries
import torch
import torchvision
import numpy as np
import sklearn
import imblearn

# Define hyperparameters
source_domain = "SECOM" # or "WAFER"
target_domain = "WAFER" # or "SECOM"
num_classes = 2 # number of defect classes
num_epochs = 50 # number of training epochs
batch_size = 32 # batch size for training and testing
learning_rate = 0.01 # learning rate for optimizer
weight_decay = 0.0005 # weight decay for optimizer
momentum = 0.9 # momentum for optimizer
threshold = 0.9 # confidence threshold for pseudo labeling
alpha = 0.1 # trade-off parameter for feature alignment loss
beta = 0.1 # trade-off parameter for label alignment loss

# Load source and target datasets
source_data = load_data(source_domain) # load data from source domain
target_data = load_data(target_domain) # load data from target domain
source_train, source_test = split_data(source_data) # split source data into train and test sets
target_train, target_test = split_data(target_data) # split target data into train and test sets
source_train_loader = create_dataloader(source_train, batch_size) # create dataloader for source train set
source_test_loader = create_dataloader(source_test, batch_size) # create dataloader for source test set
target_train_loader = create_dataloader(target_train, batch_size) # create dataloader for target train set
target_test_loader = create_dataloader(target_test, batch_size) # create dataloader for target test set

# Define model, optimizer, and loss functions
model = torchvision.models.resnet18(pretrained=True) # use a pre-trained ResNet-18 model as the feature extractor and classifier
model.fc = torch.nn.Linear(model.fc.in_features, num_classes) # replace the last layer with a new linear layer for num_classes output
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum) # use stochastic gradient descent as the optimizer
criterion_ce = torch.nn.CrossEntropyLoss() # use cross entropy loss as the classification loss
criterion_mmd = mmd_loss() # use maximum mean discrepancy as the feature alignment loss

# Define autoencoder and discriminator for data augmentation
autoencoder = AutoEncoder() # define an autoencoder model that consists of an encoder and a decoder
discriminator = Discriminator() # define a discriminator model that distinguishes between real and synthetic samples
optimizer_ae = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate) # use Adam as the optimizer for autoencoder
optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=learning_rate) # use Adam as the optimizer for discriminator
criterion_ae = torch.nn.MSELoss() # use mean squared error as the reconstruction loss for autoencoder
criterion_d = torch.nn.BCELoss() # use binary cross entropy as the adversarial loss for discriminator

# Train the model using domain adaptation and data augmentation
for epoch in range(num_epochs):
  # Train the model on source and target domains
  model.train() # set the model to training mode
  for (source_x, source_y), (target_x, _) in zip(source_train_loader, target_train_loader):
    source_x = source_x.to(device) # move source input to device (CPU or GPU)
    source_y = source_y.to(device) # move source label to device (CPU or GPU)
    target_x = target_x.to(device) # move target input to device (CPU or GPU)
    optimizer.zero_grad() # clear the gradients of the model parameters
    
    # Forward pass on source and target domains
    source_output = model(source_x) # get the output of the model on source input
    target_output = model(target_x) # get the output of the model on target input
    
    # Compute classification loss on source domain
    loss_ce = criterion_ce(source_output, source_y) # compute cross entropy loss on source output and label
    
    # Compute feature alignment loss on source and target domains using MMD
    loss_mmd = criterion_mmd(source_output, target_output) # compute MMD loss on source and target outputs
    
    # Compute label alignment loss on target domain using pseudo labeling and voting mechanism
    prob_target_output = torch.nn.functional.softmax(target_output, dim=1) # compute softmax probability on target output 
    max_prob_target_output, pseudo_target_y = torch.max(prob_target_output, dim=1) # get the maximum probability and the corresponding pseudo label for each target sample
    mask = max_prob_target_output > threshold # create a mask for the target samples that have high confidence pseudo labels
    pseudo_target_x = target_x[mask] # select the target samples that have high confidence pseudo labels
    pseudo_target_y = pseudo_target_y[mask] # select the pseudo labels that have high confidence
    pseudo_target_output = model(pseudo_target_x) # get the output of the model on the selected target samples
    loss_pl = criterion_ce(pseudo_target_output, pseudo_target_y) # compute cross entropy loss on the selected target output and pseudo label
    loss_vote = voting_loss(target_output, pseudo_target_y) # compute voting loss on the target output and pseudo label
    
    # Compute total loss as a weighted sum of classification, feature alignment, and label alignment losses
    loss = loss_ce + alpha * loss_mmd + beta * (loss_pl + loss_vote) # compute total loss
    
    # Backward pass and update the model parameters
    loss.backward() # compute the gradients of the model parameters
    optimizer.step() # update the model parameters
  
  # Train the autoencoder and discriminator on target domain using imbalanced data
  autoencoder.train() # set the autoencoder to training mode
  discriminator.train() # set the discriminator to training mode
  for target_x, target_y in target_train_loader:
    target_x = target_x.to(device) # move target input to device (CPU or GPU)
    target_y = target_y.to(device) # move target label to device (CPU or GPU)
    
    # Forward pass on autoencoder
    latent_x, recon_x = autoencoder(target_x) # get the latent representation and reconstruction of the target input
    
    # Compute reconstruction loss on autoencoder
    loss_ae = criterion_ae(recon_x, target_x) # compute MSE loss on reconstruction and target input
    
    # Backward pass and update the autoencoder parameters
    optimizer_ae.zero_grad() # clear the gradients of the autoencoder parameters
    loss_ae.backward() # compute the gradients of the autoencoder parameters
    optimizer_ae.step() # update the autoencoder parameters
    
    # Sample from latent space to generate synthetic samples for minority classes
    synthetic_x, synthetic_y = sample_from_latent_space(latent_x, target_y, num_classes) # sample synthetic samples and labels from latent space using imblearn library
    
    # Forward pass on discriminator for real and synthetic samples
    real_d = discriminator(target_x) # get the discriminator output for real samples
    synthetic_d = discriminator(synthetic_x) # get the discriminator output for synthetic samples
    
    # Compute adversarial loss on discriminator
    real_label = torch.ones(real_d.size()).to(device) # create real labels for real samples
    synthetic_label = torch.zeros(synthetic_d.size()).to(device) # create synthetic labels for synthetic samples
    loss_d_real = criterion_d(real_d, real_label) # compute BCE loss on real output and label
    loss_d_synthetic = criterion_d(synthetic_d, synthetic_label) # compute BCE loss on synthetic output and label
    loss_d = (loss_d_real + loss_d_synthetic) / 2 # compute average BCE loss
    
    # Backward pass and update the discriminator parameters
    optimizer_d.zero_grad() # clear the gradients of the discriminator parameters
    loss_d.backward() # compute the gradients of the discriminator parameters
    optimizer_d.step() # update the discriminator parameters
  
  # Test the model on source and target domains
  model.eval() # set the model to evaluation mode
  source_acc, source_prec, source_rec, source_f1 = test_model(model, source_test_loader) # test the model on source test set and get accuracy, precision, recall, and F1-score
  target_acc, target_prec, target_rec, target_f1 = test_model(model, target_test_loader) # test the model on target test set and get accuracy, precision, recall, and F1-score
  
  # Print the results for each epoch
  print(f"Epoch {epoch}:")
  print(f"Source domain: Accuracy={source_acc}, Precision={source_prec}, Recall={source_rec}, F1-score={source_f1}")
  print(f"Target domain: Accuracy={target_acc}, Precision={target_prec}, Recall={target_rec}, F1-score={target_f1}")
```