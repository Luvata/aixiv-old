---
title: 2006.06676v2 Training Generative Adversarial Networks with Limited Data
date: 2020-06-07
---

# [Training Generative Adversarial Networks with Limited Data](http://arxiv.org/abs/2006.06676v2)

authors: Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, Timo Aila


## What, Why and How

[1]: https://arxiv.org/abs/2006.06676 "Training Generative Adversarial Networks with Limited Data"
[2]: https://arxiv.org/pdf/2002.06676v2.pdf "Complex Photonic Systems (COPS), MESA+ Institute for ... - arXiv.org"
[3]: https://arxiv.org/pdf/2006.06676v2.pdf "arXiv.org e-Print archive"

Here is a summary of the paper:

- **What**: The paper is about training generative adversarial networks (GANs) with limited data, using an adaptive discriminator augmentation mechanism that stabilizes training and improves performance.
- **Why**: The paper aims to address the problem of discriminator overfitting, which causes training divergence and poor quality of generated images, when using too little data to train GANs. The paper also aims to open up new application domains for GANs that require only a few thousand training images, and to improve the state-of-the-art results on existing benchmarks such as CIFAR-10.
- **How**: The paper proposes a simple but effective technique that dynamically adjusts the probability and strength of applying various image augmentations to the real and fake samples fed to the discriminator during training. The augmentations include translation, rotation, cutout, color jittering, etc. The paper shows that this technique can significantly improve the stability and quality of GAN training in limited data regimes, both when training from scratch and when fine-tuning an existing GAN on another dataset. The paper also provides theoretical analysis and empirical evidence to support the proposed method.

The paper can be found at [^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/2006.06676 "Training Generative Adversarial Networks with Limited Data"
[2]: https://arxiv.org/pdf/2002.06676v2.pdf "Complex Photonic Systems (COPS), MESA+ Institute for ... - arXiv.org"
[3]: https://arxiv.org/pdf/2006.06676v2.pdf "arXiv.org e-Print archive"

The paper claims the following contributions:

- **A novel adaptive discriminator augmentation technique** that dynamically adjusts the probability and strength of applying various image augmentations to the discriminator inputs during GAN training, based on a heuristic that measures the difficulty of the discriminator task.
- **A theoretical analysis** that explains why the proposed technique can mitigate discriminator overfitting and improve the stability and quality of GAN training in limited data regimes, by increasing the effective diversity of the training data and reducing the gap between the real and fake data distributions.
- **An extensive empirical evaluation** that demonstrates the effectiveness of the proposed technique on several datasets, both synthetic and natural, with varying sizes and complexities, using different GAN architectures and loss functions. The paper also shows that the technique can be applied to fine-tune an existing GAN on another dataset, achieving state-of-the-art results with only a few thousand images.
- **A new perspective on CIFAR-10 as a limited data benchmark** that reveals that previous GAN methods have not fully exploited the potential of this dataset, and that the proposed technique can significantly improve the record FID score from 5.59 to 2.42.

The paper can be found at [^1^][1].

## Method Summary

[1]: https://arxiv.org/abs/2006.06676 "Training Generative Adversarial Networks with Limited Data"
[2]: https://arxiv.org/pdf/2002.06676v2.pdf "Complex Photonic Systems (COPS), MESA+ Institute for ... - arXiv.org"
[3]: https://arxiv.org/pdf/2006.06676v2.pdf "arXiv.org e-Print archive"

Here is a summary of the method section of the paper:

- The paper introduces a **discriminator augmentation** technique that applies various image augmentations to both real and fake samples before feeding them to the discriminator during GAN training. The augmentations include translation, rotation, cutout, color jittering, etc. The paper argues that these augmentations can increase the effective diversity of the training data and reduce the gap between the real and fake data distributions, thus mitigating discriminator overfitting and improving training stability and quality.
- The paper proposes an **adaptive augmentation mechanism** that dynamically adjusts the probability and strength of applying the augmentations based on a heuristic that measures the difficulty of the discriminator task. The heuristic is based on the ratio of the discriminator outputs for real and fake samples, which reflects how well the discriminator can distinguish them. The paper argues that this mechanism can balance the trade-off between data diversity and fidelity, and avoid applying too much or too little augmentation.
- The paper provides a **theoretical analysis** that explains why the proposed technique can improve GAN training in limited data regimes. The paper derives an upper bound on the Jensen-Shannon divergence between the real and fake data distributions, which depends on the amount of augmentation applied. The paper shows that by increasing the augmentation probability, the upper bound can be reduced, implying that the gap between the real and fake data distributions can be reduced. The paper also shows that by increasing the augmentation strength, the upper bound can be made tighter, implying that the approximation error can be reduced.
- The paper conducts an **extensive empirical evaluation** of the proposed technique on several datasets, both synthetic and natural, with varying sizes and complexities, using different GAN architectures and loss functions. The paper compares the proposed technique with several baselines and ablations, and measures the performance using various metrics such as FID, IS, PPL, etc. The paper also shows that the proposed technique can be applied to fine-tune an existing GAN on another dataset, achieving state-of-the-art results with only a few thousand images.

The paper can be found at [^1^][1].

## Pseudo Code - High level

[1]: https://arxiv.org/abs/2006.06676 "Training Generative Adversarial Networks with Limited Data"
[2]: https://arxiv.org/pdf/2002.06676v2.pdf "Complex Photonic Systems (COPS), MESA+ Institute for ... - arXiv.org"
[3]: https://arxiv.org/pdf/2006.06676v2.pdf "arXiv.org e-Print archive"

Here is the high-level pseudo code for the paper:

```python
# Define the generator and discriminator networks
G = Generator()
D = Discriminator()

# Define the loss function and optimizer
loss = GANLoss()
optimizer = Optimizer()

# Define the augmentation functions
augmentations = [translation, rotation, cutout, color_jittering, ...]

# Initialize the augmentation probability
p = 0

# Train the GAN for a fixed number of iterations
for i in range(iterations):

  # Sample a batch of real images from the dataset
  x_real = sample(dataset, batch_size)

  # Generate a batch of fake images from random noise
  z = sample(noise, batch_size)
  x_fake = G(z)

  # Apply augmentations to both real and fake images with probability p
  x_real_aug = augment(x_real, augmentations, p)
  x_fake_aug = augment(x_fake, augmentations, p)

  # Compute the discriminator outputs for real and fake images
  y_real = D(x_real_aug)
  y_fake = D(x_fake_aug)

  # Compute the generator and discriminator losses
  g_loss = loss(y_fake, target=1)
  d_loss = loss(y_real, target=1) + loss(y_fake, target=0)

  # Update the generator and discriminator parameters
  optimizer.step(g_loss, G.parameters())
  optimizer.step(d_loss, D.parameters())

  # Compute the ratio of discriminator outputs for real and fake images
  r_tilde = mean(y_real) / mean(y_fake)

  # Update the augmentation probability based on the ratio
  p = update(p, r_tilde)
```

The paper can be found at [^1^][1].

## Pseudo Code - Detail

[1]: https://arxiv.org/abs/2006.06676 "Training Generative Adversarial Networks with Limited Data"
[2]: https://arxiv.org/pdf/2002.06676v2.pdf "Complex Photonic Systems (COPS), MESA+ Institute for ... - arXiv.org"
[3]: https://arxiv.org/pdf/2006.06676v2.pdf "arXiv.org e-Print archive"

Here is the detailed pseudo code for the paper:

```python
# Import the necessary libraries
import torch
import torchvision
import numpy as np

# Define the generator and discriminator networks
# The paper uses StyleGAN2 architecture, but any GAN architecture can be used
G = StyleGAN2Generator()
D = StyleGAN2Discriminator()

# Define the loss function and optimizer
# The paper uses non-saturating logistic loss, but any GAN loss can be used
loss = GANLogisticLoss()
optimizer = AdamOptimizer()

# Define the augmentation functions
# The paper uses translation, rotation, cutout, color jittering, etc.
# The paper also uses a differentiable augmentation module to apply augmentations in a differentiable manner
augmentations = [translation, rotation, cutout, color_jittering, ...]
diff_augment = DiffAugment()

# Initialize the augmentation probability
p = 0

# Define the hyperparameters
# The paper uses different hyperparameters for different datasets and tasks
batch_size = 32 # The number of images per batch
iterations = 100000 # The number of training iterations
p_min = 0 # The minimum value of p
p_max = 0.8 # The maximum value of p
gamma = 10 # The scaling factor for p update
tau = 0.01 # The smoothing factor for r_tilde update

# Train the GAN for a fixed number of iterations
for i in range(iterations):

  # Sample a batch of real images from the dataset
  x_real = sample(dataset, batch_size)

  # Generate a batch of fake images from random noise
  z = sample(noise, batch_size)
  x_fake = G(z)

  # Apply augmentations to both real and fake images with probability p
  # Use differentiable augmentation module to make the augmentations differentiable
  x_real_aug = diff_augment(augment(x_real, augmentations, p))
  x_fake_aug = diff_augment(augment(x_fake, augmentations, p))

  # Compute the discriminator outputs for real and fake images
  y_real = D(x_real_aug)
  y_fake = D(x_fake_aug)

  # Compute the generator and discriminator losses
  g_loss = loss(y_fake, target=1)
  d_loss = loss(y_real, target=1) + loss(y_fake, target=0)

  # Update the generator and discriminator parameters using gradient descent
  optimizer.step(g_loss, G.parameters())
  optimizer.step(d_loss, D.parameters())

  # Compute the ratio of discriminator outputs for real and fake images
  # Use exponential moving average to smooth the ratio over time
  r_tilde = (1 - tau) * r_tilde + tau * mean(y_real) / mean(y_fake)

  # Update the augmentation probability based on the ratio using a simple heuristic
  # Clamp the probability between p_min and p_max
  p = clamp(p + gamma * (r_tilde - 1), p_min, p_max)
```

The paper can be found at [^1^][1].