---
title: 2103.14024v2 PlenOctrees for Real-time Rendering of Neural Radiance Fields
date: 2021-03-15
---

# [PlenOctrees for Real-time Rendering of Neural Radiance Fields](http://arxiv.org/abs/2103.14024v2)

authors: Alex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, Angjoo Kanazawa


## What, Why and How

[1]: https://arxiv.org/abs/2103.14024 "PlenOctrees for Real-time Rendering of Neural Radiance Fields"
[2]: http://export.arxiv.org/abs/2103.14024 "[2103.14024] PlenOctrees for Real-time Rendering of Neural Radiance Fields"
[3]: https://arxiv.org/pdf/2103.14024 "arXiv.org e-Print archive"

Here is a summary of the paper[^1^][1]:

- **What**: The paper introduces a method to render Neural Radiance Fields (NeRFs) in real time using PlenOctrees, an octree-based 3D representation which supports view-dependent effects.
- **Why**: The paper aims to overcome the limitations of conventional NeRFs, which are slow and cannot handle view-dependent effects such as specularities.
- **How**: The paper achieves real-time performance by pre-tabulating the NeRF into a PlenOctree, which stores the spherical harmonic representation of radiance at each octree node. The paper also shows that PlenOctrees can be directly optimized to minimize the reconstruction loss, and that this step can reduce the training time of NeRFs. The paper demonstrates the quality and speed of PlenOctrees on various scenes with complex geometry and view-dependent effects.

## Main Contributions

The paper claims the following contributions:

- A novel method to render NeRFs in real time using PlenOctrees, an octree-based 3D representation which supports view-dependent effects.
- A closed-form spherical harmonic factorization of radiance, which removes the viewing direction as an input to the neural network and enables efficient pre-tabulation of NeRFs.
- A direct optimization of PlenOctrees to further improve the quality and reduce the training time of NeRFs.
- An extensive evaluation of PlenOctrees on various scenes with complex geometry and view-dependent effects, showing that they achieve equal or better quality than competing methods while being over 3000 times faster than conventional NeRFs.

## Method Summary

[1]: https://arxiv.org/abs/2103.14024 "PlenOctrees for Real-time Rendering of Neural Radiance Fields"
[2]: http://export.arxiv.org/abs/2103.14024 "[2103.14024] PlenOctrees for Real-time Rendering of Neural Radiance Fields"
[3]: https://arxiv.org/pdf/2103.14024 "arXiv.org e-Print archive"

Here is a summary of the method section of the paper[^1^][1]:

- The paper proposes a two-stage pipeline to render NeRFs in real time using PlenOctrees. The first stage is to train a NeRF model that predicts a spherical harmonic representation of radiance at each 3D point, given its position and density. The second stage is to pre-tabulate the NeRF model into a PlenOctree, which stores the spherical harmonic coefficients and density values at each octree node. The paper also introduces an optional third stage, which is to directly optimize the PlenOctree to minimize the reconstruction loss using gradient descent.
- The paper describes how to factorize the appearance of a NeRF into a spherical harmonic representation, which can capture view-dependent effects such as specularities. The paper shows that it is possible to train a NeRF model to predict the spherical harmonic coefficients of radiance, instead of the RGB color and density values. The paper also shows how to compute the spherical harmonic basis functions efficiently using recurrence relations and lookup tables.
- The paper explains how to pre-tabulate a NeRF model into a PlenOctree, which is an octree-based 3D representation that adapts to the complexity of the scene. The paper describes how to construct the PlenOctree by recursively subdividing the 3D space and evaluating the NeRF model at each octree node. The paper also describes how to render a PlenOctree by ray marching through the octree structure and accumulating the radiance and transmittance along each ray.
- The paper introduces an optional step to directly optimize the PlenOctree to further improve the quality and reduce the training time of NeRFs. The paper describes how to compute the gradients of the reconstruction loss with respect to the PlenOctree parameters using automatic differentiation. The paper also describes how to update the PlenOctree parameters using gradient descent with adaptive learning rates and momentum.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Stage 1: Train a NeRF model that predicts spherical harmonic coefficients of radiance
# Input: A set of images and camera poses of a scene
# Output: A trained NeRF model f(x, sigma) that takes a 3D point x and returns its density sigma and spherical harmonic coefficients c

# Define the spherical harmonic basis functions Y(l, m) using recurrence relations and lookup tables
# Define the loss function L(f) as the negative log-likelihood of the observed colors given the predicted radiance and density
# Initialize the NeRF model f(x, sigma) randomly
# For each iteration:
  # Sample a batch of rays from the input images and camera poses
  # For each ray:
    # Sample a set of points along the ray using stratified sampling and hierarchical sampling
    # For each point:
      # Evaluate the NeRF model f(x, sigma) to get its density sigma and spherical harmonic coefficients c
      # Compute the transmittance T(x) along the ray up to the point x
      # Compute the radiance L(x) at the point x by multiplying c with Y(l, m)
    # Accumulate the radiance and transmittance along the ray to get the predicted color C(r)
    # Compute the loss L(f) as the difference between C(r) and the observed color
  # Update the NeRF model f(x, sigma) using gradient descent to minimize L(f)

# Stage 2: Pre-tabulate the NeRF model into a PlenOctree
# Input: A trained NeRF model f(x, sigma)
# Output: A PlenOctree that stores the density values and spherical harmonic coefficients at each octree node

# Define the root node of the PlenOctree as a cube that covers the entire 3D space
# Define a queue of nodes to be processed, initialized with the root node
# While the queue is not empty:
  # Dequeue a node from the queue
  # Evaluate the NeRF model f(x, sigma) at the center of the node to get its density sigma and spherical harmonic coefficients c
  # Store sigma and c at the node
  # If the node is not a leaf node:
    # Subdivide the node into eight children nodes by splitting each dimension in half
    # Enqueue the children nodes to the queue

# Stage 3 (optional): Directly optimize the PlenOctree to minimize the reconstruction loss
# Input: A PlenOctree and a set of images and camera poses of a scene
# Output: An optimized PlenOctree that better matches the input images

# Define the loss function L(p) as the difference between the rendered colors from the PlenOctree p and the observed colors from the input images
# Initialize an optimizer with adaptive learning rates and momentum for updating p
# For each iteration:
  # Sample a batch of rays from the input images and camera poses
  # For each ray:
    # Ray march through the PlenOctree p by traversing from the root node to the leaf node that contains the ray origin
    # For each node that intersects with the ray:
      # Retrieve its density value sigma and spherical harmonic coefficients c
      # Compute the transmittance T(x) along the ray up to the center of the node x
      # Compute the radiance L(x) at x by multiplying c with Y(l, m)
    # Accumulate the radiance and transmittance along the ray to get the predicted color C(r)
    # Compute the loss L(p) as the difference between C(r) and the observed color
  # Update p using gradient descent to minimize L(p)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
import imageio

# Define some constants
NUM_BANDS = 3 # The number of spherical harmonic bands
NUM_COEFFS = (NUM_BANDS + 1) ** 2 # The number of spherical harmonic coefficients
MAX_DEPTH = 10 # The maximum depth of the PlenOctree
LEAF_SIZE = 0.01 # The minimum size of a leaf node in the PlenOctree
NUM_SAMPLES = 128 # The number of samples per ray for NeRF training and PlenOctree optimization
NUM_FINE_SAMPLES = 64 # The number of fine samples per ray for NeRF training and PlenOctree optimization
NEAR = 0.1 # The near plane distance for ray marching
FAR = 10.0 # The far plane distance for ray marching
EPSILON = 1e-8 # A small value to avoid division by zero

# Define a function to compute the spherical harmonic basis functions Y(l, m) using recurrence relations and lookup tables
# Input: A direction vector d of shape (..., 3)
# Output: A tensor of shape (..., NUM_COEFFS) containing the spherical harmonic basis functions evaluated at d

def compute_sh_basis(d):
  # Convert the direction vector d to spherical coordinates (theta, phi)
  theta = torch.acos(d[..., 2]) # The polar angle in [0, pi]
  phi = torch.atan2(d[..., 1], d[..., 0]) # The azimuthal angle in [-pi, pi]

  # Initialize the output tensor y of shape (..., NUM_COEFFS)
  y = torch.zeros_like(d[..., :NUM_COEFFS])

  # Compute the normalization constants K(l, m) using a lookup table
  K = torch.tensor([
    [1.0],
    [np.sqrt(3 / np.pi)],
    [np.sqrt(15 / np.pi), np.sqrt(15 / np.pi)],
    [np.sqrt(5 / (4 * np.pi)), np.sqrt(15 / np.pi), np.sqrt(15 / np.pi)],
    [np.sqrt(35 / (16 * np.pi)), np.sqrt(105 / (4 * np.pi)), np.sqrt(21 / np.pi), np.sqrt(7 / np.pi), np.sqrt(7 / np.pi)],
    [np.sqrt(35 / (64 * np.pi)), np.sqrt(105 / (16 * np.pi)), np.sqrt(105 / (4 * np.pi)), np.sqrt(35 / (4 * np.pi)), np.sqrt(35 / (4 * np.pi)), np.sqrt(5 / (16 * np.pi))]
  ]).to(d.device)

  # Compute the associated Legendre polynomials P(l, m) using recurrence relations
  P_0_0 = torch.ones_like(theta) # P(0, 0) = 1
  P_1_0 = torch.cos(theta) # P(1, 0) = cos(theta)
  P_1_1 = -torch.sin(theta) # P(1, 1) = -sin(theta)
  P_2_0 = (3 * P_1_0 ** 2 - 1) / 2 # P(2, 0) = (3 * cos(theta)^2 - 1) / 2
  P_2_1 = -3 * torch.sin(theta) * P_1_0 # P(2, 1) = -3 * sin(theta) * cos(theta)
  P_2_2 = 3 * P_1_1 ** 2 # P(2, 2) = 3 * sin(theta)^2
  P_3_0 = (5 * P_2_0 * P_1_0 - P_0_0) / 2 # P(3, 0) = (5 * cos(theta)^3 - cos(theta)) / 2
  P_3_1 = -3/2 * torch.sin(theta) * (5 * P_1_0 ** 2 - 1) # P(3, 1) = -3/2 * sin(theta) * (5 * cos(theta)^2 - 1)
  P_3_2 = -15/2 * torch.sin(theta) ** 2 * P_1_0 # P(3, 2) = -15/2 * sin(theta)^2 * cos(theta)
  P_3_3 = 15/2 * P_1_1 ** 2 * P_1_0 # P(3, 3) = 15/2 * sin(theta)^3
  P_4_0 = (35 * P_3_0 * P_1_0 - 30 * P_2_0 * P_0_0 + 3 * P_0_0) / 8 # P(4, 0) = (35 * cos(theta)^4 - 30 * cos(theta)^2 + 3) / 8
  P_4_1 = -5/2 * torch.sin(theta) * (7 * P_3_0 - 3 * P_1_0) # P(4, 1) = -5/2 * sin(theta) * (7 * cos(theta)^3 - 3 * cos(theta))
  P_4_2 = -15/2 * torch.sin(theta) ** 2 * (7 * P_2_0 - 1) # P(4, 2) = -15/2 * sin(theta)^2 * (7 * cos(theta)^2 - 1)
  P_4_3 = -105/4 * torch.sin(theta) ** 3 * P_1_0 # P(4, 3) = -105/4 * sin(theta)^3 * cos(theta)
  P_4_4 = 105/4 * P_1_1 ** 2 * P_2_0 # P(4, 4) = 105/4 * sin(theta)^4
  P_5_0 = (63 * P_4_0 * P_1_0 - 70 * P_3_0 * P_0_0 + 15 * P_0_0) / 8 # P(5, 0) = (63 * cos(theta)^5 - 70 * cos(theta)^3 + 15 cos(theta)) / 8
  P_5_1 = -15/8 * torch.sin(theta) * (21 * P_4_0 - 14 * P_2_0 + 1) # P(5, 1) = -15/8 sin(theta) (21 cos(theta)^4 -14 cos(theta)^2 +1)
  P_5_2 = -105/8*torch.sin(theta)**2*(9*P_3-3*P-1-1)#P(5,2)=−105/8sin(θ)^2(9cos(θ)^3−3cos(θ)-1)
P-5-3=-105/8*torch.sin(theta)**3*(11*P-2-0-1)#P(5,3)=−105/8sin(θ)^3(11cos(θ)^2−1)
P-5-4=-315/16*torch.sin(theta)**4*P-1-0#P(5,4)=−315/16sin(θ)^4cos(θ)
P-5-5=315/16*P-1-1**2*P-3-0#P(5,5)=315/16sin(θ)^5

#Compute the spherical harmonic basis functions Y(l,m) by multiplying K(l,m) and P(l,m)
Y-0-0=K[0][0]*P-0-0#Y(0,0)=K(0,0)*P(0,0)
Y-1-(-1)=K[1][0]*P-1-(-1)#Y(-1,-1)=K(-1,-1)*P(-1,-1)
Y-10=K[10]*P10#Y10=K10*P10
Y11=K[11]*P11#Y11=K11*P11
Y20=K[20]*P20#Y20=K20*P20
Y21=K[21]*P21#Y21=K21*P21
Y22=K[22]*P22#Y22=K22*P22
Y30=K[30]*P30#Y30=K30*P30
Y31=K[31]*P31#Y31=K31*P31
Y32=K[32]*P32#Y32=K32*P32
Y33=K[33]*P33#Y33=K33*P33
Y40=K[40]*P40#Y40=K40*P40
Y41=K[41]*P41#Y41=K41*P41
Y42=K[42]*P42#Y42=K