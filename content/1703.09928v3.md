---
title: 1703.09928v3 Bundle Optimization for Multi-aspect Embedding
date: 2017-03-10
---

# [Bundle Optimization for Multi-aspect Embedding](http://arxiv.org/abs/1703.09928v3)

authors: Qiong Zeng, Baoquan Chen, Yanir Kleiman, Daniel Cohen-Or, Yangyan Li


## What, Why and How

[1]: https://arxiv.org/abs/1703.09928 "[1703.09928] Bundle Optimization for Multi-aspect Embedding - arXiv.org"
[2]: https://arxiv.org/pdf/1703.09928v3.pdf "arXiv.org"
[3]: https://arxiv-export-lb.library.cornell.edu/pdf/1710.09928v3 "arXiv:1710.09928v3 [cond-mat.str-el] 27 Apr 2018"

Here is a summary of the paper:

- **What**: The paper presents a method for learning the semantic similarity among images, inferring their latent aspects and embedding them into multi-spaces corresponding to their semantic aspects.
- **Why**: The paper aims to address the challenge of semantic ambiguity in image perception, where images can be perceived with emphasis on different aspects, which may be contradictory to each other.
- **How**: The paper collects and embeds qualitative measures that share the same aspects in bundles. To ensure similarity aspect sharing among multiple measures, image classification queries are presented to, and solved by users. The collected image clusters are then converted into bundles of tuples, which are fed into a bundle optimization algorithm that jointly infers the aspect similarity and multi-aspect embedding. The paper evaluates the proposed method on various datasets and compares it with state-of-the-art multi-embedding approaches.

## Main Contributions

[1]: https://arxiv.org/abs/1703.09928 "[1703.09928] Bundle Optimization for Multi-aspect Embedding - arXiv.org"
[2]: https://arxiv.org/pdf/1703.09928v3.pdf "arXiv.org"
[3]: https://arxiv-export-lb.library.cornell.edu/pdf/1710.09928v3 "arXiv:1710.09928v3 [cond-mat.str-el] 27 Apr 2018"

The paper claims the following contributions:

- **A novel method for learning multi-aspect embedding** that jointly infers the aspect similarity and multi-space embedding from qualitative clustering queries.
- **A bundle optimization algorithm** that efficiently solves the multi-aspect embedding problem by exploiting the structure of bundles and using a stochastic gradient descent method.
- **A user study** that collects large-scale multi-aspect similarity measures for images using image classification queries.
- **An extensive evaluation** that demonstrates the effectiveness and scalability of the proposed method on various datasets and compares it with state-of-the-art multi-embedding approaches.

## Method Summary

[1]: https://arxiv.org/abs/1703.09928 "[1703.09928] Bundle Optimization for Multi-aspect Embedding - arXiv.org"
[2]: https://arxiv.org/pdf/1703.09928v3.pdf "arXiv.org"
[3]: https://arxiv-export-lb.library.cornell.edu/pdf/1710.09928v3 "arXiv:1710.09928v3 [cond-mat.str-el] 27 Apr 2018"

Here is a summary of the method section of the paper:

- The paper formulates the multi-aspect embedding problem as an optimization function that evaluates the embedded distances with respect to the qualitative clustering queries.
- The paper introduces the concept of bundles, which are sets of tuples that share the same aspect similarity. A tuple consists of three images: a query image, a positive image and a negative image. The positive image is more similar to the query image than the negative image in a certain aspect.
- The paper proposes a bundle optimization algorithm that solves the optimization function by exploiting the structure of bundles and using a stochastic gradient descent method. The algorithm alternates between two steps: aspect inference and multi-space embedding. In the aspect inference step, the algorithm assigns each bundle to one of the predefined aspects based on the current embedding. In the multi-space embedding step, the algorithm updates the embedding of each image in each aspect space based on the assigned bundles.
- The paper describes how to collect large-scale multi-aspect similarity measures for images using image classification queries. The paper presents two types of queries: single-aspect queries and multi-aspect queries. Single-aspect queries ask users to classify images based on a single aspect, such as color or shape. Multi-aspect queries ask users to classify images based on multiple aspects, such as style or category. The paper converts the collected image clusters into bundles of tuples by randomly sampling query, positive and negative images from each cluster.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a set of images I, a set of aspects A, a set of bundles B
# Output: a multi-aspect embedding E

# Initialize the embedding E randomly
E = random_embedding(I, A)

# Repeat until convergence
while not converged:

  # Aspect inference step
  for each bundle b in B:
    # Find the aspect that minimizes the bundle loss
    a = argmin_a(bundle_loss(b, E))
    # Assign the bundle to the aspect
    assign(b, a)

  # Multi-space embedding step
  for each image i in I:
    for each aspect a in A:
      # Compute the gradient of the embedding loss with respect to E[i][a]
      g = gradient(embedding_loss(i, a, B, E), E[i][a])
      # Update the embedding using stochastic gradient descent
      E[i][a] = E[i][a] - learning_rate * g

# Return the multi-aspect embedding
return E
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a set of images I, a set of aspects A, a set of bundles B
# Output: a multi-aspect embedding E

# Define the bundle loss function
def bundle_loss(b, E):
  # b is a bundle of tuples (q, p, n), where q is the query image, p is the positive image and n is the negative image
  # E is the multi-aspect embedding
  # The bundle loss is the sum of the triplet losses for each tuple in the bundle
  loss = 0
  for (q, p, n) in b:
    # The triplet loss is defined as max(0, margin + d(q, p) - d(q, n)), where d is the Euclidean distance
    loss = loss + max(0, margin + distance(E[q], E[p]) - distance(E[q], E[n]))
  return loss

# Define the embedding loss function
def embedding_loss(i, a, B, E):
  # i is an image
  # a is an aspect
  # B is a set of bundles
  # E is the multi-aspect embedding
  # The embedding loss is the sum of the bundle losses for each bundle that contains i in aspect a
  loss = 0
  for b in B:
    if i in b and aspect(b) == a:
      # aspect(b) returns the assigned aspect of bundle b
      loss = loss + bundle_loss(b, E)
  return loss

# Initialize the embedding E randomly
E = random_embedding(I, A)

# Repeat until convergence
while not converged:

  # Aspect inference step
  for each bundle b in B:
    # Find the aspect that minimizes the bundle loss
    a = argmin_a(bundle_loss(b, E))
    # Assign the bundle to the aspect
    assign(b, a)

  # Multi-space embedding step
  for each image i in I:
    for each aspect a in A:
      # Compute the gradient of the embedding loss with respect to E[i][a]
      g = gradient(embedding_loss(i, a, B, E), E[i][a])
      # Update the embedding using stochastic gradient descent
      E[i][a] = E[i][a] - learning_rate * g

# Return the multi-aspect embedding
return E
```