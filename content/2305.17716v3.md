---
title: 2305.17716v3 InDL  A New Datasets and Benchmark for In-Diagram Logic Interpreting based on Visual Illusion
date: 2023-05-18
---

# [InDL: A New Datasets and Benchmark for In-Diagram Logic Interpreting based on Visual Illusion](http://arxiv.org/abs/2305.17716v3)

authors: Haobo Yang, Wenyu Wang, Ze Cao, Zhekai Duan, Xuchen Liu


## What, Why and How

[1]: https://arxiv.org/pdf/2305.17716v3.pdf "arXiv:2305.17716v3 [cs.CV] 1 Jun 2023"
[2]: https://arxiv.org/abs/2305.17716 "[2305.17716] InDL: A New Datasets and Benchmark for In ... - arXiv.org"
[3]: http://arxiv-export3.library.cornell.edu/abs/2305.17716v3 "[2305.17716v3] InDL: A New Datasets and Benchmark for In-Diagram Logic ..."

Here is a summary of the paper based on the search results:

- **What**: The paper introduces a novel approach to evaluating deep learning models' capacity for in-diagram logic interpretation based on visual illusions.
- **Why**: The paper aims to address the challenge of understanding the decision-making process of deep learning models, especially when logical reasoning is required, by using visual illusions as a testbed for comparing human and machine visual perception.
- **How**: The paper establishes a unique dataset, InDL, which contains six classic geometric optical illusions and corresponding questions that require logic interpretation. The paper then uses this dataset to benchmark various deep learning models and rank them based on their logic interpretation ability. The paper also analyzes the strengths and weaknesses of different models and provides insights for model improvements.

## Main Contributions

[1]: https://arxiv.org/pdf/2305.17716v3.pdf "arXiv:2305.17716v3 [cs.CV] 1 Jun 2023"
[2]: https://arxiv.org/abs/2305.17716 "[2305.17716] InDL: A New Datasets and Benchmark for In ... - arXiv.org"
[3]: http://arxiv-export3.library.cornell.edu/abs/2305.17716v3 "[2305.17716v3] InDL: A New Datasets and Benchmark for In-Diagram Logic ..."

According to the search results, the main contributions of this paper are:

- Introducing a novel approach to evaluating deep learning models' capacity for in-diagram logic interpretation based on visual illusions.
- Establishing a unique dataset, InDL, which contains six classic geometric optical illusions and corresponding questions that require logic interpretation.
- Creating a comparative framework between human and machine visual perception using visual illusions as a testbed.
- Providing a quantifiable measure to rank models based on their logic interpretation ability and analyzing their strengths and weaknesses.
- Making the source code and datasets publicly available for reproducible research.

## Method Summary

[1]: https://arxiv.org/pdf/2305.17716v3.pdf "arXiv:2305.17716v3 [cs.CV] 1 Jun 2023"
[2]: https://arxiv.org/abs/2305.17716 "[2305.17716] InDL: A New Datasets and Benchmark for In ... - arXiv.org"
[3]: http://arxiv-export3.library.cornell.edu/abs/2305.17716v3 "[2305.17716v3] InDL: A New Datasets and Benchmark for In-Diagram Logic ..."

Here is a summary of the method section based on the search results:

- The method section describes the process of creating the InDL dataset, which consists of six types of visual illusions: Muller-Lyer, Ponzo, Ebbinghaus, Vertical-Horizontal, Zollner and Hering illusions.
- Each illusion type has 1000 images generated by varying the parameters of the illusion. Each image is paired with a question that requires logic interpretation, such as "Which line is longer?" or "Which circle is bigger?".
- The questions are designed to be challenging for deep learning models, as they involve understanding the geometry and logic behind the illusions. The questions also have multiple-choice answers with distractors that are similar to the correct answer.
- The method section also describes the evaluation metrics used to measure the performance of different models on the InDL dataset. The metrics include accuracy, precision, recall, F1-score and confusion matrix.
- The method section also presents the details of the models used for benchmarking, which include ResNet-50, VGG-16, DenseNet-121, MobileNet-V2 and EfficientNet-B0. The models are trained on ImageNet and fine-tuned on InDL using cross-entropy loss and Adam optimizer.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Import the InDL dataset and the models
from indl import InDL
from models import ResNet50, VGG16, DenseNet121, MobileNetV2, EfficientNetB0

# Initialize the models and load the pretrained weights
models = [ResNet50(), VGG16(), DenseNet121(), MobileNetV2(), EfficientNetB0()]
for model in models:
  model.load_pretrained_weights('imagenet')

# Fine-tune the models on InDL using cross-entropy loss and Adam optimizer
for model in models:
  model.fine_tune(InDL, loss='cross_entropy', optimizer='adam')

# Evaluate the models on InDL using accuracy, precision, recall, F1-score and confusion matrix
for model in models:
  model.evaluate(InDL, metrics=['accuracy', 'precision', 'recall', 'f1_score', 'confusion_matrix'])

# Rank the models based on their logic interpretation ability
models.sort(key=lambda x: x.f1_score, reverse=True)
print('The ranking of the models is:')
for i, model in enumerate(models):
  print(f'{i+1}. {model.name} with F1-score of {model.f1_score}')
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Define the parameters for generating the visual illusions
num_illusions = 6 # number of illusion types
num_images = 1000 # number of images per illusion type
image_size = 224 # size of the image in pixels
line_width = 5 # width of the line in pixels
line_color = 'black' # color of the line
background_color = 'white' # color of the background

# Define the parameters for fine-tuning the models
num_epochs = 10 # number of epochs for training
batch_size = 32 # size of the batch for training and testing
learning_rate = 0.001 # learning rate for the optimizer

# Define the InDL dataset class
class InDL(torch.utils.data.Dataset):
  def __init__(self):
    # Initialize the dataset with empty lists
    self.images = [] # list of images as tensors
    self.questions = [] # list of questions as strings
    self.answers = [] # list of answers as integers (0-3)
    self.labels = [] # list of labels as integers (0-5)

    # Generate the images and questions for each illusion type
    for i in range(num_illusions):
      if i == 0:
        # Muller-Lyer illusion: two lines with arrowheads pointing inward or outward
        self.generate_muller_lyer()
      elif i == 1:
        # Ponzo illusion: two horizontal lines on a converging background
        self.generate_ponzo()
      elif i == 2:
        # Ebbinghaus illusion: a circle surrounded by smaller or larger circles
        self.generate_ebbinghaus()
      elif i == 3:
        # Vertical-Horizontal illusion: a vertical and a horizontal line of equal length
        self.generate_vertical_horizontal()
      elif i == 4:
        # Zollner illusion: parallel lines crossed by diagonal lines at different angles
        self.generate_zollner()
      elif i == 5:
        # Hering illusion: two straight lines that appear curved due to radial background lines
        self.generate_hering()

    # Convert the lists to tensors and normalize the images to [0,1] range
    self.images = torch.stack(self.images).float() / 255.0 
    self.questions = torch.tensor(self.questions)
    self.answers = torch.tensor(self.answers)
    self.labels = torch.tensor(self.labels)

  def __len__(self):
    # Return the length of the dataset
    return len(self.images)

  def __getitem__(self, index):
    # Return the image, question, answer and label at the given index
    return self.images[index], self.questions[index], self.answers[index], self.labels[index]

  def generate_muller_lyer(self):
    # Generate images and questions for the Muller-Lyer illusion

    # Define the parameters for generating the illusion
    line_length = image_size // 4 # length of the line in pixels
    arrow_length = image_size // 8 # length of the arrowhead in pixels

    # Loop over the number of images to generate
    for _ in range(num_images):
      # Create a blank image with background color
      image = np.full((image_size, image_size, 3), background_color)

      # Randomly choose the direction of the arrowheads (inward or outward)
      direction = np.random.choice(['inward', 'outward'])

      # Randomly choose the position of the first line (left or right)
      position = np.random.choice(['left', 'right'])

      # Randomly choose the offset of the first line from the center (positive or negative)
      offset = np.random.randint(-image_size // 8, image_size // 8)

      # Calculate the coordinates of the first line and its arrowheads
      if position == 'left':
        x1 = image_size // 4 + offset - line_length // 2 
        x2 = x1 + line_length 
      else:
        x1 = image_size * 3 // 4 + offset - line_length // 2 
        x2 = x1 + line_length 
      y1 = y2 = image_size // 2 
      if direction == 'inward':
        x3 = x1 - arrow_length 
        x4 = x2 + arrow_length 
        y3 = y4 = y1 - arrow_length 
        y5 = y6 = y1 + arrow_length 
      else:
        x3 = x1 + arrow_length 
        x4 = x2 - arrow_length 
        y3 = y4 = y1 + arrow_length 
        y5 = y6 = y1 - arrow_length 

      # Draw the first line and its arrowheads on the image
      image = cv2.line(image, (x1, y1), (x2, y2), line_color, line_width)
      image = cv2.line(image, (x1, y1), (x3, y3), line_color, line_width)
      image = cv2.line(image, (x1, y1), (x3, y5), line_color, line_width)
      image = cv2.line(image, (x2, y2), (x4, y4), line_color, line_width)
      image = cv2.line(image, (x2, y2), (x4, y6), line_color, line_width)

      # Randomly choose the offset of the second line from the center (positive or negative)
      offset = np.random.randint(-image_size // 8, image_size // 8)

      # Calculate the coordinates of the second line and its arrowheads
      if position == 'left':
        x1 = image_size * 3 // 4 + offset - line_length // 2 
        x2 = x1 + line_length 
      else:
        x1 = image_size // 4 + offset - line_length // 2 
        x2 = x1 + line_length 
      y1 = y2 = image_size // 2 
      if direction == 'inward':
        x3 = x1 - arrow_length 
        x4 = x2 + arrow_length 
        y3 = y4 = y1 - arrow_length 
        y5 = y6 = y1 + arrow_length 
      else:
        x3 = x1 + arrow_length 
        x4 = x2 - arrow_length 
        y3 = y4 = y1 + arrow_length 
        y5 = y6 = y1 - arrow_length 

      # Draw the second line and its arrowheads on the image
      image = cv2.line(image, (x1, y1), (x2, y2), line_color, line_width)
      image = cv2.line(image, (x1, y1), (x3, y3), line_color, line_width)
      image = cv2.line(image, (x1, y1), (x3, y5), line_color, line_width)
      image = cv2.line(image, (x2, y2), (x4, y4), line_color, line_width)
      image = cv2.line(image, (x2, y2), (x4, y6), line_color, line_width)

      # Convert the image to a tensor
      image = torch.from_numpy(image)

      # Create a question that asks which line is longer
      question = 'Which line is longer?'

      # Create a list of possible answers
      answers = ['The left one', 'The right one', 'Both are equal', 'Cannot tell']

      # Assign the correct answer based on the illusion
      if direction == 'inward' and position == 'left':
        answer = 0 # the left one
      elif direction == 'inward' and position == 'right':
        answer = 1 # the right one
      elif direction == 'outward' and position == 'left':
        answer = 1 # the right one
      elif direction == 'outward' and position == 'right':
        answer = 0 # the left one

      # Append the image, question, answer and label to the dataset
      self.images.append(image)
      self.questions.append(question)
      self.answers.append(answer)
      self.labels.append(0) # Muller-Lyer illusion

  def generate_ponzo(self):
    # Generate images and questions for the Ponzo illusion

    # Define the parameters for generating the illusion
    line_length = image_size // 4 # length of the horizontal lines in pixels
    gap_size = image_size // 8 # size of the gap between the horizontal lines in pixels
    angle_range = [10, 80] # range of angles for the converging lines in degrees

    # Loop over the number of images to generate
    for _ in range(num_images):
      # Create a blank image with background color
      image = np.full((image_size, image_size, 3), background_color)

      # Randomly choose an angle for the converging lines
      angle = np.random.randint(angle_range[0], angle_range[1])

      # Calculate the coordinates of the converging lines
      x1