---
title: 2306.07716v1 Dynamically Masked Discriminator for Generative Adversarial Networks
date: 2023-06-08
---

# [Dynamically Masked Discriminator for Generative Adversarial Networks](http://arxiv.org/abs/2306.07716v1)

authors: Wentian Zhang, Haozhe Liu, Bing Li, Jinheng Xie, Yawen Huang, Yuexiang Li, Yefeng Zheng, Bernard Ghanem


## What, Why and How

[1]: https://arxiv.org/pdf/2306.07716v1.pdf "arXiv:2306.07716v1 [cs.CV] 13 Jun 2023"
[2]: https://arxiv.org/abs/2306.07716 "[2306.07716] Dynamically Masked Discriminator for Generative ..."
[3]: http://export.arxiv.org/pdf/2109.07716 "arXiv:2109.07716v1 [math.OC] 16 Sep 2021"

Here is a summary of the paper at [^1^][1]:

- What: The paper proposes a novel method for training Generative Adversarial Networks (GANs) by dynamically masking the features of the discriminator to adapt to the changing distribution of generated data.
- Why: The paper aims to solve the problem of discriminator retardation, which means that the discriminator model, trained on historically generated data, often slows down its adaptation to the changes in the new arrival generated data, which accordingly decreases the quality of generated results.
- How: The paper treats the generated data in training as a stream and detects whether the discriminator slows down the learning of new knowledge in generated data. Then, it applies a dynamic mask to the features of the discriminator, such that the discriminator can learn new knowledge fast and guide the generator better. The paper evaluates the proposed method on various datasets and GAN architectures and shows that it outperforms the state-of-the-art approaches.


## Main Contributions

[1]: https://arxiv.org/pdf/2306.07716v1.pdf "arXiv:2306.07716v1 [cs.CV] 13 Jun 2023"
[2]: https://arxiv.org/abs/2306.07716 "[2306.07716] Dynamically Masked Discriminator for Generative ..."
[3]: http://export.arxiv.org/pdf/2109.07716 "arXiv:2109.07716v1 [math.OC] 16 Sep 2021"

According to the paper at [^1^][1], the main contributions are:

- The paper proposes a novel method for GANs from the viewpoint of online continual learning, which can explicitly enforce the discriminator to learn new knowledge fast and adapt to the changing distribution of generated data.
- The paper introduces a new discriminator, which automatically detects its retardation and then dynamically masks its features, such that the discriminator can focus on the local regions where the generated samples are different from the real ones.
- The paper evaluates the proposed method on various datasets and GAN architectures and shows that it outperforms the state-of-the-art approaches in terms of image quality, diversity, and stability.


## Method Summary

[1]: https://arxiv.org/pdf/2306.07716v1.pdf "arXiv:2306.07716v1 [cs.CV] 13 Jun 2023"
[2]: https://arxiv.org/abs/2306.07716 "[2306.07716] Dynamically Masked Discriminator for Generative ..."
[3]: http://export.arxiv.org/pdf/2109.07716 "arXiv:2109.07716v1 [math.OC] 16 Sep 2021"

Here is a summary of the method section of the paper at [^1^][1]:

- The paper first introduces the concept of discriminator retardation, which means that the discriminator model, trained on historically generated data, often slows down its adaptation to the changes in the new arrival generated data. The paper formalizes this problem as an online continual learning task and defines a metric to measure the discriminator retardation.
- The paper then proposes a novel discriminator, which consists of two modules: a retardation detector and a feature masker. The retardation detector computes the retardation score for each feature map in the discriminator based on the difference between the real and generated data distributions. The feature masker applies a dynamic mask to the feature maps based on their retardation scores, such that the discriminator can focus on the local regions where the generated samples are different from the real ones.
- The paper also proposes a training algorithm for the proposed discriminator, which alternates between updating the generator and updating the discriminator. The paper describes how to compute the gradients for both modules and how to optimize them using stochastic gradient descent.


## Pseudo Code - High level

Here is the high-level pseudo code for the paper:

```
# Initialize the generator G and the discriminator D
G = Generator()
D = Discriminator()

# Define the loss functions for G and D
L_G = GeneratorLoss()
L_D = DiscriminatorLoss()

# Define the optimizer for G and D
opt_G = Optimizer(G.parameters())
opt_D = Optimizer(D.parameters())

# Define the batch size and the number of training iterations
batch_size = ...
num_iter = ...

# Start the training loop
for i in range(num_iter):

  # Sample a batch of real data from the dataset
  real_data = SampleRealData(batch_size)

  # Generate a batch of fake data using G
  noise = SampleNoise(batch_size)
  fake_data = G(noise)

  # Compute the discriminator output for real and fake data
  real_output = D(real_data)
  fake_output = D(fake_data)

  # Compute the generator loss
  loss_G = L_G(fake_output)

  # Update the generator parameters
  opt_G.zero_grad()
  loss_G.backward()
  opt_G.step()

  # Compute the discriminator loss
  loss_D = L_D(real_output, fake_output)

  # Update the discriminator parameters
  opt_D.zero_grad()
  loss_D.backward()
  opt_D.step()

  # Compute the retardation score for each feature map in D
  score = RetardationDetector(real_data, fake_data, D)

  # Apply the dynamic mask to the feature maps in D
  D.mask(score)
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper:

```
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# Define the hyperparameters
batch_size = 64 # The size of each mini-batch
num_iter = 100000 # The number of training iterations
lr = 0.0002 # The learning rate for both G and D
beta1 = 0.5 # The beta1 parameter for Adam optimizer
beta2 = 0.999 # The beta2 parameter for Adam optimizer
z_dim = 100 # The dimension of the noise vector
lambda_1 = 0.1 # The weight for the feature matching loss
lambda_2 = 0.01 # The weight for the retardation loss

# Define the dataset and the data loader
transform = transforms.Compose([
  transforms.Resize(64), # Resize the images to 64x64
  transforms.CenterCrop(64), # Crop the images to 64x64
  transforms.ToTensor(), # Convert the images to tensors
  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize the images to [-1, 1]
])

dataset = torchvision.datasets.CIFAR10(root='./data', download=True, transform=transform) # Use the CIFAR10 dataset

dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2) # Use a data loader to load the data

# Define the generator model
class Generator(nn.Module):
  def __init__(self):
    super(Generator, self).__init__()

    # Define the main network as a sequential model
    self.main = nn.Sequential(
      # Input: a noise vector of size z_dim
      nn.ConvTranspose2d(z_dim, 512, 4, 1, 0, bias=False), # Output: a feature map of size 512x4x4
      nn.BatchNorm2d(512),
      nn.ReLU(True),

      nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False), # Output: a feature map of size 256x8x8
      nn.BatchNorm2d(256),
      nn.ReLU(True),

      nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False), # Output: a feature map of size 128x16x16
      nn.BatchNorm2d(128),
      nn.ReLU(True),

      nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False), # Output: a feature map of size 64x32x32
      nn.BatchNorm2d(64),
      nn.ReLU(True),

      nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False), # Output: a feature map of size 3x64x64
      nn.Tanh() # Apply tanh activation to get an image in [-1, 1]
    )

  def forward(self, x):
    # Forward pass the input through the main network
    return self.main(x)

# Define the discriminator model
class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()

    # Define the main network as a sequential model
    self.main = nn.Sequential(
      # Input: an image of size 3x64x64
      nn.Conv2d(3, 64, 4, 2, 1, bias=False), # Output: a feature map of size 64x32x32
      nn.LeakyReLU(0.2),

      nn.Conv2d(64, 128, 4, 2, 1, bias=False), # Output: a feature map of size 128x16x16
      nn.BatchNorm2d(128),
      nn.LeakyReLU(0.2),

      nn.Conv2d(128, 256, 4, 2, 1, bias=False), # Output: a feature map of size 256x8x8
      nn.BatchNorm2d(256),
      nn.LeakyReLU(0.2),

      nn.Conv2d(256, 512, 4, 2 ,1 ,bias=False), # Output: a feature map of size 
512x4x4
      nn.BatchNorm2d(512),
      nn.LeakyReLU(0.2),

      nn.Conv2d(512, 1, 4, 1, 0, bias=False), # Output: a scalar value
      nn.Sigmoid() # Apply sigmoid activation to get a probability in [0, 1]
    )

    # Define the mask network as a sequential model
    self.mask = nn.Sequential(
      # Input: a feature map of size CxHxW
      nn.AdaptiveAvgPool2d(1), # Output: a feature map of size Cx1x1
      nn.Conv2d(C, C, 1, 1, 0, bias=False), # Output: a feature map of size Cx1x1
      nn.Sigmoid() # Apply sigmoid activation to get a mask value in [0, 1]
    )

  def forward(self, x):
    # Forward pass the input through the main network
    features = self.main(x)

    # Forward pass the features through the mask network
    mask = self.mask(features)

    # Apply the mask to the features
    masked_features = features * mask

    # Return the masked features and the mask
    return masked_features, mask

# Define the generator loss function
def GeneratorLoss(fake_output):
  # Use binary cross entropy loss
  bce = nn.BCELoss()

  # Compute the loss as the negative log likelihood of the fake output being real
  loss = bce(fake_output, torch.ones(batch_size))

  # Return the loss
  return loss

# Define the discriminator loss function
def DiscriminatorLoss(real_output, fake_output):
  # Use binary cross entropy loss
  bce = nn.BCELoss()

  # Compute the loss as the negative log likelihood of the real output being real and the fake output being fake
  loss = bce(real_output, torch.ones(batch_size)) + bce(fake_output, torch.zeros(batch_size))

  # Return the loss
  return loss

# Define the retardation detector function
def RetardationDetector(real_data, fake_data, D):
  # Compute the mean and variance of the real data distribution for each feature map in D
  real_mean = torch.mean(real_data, dim=0)
  real_var = torch.var(real_data, dim=0)

  # Compute the mean and variance of the fake data distribution for each feature map in D
  fake_mean = torch.mean(fake_data, dim=0)
  fake_var = torch.var(fake_data, dim=0)

  # Compute the KL divergence between the real and fake data distributions for each feature map in D
  kl_div = torch.log(real_var / fake_var) + (fake_var + (fake_mean - real_mean) ** 2) / (2 * real_var) - 0.5

  # Compute the retardation score for each feature map in D as the inverse of the KL divergence
  score = torch.exp(-kl_div)

  # Return the retardation score
  return score

# Create an instance of the generator and the discriminator
G = Generator()
D = Discriminator()

# Create an optimizer for G and D using Adam algorithm
opt_G = optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))
opt_D = optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))

# Start the training loop
for i in range(num_iter):

  # Sample a batch of real data from the dataset
  real_data = next(iter(dataloader))

  # Generate a batch of fake data using G
  noise = torch.randn(batch_size, z_dim, 1 ,1)
  fake_data = G(noise)

  # Compute the discriminator output and mask for real and fake data
  real_output, real_mask = D(real_data)
  fake_output, fake_mask = D(fake_data)

  # Compute the generator loss using L_G and L_D functions
  loss_G = GeneratorLoss(fake_output) + lambda_1 * DiscriminatorLoss(real_output * real_mask, fake_output * fake_mask)

  # Update the generator parameters using opt_G optimizer
  opt_G.zero_grad()
  loss_G.backward()
  opt_G.step()

  # Compute the discriminator loss using L_D function
  loss_D = DiscriminatorLoss(real_output * real_mask, fake_output * fake_mask)

   # Update the discriminator parameters using opt_D optimizer 
   opt_D.zero_grad()
   loss_D.backward()
   opt_D.step()

   # Compute the retardation score for each feature map in D using RetardationDetector function 
   score = RetardationDetector(real_data, fake_data, D)

   # Apply the dynamic mask to the feature maps in D using D.mask function 
   D.mask(score)
```