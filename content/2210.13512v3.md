---
title: 2210.13512v3 Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup
date: 2022-10-14
---

# [Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup](http://arxiv.org/abs/2210.13512v3)

authors: Muthu Chidambaram, Xiang Wang, Chenwei Wu, Rong Ge


## What, Why and How

[1]: https://arxiv.org/pdf/2210.13512v3.pdf "Provably Learning Diverse Features in Multi-View Data with ... - arXiv.org"
[2]: https://arxiv.org/abs/2210.13512 "[2210.13512] Provably Learning Diverse Features in Multi-View Data with ..."
[3]: https://arxiv-export2.library.cornell.edu/abs/2210.13512v3 "[2210.13512v3] Provably Learning Diverse Features in Multi-View Data ..."

Here is a summary of the paper:

- **What**: The paper is about a data augmentation technique called **Mixup**, which constructs new data points as convex combinations of pairs of data points and their labels from the original dataset. The paper tries to explain the success of Mixup from a feature learning perspective, focusing on classification problems with multiple features (or views) per class.
- **Why**: The paper aims to provide theoretical and empirical insights into how Mixup can help learn diverse features in multi-view data, which can improve generalization and robustness. The paper also compares Mixup with empirical risk minimization (ERM), which is a standard training method that can fail to learn multiple features per class.
- **How**: The paper proposes a specific instantiation of Mixup called **Midpoint Mixup**, which uses the midpoint of two data points as the new data point. The paper proves that, for a non-trivial class of data distributions with two features per class, training a 2-layer convolutional network with Midpoint Mixup succeeds in learning both features for every class, while ERM learns only one feature with high probability. The paper also conducts experiments on image benchmarks modified to have additional synthetic features, and shows that Midpoint Mixup outperforms ERM and other variants of Mixup in terms of accuracy and feature diversity.

## Main Contributions

The paper claims to make the following contributions:

- It introduces a novel perspective on Mixup as a feature learning technique for multi-view data, and formalizes the notion of feature diversity in this setting.
- It proposes Midpoint Mixup, a simple and effective variant of Mixup that uses the midpoint of two data points as the new data point, and proves that it can provably learn diverse features in a non-trivial class of data distributions with two features per class.
- It empirically validates the theoretical results on image benchmarks modified to have additional synthetic features, and shows that Midpoint Mixup outperforms ERM and other variants of Mixup in terms of accuracy and feature diversity.

## Method Summary

The method section of the paper consists of three parts:

- The first part defines the problem setting and the notation used in the paper. It also introduces the concept of feature diversity and how it can be measured using mutual information.
- The second part describes the proposed Midpoint Mixup technique and its properties. It also states the main theoretical results of the paper, which show that Midpoint Mixup can learn diverse features in a non-trivial class of data distributions with two features per class, while ERM fails to do so with high probability.
- The third part presents the experimental setup and the results of the paper. It explains how the synthetic features are generated and added to the image benchmarks, and how the accuracy and feature diversity are evaluated. It also compares Midpoint Mixup with ERM and other variants of Mixup, and discusses the findings and implications of the experiments.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a dataset D with n data points and k classes, each with two features
# Output: a trained 2-layer convolutional network f with ReLU activation

# Define the Midpoint Mixup technique
def midpoint_mixup(x1, x2, y1, y2):
  # x1 and x2 are data points, y1 and y2 are one-hot labels
  # Return the midpoint of x1 and x2 as the new data point, and the average of y1 and y2 as the new label
  return (x1 + x2) / 2, (y1 + y2) / 2

# Initialize the network f randomly
f = initialize_network()

# Train the network f using Midpoint Mixup and cross-entropy loss
for epoch in range(num_epochs):
  # Shuffle the dataset D
  D = shuffle(D)
  # Loop over the dataset D in batches of size 2
  for i in range(0, n, 2):
    # Get the current batch of data points and labels
    x1, y1 = D[i]
    x2, y2 = D[i+1]
    # Apply Midpoint Mixup to the batch
    x_mix, y_mix = midpoint_mixup(x1, x2, y1, y2)
    # Compute the prediction and the loss of the network f on the mixed data point and label
    y_pred = f(x_mix)
    loss = cross_entropy(y_pred, y_mix)
    # Update the network f using gradient descent
    f = update_network(f, loss)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import torch
import torchvision
import torchvision.transforms as transforms

# Define the hyperparameters
num_epochs = 100 # number of training epochs
batch_size = 2 # size of the training batch
lr = 0.01 # learning rate
num_classes = 10 # number of classes in the dataset
num_features = 2 # number of features per class

# Define the data augmentation technique
def midpoint_mixup(x1, x2, y1, y2):
  # x1 and x2 are data points, y1 and y2 are one-hot labels
  # Return the midpoint of x1 and x2 as the new data point, and the average of y1 and y2 as the new label
  return (x1 + x2) / 2, (y1 + y2) / 2

# Define the synthetic feature generator
def generate_feature(x):
  # x is a data point
  # Return a random feature vector of length num_features
  return np.random.rand(num_features)

# Define the network architecture
class ConvNet(torch.nn.Module):
  def __init__(self):
    super(ConvNet, self).__init__()
    # Define the first convolutional layer with 6 filters of size 5x5 and ReLU activation
    self.conv1 = torch.nn.Conv2d(3, 6, 5)
    self.relu1 = torch.nn.ReLU()
    # Define the first max pooling layer with kernel size 2x2 and stride 2
    self.pool1 = torch.nn.MaxPool2d(2, 2)
    # Define the second convolutional layer with 16 filters of size 5x5 and ReLU activation
    self.conv2 = torch.nn.Conv2d(6, 16, 5)
    self.relu2 = torch.nn.ReLU()
    # Define the second max pooling layer with kernel size 2x2 and stride 2
    self.pool2 = torch.nn.MaxPool2d(2, 2)
    # Define the first fully connected layer with input size 16*5*5 and output size 120 and ReLU activation
    self.fc1 = torch.nn.Linear(16*5*5, 120)
    self.relu3 = torch.nn.ReLU()
    # Define the second fully connected layer with input size 120 and output size num_classes + num_features and no activation
    self.fc2 = torch.nn.Linear(120, num_classes + num_features)

  def forward(self, x):
    # Forward pass of the network
    # Apply the first convolutional layer and ReLU activation to the input x
    x = self.relu1(self.conv1(x))
    # Apply the first max pooling layer to the output x
    x = self.pool1(x)
    # Apply the second convolutional layer and ReLU activation to the output x
    x = self.relu2(self.conv2(x))
    # Apply the second max pooling layer to the output x
    x = self.pool2(x)
    # Reshape the output x to a vector of length 16*5*5
    x = x.view(-1, 16*5*5)
    # Apply the first fully connected layer and ReLU activation to the output x
    x = self.relu3(self.fc1(x))
    # Apply the second fully connected layer to the output x
    x = self.fc2(x)
    # Return the output x as a tuple of two tensors: one for class prediction and one for feature prediction
    return x[:, :num_classes], x[:, num_classes:]

# Load the CIFAR-10 dataset and apply some transformations
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True)

# Initialize the network and the optimizer
net = ConvNet()
optimizer = torch.optim.SGD(net.parameters(), lr=lr)

# Train the network using Midpoint Mixup and cross-entropy loss for class prediction and mean squared error loss for feature prediction
for epoch in range(num_epochs):
  running_loss = 0.0 # keep track of the running loss
  for i, data in enumerate(trainloader):
    # Get the current batch of data points and labels
    inputs, labels = data
    # Convert the labels to one-hot vectors
    labels = torch.nn.functional.one_hot(labels, num_classes)
    # Generate synthetic features for each data point and concatenate them to the labels
    features = torch.tensor([generate_feature(x) for x in inputs])
    labels = torch.cat((labels, features), dim=1)
    # Apply Midpoint Mixup to the batch
    inputs_mix, labels_mix = midpoint_mixup(inputs[0], inputs[1], labels[0], labels[1])
    # Reshape the mixed inputs and labels to tensors of size 1 x ...
    inputs_mix = inputs_mix.unsqueeze(0)
    labels_mix = labels_mix.unsqueeze(0)
    # Zero the parameter gradients
    optimizer.zero_grad()
    # Compute the prediction and the loss of the network on the mixed inputs and labels
    outputs_mix = net(inputs_mix)
    loss_class = torch.nn.functional.cross_entropy(outputs_mix[0], torch.argmax(labels_mix[:, :num_classes], dim=1))
    loss_feature = torch.nn.functional.mse_loss(outputs_mix[1], labels_mix[:, num_classes:])
    loss = loss_class + loss_feature
    # Backpropagate the loss and update the network parameters
    loss.backward()
    optimizer.step()
    # Print the statistics
    running_loss += loss.item()
    if i % 2000 == 1999: # print every 2000 mini-batches
      print('[%d, %5d] loss: %.3f' %
            (epoch + 1, i + 1, running_loss / 2000))
      running_loss = 0.0

print('Finished Training')
```