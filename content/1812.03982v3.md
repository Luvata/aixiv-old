---
title: 1812.03982v3 SlowFast Networks for Video Recognition
date: 2018-12-04
---

# [SlowFast Networks for Video Recognition](http://arxiv.org/abs/1812.03982v3)

authors: Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, Kaiming He


## What, Why and How

[1]: https://arxiv.org/abs/1812.03982 "[1812.03982] SlowFast Networks for Video Recognition - arXiv.org"
[2]: https://arxiv.org/pdf/1812.03982.pdf "Christoph Feichtenhofer Haoqi Fan Jitendra Malik Kaiming He ... - arXiv.org"
[3]: https://pytorch.org/hub/facebookresearch_pytorchvideo_slowfast/ "SlowFast | PyTorch"

Here is a summary of the paper:

- **What**: The paper presents SlowFast networks for video recognition, which involve two pathways: a Slow pathway that captures spatial semantics at low frame rate, and a Fast pathway that captures motion at fine temporal resolution at high frame rate[^1^][1].
- **Why**: The paper argues that space and time are not equally likely in video signals, and that the categorical spatial semantics evolve slowly while the motion evolves faster. Therefore, it is beneficial to factor the architecture to treat spatial structures and temporal events separately[^1^][1].
- **How**: The paper proposes to use a Slow pathway with high channel capacity and low temporal resolution, and a Fast pathway with low channel capacity and high temporal resolution. The two pathways are fused by lateral connections at various stages. The paper shows that the SlowFast networks achieve state-of-the-art accuracy on major video recognition benchmarks, such as Kinetics, Charades and AVA[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/1812.03982 "[1812.03982] SlowFast Networks for Video Recognition - arXiv.org"
[2]: https://ieeexplore.ieee.org/document/9008780 "SlowFast Networks for Video Recognition - IEEE Xplore"
[3]: https://arxiv.org/pdf/1812.03982.pdf "Christoph Feichtenhofer Haoqi Fan Jitendra Malik Kaiming He Facebook AI ..."
[4]: https://openaccess.thecvf.com/content_ICCV_2019/papers/Feichtenhofer_SlowFast_Networks_for_Video_Recognition_ICCV_2019_paper.pdf "SlowFast Networks for Video Recognition - CVF Open Access"
[5]: https://rainumdo.github.io/2022/03/22/SlowFast-Networks-for-Video-Recognition/ "SlowFast Networks for Video Recognition | Rainumdo's blog"

According to the paper[^1^][1], the main contributions are:

- Introducing the SlowFast concept for video recognition, which factors the architecture into two pathways with different temporal resolutions and channel capacities.
- Showing that the Fast pathway can be very lightweight and still capture useful motion information, while the Slow pathway can capture rich spatial semantics.
- Demonstrating that the SlowFast networks outperform previous methods on action classification and detection tasks on Kinetics, Charades and AVA datasets.

## Method Summary

[1]: https://arxiv.org/abs/1812.03982 "[1812.03982] SlowFast Networks for Video Recognition - arXiv.org"
[2]: https://ieeexplore.ieee.org/document/9008780 "SlowFast Networks for Video Recognition - IEEE Xplore"
[3]: https://openaccess.thecvf.com/content_ICCV_2019/papers/Feichtenhofer_SlowFast_Networks_for_Video_Recognition_ICCV_2019_paper.pdf "SlowFast Networks for Video Recognition - CVF Open Access"
[4]: https://arxiv.org/pdf/1812.03982.pdf "Christoph Feichtenhofer Haoqi Fan Jitendra Malik Kaiming He Facebook AI ..."
[5]: https://ai.facebook.com/blog/slowfast-video-recognition-through-dual-frame-rate-analysis/ "SlowFast video recognition through dual frame-rate analysis"

Here is a summary of the method section of the paper:

- The paper describes the SlowFast network architecture, which consists of two pathways: a Slow pathway with T frames and C channels, and a Fast pathway with αT frames and βC channels, where α > 1 and β < 1 are hyperparameters[^1^][1].
- The paper explains how the two pathways are fused by lateral connections that perform channel-wise concatenation after spatial and temporal striding[^1^][1].
- The paper details the implementation of the SlowFast network, which is based on a ResNet backbone with 3D convolutions. The paper also introduces a bottleneck block that reduces the temporal dimensionality of the Fast pathway by half[^1^][1].
- The paper discusses the design choices and ablation studies of the SlowFast network, such as the frame rate ratio α, the channel ratio β, the number of lateral connections, and the input clip length[^1^][1].

## Pseudo Code - High level

Here is a possible high-level pseudo code for this paper:

```python
# Define the SlowFast network class
class SlowFast(nn.Module):
  # Initialize the network with hyperparameters and backbone
  def __init__(self, alpha, beta, resnet):
    self.alpha = alpha # frame rate ratio
    self.beta = beta # channel ratio
    self.resnet = resnet # ResNet backbone with 3D convolutions
    self.lateral = nn.ModuleList() # lateral connections
    # Create lateral connections for each stage
    for i in range(1, 5):
      self.lateral.append(LateralConnection(i))

  # Forward pass of the network
  def forward(self, x):
    # Split the input into two pathways
    x_slow = x[:, :, ::self.alpha, :, :] # Slow pathway with T frames
    x_fast = x # Fast pathway with alpha*T frames
    # Initialize the outputs of each stage
    out_slow = []
    out_fast = []
    # Pass the input through the ResNet backbone
    for i in range(1, 5):
      # Get the output of the i-th stage for both pathways
      x_slow = self.resnet.layer[i](x_slow)
      x_fast = self.resnet.layer[i](x_fast)
      # Fuse the outputs by lateral connections
      x_slow, x_fast = self.lateral[i](x_slow, x_fast)
      # Append the outputs to the lists
      out_slow.append(x_slow)
      out_fast.append(x_fast)
    # Return the final outputs of both pathways
    return out_slow[-1], out_fast[-1]

# Define the lateral connection class
class LateralConnection(nn.Module):
  # Initialize the connection with stage index
  def __init__(self, i):
    self.i = i # stage index
    self.conv = nn.Conv3d() # 3D convolution layer
    self.bn = nn.BatchNorm3d() # batch normalization layer

  # Forward pass of the connection
  def forward(self, x_slow, x_fast):
    # Reduce the temporal dimension of the Fast pathway by half
    x_fast = nn.MaxPool3d(kernel_size=(1 + self.i % 2, 1, 1), stride=(1 + self.i % 2, 1, 1))(x_fast)
    # Reduce the channel dimension of the Fast pathway by beta
    x_fast = self.conv(x_fast)
    x_fast = self.bn(x_fast)
    # Concatenate the Fast pathway to the Slow pathway along channel dimension
    x_slow = torch.cat([x_slow, x_fast], dim=1)
    # Return the fused outputs
    return x_slow, x_fast

```

## Pseudo Code - Detail

Here is a possible detailed pseudo code to implement this paper:

```python
# Import the necessary modules
import torch
import torch.nn as nn
import torchvision.models as models

# Define the SlowFast network class
class SlowFast(nn.Module):
  # Initialize the network with hyperparameters and backbone
  def __init__(self, alpha=8, beta=1/8, resnet=models.resnet50(pretrained=True)):
    super(SlowFast, self).__init__()
    self.alpha = alpha # frame rate ratio
    self.beta = beta # channel ratio
    self.resnet = resnet # ResNet backbone with 3D convolutions
    self.lateral = nn.ModuleList() # lateral connections
    # Replace the first convolution layer with a 3D convolution layer
    self.resnet.conv1 = nn.Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
    # Replace the 2D convolution layers in each stage with 3D convolution layers
    for i in range(1, 5):
      for j in range(len(self.resnet.layer[i])):
        self.resnet.layer[i][j].conv1 = nn.Conv3d(self.resnet.layer[i][j].conv1.in_channels,
                                                   self.resnet.layer[i][j].conv1.out_channels,
                                                   kernel_size=(1 + i % 2, 3, 3),
                                                   stride=self.resnet.layer[i][j].conv1.stride,
                                                   padding=self.resnet.layer[i][j].conv1.padding,
                                                   bias=False)
        self.resnet.layer[i][j].conv2 = nn.Conv3d(self.resnet.layer[i][j].conv2.in_channels,
                                                   self.resnet.layer[i][j].conv2.out_channels,
                                                   kernel_size=(1 + i % 2, 3, 3),
                                                   stride=self.resnet.layer[i][j].conv2.stride,
                                                   padding=self.resnet.layer[i][j].conv2.padding,
                                                   bias=False)
        self.resnet.layer[i][j].conv3 = nn.Conv3d(self.resnet.layer[i][j].conv3.in_channels,
                                                   self.resnet.layer[i][j].conv3.out_channels,
                                                   kernel_size=(1 + i % 2, 1, 1),
                                                   stride=self.resnet.layer[i][j].conv3.stride,
                                                   padding=self.resnet.layer[i][j].conv3.padding,
                                                   bias=False)
        if self.resnet.layer[i][j].downsample is not None:
          self.resnet.layer[i][j].downsample[0] = nn.Conv3d(self.resnet.layer[i][j].downsample[0].in_channels,
                                                            self.resnet.layer[i][j].downsample[0].out_channels,
                                                            kernel_size=(1 + i % 2, 1, 1),
                                                            stride=self.resnet.layer[i][j].downsample[0].stride,
                                                            bias=False)
      # Create lateral connections for each stage
      self.lateral.append(LateralConnection(i))

  # Forward pass of the network
  def forward(self, x):
    # Split the input into two pathways
    x_slow = x[:, :, ::self.alpha, :, :] # Slow pathway with T frames
    x_fast = x # Fast pathway with alpha*T frames
    # Initialize the outputs of each stage
    out_slow = []
    out_fast = []
    # Pass the input through the first convolution layer and max pooling layer
    x_slow = self.resnet.conv1(x_slow)
    x_fast = self.resnet.conv1(x_fast)
    x_slow = self.resnet.bn1(x_slow)
    x_fast = self.resnet.bn1(x_fast)
    x_slow = self.resnet.relu(x_slow)
    x_fast = self.resnet.relu(x_fast)
    x_slow = self.resnet.maxpool(x_slow)
    x_fast = self.resnet.maxpool(x_fast)
    # Pass the input through the ResNet backbone
    for i in range(1, 5):
      # Get the output of the i-th stage for both pathways
      x_slow = self.resnet.layer[i](x_slow)
      x_fast = self.resnet.layer[i](x_fast)
      # Fuse the outputs by lateral connections
      x_slow, x_fast = self.lateral[i](x_slow, x_fast)
      # Append the outputs to the lists
      out_slow.append(x_slow)
      out_fast.append(x_fast)
    # Return the final outputs of both pathways
    return out_slow[-1], out_fast[-1]

# Define the lateral connection class
class LateralConnection(nn.Module):
  # Initialize the connection with stage index
  def __init__(self, i):
    super(LateralConnection, self).__init__()
    self.i = i # stage index
    self.conv = nn.Conv3d(64 * 2 ** (i - 1), int(64 * 2 ** (i - 1) * beta), kernel_size=1, bias=False) # 3D convolution layer
    self.bn = nn.BatchNorm3d(int(64 * 2 ** (i - 1) * beta)) # batch normalization layer

  # Forward pass of the connection
  def forward(self, x_slow, x_fast):
    # Reduce the temporal dimension of the Fast pathway by half
    x_fast = nn.MaxPool3d(kernel_size=(1 + self.i % 2, 1, 1), stride=(1 + self.i % 2, 1, 1))(x_fast)
    # Reduce the channel dimension of the Fast pathway by beta
    x_fast = self.conv(x_fast)
    x_fast = self.bn(x_fast)
    # Concatenate the Fast pathway to the Slow pathway along channel dimension
    x_slow = torch.cat([x_slow, x_fast], dim=1)
    # Return the fused outputs
    return x_slow, x_fast

```