---
title: 1804.08497v2 ALIGNet  Partial-Shape Agnostic Alignment via Unsupervised Learning
date: 2018-04-09
---

# [ALIGNet: Partial-Shape Agnostic Alignment via Unsupervised Learning](http://arxiv.org/abs/1804.08497v2)

authors: Rana Hanocka, Noa Fish, Zhenhua Wang, Raja Giryes, Shachar Fleishman, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/1804.08497v2 "[1804.08497v2] ALIGNet: Partial-Shape Agnostic Alignment via ..."
[2]: https://arxiv.org/pdf/2007.08497v2.pdf "Abstract arXiv:2007.08497v2 [cs.NE] 28 Aug 2020"

Here is a summary of the paper:

- **What**: The paper presents a deep neural network called ALIGNet that can align a pair of shapes, even if they are incomplete or have missing parts, by learning a shape-aware prior from shape datasets.
- **Why**: The paper aims to solve the problem of shape alignment, which is a fundamental operation in computer graphics, but is challenging when the shapes are incomplete or have significant differences. The paper also wants to demonstrate that the network can learn the common characteristics of shape collections and produce plausible deformations on unseen data.
- **How**: The paper trains ALIGNet on the task of shape alignment using incomplete shapes generated from full shapes for self-supervision. The network learns to warp complete source shapes to incomplete targets, as if the target shapes were complete. The paper also uses an anisotropic total variation identity regularization to promote piecewise smooth deformation fields. The paper evaluates ALIGNet on several shape datasets and shows that it can align geometrically distinct shapes and infer plausible mappings even when the target shape is significantly incomplete.

## Main Contributions

[1]: https://arxiv.org/abs/1804.08497v2 "[1804.08497v2] ALIGNet: Partial-Shape Agnostic Alignment via ..."
[2]: https://arxiv.org/pdf/2007.08497v2.pdf "Abstract arXiv:2007.08497v2 [cs.NE] 28 Aug 2020"

The paper claims the following contributions:

- **A novel deep neural network for shape alignment that is robust to shape incompleteness and does not require ground truth alignments for supervision.**
- **A shape-aware prior learned from shape datasets that enables the network to align geometrically distinct shapes and infer plausible mappings even when the target shape is significantly incomplete.**
- **An anisotropic total variation identity regularization that promotes piecewise smooth deformation fields and facilitates partial-shape agnosticism and post-deformation applications.**
- **An extensive evaluation of the network on several shape datasets and a comparison with state-of-the-art methods, showing that the network can produce plausible deformations on unseen data during test time.**

## Method Summary

[1]: https://arxiv.org/abs/1804.08497v2 "[1804.08497v2] ALIGNet: Partial-Shape Agnostic Alignment via ..."
[2]: https://arxiv.org/pdf/2007.08497v2.pdf "Abstract arXiv:2007.08497v2 [cs.NE] 28 Aug 2020"

Here is a summary of the method section of the paper:

- **The paper proposes a deep neural network called ALIGNet that takes as input a pair of shapes and outputs a deformation field that warps the source shape to the target shape.**
- **The network consists of two main components: an encoder-decoder module that learns a shape-aware prior from shape datasets and a deformation module that applies the deformation field to the source shape.**
- **The paper trains the network on the task of shape alignment using incomplete shapes generated from full shapes for self-supervision. The network learns to warp complete source shapes to incomplete targets, as if the target shapes were complete, thus essentially rendering the alignment partial-shape agnostic.**
- **The paper also introduces an anisotropic total variation identity regularization that constrains the deformation field to be piecewise smooth and close to identity, which facilitates both partial-shape agnosticism and post-deformation applications.**
- **The paper evaluates the network on several shape datasets and compares it with state-of-the-art methods, showing that the network can align geometrically distinct shapes and infer plausible mappings even when the target shape is significantly incomplete.**

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the network architecture
ALIGNet = EncoderDecoder + DeformationModule

# Define the loss function
Loss = ReconstructionLoss + RegularizationLoss

# Define the training data
TrainingData = {SourceShape, TargetShape}

# Generate incomplete shapes from full shapes
IncompleteShapes = GenerateIncompleteShapes(FullShapes)

# Train the network on the task of shape alignment
For each epoch:
  For each batch of TrainingData:
    # Get the source and target shapes
    SourceShape = TrainingData.SourceShape
    TargetShape = TrainingData.TargetShape
    
    # Feed the source and target shapes to the network
    DeformationField = ALIGNet(SourceShape, TargetShape)
    
    # Apply the deformation field to the source shape
    WarpedSourceShape = DeformationModule(SourceShape, DeformationField)
    
    # Compute the reconstruction loss between the warped source shape and the target shape
    ReconstructionLoss = L2Distance(WarpedSourceShape, TargetShape)
    
    # Compute the regularization loss on the deformation field
    RegularizationLoss = AnisotropicTotalVariationIdentity(DeformationField)
    
    # Compute the total loss
    Loss = ReconstructionLoss + Lambda * RegularizationLoss
    
    # Update the network parameters using gradient descent
    UpdateParameters(Loss)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np

# Define the network architecture
class EncoderDecoder(nn.Module):
  def __init__(self, input_channels, output_channels):
    super(EncoderDecoder, self).__init__()
    # Define the encoder layers
    self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, padding=1)
    self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
    self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
    self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)
    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
    
    # Define the decoder layers
    self.upconv1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
    self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
    self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
    self.upconv4 = nn.ConvTranspose2d(64, output_channels, kernel_size=2, stride=2)

  def forward(self, x):
    # Encode the input
    x = F.relu(self.conv1(x))
    x = self.pool(x)
    x = F.relu(self.conv2(x))
    x = self.pool(x)
    x = F.relu(self.conv3(x))
    x = self.pool(x)
    x = F.relu(self.conv4(x))
    
    # Decode the output
    x = F.relu(self.upconv1(x))
    x = F.relu(self.upconv2(x))
    x = F.relu(self.upconv3(x))
    x = F.relu(self.upconv4(x))
    
    return x

class DeformationModule(nn.Module):
  def __init__(self):
    super(DeformationModule, self).__init__()
  
  def forward(self, source_shape, deformation_field):
    # Apply the deformation field to the source