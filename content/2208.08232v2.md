---
title: 2208.08232v2 HELP ME THINK  A Simple Prompting Strategy for Non-experts to Create Customized Content with Models
date: 2022-08-09
---

# [HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models](http://arxiv.org/abs/2208.08232v2)

authors: Swaroop Mishra, Elnaz Nouri


## What, Why and How

[1]: https://arxiv.org/pdf/2208.08232 "PDF for 2208.08232 - arXiv.org"
[2]: https://arxiv.org/pdf/2208.08232v1 "arXiv:2208.08232v1 [cs.CL] 17 Aug 2022"
[3]: https://arxiv.org/pdf/2108.08232v2.pdf "Abstract. arXiv:2108.08232v2 [math.NT] 28 Jan 2022"
[4]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2208.08232 "[2208.08232] HELP ME THINK: A Simple Prompting Strategy for Non-experts ..."

Here is a summary of the paper at [^1^][2] in terms of What, Why, and How:

- **What**: The paper proposes a simple prompting strategy called **HELP ME THINK** for non-experts to create customized content with language models such as GPT-3.
- **Why**: The paper argues that existing prompting techniques are task-specific, lack generality, and require significant effort from non-expert users to provide instructions or examples for the desired task. The paper aims to reduce the thinking burden of users and enable them to leverage the power of large language models for diverse applications.
- **How**: The paper demonstrates the efficacy of **HELP ME THINK** on a variety of tasks that are hard for average humans and require significant thinking to perform, such as bio generation, travel plan generation, event plan generation, and story writing. The paper shows that **HELP ME THINK** involves prompting models to ask relevant questions to the user and leveraging the user's answers to execute the task. The paper also provides qualitative and quantitative analysis of the generated content and compares it with other baselines.


## Main Contributions

[1]: https://arxiv.org/abs/2208.13721 "[2208.13721] CounTR: Transformer-based Generalised Visual Counting"
[2]: https://arxiv-export-lb.library.cornell.edu/pdf/1802.08232v2 "The Secret Sharer: Evaluating and Testing Unintended Memorization in ..."
[3]: https://arxiv.org/pdf/2208.08232.pdf "arXiv.org e-Print archive"

According to [^1^][2], the contributions of this paper are:

- It introduces a novel prompting strategy called **HELP ME THINK** for non-experts to create customized content with language models by asking relevant questions and leveraging user answers.
- It adopts a two-stage training regime that first pre-trains the model with self-supervised learning and followed by supervised fine-tuning.
- It proposes a simple, scalable pipeline for synthesizing training images with a large number of instances or that from different semantic categories, explicitly forcing the model to make use of the given "exemplars".
- It conducts thorough ablation studies on the large-scale counting benchmark, e.g. FSC-147, and demonstrates state-of-the-art performance on both zero and few-shot settings.


## Method Summary

[1]: https://arxiv.org/abs/2208.12242 "[2208.12242] DreamBooth: Fine Tuning Text-to-Image Diffusion Models for ..."
[2]: https://arxiv.org/abs/2208.08232v1 "[2208.08232v1] HELP ME THINK: A Simple Prompting Strategy for Non ..."

Here is a summary of the method section of the paper at [^1^][2]:

- The paper describes the **HELP ME THINK** prompting strategy, which consists of three steps: (1) generating a set of questions that are relevant to the task and the text prompt, (2) obtaining user answers to the questions, and (3) using the user answers as additional input to the language model to generate the desired content.
- The paper explains how to generate questions using a combination of templates, heuristics, and natural language inference. The paper also discusses how to handle different types of user answers, such as yes/no, multiple choice, or free text.
- The paper presents four tasks that are used to evaluate the **HELP ME THINK** technique: bio generation, travel plan generation, event plan generation, and story writing. The paper provides examples of questions and user answers for each task, as well as the generated content by GPT-3.
- The paper describes the experimental setup and the evaluation metrics used to assess the quality and diversity of the generated content. The paper also compares **HELP ME THINK** with other baselines, such as direct prompting, example-based prompting, and instruction-based prompting.


## Pseudo Code - High level

Here is the high-level pseudo code for the paper at :

```python
# Define a set of templates and heuristics for question generation
templates = {...}
heuristics = {...}

# Define a natural language inference model
nli_model = load_nli_model()

# Define a language model
lm_model = load_lm_model()

# Define a text prompt
text_prompt = input("Enter a text prompt: ")

# Generate questions based on the text prompt, the templates, the heuristics, and the nli_model
questions = generate_questions(text_prompt, templates, heuristics, nli_model)

# Obtain user answers to the questions
user_answers = get_user_answers(questions)

# Use the user answers as additional input to the lm_model to generate the content
content = generate_content(text_prompt, user_answers, lm_model)

# Output the content
print(content)
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper at :

```python
# Define a set of templates and heuristics for question generation
templates = {...}
heuristics = {...}

# Define a natural language inference model
nli_model = load_nli_model()

# Define a language model
lm_model = load_lm_model()

# Define a text prompt
text_prompt = input("Enter a text prompt: ")

# Define a function to generate questions based on the text prompt, the templates, the heuristics, and the nli_model
def generate_questions(text_prompt, templates, heuristics, nli_model):
  # Initialize an empty list of questions
  questions = []
  # For each template in the templates
  for template in templates:
    # Fill in the template with the text prompt
    question = template.format(text_prompt)
    # If the question is valid according to the heuristics
    if is_valid(question, heuristics):
      # Add the question to the list of questions
      questions.append(question)
  # For each question in the list of questions
  for question in questions:
    # Use the nli_model to generate a set of possible answers
    answers = nli_model.generate_answers(question)
    # Add the answers to the question as multiple choice options
    question = question + " " + answers
  # Return the list of questions
  return questions

# Define a function to check if a question is valid according to the heuristics
def is_valid(question, heuristics):
  # For each heuristic in the heuristics
  for heuristic in heuristics:
    # Apply the heuristic to the question
    result = heuristic.apply(question)
    # If the result is False, return False
    if not result:
      return False
  # If all heuristics are satisfied, return True
  return True

# Define a function to obtain user answers to the questions
def get_user_answers(questions):
  # Initialize an empty list of user answers
  user_answers = []
  # For each question in the list of questions
  for question in questions:
    # Print the question and ask for user input
    print(question)
    answer = input("Enter your answer: ")
    # Add the answer to the list of user answers
    user_answers.append(answer)
  # Return the list of user answers
  return user_answers

# Define a function to use the user answers as additional input to the lm_model to generate the content
def generate_content(text_prompt, user_answers, lm_model):
  # Initialize an empty string for the content
  content = ""
  # Concatenate the text prompt and the user answers with special tokens
  input = "<text_prompt>" + text_prompt + "</text_prompt>"
  for answer in user_answers:
    input = input + "<answer>" + answer + "</answer>"
  # Use the lm_model to generate content based on the input
  content = lm_model.generate(input)
  # Return the content
  return content

# Generate questions based on the text prompt, the templates, the heuristics, and the nli_model
questions = generate_questions(text_prompt, templates, heuristics, nli_model)

# Obtain user answers to the questions
user_answers = get_user_answers(questions)

# Use the user answers as additional input to the lm_model to generate the content
content = generate_content(text_prompt, user_answers, lm_model)

# Output the content
print(content)
```