---
title: 2306.00473v1 Interpretable simultaneous localization of MRI corpus callosum and classification of atypical Parkinsonian disorders using YOLOv5
date: 2023-06-01
---

# [Interpretable simultaneous localization of MRI corpus callosum and classification of atypical Parkinsonian disorders using YOLOv5](http://arxiv.org/abs/2306.00473v1)

authors: Vamshi Krishna Kancharla, Debanjali Bhattacharya, Neelam Sinha, Jitender Saini, Pramod Kumar Pal, Sandhya M


## What, Why and How

[1]: https://arxiv.org/abs/2306.00473 "[2306.00473] Interpretable simultaneous localization of MRI corpus ..."
[2]: https://arxiv.org/pdf/2306.00473v1.pdf "Interpretable simultaneous localization of MRI corpus ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.00473 "[2306.00473] Interpretable simultaneous localization of MRI corpus ..."

Here is a summary of the paper:

- **What**: The paper proposes a method to simultaneously localize the corpus callosum (CC) in structural MRI images and classify atypical Parkinsonian disorders (APDs) from healthy controls (HCs) using YOLOv5, a deep learning model for object detection[^1^][1].
- **Why**: The paper aims to address the challenges of detecting subtle changes in CC that might be associated with various neurological disorders, especially APDs, which are more severe and less treatable than classical Parkinson's disease (PD). The paper also aims to provide interpretability of the model predictions by generating heatmaps that highlight the most important sub-regions of CC for classification[^1^][1].
- **How**: The paper uses a proprietary dataset of 20 HCs and 20 APDs and applies YOLOv5 to detect and crop the CC region from the MRI images. Then, it uses the cropped CC images as inputs to a classifier that distinguishes APDs from HCs. The paper also uses Eigen CAM, a technique based on eigenvalue decomposition and class activation mapping, to generate heatmaps that show which parts of CC contribute most to the classification decision[^1^][1]. The paper reports a mean classification accuracy of 92% with 3 rounds of hold-out validation, which is an improvement of 5% over state-of-the-art methods that used the same dataset[^1^][1]. The paper also shows that the mid-body of CC is the most distinguishable sub-region for classifying APDs and HCs, which is consistent with previous studies and medical knowledge[^1^][1].

## Main Contributions

The paper claims to make the following contributions:

- It proposes a novel framework to simultaneously localize CC and classify APDs from HCs using YOLOv5, which is faster and more accurate than previous methods that used CC morphometry and visual texture analysis.
- It incorporates the explainability of the model predictions by using Eigen CAM to generate heatmaps that identify the most important sub-regions of CC for classification.
- It validates the proposed method on a proprietary dataset of 20 HCs and 20 APDs and shows that it outperforms state-of-the-art methods by 5% in terms of classification accuracy.
- It provides evidence that the mid-body of CC is the most distinguishable sub-region for classifying APDs and HCs, which is in line with existing literature and medical understanding.

## Method Summary

The method section of the paper consists of four subsections: A) Dataset, B) CC detection using YOLOv5, C) Classification of APDs vs HCs, and D) Interpretability using Eigen CAM. Here is a summary of each subsection:

- A) Dataset: The paper uses a proprietary dataset of 20 HCs and 20 APDs (10 MSA and 10 PSP), which were acquired from the National Institute of Mental Health and Neurosciences (NIMHANS), Bangalore, India. The dataset consists of T1-weighted MRI images with a resolution of 256 x 256 pixels and a slice thickness of 1 mm. The paper also provides the demographic details and clinical scores of the subjects in the dataset.
- B) CC detection using YOLOv5: The paper applies YOLOv5, a deep learning model for object detection, to detect and crop the CC region from the MRI images. The paper uses the YOLOv5s variant, which is the smallest and fastest version of YOLOv5, with an input size of 416 x 416 pixels. The paper trains the model on 32 images (16 HCs and 16 APDs) with manual annotations of the CC bounding boxes and tests it on 8 images (4 HCs and 4 APDs). The paper reports the precision, recall, F1-score, and mean average precision (mAP) of the model on the test set.
- C) Classification of APDs vs HCs: The paper uses the cropped CC images as inputs to a classifier that distinguishes APDs from HCs. The paper uses a simple fully connected neural network with two hidden layers of 128 and 64 neurons, respectively, and a softmax output layer with two classes. The paper trains the classifier on 32 images (16 HCs and 16 APDs) with cross-entropy loss and Adam optimizer and tests it on 8 images (4 HCs and 4 APDs). The paper reports the accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUC) of the classifier on the test set.
- D) Interpretability using Eigen CAM: The paper uses Eigen CAM, a technique based on eigenvalue decomposition and class activation mapping, to generate heatmaps that show which parts of CC contribute most to the classification decision. The paper applies Eigen CAM to the last convolutional layer of YOLOv5s and obtains a heatmap for each class (APD or HC). The paper then overlays the heatmaps on the original MRI images and compares them with the manual annotations of the CC sub-regions (rostrum, genu, body, isthmus, and splenium). The paper also computes the correlation coefficient between the heatmaps and the annotations to quantify the agreement between them.

## Pseudo Code

Here is a possible pseudo code to implement this paper:

```python
# Import libraries
import torch # for deep learning
import numpy as np # for numerical operations
import cv2 # for image processing
import matplotlib.pyplot as plt # for visualization

# Load the dataset of MRI images and labels
X, y = load_dataset()

# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Define the YOLOv5s model for CC detection
model_yolo = YOLOv5s()

# Define the loss function and optimizer for YOLOv5s
loss_yolo = YOLOLoss()
optimizer_yolo = Adam(model_yolo.parameters(), lr=0.001)

# Train the YOLOv5s model on the train set
for epoch in range(epochs):
  # Shuffle the train set
  X_train, y_train = shuffle(X_train, y_train)
  # Loop over the train set in batches
  for i in range(0, len(X_train), batch_size):
    # Get a batch of images and annotations
    X_batch = X_train[i:i+batch_size]
    y_batch = y_train[i:i+batch_size]
    # Convert the images and annotations to tensors
    X_batch = torch.from_numpy(X_batch)
    y_batch = torch.from_numpy(y_batch)
    # Forward pass the images through the model
    y_pred = model_yolo(X_batch)
    # Compute the loss
    loss = loss_yolo(y_pred, y_batch)
    # Backward pass and update the weights
    optimizer_yolo.zero_grad()
    loss.backward()
    optimizer_yolo.step()
  # Print the epoch and loss
  print(f"Epoch {epoch}, Loss {loss.item()}")

# Test the YOLOv5s model on the test set
y_pred_test = model_yolo(X_test)
# Evaluate the performance of the model using metrics such as precision, recall, F1-score, and mAP
evaluate(y_pred_test, y_test)

# Crop the CC region from the images using the predicted bounding boxes
X_crop_train = crop(X_train, y_pred_train)
X_crop_test = crop(X_test, y_pred_test)

# Define the classifier for APDs vs HCs
model_clf = Classifier()

# Define the loss function and optimizer for the classifier
loss_clf = CrossEntropyLoss()
optimizer_clf = Adam(model_clf.parameters(), lr=0.001)

# Train the classifier on the cropped CC images and labels
for epoch in range(epochs):
  # Shuffle the train set
  X_crop_train, y_train = shuffle(X_crop_train, y_train)
  # Loop over the train set in batches
  for i in range(0, len(X_crop_train), batch_size):
    # Get a batch of images and labels
    X_batch = X_crop_train[i:i+batch_size]
    y_batch = y_train[i:i+batch_size]
    # Convert the images and labels to tensors
    X_batch = torch.from_numpy(X_batch)
    y_batch = torch.from_numpy(y_batch)
    # Forward pass the images through the model
    y_pred = model_clf(X_batch)
    # Compute the loss
    loss = loss_clf(y_pred, y_batch)
    # Backward pass and update the weights
    optimizer_clf.zero_grad()
    loss.backward()
    optimizer_clf.step()
  # Print the epoch and loss
  print(f"Epoch {epoch}, Loss {loss.item()}")

# Test the classifier on the cropped CC images and labels
y_pred_test = model_clf(X_crop_test)
# Evaluate the performance of the model using metrics such as accuracy, sensitivity, specificity, and AUC
evaluate(y_pred_test, y_test)

# Generate heatmaps using Eigen CAM for interpretability
heatmaps_apd = EigenCAM(model_yolo, X_crop_test, class="APD")
heatmaps_hc = EigenCAM(model_yolo, X_crop_test, class="HC")

# Visualize the heatmaps overlaid on the original MRI images and compare them with manual annotations of CC sub-regions
for i in range(len(X_test)):
  # Plot the original MRI image
  plt.subplot(1,4,1)
  plt.imshow(X_test[i], cmap="gray")
  plt.title("Original MRI image")
  # Plot the heatmap for APD class
  plt.subplot(1,4,2)
  plt.imshow(X_test[i], cmap="gray")
  plt.imshow(heatmaps_apd[i], cmap="jet", alpha=0.5)
  plt.title("Heatmap for APD class")
  # Plot the heatmap for HC class
  plt.subplot(1,4,3)
  plt.imshow(X_test[i], cmap="gray")
  plt.imshow(heatmaps_hc[i], cmap="jet", alpha=0.5)
  plt.title("Heatmap for HC class")
  # Plot the manual annotation of CC sub-regions
  plt.subplot(1,4,4)
  plt.imshow(X_test[i], cmap="gray")
  plt.imshow(annotation[i], cmap="jet", alpha=0.5)
  plt.title("Manual annotation of CC sub-regions")
  # Show the plots
  plt.show()

# Compute the correlation coefficient between the heatmaps and the annotations to quantify the agreement between them
corr_apd = correlation(heatmaps_apd, annotation)
corr_hc = correlation(heatmaps_hc, annotation)
print(f"Correlation coefficient for APD class: {corr_apd}")
print(f"Correlation coefficient for HC class: {corr_hc}")
```