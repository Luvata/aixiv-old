---
title: 2107.08430v2 YOLOX  Exceeding YOLO Series in 2021
date: 2021-07-09
---

# [YOLOX: Exceeding YOLO Series in 2021](http://arxiv.org/abs/2107.08430v2)

authors: Zheng Ge, Songtao Liu, Feng Wang, Zeming Li, Jian Sun


## What, Why and How

[1]: https://arxiv.org/abs/2107.08430 "[2107.08430] YOLOX: Exceeding YOLO Series in 2021 - arXiv.org"
[2]: https://arxiv.org/pdf/2107.08430v2.pdf "Number of parameters (M) - arXiv.org"
[3]: http://export.arxiv.org/abs/2107.08430 "[2107.08430] YOLOX: Exceeding YOLO Series in 2021"

Here is a summary of the paper:

- **What**: The paper presents YOLOX, a new high-performance detector that exceeds YOLO series in 2021. YOLOX is an anchor-free detector that adopts a decoupled head and the SimOTA label assignment strategy.
- **Why**: The paper aims to provide useful experience for developers and researchers in practical scenes, and to achieve state-of-the-art results across a large scale range of models with different speed and accuracy trade-offs.
- **How**: The paper switches the YOLO detector to an anchor-free manner and conducts other advanced detection techniques, such as:
    - A decoupled head that separates the classification and localization branches, and uses depthwise convolutions to reduce computation and parameters.
    - A leading label assignment strategy SimOTA that dynamically assigns positive and negative samples based on the similarity between predictions and targets, and optimizes the assignment with a Sinkhorn algorithm.
    - A unified network architecture that can be easily scaled up or down by changing the depth, width and resolution of the network.
    - A data augmentation method called Mosaic that randomly crops four images and stitches them together to form a new training image.
    - A simple self-training pipeline that leverages unlabeled data to improve the performance of the detector.

## Main Contributions

According to the paper, the contributions are:

- They propose YOLOX, a new high-performance detector that exceeds YOLO series in 2021. YOLOX is an anchor-free detector that adopts a decoupled head and the SimOTA label assignment strategy.
- They achieve state-of-the-art results across a large scale range of models with different speed and accuracy trade-offs. For example, YOLOX-L achieves 50.0% AP on COCO at a speed of 68.9 FPS on Tesla V100, exceeding YOLOv5-L by 1.8% AP.
- They provide deploy versions with ONNX, TensorRT, NCNN, and Openvino supported, and also release the source code and models.
- They won the 1st Place on Streaming Perception Challenge (Workshop on Autonomous Driving at CVPR 2021) using a single YOLOX-L model.

## Method Summary

Here is a summary of the method section of the paper:

- The paper describes the design choices and implementation details of YOLOX, an anchor-free detector that exceeds YOLO series in 2021.
- The paper first introduces the anchor-free detection framework, which predicts the center location, size and class of each object in a grid-based manner. The paper then explains how to switch the YOLO detector to an anchor-free manner by modifying the output format and loss function.
- The paper then presents the decoupled head, which separates the classification and localization branches in the detection head. The paper argues that this design can reduce the feature misalignment and feature redundancy problems in the original YOLO head. The paper also uses depthwise convolutions to reduce the computation and parameters of the head.
- The paper then introduces the SimOTA label assignment strategy, which dynamically assigns positive and negative samples based on the similarity between predictions and targets. The paper claims that this strategy can overcome the limitations of hand-crafted assignment rules and improve the recall and robustness of the detector. The paper also optimizes the assignment with a Sinkhorn algorithm to balance the positive and negative samples.
- The paper then describes the unified network architecture, which can be easily scaled up or down by changing the depth, width and resolution of the network. The paper follows the design principles of YOLOv5 and uses a modified CSPNet as the backbone, a FPN as the neck, and a decoupled head as the head. The paper also uses SiLU activation function and Mish activation function to improve the performance of the network.
- The paper then discusses the data augmentation method called Mosaic, which randomly crops four images and stitches them together to form a new training image. The paper states that this method can increase the diversity and complexity of the training data, and also improve the performance on small objects.
- The paper then presents a simple self-training pipeline, which leverages unlabeled data to improve the performance of the detector. The paper uses a teacher-student framework, where the teacher model is trained on labeled data and generates pseudo labels for unlabeled data, and then the student model is trained on both labeled data and pseudo-labeled data. The paper also uses a confidence threshold to filter out low-quality pseudo labels.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the network architecture
backbone = Modified_CSPNet()
neck = FPN()
head = Decoupled_Head()
network = YOLOX(backbone, neck, head)

# Define the loss function
loss_function = YOLOX_Loss()

# Define the label assignment strategy
label_assigner = SimOTA()

# Define the data augmentation method
data_augmenter = Mosaic()

# Train the network on labeled data
for epoch in range(num_epochs):
  for batch in labeled_data:
    # Apply data augmentation
    batch = data_augmenter(batch)
    # Forward pass
    predictions = network(batch.images)
    # Assign labels
    labels = label_assigner(predictions, batch.targets)
    # Compute loss
    loss = loss_function(predictions, labels)
    # Backward pass and update weights
    loss.backward()
    optimizer.step()

# Save the network as the teacher model
teacher_model = network

# Generate pseudo labels for unlabeled data
for batch in unlabeled_data:
  # Forward pass with teacher model
  predictions = teacher_model(batch.images)
  # Filter out low-confidence predictions
  pseudo_labels = filter(predictions, confidence_threshold)
  # Save pseudo labels
  save(pseudo_labels)

# Train the network on both labeled data and pseudo-labeled data
for epoch in range(num_epochs):
  for batch in mix(labeled_data, pseudo_labeled_data):
    # Apply data augmentation
    batch = data_augmenter(batch)
    # Forward pass
    predictions = network(batch.images)
    # Assign labels
    labels = label_assigner(predictions, batch.targets)
    # Compute loss
    loss = loss_function(predictions, labels)
    # Backward pass and update weights
    loss.backward()
    optimizer.step()
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

# Define the modified CSPNet backbone
class Modified_CSPNet(nn.Module):
  def __init__(self, num_layers, num_channels):
    super(Modified_CSPNet, self).__init__()
    # Initialize the layers
    self.conv1 = nn.Conv2d(3, num_channels, kernel_size=3, stride=2, padding=1)
    self.bn1 = nn.BatchNorm2d(num_channels)
    self.silu1 = nn.SiLU()
    self.conv2 = nn.Conv2d(num_channels, num_channels * 2, kernel_size=3, stride=2, padding=1)
    self.bn2 = nn.BatchNorm2d(num_channels * 2)
    self.silu2 = nn.SiLU()
    self.conv3 = nn.Conv2d(num_channels * 2, num_channels * 4, kernel_size=3, stride=2, padding=1)
    self.bn3 = nn.BatchNorm2d(num_channels * 4)
    self.silu3 = nn.SiLU()
    self.csp_blocks = nn.ModuleList([CSPBlock(num_channels * 4) for _ in range(num_layers)])
    self.conv4 = nn.Conv2d(num_channels * 4, num_channels * 8, kernel_size=3, stride=2, padding=1)
    self.bn4 = nn.BatchNorm2d(num_channels * 8)
    self.silu4 = nn.SiLU()
    self.conv5 = nn.Conv2d(num_channels * 8, num_channels * 16, kernel_size=3, stride=2, padding=1)
    self.bn5 = nn.BatchNorm2d(num_channels * 16)
    self.silu5 = nn.SiLU()
  
  def forward(self, x):
    # Forward pass through the layers
    x = self.silu1(self.bn1(self.conv1(x)))
    x = self.silu2(self.bn2(self.conv2(x)))
    x = self.silu3(self.bn3(self.conv3(x)))
    for csp_block in self.csp_blocks:
      x = csp_block(x)
    x_8x = x # output at 8x resolution
    x = self.silu4(self.bn4(self.conv4(x)))
    x_16x = x # output at 16x resolution
    x = self.silu5(self.bn5(self.conv5(x)))
    x_32x = x # output at 32x resolution
    return x_8x, x_16x, x_32x

# Define the CSP block
class CSPBlock(nn.Module):
  def __init__(self, num_channels):
    super(CSPBlock, self).__init__()
    # Initialize the layers
    self.conv1 = nn.Conv2d(num_channels // 2, num_channels // 2, kernel_size=1)
    self.bn1 = nn.BatchNorm2d(num_channels // 2)
    self.silu1 = nn.SiLU()
    self.conv2 = nn.Conv2d(num_channels // 2, num_channels // 2, kernel_size=3, padding=1)
    self.bn2 = nn.BatchNorm2d(num_channels // 2)
    self.silu2 = nn.SiLU()
  
  def forward(self, x):
    # Split the input into two parts
    x_1, x_2 = torch.split(x, num_channels // 2, dim=1)
    # Forward pass through the layers
    x_1 = self.silu1(self.bn1(self.conv1(x_1)))
    x_1 = self.silu2(self.bn2(self.conv2(x_1)))
    # Concatenate the outputs
    x_out = torch.cat([x_1, x_2], dim=1)
    return x_out

# Define the FPN neck
class FPN(nn.Module):
  def __init__(self, num_in_channels=[128, 256, 512], num_out_channels=[256] * 3):
    super(FPN, self).__init__()
    # Initialize the layers
    assert len(num_in_channels) == len(num_out_channels) == 3
    # Bottom-up layers
    self.conv_bu_8x = nn.Conv2d(num_in_channels[0], num_out_channels[0], kernel_size=1)
    self.bn_bu_8x = nn.BatchNorm2d(num_out_channels[0])
    self.silu_bu_8x = nn.SiLU()
    self.conv_bu_16x = nn.Conv2d(num_in_channels[1], num_out_channels[1], kernel_size=1)
    self.bn_bu_16x = nn.BatchNorm2d(num_out_channels[1])
    self.silu_bu_16x = nn.SiLU()
    self.conv_bu_32x = nn.Conv2d(num_in_channels[2], num_out_channels[2], kernel_size=1)
    self.bn_bu_32x = nn.BatchNorm2d(num_out_channels[2])
    self.silu_bu_32x = nn.SiLU()
    # Top-down layers
    self.conv_td_8x = nn.Conv2d(num_out_channels[0], num_out_channels[0], kernel_size=3, padding=1)
    self.bn_td_8x = nn.BatchNorm2d(num_out_channels[0])
    self.silu_td_8x = nn.SiLU()
    self.conv_td_16x = nn.Conv2d(num_out_channels[1], num_out_channels[1], kernel_size=3, padding=1)
    self.bn_td_16x = nn.BatchNorm2d(num_out_channels[1])
    self.silu_td_16x = nn.SiLU()
    self.conv_td_32x = nn.Conv2d(num_out_channels[2], num_out_channels[2], kernel_size=3, padding=1)
    self.bn_td_32x = nn.BatchNorm2d(num_out_channels[2])
    self.silu_td_32x = nn.SiLU()
  
  def forward(self, x):
    # Forward pass through the bottom-up layers
    x_bu_8x = self.silu_bu_8x(self.bn_bu_8x(self.conv_bu_8x(x[0])))
    x_bu_16x = self.silu_bu_16x(self.bn_bu_16x(self.conv_bu_16x(x[1])))
    x_bu_32x = self.silu_bu_32x(self.bn_bu_32x(self.conv_bu_32x(x[2])))
    # Forward pass through the top-down layers
    x_td_32x = x_bu_32x
    x_td_16x = x_bu_16x + F.interpolate(x_td_32x, scale_factor=2, mode="nearest")
    x_td_8x = x_bu_8x + F.interpolate(x_td_16x, scale_factor=2, mode="nearest")
    # Forward pass through the final layers
    x_out_8x = self.silu_td_8x(self.bn_td_8x(self.conv_td_8x(x_td_8x)))
    x_out_16x = self.silu_td_16x(self.bn_td_16x(self.conv_td_16x(x_td_16x)))
    x_out_32x = self.silu_td_32x(self.bn_td_32x(self.conv_td_32x(x_td_32x)))
    return [x_out_8x, x_out_16x, x_out_32x]

# Define the decoupled head
class DecoupledHead(nn.Module):
  def __init__(self, num_in_channels=[256] * 3, num_classes=80):
    super(DecoupledHead, self).__init__()
    # Initialize the layers
    assert len(num_in_channels) == 3
    # Classification branch
    self.cls_convs = nn.ModuleList([nn.Sequential(
      DepthwiseConv(num_in_channels[i], num_in_channels[i]),
      DepthwiseConv(num_in_channels[i], num_in_channels[i]),
      DepthwiseConv(num_in_channels[i], num_in_channels[i]),
      DepthwiseConv(num_in_channels[i], num_in_channels[i]),
      DepthwiseConv(num_in_channels[i], num_classes),
      ) for i in range(3)])
    
    # Localization branch
    self.reg_convs = nn.ModuleList([nn.Sequential(
      DepthwiseConv(num_in_channels[i], num_in_channels[i]),
      DepthwiseConv(num_in_channels[i], num_in_channels[i]),
      DepthwiseConv(num_in_channels[i], num_in_channels[i]),
      DepthwiseConv(num_in_channels[i], num_in_channels[i]),
      DepthwiseConv(num_in_channels[i], 4),
      ) for i in range(3)])
  
  def forward(self, x):
    # Forward pass through the classification branch
    cls_preds = [self.cls_convs[i](feature) for i, feature in enumerate(x)]
    
    # Forward pass through the localization branch
    reg_preds = [self.reg_convs[i](feature) for i, feature in enumerate(x