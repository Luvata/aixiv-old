---
title: 2301.05187v1 WIRE  Wavelet Implicit Neural Representations
date: 2023-01-06
---

# [WIRE: Wavelet Implicit Neural Representations](http://arxiv.org/abs/2301.05187v1)

authors: Vishwanath Saragadam, Daniel LeJeune, Jasper Tan, Guha Balakrishnan, Ashok Veeraraghavan, Richard G. Baraniuk


## What, Why and How

[1]: https://arxiv.org/pdf/2301.05187v1 "WIRE: Wavelet Implicit Neural Representations - arXiv.org"
[2]: https://arxiv.org/abs/2301.05187 "[2301.05187] WIRE: Wavelet Implicit Neural Representations - arXiv.org"
[3]: http://export.arxiv.org/abs/2103.05187v1 "[2103.05187v1] Iterative Shrinking for Referring Expression Grounding ..."

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a new implicit neural representation (INR) called WIRE that uses a continuous complex Gabor wavelet activation function in its multilayer perceptron (MLP) network.
- **Why**: The paper aims to improve the accuracy, training time, and robustness of INRs for various vision-related tasks, such as image denoising, inpainting, super-resolution, computed tomography reconstruction, and novel view synthesis. The paper argues that the choice of the nonlinearity in the MLP network is crucial for INR performance, and that existing nonlinearities have a tradeoff between accuracy and robustness.
- **How**: The paper draws inspiration from harmonic analysis and uses a complex Gabor wavelet as the nonlinearity, which has optimal concentration in space-frequency and good biases for representing images. The paper shows that WIRE has higher representation capacity than other INRs and can handle high-dimensional data efficiently. The paper also demonstrates that WIRE outperforms state-of-the-art INRs on various experiments and benchmarks.

## Main Contributions

According to the paper at , the main contributions are:

- A new INR called WIRE that uses a continuous complex Gabor wavelet activation function in its MLP network.
- A theoretical analysis of the representation capacity of WIRE and its advantages over other nonlinearities.
- A fast and efficient implementation of WIRE that can handle high-dimensional data and large-scale optimization.
- A comprehensive evaluation of WIRE on various vision-related tasks and datasets, showing that it achieves state-of-the-art results in terms of accuracy, training time, and robustness.

## Method Summary

[1]: https://arxiv.org/pdf/2301.05187v1 "WIRE: Wavelet Implicit Neural Representations - arXiv.org"
[2]: https://arxiv.org/abs/2301.05187 "[2301.05187] WIRE: Wavelet Implicit Neural Representations - arXiv.org"
[3]: http://export.arxiv.org/abs/2103.05187v1 "[2103.05187v1] Iterative Shrinking for Referring Expression Grounding ..."

Here is a summary of the method section of the paper at [^1^][1]:

- The paper introduces WIRE, a new INR that uses a continuous complex Gabor wavelet as the nonlinearity in its MLP network. The paper defines the wavelet activation function as a product of a complex sinusoid and a Gaussian envelope, and shows how to compute its gradient efficiently.
- The paper analyzes the representation capacity of WIRE and compares it with other nonlinearities, such as ReLU, sigmoid, tanh, and SIREN. The paper shows that WIRE has higher frequency resolution and lower spatial aliasing than other nonlinearities, and that it can approximate any continuous function with fewer parameters and less error.
- The paper describes how to implement WIRE for high-dimensional data and large-scale optimization. The paper proposes a fast Fourier transform (FFT) based method to compute the wavelet activation function in the frequency domain, and a stochastic gradient descent (SGD) based method to optimize the MLP network parameters. The paper also discusses how to handle complex-valued inputs and outputs for WIRE.
- The paper evaluates WIRE on various vision-related tasks and datasets, such as image denoising, inpainting, super-resolution, computed tomography reconstruction, image overfitting, and novel view synthesis with neural radiance fields. The paper shows that WIRE achieves state-of-the-art results in terms of accuracy, training time, and robustness. The paper also provides ablation studies and qualitative examples to demonstrate the effectiveness of WIRE.

## Pseudo Code - High level

Here is the high-level pseudo code for the paper at :

```python
# Define the wavelet activation function
def wavelet(x):
  # x is a complex-valued input
  # omega and sigma are learnable parameters
  # return a complex-valued output
  return exp(-sigma * x**2) * exp(1j * omega * x)

# Define the MLP network with wavelet activation
def MLP(x):
  # x is a complex-valued input
  # W and b are learnable parameters
  # L is the number of hidden layers
  # return a complex-valued output
  for l in range(L):
    x = wavelet(W[l] @ x + b[l])
  return x

# Define the loss function for a given task
def loss(y_true, y_pred):
  # y_true and y_pred are complex-valued outputs
  # return a real-valued loss
  return ...

# Define the optimization method
def optimize():
  # initialize the parameters randomly
  # use SGD to update the parameters
  # use FFT to compute the wavelet activation in frequency domain
  # use backpropagation to compute the gradients
  # return the optimized parameters

# Define the main function
def main():
  # load the data for a given task
  # split the data into train and test sets
  # train the MLP network with wavelet activation on the train set
  # evaluate the MLP network on the test set
  # report the results and visualize some examples

```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper at :

```python
# Import the necessary libraries
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.fft as fft

# Define the wavelet activation function as a custom PyTorch module
class Wavelet(nn.Module):
  def __init__(self, in_features, out_features):
    super(Wavelet, self).__init__()
    # Initialize the omega and sigma parameters randomly
    self.omega = nn.Parameter(torch.randn(out_features, in_features))
    self.sigma = nn.Parameter(torch.randn(out_features, in_features))

  def forward(self, x):
    # x is a complex-valued input tensor of shape (batch_size, in_features)
    # return a complex-valued output tensor of shape (batch_size, out_features)
    return torch.exp(-self.sigma * x**2) * torch.exp(1j * self.omega * x)

# Define the MLP network with wavelet activation as a custom PyTorch module
class MLP(nn.Module):
  def __init__(self, in_features, out_features, hidden_layers):
    super(MLP, self).__init__()
    # Initialize the W and b parameters randomly
    self.W = nn.ParameterList([nn.Parameter(torch.randn(hidden_layers[0], in_features))] + [nn.Parameter(torch.randn(hidden_layers[i+1], hidden_layers[i])) for i in range(len(hidden_layers) - 1)] + [nn.Parameter(torch.randn(out_features, hidden_layers[-1]))])
    self.b = nn.ParameterList([nn.Parameter(torch.randn(hidden_layers[0]))] + [nn.Parameter(torch.randn(hidden_layers[i])) for i in range(1, len(hidden_layers))] + [nn.Parameter(torch.randn(out_features))])
    # Initialize the wavelet activation functions
    self.wavelets = nn.ModuleList([Wavelet(in_features, hidden_layers[0])] + [Wavelet(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers) - 1)] + [Wavelet(hidden_layers[-1], out_features)])

  def forward(self, x):
    # x is a complex-valued input tensor of shape (batch_size, in_features)
    # return a complex-valued output tensor of shape (batch_size, out_features)
    for i in range(len(self.W)):
      x = self.wavelets[i](self.W[i] @ x + self.b[i])
    return x

# Define the loss function for a given task
def loss(y_true, y_pred):
  # y_true and y_pred are complex-valued output tensors of shape (batch_size, out_features)
  # return a real-valued loss tensor of shape ()
  # For example, for image reconstruction task, use mean squared error loss
  return torch.mean((y_true - y_pred)**2)

# Define the optimization method
def optimize(model, data_loader, epochs):
  # model is an instance of MLP class
  # data_loader is a PyTorch data loader that provides batches of input-output pairs
  # epochs is an integer that specifies the number of training iterations
  # use SGD optimizer with a learning rate of 0.01
  optimizer = optim.SGD(model.parameters(), lr=0.01)
  # loop over the epochs
  for epoch in range(epochs):
    # loop over the batches
    for x, y in data_loader:
      # compute the wavelet activation in frequency domain using FFT
      x = fft.fft(x)
      y = fft.fft(y)
      # compute the output and the loss
      y_pred = model(x)
      l = loss(y, y_pred)
      # compute the gradients and update the parameters
      optimizer.zero_grad()
      l.backward()
      optimizer.step()
    # print the epoch and the loss
    print(f"Epoch {epoch}, Loss {l.item()}")
  # return the optimized model
  return model

# Define the main function
def main():
  # load the data for a given task
  # For example, for image reconstruction task, use MNIST dataset
  from torchvision.datasets import MNIST
  from torchvision.transforms import ToTensor
  data = MNIST(root="data", train=True, transform=ToTensor(), download=True)
  # split the data into train and test sets
  from torch.utils.data import random_split
  train_data, test_data = random_split(data, [50000, 10000])
  # create data loaders for train and test sets with batch size of 32
  from torch.utils.data import DataLoader
  train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
  test_loader = DataLoader(test_data, batch_size=32, shuffle=False)
  # create an instance of MLP class with input and output features of 784 (28x28) and 2 hidden layers of 256 and 128 features
  model = MLP(784, 784, [256, 128])
  # train the model on the train set for 10 epochs
  model = optimize(model, train_loader, 10)
  # evaluate the model on the test set
  # use mean squared error loss as the metric
  mse = 0
  for x, y in test_loader:
    # compute the wavelet activation in frequency domain using FFT
    x = fft.fft(x)
    y = fft.fft(y)
    # compute the output and the loss
    y_pred = model(x)
    l = loss(y, y_pred)
    # accumulate the loss
    mse += l.item() * x.shape[0]
  # compute the average loss
  mse /= len(test_data)
  # print the result
  print(f"Test MSE: {mse}")
  # visualize some examples
  import matplotlib.pyplot as plt
  for i in range(10):
    # get a random sample from the test set
    x, y = test_data[i]
    # compute the wavelet activation in frequency domain using FFT
    x = fft.fft(x)
    y = fft.fft(y)
    # compute the output and convert it to image domain using inverse FFT
    y_pred = model(x)
    y_pred = fft.ifft(y_pred)
    # plot the original and reconstructed images
    plt.subplot(2, 10, i+1)
    plt.imshow(y.squeeze(), cmap="gray")
    plt.axis("off")
    plt.subplot(2, 10, i+11)
    plt.imshow(y_pred.squeeze(), cmap="gray")
    plt.axis("off")
  plt.show()

```