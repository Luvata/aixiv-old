---
title: 2306.00265v1 Doubly Robust Self-Training
date: 2023-06-01
---

# [Doubly Robust Self-Training](http://arxiv.org/abs/2306.00265v1)

authors: Banghua Zhu, Mingyu Ding, Philip Jacobson, Ming Wu, Wei Zhan, Michael Jordan, Jiantao Jiao


## What, Why and How

[1]: https://arxiv.org/pdf/2306.00265v1.pdf "Wei Zhan, Michael Jordan, Jiantao Jiao June 2, 2023 - arXiv.org"
[2]: https://arxiv.org/abs/2301.00265 "Title: Source-Free Unsupervised Domain Adaptation: A Survey - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.00265 "[2306.00265] Doubly Robust Self-Training - export.arxiv.org"

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a novel semi-supervised learning algorithm called **doubly robust self-training** that balances between two extremes: using only labeled data or using all pseudo-labeled and labeled data.
- **Why**: The paper aims to overcome the limitations of standard self-training, which can be highly sensitive to the accuracy of the teacher model and can miss important information from the labeled data.
- **How**: The paper introduces a **doubly robust loss** that combines a **direct loss** and an **inverse propensity score loss**. The direct loss measures the discrepancy between the student model and the teacher model on the pseudo-labeled data, while the inverse propensity score loss measures the discrepancy between the student model and the true model on the labeled data. The paper also provides theoretical guarantees and empirical evaluations of the proposed method on image classification and 3D object detection tasks.

## Main Contributions

[1]: https://arxiv.org/pdf/2306.00265v1.pdf "Wei Zhan, Michael Jordan, Jiantao Jiao June 2, 2023 - arXiv.org"
[2]: https://arxiv.org/abs/2301.00265 "Title: Source-Free Unsupervised Domain Adaptation: A Survey - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.00265 "[2306.00265] Doubly Robust Self-Training - export.arxiv.org"

According to the paper at [^1^][1], the main contributions are:

- **Theoretically**: The paper establishes a **consistency** and **sample complexity** result for the doubly robust self-training algorithm under a general semi-supervised learning framework. The paper also shows that the doubly robust loss can be viewed as a **generalization** of the standard self-training loss and the empirical risk minimization loss.
- **Empirically**: The paper demonstrates the **superiority** of the doubly robust self-training algorithm over the standard self-training baseline on both the ImageNet dataset for image classification and the nuScenes autonomous driving dataset for 3D object detection. The paper also shows that the doubly robust self-training algorithm can achieve **comparable** or **better** performance than state-of-the-art semi-supervised learning methods on these tasks.

## Method Summary

[1]: https://arxiv.org/pdf/2306.00265v1.pdf "Wei Zhan, Michael Jordan, Jiantao Jiao June 2, 2023 - arXiv.org"
[2]: https://arxiv.org/abs/2301.00265 "Title: Source-Free Unsupervised Domain Adaptation: A Survey - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.00265 "[2306.00265] Doubly Robust Self-Training - export.arxiv.org"

Here is a summary of the method section of the paper at [^1^][1]:

- The paper introduces a general semi-supervised learning framework that consists of a teacher model, a student model, a labeled dataset and an unlabeled dataset. The paper assumes that the teacher model is obtained from prior training and can generate pseudo-labels for the unlabeled data. The paper also assumes that the labeled data and the unlabeled data are drawn from different but related distributions.
- The paper defines the **doubly robust loss** as a combination of a **direct loss** and an **inverse propensity score loss**. The direct loss measures the discrepancy between the student model and the teacher model on the pseudo-labeled data, while the inverse propensity score loss measures the discrepancy between the student model and the true model on the labeled data. The paper shows that the doubly robust loss can be viewed as a generalization of the standard self-training loss and the empirical risk minimization loss.
- The paper establishes a **consistency** result for the doubly robust self-training algorithm, which states that under certain conditions, the student model converges to the true model as the sample size increases. The paper also provides a **sample complexity** result for the doubly robust self-training algorithm, which states that under certain conditions, the student model achieves a fast convergence rate with respect to both the labeled data and the unlabeled data.
- The paper applies the doubly robust self-training algorithm to two tasks: image classification and 3D object detection. The paper uses ResNet-50 as the backbone network for both tasks and modifies it according to different architectures. The paper also uses different teacher models for different tasks, such as MoCo-v2 for image classification and PointPillars for 3D object detection. The paper evaluates the performance of the doubly robust self-training algorithm on both the ImageNet dataset and the nuScenes autonomous driving dataset.

## Pseudo Code

Here is a possible pseudo code to implement the paper:

```python
# Input: a teacher model T, a student model S, a labeled dataset D_l, an unlabeled dataset D_u
# Output: a trained student model S
# Hyperparameters: learning rate alpha, batch size B, number of epochs E

# Initialize S with the same weights as T
# For each epoch e in 1 to E:
  # Shuffle D_l and D_u
  # For each batch of B samples from D_l and D_u:
    # Generate pseudo-labels for the unlabeled samples using T
    # Compute the direct loss L_d as the cross-entropy between S and T on the pseudo-labeled samples
    # Compute the inverse propensity score w for each labeled sample as the probability of being labeled given its features
    # Compute the inverse propensity score loss L_ips as the weighted cross-entropy between S and the true labels on the labeled samples
    # Compute the doubly robust loss L_dr as L_d + L_ips
    # Update S by gradient descent with learning rate alpha on L_dr
# Return S
```