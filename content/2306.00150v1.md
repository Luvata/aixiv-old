---
title: 2306.00150v1 Enrichment of the NLST and NSCLC-Radiomics computed tomography collections with AI-derived annotations
date: 2023-06-01
---

# [Enrichment of the NLST and NSCLC-Radiomics computed tomography collections with AI-derived annotations](http://arxiv.org/abs/2306.00150v1)

authors: Deepa Krishnaswamy, Dennis Bontempi, Vamsi Thiriveedhi, Davide Punzo, David Clunie, Christopher P Bridge, Hugo JWL Aerts, Ron Kikinis, Andrey Fedorov


## What, Why and How

[1]: https://arxiv.org/abs/2306.00150 "[2306.00150] Enrichment of the NLST and NSCLC-Radiomics computed ..."
[2]: https://arxiv.org/pdf/2306.00150 "SCIENTIFIC DATA PAPER arxiv"
[3]: http://export.arxiv.org/abs/2306.00150 "[2306.00150] Enrichment of the NLST and NSCLC-Radiomics computed ..."

Here is a summary of the paper:

- **What**: The paper describes how AI-derived annotations were generated for two collections of computed tomography images of the chest, NSCLC-Radiomics and the National Lung Screening Trial, and made publicly available within NCI Imaging Data Commons (IDC).
- **Why**: The paper aims to enrich public data for the development and evaluation of automated tools in cancer imaging, as many datasets do not include annotations or image-derived features that are useful for downstream analysis.
- **How**: The paper uses publicly available AI algorithms to derive volumetric annotations of thoracic organs at risk, their corresponding radiomics features, and slice-level annotations of anatomical landmarks and regions. The paper also provides cloud-enabled notebooks demonstrating how to use the annotations within IDC.

## Main Contributions

[1]: https://arxiv.org/abs/2306.00150 "[2306.00150] Enrichment of the NLST and NSCLC-Radiomics computed ..."
[2]: https://arxiv.org/pdf/2306.00150 "SCIENTIFIC DATA PAPER arxiv"
[3]: http://export.arxiv.org/abs/2306.00150 "[2306.00150] Enrichment of the NLST and NSCLC-Radiomics computed ..."

The paper claims to make the following contributions:

- It introduces AI-generated annotations for two collections of computed tomography images of the chest, NSCLC-Radiomics and the National Lung Screening Trial, which are publicly available within NCI Imaging Data Commons (IDC).
- It uses publicly available AI algorithms to derive volumetric annotations of thoracic organs at risk, their corresponding radiomics features, and slice-level annotations of anatomical landmarks and regions.
- It provides cloud-enabled notebooks demonstrating how to use the annotations within IDC for various tasks such as cohort selection, data exploration, and feature extraction.
- It reinforces the need for large, publicly accessible curated datasets and demonstrates how AI can be used to aid in cancer imaging.

## Method Summary

[1]: https://arxiv.org/abs/2306.00150 "[2306.00150] Enrichment of the NLST and NSCLC-Radiomics computed ..."
[2]: https://arxiv.org/pdf/2306.00150 "SCIENTIFIC DATA PAPER arxiv"
[3]: http://export.arxiv.org/abs/2306.00150 "[2306.00150] Enrichment of the NLST and NSCLC-Radiomics computed ..."

Here is a summary of the method section of the paper:

- The paper describes the methods used to perform the preprocessing, analysis, and post-processing of the results for generating AI annotations for two collections of computed tomography images of the chest, NSCLC-Radiomics and the National Lung Screening Trial.
- The preprocessing steps include downloading the data from TCIA, converting them to DICOM format, and uploading them to IDC.
- The analysis steps include applying publicly available AI algorithms to derive volumetric annotations of thoracic organs at risk, their corresponding radiomics features, and slice-level annotations of anatomical landmarks and regions. The paper also describes how to validate the AI annotations using manual annotations or existing literature.
- The post-processing steps include storing the AI annotations in IDC using DICOM format, creating cohorts based on the annotations, and providing cloud-enabled notebooks to demonstrate how to use the annotations for various tasks such as cohort selection, data exploration, and feature extraction.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the collections of interest
collections = ["NSCLC-Radiomics", "NLST"]

# Download the data from TCIA
data = download_data_from_tcia(collections)

# Convert the data to DICOM format
data = convert_to_dicom(data)

# Upload the data to IDC
upload_to_idc(data)

# Apply AI algorithms to derive annotations
annotations = apply_ai_algorithms(data)

# Validate the annotations using manual annotations or existing literature
validate_annotations(annotations)

# Store the annotations in IDC using DICOM format
store_annotations_in_idc(annotations)

# Create cohorts based on the annotations
cohorts = create_cohorts(annotations)

# Provide cloud-enabled notebooks to demonstrate how to use the annotations
provide_notebooks(cohorts, annotations)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import requests
import pydicom
import numpy as np
import pandas as pd
import SimpleITK as sitk
import radiomics
import matplotlib.pyplot as plt
import tensorflow as tf

# Define the collections of interest
collections = ["NSCLC-Radiomics", "NLST"]

# Define the base URL for TCIA API
base_url = "https://services.cancerimagingarchive.net/services/v4/TCIA"

# Define the base URL for IDC API
idc_url = "https://idc-sandbox-000.firebaseapp.com"

# Define the AI algorithms to use
ai_algorithms = {
    "organ_segmentation": "https://github.com/DeepSeg/DeepSeg",
    "radiomics_features": "https://github.com/Radiomics/pyradiomics",
    "landmark_detection": "https://github.com/aim-harvard/landmark-detection"
}

# Define the validation sources
validation_sources = {
    "organ_segmentation": "https://github.com/aim-harvard/manual-segmentations",
    "radiomics_features": "https://www.nature.com/articles/sdata2017117",
    "landmark_detection": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7239708/"
}

# Define a function to download data from TCIA
def download_data_from_tcia(collections):
    # Initialize an empty list to store the data
    data = []

    # Loop through each collection
    for collection in collections:
        # Get the series instances for the collection
        series_url = base_url + "/query/getSeries?Collection=" + collection
        series_response = requests.get(series_url)
        series_json = series_response.json()

        # Loop through each series instance
        for series in series_json:
            # Get the series UID and modality
            series_uid = series["SeriesInstanceUID"]
            modality = series["Modality"]

            # Skip if the modality is not CT
            if modality != "CT":
                continue

            # Get the image instances for the series
            image_url = base_url + "/query/getImage?SeriesInstanceUID=" + series_uid
            image_response = requests.get(image_url)

            # Extract the zip file containing the images
            zip_file = image_response.content
            zip_path = "./" + collection + "/" + series_uid + ".zip"
            with open(zip_path, "wb") as f:
                f.write(zip_file)

            # Unzip the file and read the images as numpy arrays
            images = []
            with zipfile.ZipFile(zip_path, "r") as z:
                for filename in z.namelist():
                    with z.open(filename) as f:
                        ds = pydicom.dcmread(f)
                        img = ds.pixel_array.astype(np.float32)
                        images.append(img)

            # Stack the images along the z-axis to form a 3D volume
            volume = np.stack(images, axis=0)

            # Append the volume and the metadata to the data list
            data.append({
                "collection": collection,
                "series_uid": series_uid,
                "volume": volume,
                "metadata": ds
            })

    # Return the data list
    return data

# Define a function to convert data to DICOM format
def convert_to_dicom(data):
    # Loop through each item in the data list
    for item in data:
        # Get the volume and the metadata
        volume = item["volume"]
        metadata = item["metadata"]

        # Loop through each slice in the volume
        for i in range(volume.shape[0]):
            # Get the slice and update its metadata
            slice = volume[i]
            metadata.SliceLocation = i + 1

            # Create a new DICOM object and copy the metadata and pixel data
            ds = pydicom.dataset.Dataset()
            ds.update(metadata)
            ds.PixelData = slice.tobytes()

            # Save the DICOM object as a file
            dicom_path = "./" + item["collection"] + "/" + item["series_uid"] + "/" + str(i) + ".dcm"
            pydicom.filewriter.dcmwrite(dicom_path, ds)

    # Return the data list with updated paths to DICOM files
    return data

# Define a function to upload data to IDC
def upload_to_idc(data):
    # Loop through each item in the data list
    for item in data:
        # Get the collection and series UID
        collection = item["collection"]
        series_uid = item["series_uid"]

        # Create a new bucket for the collection in IDC
        bucket_url = idc_url + "/api/v1/buckets"
        bucket_data = {"name": collection}
        bucket_response = requests.post(bucket_url, json=bucket_data)
        bucket_id = bucket_response.json()["id"]

        # Upload the DICOM files to the bucket
        upload_url = idc_url + "/api/v1/buckets/" + bucket_id + "/upload"
        upload_data = {"series_uid": series_uid}
        upload_files = []
        for filename in os.listdir("./" + collection + "/" + series_uid):
            file_path = "./" + collection + "/" + series_uid + "/" + filename
            upload_files.append(("files", open(file_path, "rb")))
        upload_response = requests.post(upload_url, data=upload_data, files=upload_files)

    # Return the data list with updated paths to IDC buckets
    return data

# Define a function to apply AI algorithms to derive annotations
def apply_ai_algorithms(data):
    # Initialize an empty list to store the annotations
    annotations = []

    # Loop through each item in the data list
    for item in data:
        # Get the volume and the metadata
        volume = item["volume"]
        metadata = item["metadata"]

        # Convert the volume to a SimpleITK image
        sitk_image = sitk.GetImageFromArray(volume)

        # Apply the organ segmentation algorithm to get a mask of thoracic organs at risk
        organ_segmentation_model = tf.keras.models.load_model(ai_algorithms["organ_segmentation"])
        organ_segmentation_mask = organ_segmentation_model.predict(volume)
        organ_segmentation_mask = np.argmax(organ_segmentation_mask, axis=-1)
        organ_segmentation_mask = sitk.GetImageFromArray(organ_segmentation_mask)

        # Apply the radiomics features algorithm to get a set of features for each organ
        radiomics_extractor = radiomics.featureextractor.RadiomicsFeatureExtractor(ai_algorithms["radiomics_features"])
        radiomics_features = {}
        for i in range(1, 5):
            organ_mask = sitk.BinaryThreshold(organ_segmentation_mask, i, i)
            features = radiomics_extractor.execute(sitk_image, organ_mask)
            radiomics_features[i] = features

        # Apply the landmark detection algorithm to get a set of landmarks and regions for each slice
        landmark_detection_model = tf.keras.models.load_model(ai_algorithms["landmark_detection"])
        landmark_detection_results = landmark_detection_model.predict(volume)
        landmark_detection_landmarks = landmark_detection_results[0]
        landmark_detection_regions = landmark_detection_results[1]

        # Append the annotations and the metadata to the annotations list
        annotations.append({
            "collection": item["collection"],
            "series_uid": item["series_uid"],
            "organ_segmentation_mask": organ_segmentation_mask,
            "radiomics_features": radiomics_features,
            "landmark_detection_landmarks": landmark_detection_landmarks,
            "landmark_detection_regions": landmark_detection_regions,
            "metadata": metadata
        })

    # Return the annotations list
    return annotations

# Define a function to validate the annotations using manual annotations or existing literature
def validate_annotations(annotations):
    # Loop through each item in the annotations list
    for item in annotations:
        # Get the collection and series UID
        collection = item["collection"]
        series_uid = item["series_uid"]

        # Get the organ segmentation mask and radiomics features
        organ_segmentation_mask = item["organ_segmentation_mask"]
        radiomics_features = item["radiomics_features"]

        # Get the validation source for organ segmentation
        validation_source = validation_sources["organ_segmentation"]

        # Download the manual segmentation mask for the same series UID from the validation source
        manual_segmentation_url = validation_source + "/" + series_uid + ".nii.gz"
        manual_segmentation_response = requests.get(manual_segmentation_url)
        manual_segmentation_file = manual_segmentation_response.content
        manual_segmentation_path = "./" + collection + "/" + series_uid + "_manual.nii.gz"
        with open(manual_segmentation_path, "wb") as f:
            f.write(manual_segmentation_file)

        # Read the manual segmentation mask as a SimpleITK image
        manual_segmentation_mask = sitk.ReadImage(manual_segmentation_path)

        # Compute the Dice similarity coefficient between the AI and manual segmentation masks for each organ
        dice_scores = {}
        for i in range(1, 5):
            ai_organ_mask = sitk.BinaryThreshold(organ_segmentation_mask, i, i)
            manual_organ_mask = sitk.BinaryThreshold(manual_segmentation_mask, i, i)
            dice_score = sitk.LabelOverlapMeasuresImageFilter().Execute(ai_organ_mask, manual_organ_mask)
            dice_scores[i] = dice_score

        # Plot the AI and manual