---
title: 1906.02361v1 Explain Yourself! Leveraging Language Models for Commonsense Reasoning
date: 2019-06-03
---

# [Explain Yourself! Leveraging Language Models for Commonsense Reasoning](http://arxiv.org/abs/1906.02361v1)

authors: Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, Richard Socher


## What, Why and How

[1]: https://arxiv.org/abs/1906.02361 "[1906.02361] Explain Yourself! Leveraging Language Models for ..."
[2]: https://arxiv.org/pdf/1906.02361v1.pdf "arXiv:1906.02361v1 [cs.CL] 6 Jun 2019"
[3]: http://export.arxiv.org/abs/2006.02361v1 "Title: Optimizing Neural Networks via Koopman Operator Theory"

Here is a summary of the paper:

- **What**: The paper proposes a novel framework called **Commonsense Auto-Generated Explanation (CAGE)** that leverages language models to generate explanations for commonsense reasoning tasks[^1^][1].
- **Why**: The paper aims to improve the performance of deep learning models on tasks that require commonsense reasoning, which often necessitates some form of world-knowledge or reasoning over information not immediately present in the input[^1^][1].
- **How**: The paper introduces a new dataset called **Common Sense Explanations (CoS-E)** that contains human explanations for commonsense reasoning in the form of natural language sequences and highlighted annotations[^1^][1]. The paper uses CoS-E to train language models to automatically generate explanations that can be used during training and inference in the CAGE framework[^1^][1]. The paper evaluates CAGE on the challenging CommonsenseQA task and shows that it improves the state-of-the-art by 10%[^1^][1]. The paper also studies commonsense reasoning in DNNs using both human and auto-generated explanations including transfer to out-of-domain tasks[^1^][1].

## Main Contributions

The paper claims to make the following contributions:

- It collects and releases a new dataset called CoS-E that contains human explanations for commonsense reasoning.
- It proposes a novel framework called CAGE that leverages language models to generate explanations for commonsense reasoning.
- It improves the state-of-the-art by 10% on the CommonsenseQA task using CAGE.
- It studies the impact of human and auto-generated explanations on commonsense reasoning in DNNs and shows that they can transfer to out-of-domain tasks.

## Method Summary

[1]: https://arxiv.org/pdf/1906.02361v1.pdf "arXiv:1906.02361v1 [cs.CL] 6 Jun 2019"
[2]: https://arxiv.org/abs/1906.02361 "[1906.02361] Explain Yourself! Leveraging Language Models for ..."
[3]: https://arxiv-export2.library.cornell.edu/abs/1909.02361v1 "[1909.02361v1] Homology Groups and Categorical Diagonalization"

Here is a summary of the method section of the paper:

- The paper proposes **Commonsense Auto-Generated Explanations (CAGE)** as a framework for generating explanations for **CommonsenseQA (CQA)**, a multiple-choice question answering dataset that requires commonsense reasoning[^1^][1].
- The paper breaks down the task of commonsense reasoning into two phases: **explanation generation** and **explanation-augmented reasoning**[^1^][1].
- In the explanation generation phase, the paper provides a CQA example alongside the corresponding **Common Sense Explanations (CoS-E)** explanation to a language model and asks it to generate an explanation for each answer choice[^1^][1]. The paper uses a pretrained **GPT-2** model (Radford et al., 2019) as the language model and fine-tunes it on CoS-E[^1^][1].
- In the explanation-augmented reasoning phase, the paper uses the generated explanations as additional input to a question answering model and predicts the correct answer choice[^1^][1]. The paper uses a pretrained **BERT** model (Devlin et al., 2019) as the question answering model and fine-tunes it on CQA with or without explanations[^1^][1].
- The paper also introduces a novel technique called **explanation dropout** that randomly drops out some of the generated explanations during training to make the model more robust and less reliant on explanations[^1^][1].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Load the pretrained GPT-2 and BERT models
gpt2 = load_model("gpt2")
bert = load_model("bert")

# Fine-tune GPT-2 on CoS-E dataset
for question, answer_choices, human_explanation in CoS-E:
  for answer_choice in answer_choices:
    # Generate an explanation for each answer choice
    generated_explanation = gpt2.generate(question + answer_choice)
    # Compute the loss between the generated and human explanations
    loss = compute_loss(generated_explanation, human_explanation)
    # Update the parameters of GPT-2
    gpt2.update(loss)

# Fine-tune BERT on CQA dataset with or without explanations
for question, answer_choices, correct_answer in CQA:
  for answer_choice in answer_choices:
    # Generate an explanation for each answer choice using the fine-tuned GPT-2
    generated_explanation = gpt2.generate(question + answer_choice)
    # Apply explanation dropout with some probability
    if random() < dropout_prob:
      generated_explanation = ""
    # Concatenate the question, answer choice and explanation as input to BERT
    input = question + answer_choice + generated_explanation
    # Predict the probability of the answer choice being correct using BERT
    prob = bert.predict(input)
  # Compute the loss between the predicted and correct probabilities
  loss = compute_loss(prob, correct_answer)
  # Update the parameters of BERT
  bert.update(loss)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import transformers
import datasets

# Load the pretrained GPT-2 and BERT models and their tokenizers
gpt2 = transformers.GPT2LMHeadModel.from_pretrained("gpt2")
gpt2_tokenizer = transformers.GPT2Tokenizer.from_pretrained("gpt2")
bert = transformers.BertForMultipleChoice.from_pretrained("bert-base-uncased")
bert_tokenizer = transformers.BertTokenizer.from_pretrained("bert-base-uncased")

# Load the CoS-E and CQA datasets
cos_e = datasets.load_dataset("cos_e")
cqa = datasets.load_dataset("commonsense_qa")

# Define the hyperparameters
batch_size = 32
num_epochs = 10
learning_rate = 1e-4
dropout_prob = 0.1

# Define the optimizers
gpt2_optimizer = torch.optim.Adam(gpt2.parameters(), lr=learning_rate)
bert_optimizer = torch.optim.Adam(bert.parameters(), lr=learning_rate)

# Define the loss function
loss_fn = torch.nn.CrossEntropyLoss()

# Fine-tune GPT-2 on CoS-E dataset
for epoch in range(num_epochs):
  # Shuffle the CoS-E dataset
  cos_e.shuffle()
  # Create batches of CoS-E examples
  cos_e_batches = cos_e.batch(batch_size)
  for batch in cos_e_batches:
    # Extract the question, answer choices and human explanation from the batch
    question = batch["question"]
    answer_choices = batch["answer_choices"]
    human_explanation = batch["explanation"]
    # Initialize the loss for this batch
    batch_loss = 0
    for i in range(batch_size):
      for j in range(5):
        # Generate an explanation for each answer choice using GPT-2
        input_ids = gpt2_tokenizer.encode(question[i] + answer_choices[i][j], return_tensors="pt")
        output_ids = gpt2.generate(input_ids, max_length=50)
        generated_explanation = gpt2_tokenizer.decode(output_ids[0])
        # Compute the loss between the generated and human explanations using token-level cross entropy
        target_ids = gpt2_tokenizer.encode(human_explanation[i][j], return_tensors="pt")
        logits = gpt2(output_ids).logits
        loss = loss_fn(logits, target_ids)
        # Accumulate the loss for this batch
        batch_loss += loss
    # Update the parameters of GPT-2 using the average loss for this batch
    batch_loss /= (batch_size * 5)
    gpt2_optimizer.zero_grad()
    batch_loss.backward()
    gpt2_optimizer.step()

# Fine-tune BERT on CQA dataset with or without explanations
for epoch in range(num_epochs):
  # Shuffle the CQA dataset
  cqa.shuffle()
  # Create batches of CQA examples
  cqa_batches = cqa.batch(batch_size)
  for batch in cqa_batches:
    # Extract the question, answer choices and correct answer from the batch
    question = batch["question"]
    answer_choices = batch["answer_choices"]
    correct_answer = batch["answerKey"]
    # Initialize the input and label tensors for this batch
    input_ids = torch.zeros((batch_size, 5, 128), dtype=torch.long)
    attention_mask = torch.zeros((batch_size, 5, 128), dtype=torch.long)
    labels = torch.zeros((batch_size,), dtype=torch.long)
    for i in range(batch_size):
      for j in range(5):
        # Generate an explanation for each answer choice using the fine-tuned GPT-2
        input_ids_1 = gpt2_tokenizer.encode(question[i] + answer_choices[i][j], return_tensors="pt")
        output_ids_1 = gpt2.generate(input_ids_1, max_length=50)
        generated_explanation = gpt2_tokenizer.decode(output_ids_1[0])
        # Apply explanation dropout with some probability
        if random() < dropout_prob:
          generated_explanation = ""
        # Concatenate the question, answer choice and explanation as input to BERT and tokenize it
        input_text = question[i] + "[SEP]" + answer_choices[i][j] + "[SEP]" + generated_explanation
        input_ids_2 = bert_tokenizer.encode(input_text, max_length=128, padding="max_length", truncation=True)
        attention_mask_2 = [int(token_id > 0) for token_id in input_ids_2]
        # Store the input and attention mask tensors for this batch
        input_ids[i][j] = torch.tensor(input_ids_2)
        attention_mask[i][j] = torch.tensor(attention_mask_2)
      # Convert the correct answer to a numerical label and store it for this batch
      label = ord(correct_answer[i]) - ord("A")
      labels[i] = label
    # Predict the probability of the answer choice being correct using BERT
    outputs = bert(input_ids, attention_mask)
    probs = outputs.logits
    # Compute the loss between the predicted and correct probabilities using batch-level cross entropy
    loss = loss_fn(probs, labels)
    # Update the parameters of BERT using the loss for this batch
    bert_optimizer.zero_grad()
    loss.backward()
    bert_optimizer.step()
```