---
title: 2105.02769v1 Computer-Aided Design as Language
date: 2021-05-03
---

# [Computer-Aided Design as Language](http://arxiv.org/abs/2105.02769v1)

authors: Yaroslav Ganin, Sergey Bartunov, Yujia Li, Ethan Keller, Stefano Saliceti


## What, Why and How

[1]: https://arxiv.org/abs/2105.02769 "[2105.02769] Computer-Aided Design as Language - arXiv.org"
[2]: https://arxiv.org/pdf/2105.02769v1.pdf "Computer-AidedDesignasLanguage - arXiv.org"
[3]: http://export.arxiv.org/abs/1602.02769v1 "[1602.02769v1] Exponential growth of colored HOMFLY-PT homology"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a machine learning model that can automatically generate 2D sketches for Computer-Aided Design (CAD) applications.
- **Why**: CAD applications are used to model objects for manufacturing, but they are complex and require expertise to use. A component of CAD models that is particularly difficult to make are the 2D sketches that define the shape and constraints of the 3D object. The paper aims to develop intelligent tools that can help engineers create better designs with less effort.
- **How**: The paper uses a combination of a general-purpose language modeling technique (GPT-3) and an off-the-shelf data serialization protocol (Protocol Buffers) to represent and generate 2D sketches. The paper shows that this approach can handle the complexity of the domain and perform well for both unconditional synthesis and image-to-sketch translation tasks.

## Main Contributions

The paper claims to make the following contributions:

- It introduces a novel way of representing 2D sketches as language using Protocol Buffers, which enables the use of general-purpose language models for sketch generation.
- It demonstrates the effectiveness of using GPT-3 as a sketch generator for both unconditional synthesis and image-to-sketch translation tasks, and compares it with existing methods.
- It provides a large-scale dataset of 2D sketches from various CAD domains, which can be used for future research and applications.

## Method Summary

[1]: https://arxiv.org/abs/2105.02769 "[2105.02769] Computer-Aided Design as Language - arXiv.org"
[2]: https://arxiv.org/pdf/2105.02769v1.pdf "Computer-AidedDesignasLanguage - arXiv.org"
[3]: http://export.arxiv.org/abs/2305.02769v1 "[2305.02769v1] Towards End-to-End Semi-Supervised Table Detection with ..."

Here is a summary of the method section of the paper[^1^][1]:

- The paper defines a way of representing 2D sketches as language using Protocol Buffers, which is a data serialization protocol that allows defining structured data types and encoding them as binary strings.
- The paper uses GPT-3, a large-scale pre-trained language model, to generate sketches from these binary strings. The paper fine-tunes GPT-3 on a dataset of 2D sketches collected from various CAD domains, and uses a custom tokenizer to handle the binary strings.
- The paper evaluates the sketch generation model on two tasks: unconditional synthesis and image-to-sketch translation. For the latter task, the paper uses an off-the-shelf image encoder to extract features from images and feed them to GPT-3 as additional input. The paper compares the model with existing methods on several metrics and datasets.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the sketch data type using Protocol Buffers
message Sketch {
  repeated Entity entities = 1;
  repeated Constraint constraints = 2;
}

# Define the entity and constraint types using Protocol Buffers
message Entity {
  oneof entity_type {
    PointEntity point = 1;
    LineEntity line = 2;
    CircleArcEntity circle_arc = 3;
    InterpolatedSplineEntity spline = 4;
  }
}

message Constraint {
  oneof constraint_type {
    FixConstraint fix = 1;
    CoincidentConstraint coincident = 2;
    ConcentricConstraint concentric = 3;
    # ... other constraint types
  }
}

# Load the pre-trained GPT-3 model and the custom tokenizer
gpt3 = load_model("gpt-3")
tokenizer = load_tokenizer("custom")

# Fine-tune GPT-3 on the sketch dataset
sketches = load_dataset("sketches")
for sketch in sketches:
  binary_string = encode_sketch(sketch) # encode the sketch as a binary string
  tokens = tokenizer.tokenize(binary_string) # tokenize the binary string
  gpt3.train(tokens) # train GPT-3 on the tokens

# Generate sketches from GPT-3
for i in range(num_sketches):
  tokens = gpt3.generate() # generate tokens from GPT-3
  binary_string = tokenizer.detokenize(tokens) # detokenize the tokens
  sketch = decode_sketch(binary_string) # decode the binary string as a sketch
  display_sketch(sketch) # display the sketch

# Translate images to sketches using GPT-3 and an image encoder
images = load_dataset("images")
image_encoder = load_model("image_encoder")
for image in images:
  image_features = image_encoder(image) # extract features from the image
  tokens = gpt3.generate(image_features) # generate tokens from GPT-3 with image features as input
  binary_string = tokenizer.detokenize(tokens) # detokenize the tokens
  sketch = decode_sketch(binary_string) # decode the binary string as a sketch
  display_sketch(sketch) # display the sketch
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the required libraries
import protocol_buffers as pb
import gpt_3 as gpt3
import tokenizer as tk
import image_encoder as ie
import sketch_utils as su

# Define the sketch data type using Protocol Buffers
class Sketch(pb.Message):
  entities = pb.RepeatedField(Entity, 1)
  constraints = pb.RepeatedField(Constraint, 2)

# Define the entity and constraint types using Protocol Buffers
class Entity(pb.Message):
  entity_type = pb.OneofField(
    point = PointEntity(1),
    line = LineEntity(2),
    circle_arc = CircleArcEntity(3),
    spline = InterpolatedSplineEntity(4)
  )

class Constraint(pb.Message):
  constraint_type = pb.OneofField(
    fix = FixConstraint(1),
    coincident = CoincidentConstraint(2),
    concentric = ConcentricConstraint(3),
    # ... other constraint types
  )

# Define the subtypes of entities and constraints using Protocol Buffers
class PointEntity(pb.Message):
  is_construction = pb.BoolField(1)
  point = Vector(2)

class LineEntity(pb.Message):
  is_construction = pb.BoolField(1)
  start = Vector(2)
  end = Vector(3)

class CircleArcEntity(pb.Message):
  is_construction = pb.BoolField(1)
  center = Vector(2)
  additional_params = pb.OneofField(
    circle_params = CircleParams(3),
    arc_params = ArcParams(4)
  )

class InterpolatedSplineEntity(pb.Message):
  is_construction = pb.BoolField(1)
  is_periodic = pb.BoolField(2)
  interp_points = pb.RepeatedField(Vector, 3, at_least=2)
  start_derivative = Vector(4)
  end_derivative = Vector(5)
  additional_params = pb.OneofField(
    untrimmed_params = Empty(6),
    trimmed_params = TrimmedParams(7)
  )

# ... other subtypes of entities and constraints

# Define the vector type using Protocol Buffers
class Vector(pb.Message):
  x = pb.DoubleField(1)
  y = pb.DoubleField(2)

# Load the pre-trained GPT-3 model and the custom tokenizer
gpt3_model = gpt3.load_model("gpt-3")
tokenizer_model = tk.load_tokenizer("custom")

# Fine-tune GPT-3 on the sketch dataset
sketches_data = su.load_dataset("sketches")
for sketch_data in sketches_data:
  binary_string_data = su.encode_sketch(sketch_data) # encode the sketch as a binary string
  tokens_data = tokenizer_model.tokenize(binary_string_data) # tokenize the binary string
  gpt3_model.train(tokens_data) # train GPT-3 on the tokens

# Generate sketches from GPT-3
for i in range(num_sketches):
  tokens_gen = gpt3_model.generate() # generate tokens from GPT-3
  binary_string_gen = tokenizer_model.detokenize(tokens_gen) # detokenize the tokens
  sketch_gen = su.decode_sketch(binary_string_gen) # decode the binary string as a sketch
  su.display_sketch(sketch_gen) # display the sketch

# Translate images to sketches using GPT-3 and an image encoder
images_data = su.load_dataset("images")
image_encoder_model = ie.load_model("image_encoder")
for image_data in images_data:
  image_features_data = image_encoder_model(image_data) # extract features from the image
  tokens_gen = gpt3_model.generate(image_features_data) # generate tokens from GPT-3 with image features as input
  binary_string_gen = tokenizer_model.detokenize(tokens_gen) # detokenize the tokens
  sketch_gen = su.decode_sketch(binary_string_gen) # decode the binary string as a sketch
  su.display_sketch(sketch_gen) # display the sketch
```