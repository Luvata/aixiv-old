---
title: 2012.07463v2 Parameter-Efficient Transfer Learning with Diff Pruning
date: 2020-12-08
---

# [Parameter-Efficient Transfer Learning with Diff Pruning](http://arxiv.org/abs/2012.07463v2)

authors: Demi Guo, Alexander M. Rush, Yoon Kim


## What, Why and How

[1]: https://arxiv.org/pdf/2012.07463v2.pdf "Parameter-Efﬁcient Transfer Learning with Diff Pruning - arXiv.org"
[2]: https://arxiv.org/abs/2012.07463 "[2012.07463] Parameter-Efficient Transfer Learning with Diff Pruning"
[3]: http://export.arxiv.org/abs/2208.07463v2 "[2208.07463v2] Conv-Adapter: Exploring Parameter Efficient Transfer ..."

Here is a summary of the paper in terms of What, Why, and How:

- **What**: The paper proposes a method called **diff pruning** that enables parameter-efficient transfer learning for pretrained networks[^1^][1].
- **Why**: The paper aims to address the problem of deploying multiple tasks in storage-constrained settings, such as on-device applications, where finetuning the entire model for each task is costly and inefficient[^1^][1].
- **How**: The paper introduces a task-specific **diff vector** that extends the original pretrained parameters and is adaptively pruned during training with a differentiable approximation to the L0-norm penalty to encourage sparsity[^1^][1]. The paper evaluates diff pruning on the GLUE benchmark and shows that it can match the performance of finetuned baselines while only modifying 0.5% of the pretrained model's parameters per task[^1^][1]. The paper also compares diff pruning with other popular pruning approaches and demonstrates its scalability and flexibility[^1^][1].

## Main Contributions

The paper claims the following contributions:

- It proposes **diff pruning**, a simple and effective approach to enable parameter-efficient transfer learning within the pretrain-finetune framework.
- It shows that diff pruning can achieve competitive results on the GLUE benchmark while only modifying a small fraction of the pretrained model's parameters per task.
- It demonstrates that diff pruning scales favorably with the number of tasks and does not require access to all tasks during training, which makes it suitable for on-device deployment settings.
- It provides a theoretical analysis of diff pruning and its relation to other popular pruning methods.

## Method Summary

[1]: https://arxiv.org/pdf/2012.07463v2.pdf "Parameter-Efﬁcient Transfer Learning with Diff Pruning - arXiv.org"
[2]: https://arxiv.org/abs/2012.07463 "[2012.07463] Parameter-Efficient Transfer Learning with Diff Pruning"
[3]: https://arxiv-export2.library.cornell.edu/abs/2207.07463v2 "[2207.07463v2] The nonlinear Schr\\\"odinger equation with forcing ..."

Here is a summary of the method section of the paper:

- The paper describes **diff pruning** as a way of learning a task-specific **diff vector** that extends the original pretrained parameters and is applied on top of them[^1^][1].
- The paper defines the diff vector as a sparse vector that has the same dimension as the pretrained parameter vector and has nonzero entries only at a subset of positions[^1^][1].
- The paper introduces a differentiable approximation to the L0-norm penalty that encourages sparsity in the diff vector and allows for gradient-based optimization[^1^][1].
- The paper applies diff pruning to transformer-based models and shows how to prune different components of the model, such as embeddings, attention weights, and feed-forward layers[^1^][1].
- The paper provides a theoretical analysis of diff pruning and its relation to other popular pruning methods, such as magnitude pruning and movement pruning[^1^][1].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a pretrained model M, a task-specific dataset D, a sparsity parameter lambda
# Output: a pruned model M' for the task

# Initialize a diff vector d with the same dimension as M and set it to zero
d = torch.zeros_like(M)

# Define a differentiable approximation to the L0-norm penalty
def L0_penalty(d):
  return torch.sum(torch.sigmoid(d / beta))

# Define a loss function that combines the task loss and the sparsity penalty
def loss_function(M, d, D):
  # Apply the diff vector on top of the pretrained model
  M' = M + d
  # Compute the task loss on the dataset
  task_loss = compute_task_loss(M', D)
  # Compute the sparsity penalty on the diff vector
  sparsity_penalty = lambda * L0_penalty(d)
  # Return the total loss
  return task_loss + sparsity_penalty

# Optimize the diff vector using gradient descent
optimizer = torch.optim.Adam([d])
for epoch in range(num_epochs):
  # Shuffle the dataset
  D = shuffle(D)
  for batch in D:
    # Compute the loss
    loss = loss_function(M, d, batch)
    # Compute the gradients
    loss.backward()
    # Update the diff vector
    optimizer.step()
    # Reset the gradients
    optimizer.zero_grad()

# Prune the diff vector by setting small entries to zero
d = prune(d)

# Return the pruned model
M' = M + d
return M'
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import transformers

# Define some hyperparameters
num_epochs = 10 # number of training epochs
batch_size = 32 # batch size for training
lambda = 0.01 # sparsity parameter for L0 penalty
beta = 1.0 # temperature parameter for L0 penalty
threshold = 1e-3 # threshold for pruning small entries

# Load a pretrained transformer model and tokenizer
model = transformers.AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')

# Load a task-specific dataset and create a data loader
dataset = load_dataset('glue', 'sst2')
dataloader = torch.utils.data.DataLoader(dataset['train'], batch_size=batch_size, shuffle=True)

# Initialize a diff vector with the same dimension as the model and set it to zero
diff = torch.zeros_like(model.state_dict())

# Define a differentiable approximation to the L0-norm penalty
def L0_penalty(diff):
  return torch.sum(torch.sigmoid(diff / beta))

# Define a loss function that combines the task loss and the sparsity penalty
def loss_function(model, diff, input_ids, attention_mask, labels):
  # Apply the diff vector on top of the pretrained model parameters
  model.load_state_dict(model.state_dict() + diff)
  # Compute the task loss on the input batch
  outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
  task_loss = outputs.loss
  # Compute the sparsity penalty on the diff vector
  sparsity_penalty = lambda * L0_penalty(diff)
  # Return the total loss
  return task_loss + sparsity_penalty

# Optimize the diff vector using gradient descent
optimizer = torch.optim.Adam([diff])
for epoch in range(num_epochs):
  for batch in dataloader:
    # Tokenize the input sentences and convert them to tensors
    input_ids = tokenizer(batch['sentence'], padding=True, return_tensors='pt').input_ids
    attention_mask = tokenizer(batch['sentence'], padding=True, return_tensors='pt').attention_mask
    labels = torch.tensor(batch['label'])
    # Compute the loss
    loss = loss_function(model, diff, input_ids, attention_mask, labels)
    # Compute the gradients
    loss.backward()
    # Update the diff vector
    optimizer.step()
    # Reset the gradients
    optimizer.zero_grad()

# Prune the diff vector by setting small entries to zero
diff[torch.abs(diff) < threshold] = 0

# Return the pruned model
model.load_state_dict(model.state_dict() + diff)
return model
```