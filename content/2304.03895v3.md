---
title: 2304.03895v3 MCDIP-ADMM  Overcoming Overfitting in DIP-based CT reconstruction
date: 2023-04-04
---

# [MCDIP-ADMM: Overcoming Overfitting in DIP-based CT reconstruction](http://arxiv.org/abs/2304.03895v3)

authors: Chen Cheng, Qingping Zhou


## What, Why and How

[1]: https://arxiv.org/abs/2304.03895 "[2304.03895] Multi-code deep image prior based plug-and-play ADMM for ..."
[2]: https://arxiv.org/pdf/2304.03895 "PDF for 2304.03895 - arXiv.org"
[3]: https://lib-arxiv-013.serverfarm.cornell.edu/abs/2304.03895v3 "[2304.03895v3] MCDIP-ADMM: Overcoming Overfitting in DIP-based CT ..."

Here is a summary of the paper:

- **What**: The paper proposes a **multi-code deep image prior (MCDIP)** based plug-and-play ADMM method for image denoising and CT reconstruction. MCDIP is a variant of the deep image prior (DIP) that uses multiple latent codes to represent an image. The paper also combines MCDIP with a handcrafted prior to improve the performance of imaging inverse problems.
- **Why**: The paper aims to overcome the overfitting problem that occurs in DIP-based methods, which can degrade the quality of the reconstructed images. The paper also aims to improve the interpretability and representability of the image prior by using multiple latent codes and a handcrafted prior.
- **How**: The paper uses the alternative direction method of multipliers (ADMM) algorithm to solve the imaging inverse problems with MCDIP and a handcrafted prior. The paper compares the proposed method with existing state-of-the-art methods on image denoising and CT reconstruction tasks, and shows that the proposed method achieves better results in terms of peak signal to noise ratio (PSNR) and structural similarity index (SSIM).[^1^][1] [^2^][2] [^3^][3]


## Main Contributions

The paper claims the following contributions:

- It proposes a novel multi-code deep image prior that can eliminate overfitting and is robust to the different numbers of the latent codes.
- It combines the multi-code deep image prior with a handcrafted prior to enhance the interpretability and representability of the image prior.
- It applies the proposed method to image denoising and CT reconstruction problems and demonstrates its superiority over existing methods.

## Method Summary

The method section of the paper consists of three parts:

- The first part introduces the deep image prior (DIP) and its limitations, such as overfitting and sensitivity to the number of latent codes. It also reviews some existing approaches to image priors, such as variational Bayesian TV (VBTV) and weighted TV (WTV).
- The second part presents the proposed multi-code deep image prior (MCDIP), which uses multiple latent codes to represent an image. It explains how MCDIP can overcome overfitting and improve the representability of the image prior. It also shows how MCDIP can be combined with a handcrafted prior to form a hybrid prior.
- The third part describes the plug-and-play ADMM algorithm that is used to solve the imaging inverse problems with the proposed hybrid prior. It gives the details of the algorithm and the implementation. It also discusses some practical issues, such as the choice of parameters and the stopping criterion.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: y: observed image, A: measurement operator, lambda: regularization parameter, K: number of latent codes, N: number of iterations
# Output: x: reconstructed image

# Initialize x, z, u, v, w with random values
# Initialize DIP network f with random weights
# Initialize handcrafted prior g

for i in range(N):
  # Update x by solving a least squares problem with ADMM
  x = argmin_x(||Ax - y||^2 + rho/2 * ||x - z + u||^2)
  
  # Update z by solving a denoising problem with MCDIP and handcrafted prior
  z = argmin_z(rho/2 * ||x - z + u||^2 + lambda * (||g(z)||_1 + ||f(z)||_2^2))
  
  # Update u by gradient ascent
  u = u + alpha * (x - z)
  
  # Update v by solving a least squares problem with ADMM
  v = argmin_v(||f(v) - w||^2 + rho/2 * ||v - z + u||^2)
  
  # Update w by solving a denoising problem with MCDIP
  w = argmin_w(||f(v) - w||^2 + lambda * ||f(w)||_2^2)
  
  # Update f by gradient descent
  f = f - beta * grad_f(||f(v) - w||^2 + lambda * (||f(z)||_2^2 + ||f(w)||_2^2))
  
  # Check the stopping criterion
  if converged:
    break

return x
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import libraries
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from scipy.sparse.linalg import cg

# Define the DIP network f
class DIP(nn.Module):
  def __init__(self, K):
    super(DIP, self).__init__()
    # K: number of latent codes
    # C: number of channels
    # H: height of the image
    # W: width of the image
    
    # Define the encoder layers
    self.enc1 = nn.Conv2d(C, 64, 3, padding=1)
    self.enc2 = nn.Conv2d(64, 128, 3, padding=1)
    self.enc3 = nn.Conv2d(128, 256, 3, padding=1)
    
    # Define the decoder layers
    self.dec1 = nn.ConvTranspose2d(256 * K, 128, 3, padding=1)
    self.dec2 = nn.ConvTranspose2d(128, 64, 3, padding=1)
    self.dec3 = nn.ConvTranspose2d(64, C, 3, padding=1)
    
    # Define the activation function
    self.relu = nn.ReLU()
    
    # Define the latent codes
    self.z = nn.Parameter(torch.randn(K, 256, H // 8, W // 8))
  
  def forward(self, x):
    # x: input image of shape (C, H, W)
    
    # Encode x
    x = self.relu(self.enc1(x))
    x = self.relu(self.enc2(x))
    x = self.relu(self.enc3(x))
    
    # Concatenate x with z
    x = torch.cat([x] + [self.z[i] for i in range(K)], dim=1)
    
    # Decode x
    x = self.relu(self.dec1(x))
    x = self.relu(self.dec2(x))
    x = self.relu(self.dec3(x))
    
    return x

# Define the handcrafted prior g
def g(x):
  # x: input image of shape (C, H, W)
  
  # Compute the gradient of x along horizontal and vertical directions
  gx = np.gradient(x)[0]
  gy = np.gradient(x)[1]
  
  # Compute the magnitude of the gradient
  gxy = np.sqrt(gx ** 2 + gy ** 2)
  
  return gxy

# Define the measurement operator A
def A(x):
  # x: input image of shape (C * H * W,)
  
  # Convert x to a matrix of shape (H * W, C)
  x = x.reshape(H * W, C)
  
  # Apply a random mask to each channel of x
  mask = np.random.choice([0, 1], size=(H * W,))
  y = np.multiply(x.T, mask).T
  
  # Convert y to a vector of shape (C * H * W,)
  y = y.reshape(C * H * W,)
  
  return y

# Define the ADMM algorithm
def ADMM(y):
  # y: observed image of shape (C * H * W,)
  
  # Initialize x, z, u, v, w with random values of shape (C * H * W,)
  x = np.random.randn(C * H * W,)
  z = np.random.randn(C * H * W,)
  u = np.random.randn(C * H * W,)
  v = np.random.randn(C * H * W,)
  w = np.random.randn(C * H * W,)
  
  # Initialize DIP network f with random weights
  f = DIP(K)
  
  # Initialize optimizer for f
  optimizer = optim.Adam(f.parameters(), lr=beta)
  
  for i in range(N):
    # Update x by solving a least squares problem with conjugate gradient method
    b = y + rho * (z - u) / (A.T @ A + rho * np.eye(C * H * W,))
    x = cg(A.T @ A + rho * np.eye(C * H * W,), b)[0]
    
    # Update z by solving a denoising problem with MCDIP and handcrafted prior using soft thresholding
    z_hat = x + u
    z_hat_img = z_hat.reshape(C, H, W) # convert z_hat to an image of shape (C, H, W)
    
    f_z_hat_img = f(z_hat_img) # apply f to z_hat_img
    f_z_hat = f_z_hat_img.reshape(C * H * W,) # convert f_z_hat_img to a vector of shape (C * H * W,)
    
    g_z_hat_img = g(z_hat_img) # apply g to z_hat_img
    g_z_hat = g_z_hat_img.reshape(C * H * W,) # convert g_z_hat_img to a vector of shape (C * H * W,)
    
    z = np.sign(z_hat - lambda / rho * (f_z_hat + g_z_hat)) * np.maximum(np.abs(z_hat - lambda / rho * (f_z_hat + g_z_hat)) - lambda / rho, 0)
    
    # Update u by gradient ascent
    u = u + alpha * (x - z)
    
    # Update v by solving a least squares problem with conjugate gradient method
    b = w + rho * (z - u) / (f(v).T @ f(v) + rho * np.eye(C * H * W,))
    v = cg(f(v).T @ f(v) + rho * np.eye(C * H * W,), b)[0]
    
    # Update w by solving a denoising problem with MCDIP using soft thresholding
    w_hat = f(v)
    w = np.sign(w_hat - lambda / rho * f(w)) * np.maximum(np.abs(w_hat - lambda / rho * f(w)) - lambda / rho, 0)
    
    # Update f by gradient descent
    optimizer.zero_grad()
    loss = torch.norm(f(v) - w) ** 2 + lambda * (torch.norm(f(z) ** 2) + torch.norm(f(w) ** 2))
    loss.backward()
    optimizer.step()
    
    # Check the stopping criterion
    if np.linalg.norm(x - z) < epsilon and np.linalg.norm(v - z) < epsilon:
      break
  
  return x
```