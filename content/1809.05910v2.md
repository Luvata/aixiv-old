---
title: 1809.05910v2 MeshCNN  A Network with an Edge
date: 2018-09-06
---

# [MeshCNN: A Network with an Edge](http://arxiv.org/abs/1809.05910v2)

authors: Rana Hanocka, Amir Hertz, Noa Fish, Raja Giryes, Shachar Fleishman, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/1809.05910 "[1809.05910] MeshCNN: A Network with an Edge - arXiv.org"
[2]: https://arxiv.org/pdf/1809.05910v2.pdf "arXiv.org e-Print archive"
[3]: http://export.arxiv.org/abs/1809.05910 "[1809.05910] MeshCNN: A Network with an Edge - export.arxiv.org"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes MeshCNN, a convolutional neural network designed specifically for triangular meshes.
- **Why**: The paper aims to utilize the unique properties of the mesh for a direct analysis of 3D shapes using neural networks that combine convolution and pooling operations.
- **How**: The paper introduces specialized convolution and pooling layers that operate on the mesh edges, by leveraging their intrinsic geodesic connections. Convolutions are applied on edges and the four edges of their incident triangles, and pooling is applied via an edge collapse operation that retains surface topology, thereby, generating new mesh connectivity for the subsequent convolutions. MeshCNN learns which edges to collapse, thus forming a task-driven process where the network exposes and expands the important features while discarding the redundant ones. The paper demonstrates the effectiveness of MeshCNN on various learning tasks applied to 3D meshes.


## Main Contributions

[1]: https://arxiv.org/pdf/1809.05910v1 "MeshCNN: A Network with an Edge - arXiv.org"
[2]: https://arxiv.org/abs/1809.05910 "[1809.05910] MeshCNN: A Network with an Edge - arXiv.org"
[3]: https://www.sciencedirect.com/science/article/pii/S0169260721004466 "MedmeshCNN - Enabling meshcnn for medical surface models"
[4]: https://dl.acm.org/doi/10.1145/3306346.3322959 "MeshCNN: a network with an edge - ACM Digital Library"
[5]: https://www.mdpi.com/2079-9292/11/15/2466 "Face-Based CNN on Triangular Mesh with Arbitrary Connectivity - MDPI"

According to the paper[^1^][1], the main contributions are:

- The paper introduces **MeshCNN**, a neural network that is analogous to the well-known CNN, but designed specifically for meshes.
- The paper presents **specialized convolution and pooling layers** that operate on the mesh edges, by leveraging their intrinsic geodesic connections.
- The paper proposes a **task-driven pooling** process where the network learns which edges to collapse, thus forming a non-uniform representation that adapts to the shape features.
- The paper demonstrates the effectiveness of MeshCNN on various learning tasks applied to 3D meshes, such as **shape classification**, **segmentation**, and **human correspondence**.

## Method Summary

[1]: https://arxiv.org/abs/1809.05910 "[1809.05910] MeshCNN: A Network with an Edge - arXiv.org"
[2]: https://dl.acm.org/doi/10.1145/3306346.3322959 "MeshCNN: a network with an edge - ACM Digital Library"
[3]: https://dl.acm.org/doi/10.1016/j.cmpb.2021.106372 "MedmeshCNN - Enabling meshcnn for medical surface models"

Here is a summary of the method section of the paper[^1^][1]:

- The paper defines the **mesh representation** as a set of edges and their features, such as length, dihedral angle, and edge collapse cost.
- The paper introduces the **edge convolution layer**, which takes as input a set of edges and their features, and applies a 1D convolution on each edge and its four neighboring edges in the mesh. The output is a new set of edge features with the same size as the input.
- The paper presents the **edge pooling layer**, which takes as input a set of edges and their features, and applies an edge collapse operation on a subset of edges that have the lowest collapse cost. The output is a new set of edges and features with a reduced size. The paper also introduces an **unpooling layer**, which reverses the pooling operation by splitting the collapsed edges and restoring their original features.
- The paper describes how to implement the **edge convolution** and **pooling** layers using PyTorch, and how to handle dynamic graph updates during training and inference.
- The paper explains how to design **MeshCNN architectures** for different tasks, such as shape classification, segmentation, and human correspondence. The paper also discusses some implementation details, such as data augmentation, loss functions, and hyperparameters.

## Pseudo Code - High level

Here is a possible high-level pseudo code for this paper:

```python
# Define the mesh representation as a set of edges and their features
class Mesh:
  def __init__(self, vertices, faces):
    self.edges = compute_edges(vertices, faces) # a list of edge indices
    self.features = compute_features(self.edges) # a tensor of edge features
    self.pooling_mask = compute_pooling_mask(self.edges) # a tensor of edge collapse costs

# Define the edge convolution layer
class EdgeConv(nn.Module):
  def __init__(self, in_channels, out_channels):
    self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)

  def forward(self, mesh):
    # For each edge, get its four neighboring edges in the mesh
    neighbors = get_edge_neighbors(mesh.edges)
    # Concatenate the edge features with the neighbor features
    x = torch.cat([mesh.features[edge] for edge in neighbors], dim=1)
    # Apply the 1D convolution on the concatenated features
    x = self.conv(x)
    # Return the new mesh with updated features
    return Mesh(mesh.edges, x)

# Define the edge pooling layer
class EdgePool(nn.Module):
  def __init__(self):
    pass

  def forward(self, mesh):
    # Get the edges with the lowest collapse costs
    edges_to_collapse = get_lowest_cost_edges(mesh.pooling_mask)
    # Collapse the edges and update the mesh connectivity and features
    new_edges, new_features = collapse_edges(mesh.edges, mesh.features, edges_to_collapse)
    # Return the new mesh with reduced size
    return Mesh(new_edges, new_features)

# Define the unpooling layer
class EdgeUnpool(nn.Module):
  def __init__(self):
    pass

  def forward(self, mesh, old_mesh):
    # Get the edges that were collapsed in the previous pooling layer
    edges_to_split = get_collapsed_edges(mesh.edges, old_mesh.edges)
    # Split the edges and restore the original mesh connectivity and features
    new_edges, new_features = split_edges(mesh.edges, mesh.features, edges_to_split, old_mesh.features)
    # Return the new mesh with increased size
    return Mesh(new_edges, new_features)

# Define a MeshCNN architecture for shape classification
class MeshCNNClassifier(nn.Module):
  def __init__(self):
    self.conv1 = EdgeConv(5, 16) # input features: length, dihedral angle, x/y/z coordinates
    self.pool1 = EdgePool()
    self.conv2 = EdgeConv(16, 32)
    self.pool2 = EdgePool()
    self.conv3 = EdgeConv(32, 64)
    self.pool3 = EdgePool()
    self.fc1 = nn.Linear(64 * num_edges_after_pooling, 256)
    self.fc2 = nn.Linear(256, num_classes)

  def forward(self, mesh):
    # Apply edge convolution and pooling layers
    x = self.conv1(mesh)
    x = self.pool1(x)
    x = self.conv2(x)
    x = self.pool2(x)
    x = self.conv3(x)
    x = self.pool3(x)
    # Flatten the edge features and apply fully connected layers
    x = x.features.view(-1, 64 * num_edges_after_pooling)
    x = self.fc1(x)
    x = nn.ReLU()(x)
    x = self.fc2(x)
    # Return the logits for each class
    return x

```

## Pseudo Code - Detail

Here is a possible detailed pseudo code to implement this paper:

```python
# Define some helper functions to compute edge features and collapse costs
def compute_edges(vertices, faces):
  # Initialize an empty list of edges
  edges = []
  # For each face in the mesh
  for face in faces:
    # Get the three vertex indices of the face
    v1, v2, v3 = face
    # Add the three edges of the face to the list, if not already present
    edges.append((v1, v2) if (v1, v2) not in edges else (v2, v1))
    edges.append((v2, v3) if (v2, v3) not in edges else (v3, v2))
    edges.append((v3, v1) if (v3, v1) not in edges else (v1, v3))
  # Return the list of edges
  return edges

def compute_features(edges):
  # Initialize an empty tensor of edge features
  features = torch.zeros(len(edges), 5)
  # For each edge in the mesh
  for i, edge in enumerate(edges):
    # Get the two vertex indices of the edge
    v1, v2 = edge
    # Compute the length of the edge as the Euclidean distance between the vertices
    length = torch.norm(vertices[v1] - vertices[v2])
    # Compute the dihedral angle of the edge as the angle between the normals of the two adjacent faces
    f1, f2 = get_adjacent_faces(edge)
    n1 = get_face_normal(f1)
    n2 = get_face_normal(f2)
    dihedral = torch.acos(torch.dot(n1, n2))
    # Compute the x/y/z coordinates of the edge as the average of the vertices coordinates
    x = (vertices[v1][0] + vertices[v2][0]) / 2
    y = (vertices[v1][1] + vertices[v2][1]) / 2
    z = (vertices[v1][2] + vertices[v2][2]) / 2
    # Store the edge features in the tensor
    features[i] = torch.tensor([length, dihedral, x, y, z])
  # Return the tensor of edge features
  return features

def compute_pooling_mask(edges):
  # Initialize an empty tensor of edge collapse costs
  pooling_mask = torch.zeros(len(edges))
  # For each edge in the mesh
  for i, edge in enumerate(edges):
    # Compute the QEM matrix of the edge as the sum of the QEM matrices of the two adjacent faces
    f1, f2 = get_adjacent_faces(edge)
    Q1 = get_face_QEM(f1)
    Q2 = get_face_QEM(f2)
    Q = Q1 + Q2
    # Compute the optimal position of the collapsed vertex as the one that minimizes the QEM cost
    v_opt = get_optimal_vertex(Q)
    # Compute the collapse cost as the QEM cost at the optimal position
    cost = get_QEM_cost(Q, v_opt)
    # Store the collapse cost in the tensor
    pooling_mask[i] = cost
  # Return the tensor of edge collapse costs
  return pooling_mask

# Define some helper functions to get edge neighbors and adjacent faces

def get_edge_neighbors(edges):
  # Initialize an empty list of neighbors
  neighbors = []
  # For each edge in the mesh
  for edge in edges:
    # Get the two vertex indices of the edge
    v1, v2 = edge
    # Find all other edges that share a vertex with this edge
    e1 = [e for e in edges if e != edge and v1 in e]
    e2 = [e for e in edges if e != edge and v2 in e]
    # Sort them by their dihedral angle with this edge in ascending order
    e1.sort(key=lambda e: get_dihedral_angle(edge, e))
    e2.sort(key=lambda e: get_dihedral_angle(edge, e))
    # Take the first and last edges from each list as the neighbors
    n1 = e1[0]
    n2 = e1[-1]
    n3 = e2[0]
    n4 = e2[-1]
    # Add them to the list of neighbors
    neighbors.append([edge, n1, n2, n3, n4])
  # Return the list of neighbors
  return neighbors

def get_adjacent_faces(edge):
  # Initialize an empty list of adjacent faces
  faces = []
  # For each face in the mesh
  for face in faces:
    # Get the three vertex indices of the face
    v1, v2, v3 = face
    # Check if the face contains the edge
    if (v1, v2) == edge or (v2, v1) == edge or \
       (v2, v3) == edge or (v3, v2) == edge or \
       (v3, v1) == edge or (v1, v3) == edge:
      # Add the face to the list of adjacent faces
      faces.append(face)
  # Return the list of adjacent faces
  return faces

# Define some helper functions to compute QEM matrices and costs

def get_face_normal(face):
  # Get the three vertex indices of the face
  v1, v2, v3 = face
  # Get the three vertex coordinates of the face
  p1 = vertices[v1]
  p2 = vertices[v2]
  p3 = vertices[v3]
  # Compute the normal of the face as the cross product of two edge vectors
  e1 = p2 - p1
  e2 = p3 - p1
  n = torch.cross(e1, e2)
  # Normalize the normal vector to unit length
  n = n / torch.norm(n)
  # Return the normal vector
  return n

def get_face_QEM(face):
  # Get the normal vector of the face
  n = get_face_normal(face)
  # Get the four components of the plane equation of the face: ax + by + cz + d = 0
  a = n[0]
  b = n[1]
  c = n[2]
  d = -torch.dot(n, vertices[face[0]])
  # Compute the QEM matrix of the face as the outer product of the plane vector: [a b c d]^T * [a b c d]
  Q = torch.outer(torch.tensor([a, b, c, d]), torch.tensor([a, b, c, d]))
  # Return the QEM matrix
  return Q

def get_optimal_vertex(Q):
  # Check if the QEM matrix is invertible
  if torch.det(Q[:3,:3]) != 0:
    # If yes, compute the optimal vertex as the one that satisfies Q * [x y z w]^T = 0
    v_opt = -torch.inverse(Q[:3,:3]) @ Q[:3,3]
    w_opt = torch.tensor([1.0])
    return torch.cat([v_opt, w_opt])
  else:
    # If no, compute the optimal vertex as the average of the two vertices of the edge
    v1 = vertices[edge[0]]
    v2 = vertices[edge[1]]
    v_opt = (v1 + v2) / 2
    w_opt = torch.tensor([1.0])
    return torch.cat([v_opt, w_opt])

def get_QEM_cost(Q, v):
  # Compute the QEM cost as v^T * Q * v
  cost = v @ Q @ v
  # Return the QEM cost
  return cost

# Define some helper functions to collapse and split edges

def collapse_edges(edges, features, edges_to_collapse):
  # Initialize an empty list of new edges and an empty tensor of new features
  new_edges = []
  new_features = torch.zeros(len(edges) - len(edges_to_collapse), features.size(1))
  # Initialize a dictionary to store the mapping from old vertices to new vertices
  vertex_map = {}
  # Initialize a counter for the new vertex index
  new_vertex_index = 0
  # For each edge in the mesh
  for i, edge in enumerate(edges):
    # Check if the edge is in the list of edges to collapse
    if edge in edges_to_collapse:
      # If yes, compute the optimal position of the collapsed vertex as described above
      Q = get_QEM_matrix(edge)
      v_opt = get_optimal_vertex(Q)
      # Map both vertices of the edge to the new vertex index in the dictionary
      vertex_map[edge[0]] = new_vertex_index
      vertex_map[edge[1]] = new_vertex_index
      # Store the optimal position as the new feature for this vertex index in the tensor
      new_features[new_vertex_index] = v_opt
      # Increment the new vertex index by one
      new_vertex_index += 1
    else:
      # If no, copy the edge and its features to the new list and tensor without any change
      new_edges.append(edge)
      new_features[i] = features[i]