---
title: 1806.10206v5 Deep Feature Factorization For Concept Discovery
date: 2018-06-11
---

# [Deep Feature Factorization For Concept Discovery](http://arxiv.org/abs/1806.10206v5)

authors: Edo Collins, Radhakrishna Achanta, Sabine SÃ¼sstrunk


## What, Why and How

[1]: https://arxiv.org/abs/1806.10206v5 "[1806.10206v5] Deep Feature Factorization For Concept Discovery - arXiv.org"
[2]: https://arxiv.org/pdf/1806.10206v5.pdf "Deep Feature Factorization For Concept arXiv:1806.10206v5 [cs.LG] 8 Oct ..."
[3]: http://export.arxiv.org/abs/1806.10206v5 "[1806.10206v5] Deep Feature Factorization For Concept Discovery"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a method called **Deep Feature Factorization (DFF)**, which can localize similar semantic concepts within an image or a set of images by applying non-negative matrix factorization (NMF) to the activations of a deep convolutional neural network (CNN) layer.
- **Why**: The paper aims to gain insight into the learned features of a CNN and to visualize the semantic similarity of image regions as heat maps. The paper also shows that DFF can be used for co-segmentation and co-localization tasks, achieving state-of-the-art results.
- **How**: The paper uses a pre-trained CNN for ImageNet classification and applies NMF to the activations of a chosen layer to obtain a low-rank approximation of the feature space. The paper then clusters the feature vectors using k-means and assigns each cluster a color. The paper then maps the cluster colors back to the image regions to produce heat maps that highlight the semantic correspondences. The paper also applies DFF to multiple images to find common concepts across them. The paper evaluates DFF on several datasets and compares it with existing methods for co-segmentation and co-localization.

## Main Contributions

According to the paper, the main contributions are:

- A novel method for concept discovery based on deep feature factorization, which can localize similar semantic concepts within an image or a set of images.
- A visualization technique that reveals the hierarchical cluster structures in feature space and the semantic similarity of image regions as heat maps.
- A demonstration of the applicability of DFF for co-segmentation and co-localization tasks, achieving state-of-the-art results on several datasets.

## Method Summary

The method section of the paper describes the following steps:

- Given an input image or a set of images, the paper extracts the activations of a chosen layer from a pre-trained CNN. The paper uses the VGG-16 network [32] trained on ImageNet [30] and selects the conv5_3 layer as the default layer for feature extraction.
- The paper applies NMF to the activation matrix to obtain a low-rank approximation of the feature space. The paper uses the multiplicative update algorithm [22] to solve the NMF problem and sets the rank parameter k to be equal to the number of semantic concepts to be discovered.
- The paper clusters the feature vectors using k-means and assigns each cluster a color. The paper uses the Euclidean distance as the similarity measure and initializes the cluster centers randomly. The paper then maps the cluster colors back to the image regions to produce heat maps that highlight the semantic correspondences.
- The paper also applies DFF to multiple images to find common concepts across them. The paper concatenates the activation matrices of all images and performs NMF and k-means on the combined matrix. The paper then generates heat maps for each image using the same cluster colors. The paper also introduces a measure called concept consistency score (CCS) to quantify how well DFF can discover common concepts across images.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a set of images I = {I_1, I_2, ..., I_n}
# Output: a set of heat maps H = {H_1, H_2, ..., H_n}

# Load a pre-trained CNN model (e.g., VGG-16)
model = load_model("vgg16")

# Choose a layer for feature extraction (e.g., conv5_3)
layer = model.get_layer("conv5_3")

# Initialize an empty activation matrix A
A = []

# For each image in the input set
for i in range(n):
  # Extract the activations of the chosen layer
  activations = layer.predict(I_i)
  # Reshape the activations to a 2D matrix
  activations = reshape(activations, (h * w, c))
  # Append the activations to the matrix A
  A.append(activations)

# Concatenate the activation matrices of all images
A = concatenate(A, axis=0)

# Apply NMF to the matrix A to obtain a low-rank approximation W * H
W, H = NMF(A, k)

# Cluster the rows of H using k-means to obtain cluster labels L
L = kmeans(H, k)

# Assign a color to each cluster label
colors = assign_colors(L)

# Initialize an empty set of heat maps H
H = []

# For each image in the input set
for i in range(n):
  # Create an empty heat map
  heat_map = zeros((h, w))
  # For each pixel in the image
  for x in range(h):
    for y in range(w):
      # Get the cluster label of the corresponding feature vector
      label = L[i * h * w + x * w + y]
      # Get the color of the cluster label
      color = colors[label]
      # Set the pixel value of the heat map to the color
      heat_map[x][y] = color
  # Append the heat map to the set H
  H.append(heat_map)

# Return the set of heat maps H
return H

```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a set of images I = {I_1, I_2, ..., I_n}
# Output: a set of heat maps H = {H_1, H_2, ..., H_n}

# Import the necessary libraries
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.decomposition import NMF
from sklearn.cluster import KMeans

# Load a pre-trained CNN model (e.g., VGG-16)
model = tf.keras.applications.VGG16(weights="imagenet", include_top=False)

# Choose a layer for feature extraction (e.g., conv5_3)
layer = model.get_layer("block5_conv3")

# Initialize an empty activation matrix A
A = []

# For each image in the input set
for i in range(n):
  # Preprocess the image for the model
  image = tf.keras.applications.vgg16.preprocess_input(I_i)
  # Extract the activations of the chosen layer
  activations = layer.predict(image)
  # Get the shape of the activations (height, width, channels)
  h, w, c = activations.shape
  # Reshape the activations to a 2D matrix
  activations = np.reshape(activations, (h * w, c))
  # Append the activations to the matrix A
  A.append(activations)

# Concatenate the activation matrices of all images
A = np.concatenate(A, axis=0)

# Apply NMF to the matrix A to obtain a low-rank approximation W * H
nmf = NMF(n_components=k, init="random", random_state=0)
W = nmf.fit_transform(A)
H = nmf.components_

# Cluster the rows of H using k-means to obtain cluster labels L
kmeans = KMeans(n_clusters=k, random_state=0)
L = kmeans.fit_predict(H)

# Assign a color to each cluster label
colors = plt.cm.rainbow(np.linspace(0, 1, k))

# Initialize an empty set of heat maps H
H = []

# For each image in the input set
for i in range(n):
  # Create an empty heat map
  heat_map = np.zeros((h, w, 3))
  # For each pixel in the image
  for x in range(h):
    for y in range(w):
      # Get the cluster label of the corresponding feature vector
      label = L[i * h * w + x * w + y]
      # Get the color of the cluster label
      color = colors[label]
      # Set the pixel value of the heat map to the color
      heat_map[x][y] = color
  # Append the heat map to the set H
  H.append(heat_map)

# Return the set of heat maps H
return H

```