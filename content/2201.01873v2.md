---
title: 2201.01873v2 NeuralMLS  Geometry-Aware Control Point Deformation
date: 2022-01-02
---

# [NeuralMLS: Geometry-Aware Control Point Deformation](http://arxiv.org/abs/2201.01873v2)

authors: Meitar Shechter, Rana Hanocka, Gal Metzer, Raja Giryes, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/2201.01873v2 "NeuralMLS: Geometry-Aware Control Point Deformation"
[2]: https://arxiv.org/pdf/2201.01873v2.pdf "MLS: G -A C P D - arXiv.org"
[3]: http://export.arxiv.org/abs/2201.01873v2 "[2201.01873v2] NeuralMLS: Geometry-Aware Control Point Deformation"

Here is a summary of the paper:

- **What**: The paper introduces NeuralMLS, a space-based deformation technique for 3D shapes, guided by a set of displaced control points[^1^][1] [^2^][2].
- **Why**: The paper aims to enable a realistic and intuitive shape deformation that is aware of the underlying shape geometry and can handle different surface representations and qualities[^1^][1] [^2^][2].
- **How**: The paper leverages the power of neural networks to learn a weighting function that determines the influence of each control point on every point in space, based on the input shape[^1^][1] [^2^][2]. The paper builds upon moving least-squares (MLS), a classical deformation technique that minimizes a weighted sum of the given control point displacements[^1^][1] [^2^][2]. The paper trains a network on the control points from a single input shape and exploits the innate smoothness and piecewise smoothness of neural networks[^1^][1] [^2^][2]. The paper shows that NeuralMLS facilitates intuitive piecewise smooth deformations, which are well suited for manufactured objects, and compares favorably to existing surface and space-based deformation techniques[^1^][1] [^2^][2].


## Main Contributions

The paper claims the following contributions:

- A novel space-based deformation technique that is guided by a set of displaced control points and is aware of the underlying shape geometry.
- A neural network approach to learn a weighting function that determines the influence of each control point on every point in space, based on the input shape.
- A demonstration of the advantages of NeuralMLS over existing surface and space-based deformation techniques, both quantitatively and qualitatively.

## Method Summary

The method section of the paper consists of four subsections:

- **Preliminaries**: The paper reviews the basics of moving least-squares (MLS) deformation and its variants, such as affine and rigid MLS. The paper also introduces the notation and terminology used throughout the paper.
- **NeuralMLS**: The paper presents the main idea of NeuralMLS, which is to learn a weighting function that determines the influence of each control point on every point in space, based on the input shape. The paper describes how to train a neural network on the control points from a single input shape and how to use it for deformation during inference. The paper also discusses some implementation details and design choices of the network architecture and loss function.
- **Deformation Modes**: The paper shows how to use NeuralMLS for different deformation modes, such as affine, rigid, and non-linear. The paper explains how to modify the network output and loss function accordingly for each mode. The paper also introduces a hybrid mode that combines affine and rigid MLS to achieve smooth and realistic deformations.
- **Extensions**: The paper explores some extensions of NeuralMLS, such as handling multiple shapes, applying constraints, and incorporating user feedback. The paper describes how to adapt the network input and output for each extension and provides some examples.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a 3D shape S represented by a point cloud or a mesh
# Output: a deformed shape S' according to the user-defined control points

# Step 1: Define a set of control points C on the shape S
C = select_control_points(S)

# Step 2: Train a neural network N on the control points C
N = train_network(C)

# Step 3: Displace the control points C to C' according to the user's manipulation
C' = displace_control_points(C)

# Step 4: Deform the shape S to S' using NeuralMLS
S' = NeuralMLS(S, C, C', N)

# NeuralMLS function
def NeuralMLS(S, C, C', N):
  # Initialize an empty shape S'
  S' = []
  # For each point p in S
  for p in S:
    # Compute the network output w for p
    w = N(p)
    # Normalize w to sum to one
    w = w / sum(w)
    # Compute the deformed point p' as a weighted sum of the displaced control points C'
    p' = sum(w[i] * C'[i] for i in range(len(C)))
    # Append p' to S'
    S'.append(p')
  # Return the deformed shape S'
  return S'
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a 3D shape S represented by a point cloud or a mesh
# Output: a deformed shape S' according to the user-defined control points

# Step 1: Define a set of control points C on the shape S
C = select_control_points(S)

# Step 2: Train a neural network N on the control points C
N = train_network(C)

# Step 3: Displace the control points C to C' according to the user's manipulation
C' = displace_control_points(C)

# Step 4: Deform the shape S to S' using NeuralMLS
S' = NeuralMLS(S, C, C', N)

# NeuralMLS function
def NeuralMLS(S, C, C', N):
  # Initialize an empty shape S'
  S' = []
  # For each point p in S
  for p in S:
    # Compute the network output w for p
    w = N(p)
    # Normalize w to sum to one
    w = w / sum(w)
    # Compute the deformed point p' as a weighted sum of the displaced control points C'
    p' = sum(w[i] * C'[i] for i in range(len(C)))
    # Append p' to S'
    S'.append(p')
  # Return the deformed shape S'
  return S'

# train_network function
def train_network(C):
  # Initialize a neural network N with three fully connected layers and ReLU activations
  N = NeuralNetwork([FC(3, 64), ReLU(), FC(64, 64), ReLU(), FC(64, len(C))])
  # Assign each control point c in C a unique class label l from 0 to len(C) - 1
  L = assign_labels(C)
  # Convert L to one-hot encoding O
  O = one_hot(L)
  # Define a loss function L as the mean squared error between the network output and the one-hot encoding
  L = MSE(N(C), O)
  # Define an optimizer O as Adam with a learning rate of 0.001
  O = Adam(lr=0.001)
  # Define a number of epochs E as 1000
  E = 1000
  # For each epoch e in E
  for e in range(E):
    # Shuffle the control points C and their labels O
    C, O = shuffle(C, O)
    # Compute the loss L for the current batch of control points C and their labels O
    L = MSE(N(C), O)
    # Compute the gradients of L with respect to the network parameters
    G = grad(L, N.parameters())
    # Update the network parameters using the optimizer O and the gradients G
    N.parameters() = O.step(N.parameters(), G)
    # Print the current epoch and loss
    print(e, L)
  # Return the trained network N
  return N

# select_control_points function
def select_control_points(S):
  # Initialize an empty set of control points C
  C = []
  # Define a number of control points K as desired by the user (e.g., K = 10)
  K = user_input()
  # Use a farthest point sampling algorithm to select K points from S that are maximally distant from each other
  C = FPS(S, K)
  # Return the set of control points C
  return C

# displace_control_points function
def displace_control_points(C):
  # Initialize an empty set of displaced control points C'
  C' = []
  # For each control point c in C
  for c in C:
    # Ask the user to drag c to a new position c' using a graphical user interface (GUI)
    c' = GUI.drag(c)
    # Append c' to C'
    C'.append(c')
  # Return the set of displaced control points C'
  return C'
```