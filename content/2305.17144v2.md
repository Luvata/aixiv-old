---
title: 2305.17144v2 Ghost in the Minecraft  Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory
date: 2023-05-18
---

# [Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory](http://arxiv.org/abs/2305.17144v2)

authors: Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang, Jifeng Dai


## What, Why and How

[1]: https://arxiv.org/abs/2305.17144 "Ghost in the Minecraft: Generally Capable Agents for Open-World ..."
[2]: https://arxiv.org/pdf/2305.17144.pdf "arXiv.org"
[3]: https://arxiv-export2.library.cornell.edu/abs/2303.17144v2 "[2303.17144v2] DAMO-StreamNet: Optimizing Streaming Perception in ..."

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper introduces Ghost in the Minecraft (GITM), a novel framework that integrates Large Language Models (LLMs) with text-based knowledge and memory, aiming to create Generally Capable Agents (GCAs) in Minecraft.
- **Why**: The paper aims to tackle the challenges of developing intelligent agents that can function in open-world environments, such as Minecraft, and generalize to a broader spectrum of tasks beyond specific objectives, such as the popular "ObtainDiamond" task. The paper also aims to demonstrate the superior robustness and logic capabilities of LLMs compared to traditional Reinforcement Learning (RL) based controllers.
- **How**: The paper develops a set of structured actions and leverages LLMs to generate action plans for the agents to execute. The paper evaluates the performance of GITM on various tasks in Minecraft, such as obtaining different items, crafting tools, and exploring biomes. The paper shows that GITM markedly surpasses previous methods, achieving a remarkable improvement of +47.5% in success rate on the "ObtainDiamond" task, and being the first to procure all items in the Minecraft Overworld technology tree.

## Main Contributions

The paper claims the following contributions:

- It introduces GITM, a novel framework that integrates LLMs with text-based knowledge and memory, aiming to create GCAs in Minecraft.
- It develops a set of structured actions and leverages LLMs to generate action plans for the agents to execute, without any GPU for training.
- It demonstrates the superior robustness and logic capabilities of LLMs compared to traditional RL-based controllers, achieving a remarkable improvement of +47.5% in success rate on the "ObtainDiamond" task, and being the first to procure all items in the Minecraft Overworld technology tree.

## Method Summary

Here is a summary of the method section of the paper:

- The paper proposes GITM, a framework that consists of three components: a LLM-based agent, a text-based knowledge base, and a text-based memory module.
- The LLM-based agent is responsible for generating action plans based on the current observation and the task description. The agent uses a pre-trained LLM (GPT-3) and fine-tunes it on a large corpus of Minecraft-related texts. The agent also uses a set of structured actions that are defined by the authors, such as `move`, `look`, `break`, `place`, `craft`, etc. The agent generates action plans by concatenating the task description, the observation, and the structured actions, and feeding them to the LLM. The LLM outputs a sequence of actions that the agent executes in the environment.
- The text-based knowledge base is a collection of facts and rules about Minecraft that are extracted from various sources, such as wikis, forums, and guides. The knowledge base is used to provide additional information to the agent when needed, such as the crafting recipes, the item properties, and the biome features. The knowledge base is accessed by the agent using natural language queries that are generated by the LLM.
- The text-based memory module is a dynamic storage that records the agent's past experiences and observations. The memory module is used to help the agent recall relevant information that may not be available in the current observation or the knowledge base, such as the location of resources, the state of items, and the history of actions. The memory module is updated by the agent using natural language statements that are generated by the LLM.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Initialize the LLM-based agent, the text-based knowledge base, and the text-based memory module
agent = LLM_Agent()
knowledge_base = Text_Knowledge_Base()
memory_module = Text_Memory_Module()

# Get the task description from the user
task_description = input("Please enter the task description: ")

# Loop until the task is completed or failed
while not task_completed_or_failed():

  # Get the current observation from the environment
  observation = get_observation()

  # Generate an action plan using the LLM-based agent
  action_plan = agent.generate_action_plan(task_description, observation)

  # Execute each action in the action plan
  for action in action_plan:

    # Check if the action requires additional information from the knowledge base or the memory module
    if action.requires_knowledge():

      # Generate a natural language query using the LLM-based agent
      query = agent.generate_query(action)

      # Retrieve the relevant information from the knowledge base or the memory module
      information = knowledge_base.retrieve_information(query) or memory_module.retrieve_information(query)

      # Update the action with the retrieved information
      action.update(information)

    # Execute the action in the environment and get the feedback
    feedback = execute_action(action)

    # Update the memory module with the feedback using natural language statements generated by the LLM-based agent
    statements = agent.generate_statements(feedback)
    memory_module.update(statements)

  # Check if the task is completed or failed based on the feedback
  task_completed_or_failed = check_task_status(feedback)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import gpt3 # The pre-trained LLM (GPT-3)
import minecraft # The Minecraft environment
import nltk # The natural language toolkit

# Define the constants
MAX_ACTION_PLAN_LENGTH = 10 # The maximum length of the action plan
MAX_MEMORY_SIZE = 100 # The maximum size of the memory module
ACTION_TYPES = ["move", "look", "break", "place", "craft", "use", "equip", "drop", "query", "remember"] # The types of structured actions
ACTION_FORMATS = {"move": "move [direction] [steps]", "look": "look [direction]", "break": "break [block]", "place": "place [block] [direction]", "craft": "craft [item]", "use": "use [item]", "equip": "equip [item]", "drop": "drop [item]", "query": "query [information]", "remember": "remember [statement]"} # The formats of structured actions

# Define the helper functions
def tokenize(text):
  # Tokenize the text using nltk
  return nltk.word_tokenize(text)

def detokenize(tokens):
  # Detokenize the tokens using nltk
  return nltk.detokenize(tokens)

def format_action(action_type, action_args):
  # Format the action according to its type and arguments
  return ACTION_FORMATS[action_type].replace("[direction]", action_args["direction"]).replace("[steps]", action_args["steps"]).replace("[block]", action_args["block"]).replace("[item]", action_args["item"]).replace("[information]", action_args["information"]).replace("[statement]", action_args["statement"])

def parse_action(action):
  # Parse the action into its type and arguments
  tokens = tokenize(action)
  action_type = tokens[0]
  action_args = {}
  if action_type == "move":
    action_args["direction"] = tokens[1]
    action_args["steps"] = tokens[2]
  elif action_type == "look":
    action_args["direction"] = tokens[1]
  elif action_type == "break":
    action_args["block"] = tokens[1]
  elif action_type == "place":
    action_args["block"] = tokens[1]
    action_args["direction"] = tokens[2]
  elif action_type == "craft":
    action_args["item"] = tokens[1]
  elif action_type == "use":
    action_args["item"] = tokens[1]
  elif action_type == "equip":
    action_args["item"] = tokens[1]
  elif action_type == "drop":
    action_args["item"] = tokens[1]
  elif action_type == "query":
    action_args["information"] = detokenize(tokens[1:])
  elif action_type == "remember":
    action_args["statement"] = detokenize(tokens[1:])
  return (action_type, action_args)

# Define the classes
class LLM_Agent:
  def __init__(self):
    # Initialize the LLM-based agent with a pre-trained LLM (GPT-3)
    self.llm = gpt3.load_model()

    # Fine-tune the LLM on a large corpus of Minecraft-related texts
    self.llm.fine_tune("minecraft_corpus.txt")

  def generate_action_plan(self, task_description, observation):
    # Generate an action plan using the LLM based on the task description and the observation

    # Concatenate the task description, the observation, and the structured actions as the input to the LLM
    input_text = task_description + "\n" + observation + "\n" + "\n".join(ACTION_TYPES)

    # Generate a sequence of actions as the output of the LLM
    output_text = self.llm.generate_text(input_text, max_length=MAX_ACTION_PLAN_LENGTH)

    # Split the output text into a list of actions
    action_plan = output_text.split("\n")

    # Return the action plan
    return action_plan

  def generate_query(self, action):
    # Generate a natural language query using the LLM based on the action

    # Format the action according to its type and arguments
    formatted_action = format_action(action[0], action[1])

    # Concatenate the formatted action and a question mark as the input to the LLM
    input_text = formatted_action + "?"

    # Generate a natural language query as the output of the LLM
    output_text = self.llm.generate_text(input_text)

    # Return the query
    return output_text

  def generate_statements(self, feedback):
    # Generate natural language statements using the LLM based on the feedback

    # Concatenate the feedback and a period as the input to the LLM
    input_text = feedback + "."

    # Generate a sequence of statements as the output of the LLM
    output_text = self.llm.generate_text(input_text)

    # Split the output text into a list of statements
    statements = output_text.split("\n")

    # Return the statements
    return statements

class Text_Knowledge_Base:
  def __init__(self):
    # Initialize the text-based knowledge base with a collection of facts and rules about Minecraft

    # Load the facts and rules from various sources, such as wikis, forums, and guides
    self.facts_and_rules = load_facts_and_rules("minecraft_sources.txt")

  def retrieve_information(self, query):
    # Retrieve the relevant information from the text-based knowledge base based on the query

    # Search for the query in the facts and rules
    results = self.facts_and_rules.search(query)

    # If there are any results, return the first one
    if results:
      return results[0]

    # Otherwise, return None
    else:
      return None

class Text_Memory_Module:
  def __init__(self):
    # Initialize the text-based memory module with an empty list of statements
    self.statements = []

  def update(self, statements):
    # Update the text-based memory module with a list of statements

    # Append the statements to the memory module
    self.statements.extend(statements)

    # If the memory module exceeds its maximum size, remove the oldest statements
    if len(self.statements) > MAX_MEMORY_SIZE:
      self.statements = self.statements[-MAX_MEMORY_SIZE:]

  def retrieve_information(self, query):
    # Retrieve the relevant information from the text-based memory module based on the query

    # Search for the query in the statements
    results = [statement for statement in self.statements if query in statement]

    # If there are any results, return the last one
    if results:
      return results[-1]

    # Otherwise, return None
    else:
      return None

# Initialize the LLM-based agent, the text-based knowledge base, and the text-based memory module
agent = LLM_Agent()
knowledge_base = Text_Knowledge_Base()
memory_module = Text_Memory_Module()

# Get the task description from the user
task_description = input("Please enter the task description: ")

# Loop until the task is completed or failed
while not task_completed_or_failed():

  # Get the current observation from the environment
  observation = minecraft.get_observation()

  # Generate an action plan using the LLM-based agent
  action_plan = agent.generate_action_plan(task_description, observation)

  # Execute each action in the action plan
  for action in action_plan:

    # Parse the action into its type and arguments
    parsed_action = parse_action(action)

    # Check if the action requires additional information from the knowledge base or the memory module
    if parsed_action[0] == "query" or parsed_action[0] == "remember":

      # Generate a natural language query using the LLM-based agent
      query = agent.generate_query(parsed_action)

      # Retrieve the relevant information from the knowledge base or the memory module
      information = knowledge_base.retrieve_information(query) or memory_module.retrieve_information(query)

      # Update the action with the retrieved information
      parsed_action[1]["information"] = information

      # Format the action according to its type and arguments
      action = format_action(parsed_action[0], parsed_action[1])

    # Execute the action in the environment and get the feedback
    feedback = minecraft.execute_action(action)

    # Update the memory module with the feedback using natural language statements generated by the LLM-based agent
    statements = agent.generate_statements(feedback)
    memory_module.update(statements)

  # Check if the task is completed or failed based on the feedback
  task_completed_or_failed = minecraft.check_task_status(feedback)
```