---
title: 2007.02190v2 BézierSketch  A generative model for scalable vector sketches
date: 2020-07-03
---

# [BézierSketch: A generative model for scalable vector sketches](http://arxiv.org/abs/2007.02190v2)

authors: Ayan Das, Yongxin Yang, Timothy Hospedales, Tao Xiang, Yi-Zhe Song


## What, Why and How

[1]: https://arxiv.org/pdf/2007.02190v2.pdf "B ezierSketch: A generative model for scalable vector sketches - arXiv.org"
[2]: https://arxiv.org/abs/2007.02190 "BézierSketch: A generative model for scalable vector sketches"
[3]: http://export.arxiv.org/abs/2007.02190 "[2007.02190] B\\'ezierSketch: A generative model for scalable vector ..."

Here is a summary of the paper:

- **What**: The paper presents a novel generative model for scalable vector sketches, called BézierSketch, that uses Bézier curves to parameterize each stroke of a sketch.
- **Why**: The paper aims to overcome the limitations of existing sketch generation models, such as SketchRNN, that produce low-resolution images and fail to model long sketches. The paper also seeks to establish links between sketch image generation and the human drawing process.
- **How**: The paper introduces a novel inverse graphics approach to stroke embedding that trains an encoder to embed each stroke to its best fit Bézier curve. The paper then uses a recurrent neural network with attention and variational inference to generate sketches as short sequences of parameterized strokes. The paper evaluates the proposed model on the Quick, Draw! benchmark and shows qualitative and quantitative results.

## Main Contributions

The paper claims to make the following contributions:

- It proposes a novel generative model for scalable vector sketches that uses Bézier curves to parameterize each stroke of a sketch.
- It introduces a novel inverse graphics approach to stroke embedding that trains an encoder to embed each stroke to its best fit Bézier curve.
- It demonstrates the advantages of the proposed model over existing sketch generation models, such as SketchRNN, in terms of resolution, scalability, diversity, and fidelity of sketch generation.

## Method Summary

[1]: https://arxiv.org/pdf/2007.02190v2.pdf "B ezierSketch: A generative model for scalable vector sketches - arXiv.org"
[2]: https://arxiv.org/abs/2007.02190 "BézierSketch: A generative model for scalable vector sketches"
[3]: http://export.arxiv.org/abs/2007.02190 "[2007.02190] B\\'ezierSketch: A generative model for scalable vector ..."

Here is a summary of the method section of the paper:

- The paper proposes a two-stage method for sketch generation: stroke embedding and sketch generation.
- The stroke embedding stage aims to convert each stroke of a sketch into a Bézier curve representation, which consists of four control points and a pen state. The paper introduces a novel inverse graphics approach to stroke embedding that trains an encoder to embed each stroke to its best fit Bézier curve. The encoder consists of a convolutional neural network (CNN) that extracts features from the rasterized stroke image, and a fully connected network (FCN) that predicts the Bézier curve parameters and the pen state from the features. The paper also proposes a novel loss function for stroke embedding that combines the reconstruction error, the smoothness constraint, and the regularization term.
- The sketch generation stage aims to generate sketches as short sequences of parameterized strokes. The paper uses a recurrent neural network (RNN) with attention and variational inference to model the sketch generation process. The RNN consists of an encoder-decoder architecture with a latent variable layer in between. The encoder takes the Bézier curve representations of the strokes as input and encodes them into a hidden state. The latent variable layer samples a latent vector from a Gaussian distribution conditioned on the hidden state. The decoder takes the latent vector as input and generates the Bézier curve representations of the strokes as output. The paper also uses an attention mechanism to allow the decoder to focus on different parts of the input sketch. The paper trains the sketch generation model using the variational lower bound objective that combines the reconstruction loss and the KL divergence term.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the stroke embedding encoder
def stroke_embedding_encoder(stroke):
  # Rasterize the stroke image
  stroke_image = rasterize(stroke)
  # Extract features from the stroke image using a CNN
  features = CNN(stroke_image)
  # Predict the Bézier curve parameters and the pen state using a FCN
  bezier_params, pen_state = FCN(features)
  # Return the Bézier curve representation of the stroke
  return bezier_params, pen_state

# Define the sketch generation encoder
def sketch_generation_encoder(sketch):
  # Convert each stroke of the sketch into a Bézier curve representation using the stroke embedding encoder
  bezier_sketch = [stroke_embedding_encoder(stroke) for stroke in sketch]
  # Encode the Bézier sketch into a hidden state using an RNN
  hidden_state = RNN(bezier_sketch)
  # Return the hidden state
  return hidden_state

# Define the sketch generation decoder
def sketch_generation_decoder(latent_vector):
  # Initialize an empty list to store the generated strokes
  generated_strokes = []
  # Initialize the decoder state with the latent vector
  decoder_state = latent_vector
  # Initialize the attention context vector with zeros
  attention_context = zeros()
  # Loop until the end of sketch token is generated or the maximum length is reached
  while True:
    # Concatenate the decoder state and the attention context vector
    decoder_input = concatenate(decoder_state, attention_context)
    # Predict the Bézier curve parameters and the pen state using a FCN
    bezier_params, pen_state = FCN(decoder_input)
    # Append the generated stroke to the list
    generated_strokes.append((bezier_params, pen_state))
    # Update the decoder state using an RNN
    decoder_state = RNN(decoder_input, decoder_state)
    # Update the attention context vector using an attention mechanism
    attention_context = attention(bezier_sketch, decoder_state)
    # Break if the end of sketch token is generated
    if pen_state == end_of_sketch:
      break
  # Return the generated sketch as a sequence of Bézier curves
  return generated_strokes

# Define the sketch generation model
def sketch_generation_model(sketch):
  # Encode the sketch into a hidden state using the sketch generation encoder
  hidden_state = sketch_generation_encoder(sketch)
  # Sample a latent vector from a Gaussian distribution conditioned on the hidden state
  latent_vector = sample(hidden_state)
  # Generate a sketch as a sequence of Bézier curves using the sketch generation decoder
  generated_sketch = sketch_generation_decoder(latent_vector)
  # Return the generated sketch and the latent vector
  return generated_sketch, latent_vector

# Define the loss function for stroke embedding
def stroke_embedding_loss(stroke, bezier_params, pen_state):
  # Compute the reconstruction error between the original stroke and the predicted Bézier curve
  reconstruction_error = distance(stroke, bezier_curve(bezier_params))
  # Compute the smoothness constraint that penalizes sharp angles in the Bézier curve
  smoothness_constraint = angle(bezier_params)
  # Compute the regularization term that penalizes large values in the Bézier curve parameters
  regularization_term = norm(bezier_params)
  # Combine the three terms with appropriate weights
  loss = reconstruction_error + smoothness_constraint + regularization_term
  # Return the loss value
  return loss

# Define the loss function for sketch generation
def sketch_generation_loss(sketch, generated_sketch, latent_vector, hidden_state):
  # Compute the reconstruction loss between the original sketch and the generated sketch as the negative log-likelihood of each stroke given the previous strokes and the latent vector
  reconstruction_loss = -log_likelihood(sketch, generated_sketch, latent_vector)
  # Compute the KL divergence term between the posterior and prior distributions of the latent vector conditioned on the hidden state
  kl_divergence_term = kl_divergence(latent_vector, hidden_state)
  # Combine the two terms with an appropriate weight that balances reconstruction and diversity
  loss = reconstruction_loss + kl_divergence_term
  # Return the loss value
  return loss

# Train both models using gradient-based optimization methods on a large-scale sketch dataset such as Quick, Draw!
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Define some hyperparameters
batch_size = 64 # The number of sketches in each batch
stroke_size = 64 # The size of the rasterized stroke image
bezier_size = 8 # The size of the Bézier curve parameters
pen_size = 3 # The size of the pen state
hidden_size = 256 # The size of the hidden state and the latent vector
attention_size = 128 # The size of the attention context vector
max_length = 100 # The maximum number of strokes in a sketch
learning_rate = 0.001 # The learning rate for optimization
kl_weight = 0.1 # The weight for the KL divergence term
smooth_weight = 0.01 # The weight for the smoothness constraint term
reg_weight = 0.001 # The weight for the regularization term

# Define a function to rasterize a stroke into a binary image
def rasterize(stroke):
  # Create an empty image of stroke_size x stroke_size
  image = np.zeros((stroke_size, stroke_size))
  # Initialize the current position as the center of the image
  x, y = stroke_size // 2, stroke_size // 2
  # Loop through each point in the stroke
  for dx, dy, p in stroke:
    # Update the current position by adding the offsets
    x += dx
    y += dy
    # Clip the current position to be within the image boundaries
    x = np.clip(x, 0, stroke_size - 1)
    y = np.clip(y, 0, stroke_size - 1)
    # Set the pixel value at the current position to be one
    image[y, x] = 1
    # Break if the pen state is end of stroke or end of sketch
    if p > 0:
      break
  # Return the image as a flattened vector
  return image.reshape(-1)

# Define a function to compute a Bézier curve from four control points
def bezier_curve(control_points):
  # Unpack the control points into four variables
  p0, p1, p2, p3 = control_points.reshape(4, -1)
  # Define a function to compute a linear interpolation between two points given a parameter t
  def lerp(p1, p2, t):
    return (1 - t) * p1 + t * p2
  # Define a function to compute a quadratic Bézier curve from three points given a parameter t
  def quad_bezier(p0, p1, p2, t):
    return lerp(lerp(p0, p1, t), lerp(p1, p2, t), t)
  # Define a function to compute a cubic Bézier curve from four points given a parameter t
  def cubic_bezier(p0, p1, p2, p3, t):
    return lerp(quad_bezier(p0, p1, p2, t), quad_bezier(p1, p2, p3, t), t)
  # Create an array of equally spaced values between zero and one with stroke_size elements
  ts = np.linspace(0, 1, stroke_size)
  # Compute the Bézier curve by applying the cubic Bézier function to each value in ts
  curve = np.array([cubic_bezier(p0, p1, p2, p3, t) for t in ts])
  # Return the curve as a flattened vector
  return curve.reshape(-1)

# Define a function to compute the distance between a stroke and a Bézier curve as the reconstruction error
def distance(stroke, bezier_params):
  # Rasterize the stroke into a binary image
  stroke_image = rasterize(stroke)
  # Compute the Bézier curve from the Bézier parameters
  bezier_curve = bezier_curve(bezier_params)
  # Rasterize the Bézier curve into a binary image
  bezier_image = rasterize(bezier_curve)
  # Compute the mean squared error between the two images as the distance metric
  mse = tf.reduce_mean(tf.square(stroke_image - bezier_image))
  # Return the mse value
  return mse

# Define a function to compute the angle between two vectors as the smoothness constraint
def angle(v1, v2):
  # Normalize the two vectors to have unit length
  v1_norm = v1 / tf.norm(v1)
  v2_norm = v2 / tf.norm(v2)
  # Compute the dot product between the two vectors
  dot = tf.reduce_sum(v1_norm * v2_norm)
  # Compute the angle between the two vectors using the inverse cosine function
  angle = tf.acos(dot)
  # Return the angle value
  return angle

# Define a function to compute the norm of a vector as the regularization term
def norm(v):
  # Compute the squared norm of the vector
  norm = tf.reduce_sum(tf.square(v))
  # Return the norm value
  return norm

# Define the stroke embedding encoder as a class
class StrokeEmbeddingEncoder(tf.keras.Model):
  # Define the constructor method
  def __init__(self):
    # Call the parent constructor
    super(StrokeEmbeddingEncoder, self).__init__()
    # Define the CNN layer with stroke_size filters and a kernel size of 3
    self.cnn = tf.keras.layers.Conv2D(stroke_size, 3, padding='same', activation='relu')
    # Define the FCN layer with bezier_size + pen_size units and a linear activation
    self.fcn = tf.keras.layers.Dense(bezier_size + pen_size)

  # Define the call method
  def call(self, stroke):
    # Reshape the stroke into a stroke_size x stroke_size x 1 image
    stroke_image = tf.reshape(stroke, (-1, stroke_size, stroke_size, 1))
    # Apply the CNN layer to extract features from the stroke image
    features = self.cnn(stroke_image)
    # Flatten the features into a vector
    features = tf.reshape(features, (-1, stroke_size * stroke_size))
    # Apply the FCN layer to predict the Bézier curve parameters and the pen state from the features
    output = self.fcn(features)
    # Split the output into two tensors: one for the Bézier curve parameters and one for the pen state
    bezier_params, pen_state = tf.split(output, [bezier_size, pen_size], axis=-1)
    # Apply a softmax activation to the pen state to get a probability distribution over three possible values: continue, end of stroke, end of sketch
    pen_state = tf.nn.softmax(pen_state)
    # Return the Bézier curve parameters and the pen state as the output of the encoder
    return bezier_params, pen_state

# Define the sketch generation encoder as a class
class SketchGenerationEncoder(tf.keras.Model):
  # Define the constructor method
  def __init__(self):
    # Call the parent constructor
    super(SketchGenerationEncoder, self).__init__()
    # Define the RNN layer with hidden_size units and a GRU cell
    self.rnn = tf.keras.layers.RNN(tf.keras.layers.GRUCell(hidden_size))

  # Define the call method
  def call(self, sketch):
    # Convert each stroke of the sketch into a Bézier curve representation using the stroke embedding encoder
    bezier_sketch = [stroke_embedding_encoder(stroke) for stroke in sketch]
    # Concatenate each Bézier curve representation and its corresponding pen state into a single vector of size bezier_size + pen_size
    bezier_sketch = [tf.concat([bezier_params, pen_state], axis=-1) for bezier_params, pen_state in bezier_sketch]
    # Pad each vector with zeros to have a fixed length of max_length
    bezier_sketch = [tf.pad(vector, [[0, max_length - tf.shape(vector)[0]]]) for vector in bezier_sketch]
    # Stack each padded vector into a batch_size x max_length x (bezier_size + pen_size) tensor
    bezier_sketch = tf.stack(bezier_sketch)
    # Apply the RNN layer to encode the Bézier sketch into a hidden state of size hidden_size
    hidden_state = self.rnn(bezier_sketch)
    # Return the hidden state as the output of the encoder
    return hidden_state

# Define the sketch generation decoder as a class
class SketchGenerationDecoder(tf.keras.Model):
  # Define the constructor method
  def __init__(self):
    # Call the parent constructor
    super(SketchGenerationDecoder, self).__init__()
    # Define the RNN layer with hidden_size units and a GRU cell
    self.rnn = tf.keras.layers.RNN(tf.keras.layers.GRUCell(hidden_size), return_sequences=True, return_state=True)
    # Define the FCN layer with bezier_size + pen_size units and a linear activation
    self.fcn = tf.keras.layers.Dense(bezier_size + pen_size)
    # Define the attention layer with attention_size units and a Bahdanau mechanism
    self.attention = tf.keras.layers.Attention(attention_size)

  # Define the call method
  def call(self, latent_vector, bezier_sketch):
    # Initialize an empty list to store the generated strokes