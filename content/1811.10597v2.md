---
title: 1811.10597v2 GAN Dissection  Visualizing and Understanding Generative Adversarial Networks
date: 2018-11-11
---

# [GAN Dissection: Visualizing and Understanding Generative Adversarial Networks](http://arxiv.org/abs/1811.10597v2)

authors: David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B. Tenenbaum, William T. Freeman, Antonio Torralba


## What, Why and How

[1]: https://arxiv.org/abs/1811.10597v2 "[1811.10597v2] GAN Dissection: Visualizing and ... - arXiv.org"
[2]: https://arxiv.org/pdf/1811.10597v2.pdf "A arXiv:1811.10597v2 [cs.CV] 8 Dec 2018"
[3]: http://export.arxiv.org/abs/1811.10597 "[1811.10597] GAN Dissection: Visualizing and Understanding Generative ..."

Here is a summary of the paper:

```
What: The paper presents an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level.

Why: The paper aims to answer questions such as how a GAN represents our visual world internally, what causes the artifacts in GAN results, and how architectural choices affect GAN learning.

How: The paper uses a segmentation-based network dissection method to identify interpretable units that are closely related to object concepts, measures the causal effect of these units by intervening on them, and examines the contextual relationship between these units and their surroundings by inserting them into new images. The paper also shows several applications of the framework, such as comparing internal representations, improving GANs by removing artifact-causing units, and interactively manipulating objects in a scene.
```

## Main Contributions

[1]: https://arxiv.org/abs/1811.10597 "[1811.10597] GAN Dissection: Visualizing and Understanding Generative ..."
[2]: https://arxiv.org/pdf/1811.10597.pdf "A arXiv:1811.10597v2 [cs.CV] 8 Dec 2018"
[3]: https://gandissect.csail.mit.edu/ "GAN Dissection"

Some of the contributions of this paper are:

- A segmentation-based network dissection method to identify interpretable units that are closely related to object concepts in GANs.
- A causal intervention method to measure the ability of these units to control objects in the output.
- A contextual insertion method to examine the relationship between these units and their surroundings by inserting them into new images.
- Several practical applications of the framework, such as comparing internal representations, improving GANs by removing artifact-causing units, and interactively manipulating objects in a scene.
- Open source interpretation tools to help researchers and practitioners better understand their GAN models.

## Method Summary

[1]: https://arxiv.org/abs/1811.10597 "[1811.10597] GAN Dissection: Visualizing and Understanding Generative ..."
[2]: https://arxiv.org/pdf/1811.10597.pdf "A arXiv:1811.10597v2 [cs.CV] 8 Dec 2018"
[3]: http://gandissect.csail.mit.edu/ "GAN Dissection"

Here is a summary of the method section of the paper:

```
The method section of the paper consists of three parts: network dissection, causal intervention, and contextual insertion.

Network dissection is a technique to identify interpretable units that are related to object concepts in GANs. It uses a segmentation network to label the output images of GANs with semantic categories, and then computes the alignment between each unit and each category using an IoU score. A unit is considered interpretable if its IoU score exceeds a threshold for at least one category.

Causal intervention is a technique to measure the causal effect of interpretable units on the output images. It involves ablating or activating a set of units and observing the changes in the output. A unit is considered causal if its intervention changes the presence or absence of an object concept in the output.

Contextual insertion is a technique to examine the contextual relationship between interpretable units and their surroundings. It involves inserting an object concept into a new image by activating a set of units and masking out the rest. The quality and realism of the insertion depend on how well the GAN has learned the context and structure of the scene.
```

## Pseudo Code - High level

[1]: https://arxiv.org/pdf/1811.10597.pdf "A arXiv:1811.10597v2 [cs.CV] 8 Dec 2018"
[2]: https://arxiv.org/abs/1811.10597 "[1811.10597] GAN Dissection: Visualizing and Understanding Generative ..."
[3]: https://paperswithcode.com/paper/gan-dissection-visualizing-and-understanding "Papers with Code - GAN Dissection: Visualizing and Understanding ..."

Here is a high-level pseudo code for the paper:

```
# Define a GAN model and a segmentation network
GAN = load_model("GAN")
SEG = load_model("SEG")

# Define a set of semantic categories
categories = ["sky", "tree", "grass", "building", "door", ...]

# Define a threshold for IoU score
threshold = 0.04

# Network dissection
for each layer in GAN:
  units = get_units(layer) # get the units of the layer
  for each unit in units:
    outputs = generate_outputs(GAN, unit) # generate output images by varying the unit
    labels = segment_outputs(SEG, outputs) # segment output images using SEG
    for each category in categories:
      iou = compute_iou(labels, category) # compute the IoU score between labels and category
      if iou > threshold: # if the unit is interpretable for the category
        add_to_interpretable_units(unit, category, iou) # store the unit, category, and iou

# Causal intervention
for each interpretable unit in interpretable_units:
  category = get_category(unit) # get the category of the unit
  for each intervention in [ablation, activation]:
    outputs = apply_intervention(GAN, unit, intervention) # apply intervention to the unit and generate output images
    labels = segment_outputs(SEG, outputs) # segment output images using SEG
    presence = compute_presence(labels, category) # compute the presence score of the category in the output images
    add_to_causal_units(unit, category, intervention, presence) # store the unit, category, intervention, and presence

# Contextual insertion
for each interpretable unit in interpretable_units:
  category = get_category(unit) # get the category of the unit
  for each image in new_images: # new images from a different dataset or user input
    mask = generate_mask(image, category) # generate a mask for the image based on the category
    output = insert_object(GAN, unit, image, mask) # insert an object concept into the image by activating the unit and masking out the rest
    display(output) # display the output image with the inserted object
```

## Pseudo Code - Detail

[1]: https://arxiv.org/pdf/1811.10597.pdf "A arXiv:1811.10597v2 [cs.CV] 8 Dec 2018"
[2]: https://arxiv.org/abs/1811.10597 "[1811.10597] GAN Dissection: Visualizing and Understanding Generative ..."
[3]: https://github.com/CSAILVision/GANDissect "GitHub - CSAILVision/gandissect: Pytorch-based tools for visualizing ..."

Here is a detailed pseudo code to implement the paper:

```
# Import libraries
import torch
import torchvision
import numpy as np
import cv2

# Define a GAN model and a segmentation network
GAN = load_model("GAN")
SEG = load_model("SEG")

# Define a set of semantic categories
categories = ["sky", "tree", "grass", "building", "door", ...]

# Define a threshold for IoU score
threshold = 0.04

# Define a function to get the units of a layer
def get_units(layer):
  # Get the shape of the layer output
  shape = layer.shape
  # Reshape the layer output to a 2D matrix, where each row is a unit vector
  matrix = layer.reshape(shape[0], -1)
  # Return the matrix as a list of unit vectors
  return matrix.tolist()

# Define a function to generate output images by varying a unit
def generate_outputs(GAN, unit):
  # Initialize an empty list to store output images
  outputs = []
  # Define a range of values to vary the unit
  values = np.linspace(-3, 3, 11)
  # For each value in the range
  for value in values:
    # Set the unit to the value
    unit = value
    # Generate an output image using GAN
    output = GAN.generate()
    # Append the output image to the list
    outputs.append(output)
  # Return the list of output images
  return outputs

# Define a function to segment output images using SEG
def segment_outputs(SEG, outputs):
  # Initialize an empty list to store segmented images
  labels = []
  # For each output image in the list
  for output in outputs:
    # Segment the output image using SEG and get the label map
    label = SEG.segment(output)
    # Append the label map to the list
    labels.append(label)
  # Return the list of label maps
  return labels

# Define a function to compute the IoU score between labels and category
def compute_iou(labels, category):
  # Initialize variables to store intersection and union areas
  intersection = 0
  union = 0
  # For each label map in the list
  for label in labels:
    # Get a binary mask for the category in the label map
    mask = (label == category)
    # Compute the intersection area between the mask and the label map
    intersection += np.sum(mask & label)
    # Compute the union area between the mask and the label map
    union += np.sum(mask | label)
  # Compute the IoU score as the ratio of intersection and union areas
  iou = intersection / union
  # Return the IoU score
  return iou

# Define a function to apply intervention to a unit and generate output images
def apply_intervention(GAN, unit, intervention):
  # Initialize an empty list to store output images
  outputs = []
  # If the intervention is ablation, set the unit to zero
  if intervention == "ablation":
    unit = 0
  # If the intervention is activation, set the unit to three standard deviations above its mean activation value 
  elif intervention == "activation":
    unit = unit.mean() + unit.std() * 3 
  # Generate an output image using GAN 
  output = GAN.generate()
  # Append the output image to the list 
  outputs.append(output)
  # Return the list of output images 
  return outputs

# Define a function to compute the presence score of a category in the output images 
def compute_presence(labels, category):
   # Initialize a variable to store presence score 
   presence = 0 
   # For each label map in the list 
   for label in labels: 
     # Get a binary mask for the category in the label map 
     mask = (label == category) 
     # Compute the presence score as the ratio of pixels in the mask and total pixels 
     presence += np.sum(mask) / np.prod(label.shape) 
   # Return the presence score 
   return presence

# Define a function to generate a mask for an image based on a category 
def generate_mask(image, category): 
   # Segment the image using SEG and get the label map 
   label = SEG.segment(image) 
   # Get a binary mask for the category in the label map 
   mask = (label == category) 
   # Return the mask 
   return mask

# Define a function to insert an object concept into an image by activating a unit and masking out the rest 
def insert_object(GAN, unit, image, mask): 
   # Set all other units except for the target unit to zero 
   units = get_units(GAN.layer) 
   for u in units: 
     if u != unit: 
       u = 0 
   # Generate an output image using GAN 
   output = GAN.generate() 
   # Mask out the output image using the mask 
   output = output * mask 
   # Invert the mask 
   mask = 1 - mask 
   # Mask out the input image using the inverted mask 
   image = image * mask 
   # Add the output image and the input image to get the final image 
   final = output + image 
   # Return the final image 
   return final

# Network dissection
for each layer in GAN:
  units = get_units(layer) # get the units of the layer
  for each unit in units:
    outputs = generate_outputs(GAN, unit) # generate output images by varying the unit
    labels = segment_outputs(SEG, outputs) # segment output images using SEG
    for each category in categories:
      iou = compute_iou(labels, category) # compute the IoU score between labels and category
      if iou > threshold: # if the unit is interpretable for the category
        add_to_interpretable_units(unit, category, iou) # store the unit, category, and iou

# Causal intervention
for each interpretable unit in interpretable_units:
  category = get_category(unit) # get the category of the unit
  for each intervention in [ablation, activation]:
    outputs = apply_intervention(GAN, unit, intervention) # apply intervention to the unit and generate output images
    labels = segment_outputs(SEG, outputs) # segment output images using SEG
    presence = compute_presence(labels, category) # compute the presence score of the category in the output images
    add_to_causal_units(unit, category, intervention, presence) # store the unit, category, intervention, and presence

# Contextual insertion
for each interpretable unit in interpretable_units:
  category = get_category(unit) # get the category of the unit
  for each image in new_images: # new images from a different dataset or user input
    mask = generate_mask(image, category) # generate a mask for the image based on the category
    output = insert_object(GAN, unit, image, mask) # insert an object concept into the image by activating the unit and masking out the rest
    display(output) # display the output image with the inserted object
```