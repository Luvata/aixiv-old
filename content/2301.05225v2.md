---
title: 2301.05225v2 Domain Expansion of Image Generators
date: 2023-01-06
---

# [Domain Expansion of Image Generators](http://arxiv.org/abs/2301.05225v2)

authors: Yotam Nitzan, MichaÃ«l Gharbi, Richard Zhang, Taesung Park, Jun-Yan Zhu, Daniel Cohen-Or, Eli Shechtman


## What, Why and How

[1]: https://arxiv.org/abs/2301.05225 "[2301.05225] Domain Expansion of Image Generators - arXiv.org"
[2]: https://arxiv.org/abs/2301.00808 "[2301.00808] ConvNeXt V2: Co-designing and Scaling ConvNets ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2304.05225v2 "[2304.05225v2] Is $f_2(1950)$ the tensor glueball? - export.arxiv.org"

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a new task called **domain expansion**, which aims to inject new concepts into an already trained image generator, while respecting its existing structure and knowledge.
- **Why**: The paper argues that domain expansion can enable one expanded model to supersede numerous domain-specific models, without expanding the model size. Additionally, a single expanded generator can natively support smooth transitions between domains, as well as composition of domains.
- **How**: The paper leverages the observation that the latent space of a pretrained generator contains unused, "dormant" directions, which do not affect the output. By "repurposing" these directions, the paper can represent new domains without perturbing the original representation. The paper also introduces a novel domain expansion loss that encourages the expanded generator to produce realistic and diverse images across all domains.

## Main Contributions

According to the paper at , the main contributions are:

- The paper defines a new task of domain expansion for image generators and provides a benchmark dataset for evaluation.
- The paper proposes a method to identify and repurpose dormant directions in the latent space of a pretrained generator to represent new domains.
- The paper introduces a domain expansion loss that balances realism, diversity, and harmony across all domains.
- The paper demonstrates that domain expansion can significantly improve the performance and versatility of image generators, without increasing the model size or complexity.

## Method Summary

The method section of the paper at  consists of three subsections:

- **Domain Expansion Framework**: This subsection describes the overall framework of domain expansion, which consists of a pretrained generator G and a domain encoder E. The domain encoder maps an input domain label d to a domain vector e(d), which is then concatenated with a latent code z to form the input of the generator. The paper assumes that the generator has a meaningful latent space that can be decomposed into two orthogonal subspaces: a content space and a style space. The paper also assumes that the generator has a residual structure that allows adding new domains without affecting the existing ones.
- **Dormant Direction Discovery**: This subsection explains how to find and repurpose dormant directions in the latent space of the generator. The paper defines a dormant direction as a direction that has no effect on the output image when added to any latent code. The paper proposes an algorithm to identify dormant directions by sampling latent codes and measuring their output similarity under perturbations. The paper then assigns each new domain to a dormant direction and uses it as the domain vector e(d).
- **Domain Expansion Loss**: This subsection introduces the loss function that guides the training of the domain encoder and the fine-tuning of the generator. The loss function consists of three terms: a realism term that encourages realistic images for each domain, a diversity term that encourages diverse images for each domain, and a harmony term that encourages smooth transitions and compositions between domains. The paper also describes some implementation details and hyperparameters for the training process.

## Pseudo Code - High level

Here is the high-level pseudo code for the paper at :

```python
# Input: a pretrained generator G, a set of new domains D
# Output: an expanded generator G', a domain encoder E

# Step 1: Find dormant directions in the latent space of G
dormant_directions = []
for i in range(max_iterations):
  # Sample a latent code z from the prior distribution
  z = sample_prior()
  # Sample a random direction v from the unit sphere
  v = sample_unit_sphere()
  # Compute the output similarity between z and z + v
  sim = output_similarity(G(z), G(z + v))
  # If the similarity is above a threshold, add v to the dormant directions
  if sim > threshold:
    dormant_directions.append(v)

# Step 2: Assign each new domain to a dormant direction
domain_vectors = {}
for d in D:
  # Pop a dormant direction from the list
  v = dormant_directions.pop()
  # Assign v as the domain vector for d
  domain_vectors[d] = v

# Step 3: Train the domain encoder and fine-tune the generator
E = initialize_domain_encoder()
G' = copy_generator(G)
for epoch in range(num_epochs):
  for batch in data_loader:
    # Sample a batch of domain labels and latent codes
    d_batch, z_batch = batch
    # Encode the domain labels to domain vectors using E
    e_batch = E(d_batch)
    # Concatenate the latent codes and domain vectors
    x_batch = concatenate(z_batch, e_batch)
    # Generate images using G'
    y_batch = G'(x_batch)
    # Compute the realism loss using a discriminator or an encoder
    L_realism = compute_realism_loss(y_batch, d_batch)
    # Compute the diversity loss using a diversity metric
    L_diversity = compute_diversity_loss(y_batch, d_batch)
    # Compute the harmony loss using a harmony metric
    L_harmony = compute_harmony_loss(y_batch, d_batch)
    # Compute the total loss as a weighted sum of the three terms
    L_total = alpha * L_realism + beta * L_diversity + gamma * L_harmony
    # Update the parameters of E and G' using gradient descent
    update_parameters(E, G', L_total)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper at :

```python
# Import the necessary libraries
import torch
import torchvision
import numpy as np

# Define some hyperparameters
max_iterations = 1000 # The maximum number of iterations to find dormant directions
threshold = 0.99 # The similarity threshold to identify dormant directions
num_epochs = 100 # The number of epochs to train the domain encoder and fine-tune the generator
batch_size = 64 # The batch size for training
alpha = 1.0 # The weight for the realism loss
beta = 0.1 # The weight for the diversity loss
gamma = 0.01 # The weight for the harmony loss
lr = 0.0001 # The learning rate for gradient descent
latent_dim = 512 # The dimension of the latent code
domain_dim = 64 # The dimension of the domain vector

# Load a pretrained generator G (e.g., StyleGAN2)
G = load_pretrained_generator()
# Freeze the parameters of G
G.eval()
for p in G.parameters():
  p.requires_grad = False

# Define a function to sample a latent code z from the prior distribution (e.g., normal distribution)
def sample_prior():
  z = torch.randn(1, latent_dim)
  return z

# Define a function to sample a random direction v from the unit sphere
def sample_unit_sphere():
  v = torch.randn(1, latent_dim)
  v = v / torch.norm(v)
  return v

# Define a function to compute the output similarity between two images using cosine similarity
def output_similarity(img1, img2):
  img1 = img1.flatten()
  img2 = img2.flatten()
  sim = torch.dot(img1, img2) / (torch.norm(img1) * torch.norm(img2))
  return sim

# Define a function to compute the realism loss using a discriminator or an encoder (e.g., CLIP)
def compute_realism_loss(y_batch, d_batch):
  # Use a pretrained discriminator or encoder to score the images
  scores = score_images(y_batch)
  # Use a pretrained classifier or encoder to encode the domain labels
  labels = encode_labels(d_batch)
  # Compute the realism loss as the negative log-likelihood of matching scores and labels
  L_realism = -torch.mean(torch.log(scores * labels + (1 - scores) * (1 - labels)))
  return L_realism

# Define a function to compute the diversity loss using a diversity metric (e.g., LPIPS)
def compute_diversity_loss(y_batch, d_batch):
  # Compute the pairwise distances between images of the same domain
  distances = compute_pairwise_distances(y_batch, d_batch)
  # Compute the diversity loss as the negative mean of the distances
  L_diversity = -torch.mean(distances)
  return L_diversity

# Define a function to compute the harmony loss using a harmony metric (e.g., style consistency)
def compute_harmony_loss(y_batch, d_batch):
  # Compute the style vectors of the images using G'
  styles = compute_style_vectors(y_batch)
  # Compute the pairwise distances between style vectors of different domains
  distances = compute_pairwise_distances(styles, d_batch, same_domain=False)
  # Compute the harmony loss as the mean of the distances
  L_harmony = torch.mean(distances)
  return L_harmony

# Define an optimizer for updating the parameters of E and G'
optimizer = torch.optim.Adam([E.parameters(), G'.parameters()], lr=lr)

# Step 1: Find dormant directions in the latent space of G
dormant_directions = []
for i in range(max_iterations):
  # Sample a latent code z from the prior distribution
  z = sample_prior()
  # Sample a random direction v from the unit sphere
  v = sample_unit_sphere()
  # Compute the output similarity between z and z + v using G
  sim = output_similarity(G(z), G(z + v))
  # If the similarity is above a threshold, add v to the dormant directions
  if sim > threshold:
    dormant_directions.append(v)

# Step 2: Assign each new domain to a dormant direction
domain_vectors = {}
for d in D:
  # Pop a dormant direction from the list
  v = dormant_directions.pop()
  # Assign v as the domain vector for d
  domain_vectors[d] = v

# Step 3: Train the domain encoder and fine-tune the generator
E = initialize_domain_encoder()
G' = copy_generator(G)
for epoch in range(num_epochs):
  
```