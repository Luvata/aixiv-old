---
title: 2304.06408v1 Intriguing properties of synthetic images  from generative adversarial networks to diffusion models
date: 2023-04-07
---

# [Intriguing properties of synthetic images: from generative adversarial networks to diffusion models](http://arxiv.org/abs/2304.06408v1)

authors: Riccardo Corvi, Davide Cozzolino, Giovanni Poggi, Koki Nagano, Luisa Verdoliva


## What, Why and How

[1]: https://arxiv.org/abs/2304.06408 "[2304.06408] Intriguing properties of synthetic images: from generative ..."
[2]: https://arxiv.org/pdf/2304.06408.pdf "arXiv:2304.06408v1 [cs.CV] 13 Apr 2023"
[3]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2304.06408v1 "[2304.06408v1] Intriguing properties of synthetic images: from ..."

Here is a summary of the paper:

- **What**: The paper is a systematic study of a large number of image generators of different families, such as Generative Adversarial Networks (GAN), Diffusion Models (DM), and Vector Quantized Generative Adversarial Networks (VQ-GAN), aimed at discovering the most forensically relevant characteristics of real and generated images[^1^][1].
- **Why**: The paper's motivation is to detect fake images, which is becoming a major goal of computer vision, as synthesis methods are becoming more and more realistic and powerful[^1^][1].
- **How**: The paper analyzes the synthetic images generated by state-of-the-art models in terms of their frequency domain, spatial domain, and spectral power distributions, and compares them with real images from popular datasets. The paper also investigates the impact of the training data on the generated images[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/2304.06408 "[2304.06408] Intriguing properties of synthetic images: from generative ..."
[2]: https://arxiv.org/pdf/2304.06408.pdf "arXiv:2304.06408v1 [cs.CV] 13 Apr 2023"
[3]: http://export.arxiv.org/abs/2305.06408v1 "[2305.06408v1] Accelerating Batch Active Learning Using Continual ..."

The paper claims the following contributions[^1^][1]:

- It provides a comprehensive analysis of the artifacts and characteristics of synthetic images generated by different families of models, such as GAN, DM, and VQ-GAN, in the frequency and spatial domains.
- It reveals some biases and limitations of the synthetic images due to the lack of diversity or quality of the training data, and shows how they can be exploited for forensic purposes.
- It proposes a novel method to measure the differences between synthetic and real images in terms of their radial and angular spectral power distributions, and shows that they can be used as effective features for fake image detection.

## Method Summary

[1]: https://arxiv.org/abs/2304.06408 "[2304.06408] Intriguing properties of synthetic images: from generative ..."
[2]: https://arxiv.org/pdf/2304.06408.pdf "arXiv:2304.06408v1 [cs.CV] 13 Apr 2023"
[3]: http://export.arxiv.org/abs/2305.06408v1 "[2305.06408v1] Accelerating Batch Active Learning Using Continual ..."

Here is a summary of the method section of the paper:

- The paper uses a set of 12 image generators of different families, such as GAN, DM, and VQ-GAN, to produce synthetic images of various scenes and objects. The paper also uses four real datasets, such as ImageNet and FFHQ, as references for comparison[^1^][2].
- The paper applies a noise residual extraction method to remove the low-frequency content from the images and enhance the high-frequency artifacts. The paper then computes the power spectra and the autocorrelation of the noise residuals for each image[^1^][2].
- The paper analyzes the power spectra and the autocorrelation of the synthetic and real images, and identifies some distinctive patterns and anomalies that can be used for forensic detection. The paper also investigates how the training data affects the characteristics of the synthetic images[^1^][2].
- The paper proposes a novel method to measure the radial and angular spectral power distributions of the images, and shows that they can capture the differences between synthetic and real images in terms of their mid-high frequency signal content. The paper also evaluates the effectiveness of these features for fake image detection using a simple classifier[^1^][2].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the image generators and the real datasets
generators = [StyleGAN-T, GALIP, Taming Transformers, DALL-E Mini, Stable Diffusion, eDiff-I, etc.]
real_datasets = [ImageNet, FFHQ, LAION, etc.]

# Generate synthetic images and collect real images
synthetic_images = []
real_images = []
for generator in generators:
  synthetic_images.append(generator.generate_images())
for dataset in real_datasets:
  real_images.append(dataset.sample_images())

# Extract noise residuals from images
noise_residuals = []
for image in synthetic_images + real_images:
  noise_residuals.append(extract_noise_residual(image))

# Compute power spectra and autocorrelation of noise residuals
power_spectra = []
autocorrelation = []
for noise_residual in noise_residuals:
  power_spectra.append(compute_power_spectrum(noise_residual))
  autocorrelation.append(compute_autocorrelation(noise_residual))

# Analyze power spectra and autocorrelation for forensic detection
for power_spectrum, autocorrelation in zip(power_spectra, autocorrelation):
  analyze_power_spectrum(power_spectrum)
  analyze_autocorrelation(autocorrelation)

# Measure radial and angular spectral power distributions of images
radial_spectral_power = []
angular_spectral_power = []
for image in synthetic_images + real_images:
  radial_spectral_power.append(measure_radial_spectral_power(image))
  angular_spectral_power.append(measure_angular_spectral_power(image))

# Evaluate radial and angular spectral power features for fake image detection
classifier = train_classifier(radial_spectral_power + angular_spectral_power, labels)
test_accuracy = test_classifier(classifier, test_data)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import libraries
import numpy as np
import cv2
import torch
import torchvision
import sklearn

# Define the image generators and the real datasets
generators = [StyleGAN-T, GALIP, Taming Transformers, DALL-E Mini, Stable Diffusion, eDiff-I, etc.]
real_datasets = [ImageNet, FFHQ, LAION, etc.]

# Define the parameters
num_images = 1000 # number of images to generate or sample from each source
image_size = 256 # size of the images
num_bins = 64 # number of bins for the radial and angular spectral power histograms

# Generate synthetic images and collect real images
synthetic_images = []
real_images = []
labels = [] # 0 for real, 1 for synthetic
for generator in generators:
  synthetic_images.append(generator.generate_images(num_images, image_size))
  labels.extend([1] * num_images)
for dataset in real_datasets:
  real_images.append(dataset.sample_images(num_images, image_size))
  labels.extend([0] * num_images)

# Convert images to grayscale and normalize them
images = synthetic_images + real_images
images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in images]
images = [image / 255.0 for image in images]

# Extract noise residuals from images using a high-pass filter
noise_residuals = []
kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]) # Laplacian filter
for image in images:
  noise_residual = cv2.filter2D(image, -1, kernel)
  noise_residuals.append(noise_residual)

# Compute power spectra and autocorrelation of noise residuals using FFT and IFFT
power_spectra = []
autocorrelation = []
for noise_residual in noise_residuals:
  fft = np.fft.fft2(noise_residual) # fast Fourier transform
  fft_shift = np.fft.fftshift(fft) # shift zero frequency to the center
  power_spectrum = np.abs(fft_shift) ** 2 # compute power spectrum
  power_spectra.append(power_spectrum)
  ifft_shift = np.fft.ifftshift(fft_shift) # shift zero frequency back to the origin
  ifft = np.fft.ifft2(ifft_shift) # inverse fast Fourier transform
  autocorr = np.abs(ifft) ** 2 # compute autocorrelation
  autocorrelation.append(autocorr)

# Analyze power spectra and autocorrelation for forensic detection using visualization and statistics
for power_spectrum, autocorrelation in zip(power_spectra, autocorrelation):
  visualize_power_spectrum(power_spectrum) # plot the power spectrum as an image
  visualize_autocorrelation(autocorrelation) # plot the autocorrelation as an image
  compute_statistics(power_spectrum, autocorrelation) # compute mean, variance, skewness, kurtosis, etc.

# Measure radial and angular spectral power distributions of images using polar coordinates and histograms
radial_spectral_power = []
angular_spectral_power = []
for image in images:
  polar_image = cv2.linearPolar(image, (image_size/2,image_size/2), image_size/2, cv2.WARP_FILL_OUTLIERS) # convert image to polar coordinates
  polar_image = polar_image / np.sum(polar_image) # normalize the image
  radial_profile = np.sum(polar_image, axis=1) # sum along the angular axis to get the radial profile
  angular_profile = np.sum(polar_image, axis=0) # sum along the radial axis to get the angular profile
  radial_histogram = np.histogram(radial_profile, bins=num_bins)[0] # compute the histogram of the radial profile
  angular_histogram = np.histogram(angular_profile, bins=num_bins)[0] # compute the histogram of the angular profile
  radial_spectral_power.append(radial_histogram)
  angular_spectral_power.append(angular_histogram)

# Evaluate radial and angular spectral power features for fake image detection using a simple classifier such as logistic regression or SVM
features = np.concatenate((radial_spectral_power, angular_spectral_power), axis=1) # concatenate the two histograms as features
labels = np.array(labels) # convert labels to numpy array
classifier = sklearn.linear_model.LogisticRegression() # define the classifier model
classifier.fit(features, labels) # train the classifier on the features and labels
test_accuracy = classifier.score(test_features, test_labels) # test the classifier on some test data and get the accuracy score

```