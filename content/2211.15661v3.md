---
title: 2211.15661v3 What learning algorithm is in-context learning? Investigations with linear models
date: 2022-11-16
---

# [What learning algorithm is in-context learning? Investigations with linear models](http://arxiv.org/abs/2211.15661v3)

authors: Ekin Aky√ºrek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, Denny Zhou


## What, Why and How

[1]: https://arxiv.org/abs/2211.15661 "[2211.15661] What learning algorithm is in-context learning ... - arXiv.org"
[2]: https://arxiv.org/pdf/2211.15661v3.pdf "WHAT LEARNING ALGORITHM IS IN CONTEXT LEARN ... - arXiv.org"
[3]: https://arxiv.org/pdf/2211.15661v2.pdf "arXiv.org e-Print archive"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper investigates the hypothesis that transformer-based in-context learners implement standard learning algorithms implicitly, by encoding smaller models in their activations, and updating these implicit models as new examples appear in the context.
- **Why**: The paper aims to understand how neural sequence models can perform in-context learning, which is the ability to construct new predictors from sequences of labeled examples without further parameter updates.
- **How**: The paper uses linear regression as a prototypical problem, and offers three sources of evidence for the hypothesis: (1) a theoretical construction that shows transformers can implement learning algorithms for linear models based on gradient descent and closed-form ridge regression; (2) an empirical evaluation that shows trained in-context learners closely match the predictors computed by gradient descent, ridge regression, and exact least-squares regression, transitioning between different predictors as transformer depth and dataset noise vary, and converging to Bayesian estimators for large widths and depths; (3) an analysis that shows in-context learners share algorithmic features with these predictors: learners' late layers non-linearly encode weight vectors and moment matrices.


## Main Contributions

[1]: https://arxiv.org/abs/2211.15661 "[2211.15661] What learning algorithm is in-context learning ... - arXiv.org"
[2]: https://arxiv.org/pdf/2211.15661v3.pdf "WHAT LEARNING ALGORITHM IS IN CONTEXT LEARN ... - arXiv.org"
[3]: https://arxiv.org/pdf/2211.15661v2.pdf "arXiv.org e-Print archive"

The paper[^1^][1] has the following contributions:

- It provides a theoretical construction that shows transformers can implement learning algorithms for linear models based on gradient descent and closed-form ridge regression.
- It conducts an empirical evaluation that shows trained in-context learners closely match the predictors computed by gradient descent, ridge regression, and exact least-squares regression, transitioning between different predictors as transformer depth and dataset noise vary, and converging to Bayesian estimators for large widths and depths.
- It presents an analysis that shows in-context learners share algorithmic features with these predictors: learners' late layers non-linearly encode weight vectors and moment matrices.


## Method Summary

[1]: https://arxiv.org/abs/2211.15661 "[2211.15661] What learning algorithm is in-context learning ... - arXiv.org"
[2]: https://arxiv.org/pdf/2211.15661v3.pdf "WHAT LEARNING ALGORITHM IS IN CONTEXT LEARN ... - arXiv.org"
[3]: https://arxiv.org/pdf/2211.15661v2.pdf "arXiv.org e-Print archive"

Here is a summary of the method section of the paper[^1^][2]:

- The paper uses linear regression as a prototypical problem, where the goal is to learn a linear function f(x) = w^T x + b from a set of labeled examples (x, f(x)).
- The paper considers two types of in-context learners: (1) a transformer-based predictor that takes a sequence of examples as input and outputs a prediction for a new input; (2) a transformer-based learner that takes a sequence of examples as input and outputs a weight vector w that can be used to make predictions for any input.
- The paper proves by construction that transformers can implement learning algorithms for linear models based on gradient descent and closed-form ridge regression, by showing how to encode the weight vector w and the moment matrix M in the activations of the transformer layers, and how to update them using the attention mechanism and the feed-forward network.
- The paper evaluates the performance of the in-context learners on synthetic and real-world datasets, and compares them with the predictors computed by gradient descent, ridge regression, and exact least-squares regression. The paper also studies how the performance varies with respect to the transformer depth, width, dataset noise, and regularization strength.
- The paper analyzes the algorithmic features of the in-context learners, by visualizing the weight vectors and moment matrices encoded in the activations of the transformer layers, and by measuring the similarity between them and the predictors computed by gradient descent, ridge regression, and exact least-squares regression.


## Pseudo Code - High level

[1]: https://arxiv.org/abs/2211.15661 "[2211.15661] What learning algorithm is in-context learning ... - arXiv.org"
[2]: https://arxiv.org/pdf/2211.15661v3.pdf "WHAT LEARNING ALGORITHM IS IN CONTEXT LEARN ... - arXiv.org"
[3]: https://arxiv.org/pdf/2211.15661v2.pdf "arXiv.org e-Print archive"

Here is the high-level pseudo code for the paper[^1^][2]:

- Define a transformer-based predictor that takes a sequence of examples as input and outputs a prediction for a new input
- Define a transformer-based learner that takes a sequence of examples as input and outputs a weight vector that can be used to make predictions for any input
- For each layer of the transformer, define how to encode the weight vector w and the moment matrix M in the activations of the layer, and how to update them using the attention mechanism and the feed-forward network
- Train the transformer-based predictor and learner on synthetic and real-world datasets using cross-entropy loss
- Evaluate the performance of the transformer-based predictor and learner on test datasets, and compare them with the predictors computed by gradient descent, ridge regression, and exact least-squares regression
- Analyze the algorithmic features of the transformer-based predictor and learner, by visualizing the weight vectors and moment matrices encoded in the activations of the transformer layers, and by measuring the similarity between them and the predictors computed by gradient descent, ridge regression, and exact least-squares regression


## Pseudo Code - Detail

[1]: https://arxiv.org/abs/2211.15661 "[2211.15661] What learning algorithm is in-context learning ... - arXiv.org"
[2]: https://arxiv.org/pdf/2211.15661v3.pdf "WHAT LEARNING ALGORITHM IS IN CONTEXT LEARN ... - arXiv.org"
[3]: https://arxiv.org/pdf/2211.15661v2.pdf "arXiv.org e-Print archive"

Here is the detailed pseudo code for the paper[^1^][2]:

- Define a transformer-based predictor that takes a sequence of examples as input and outputs a prediction for a new input
  - Input: a sequence of examples (x_1, f(x_1)), ..., (x_n, f(x_n)), and a new input x_0
  - Output: a prediction f(x_0)
  - Initialize the weight vector w and the moment matrix M to zero
  - For each layer l = 1, ..., L of the transformer:
    - Encode w and M in the activations of the layer using a linear projection
    - Update w and M using the attention mechanism and the feed-forward network
    - Decode w and M from the activations of the layer using another linear projection
  - Return the dot product of w and x_0 as the prediction f(x_0)
- Define a transformer-based learner that takes a sequence of examples as input and outputs a weight vector that can be used to make predictions for any input
  - Input: a sequence of examples (x_1, f(x_1)), ..., (x_n, f(x_n))
  - Output: a weight vector w
  - Initialize the weight vector w and the moment matrix M to zero
  - For each layer l = 1, ..., L of the transformer:
    - Encode w and M in the activations of the layer using a linear projection
    - Update w and M using the attention mechanism and the feed-forward network
    - Decode w and M from the activations of the layer using another linear projection
  - Return w as the output
- Train the transformer-based predictor and learner on synthetic and real-world datasets using cross-entropy loss
  - For each dataset D in the training set:
    - Split D into train, validation, and test sets
    - For each epoch e = 1, ..., E:
      - Shuffle the train set
      - For each batch B of examples in the train set:
        - Compute the predictions for B using the transformer-based predictor
        - Compute the cross-entropy loss between the predictions and the true labels
        - Update the parameters of the transformer-based predictor using gradient descent
      - Compute the validation loss and accuracy using the transformer-based predictor
      - Save the best model based on validation accuracy
    - Evaluate the test loss and accuracy using the best model
  - Repeat the same procedure for training the transformer-based learner
- Evaluate the performance of the transformer-based predictor and learner on test datasets, and compare them with the predictors computed by gradient descent, ridge regression, and exact least-squares regression
  - For each dataset D in the test set:
    - Split D into train, validation, and test sets
    - Compute the predictions for D using the transformer-based predictor and learner
    - Compute the mean squared error (MSE) between the predictions and the true labels
    - Compute the predictors for D using gradient descent, ridge regression, and exact least-squares regression
    - Compute the MSE between these predictors and the true labels
    - Compare the MSEs of different methods and report them in a table or a plot
- Analyze the algorithmic features of the transformer-based predictor and learner, by visualizing the weight vectors and moment matrices encoded in the activations of the transformer layers, and by measuring the similarity between them and the predictors computed by gradient descent, ridge regression, and exact least-squares regression
  - For each dataset D in the test set:
    - Split D into train, validation, and test sets
    - Extract w and M from each layer of the transformer-based predictor and learner using linear projections
    - Visualize w and M using heatmaps or scatter plots
    - Compute cosine similarity between w and M from different layers and different methods
    - Report similarity scores in a table or a plot