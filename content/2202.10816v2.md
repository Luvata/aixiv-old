---
title: 2202.10816v2 Why Fair Labels Can Yield Unfair Predictions  Graphical Conditions for Introduced Unfairness
date: 2022-02-11
---

# [Why Fair Labels Can Yield Unfair Predictions: Graphical Conditions for Introduced Unfairness](http://arxiv.org/abs/2202.10816v2)

authors: Carolyn Ashurst, Ryan Carey, Silvia Chiappa, Tom Everitt


## What, Why and How

[1]: https://arxiv.org/pdf/2202.10816v2.pdf "Why Fair Labels Can Yield Unfair Predictions: Graphical Conditions for ..."
[2]: https://arxiv.org/abs/2202.10816 "[2202.10816] Why Fair Labels Can Yield Unfair Predictions: Graphical ..."
[3]: https://arxiv.org/pdf/2202.10816v1.pdf "arXiv:2202.10816v1 [cs.LG] 22 Feb 2022"

Here is a summary of the paper:

```
What: The paper investigates the conditions under which machine learning systems can introduce or amplify unfairness in their predictions, even when the training labels are fair.

Why: The paper aims to understand why and when introduced unfairness occurs, and how it can be removed or prevented.

How: The paper proposes introduced total variation as a measure of introduced unfairness, and establishes graphical conditions under which it may be incentivised to occur. The paper also uses structural causal models and influence diagrams to represent the relationships between the variables underlying the training data, the predictor, and the loss function of the machine learning system.
```


## Main Contributions

[1]: https://arxiv.org/pdf/2202.10816v2.pdf "Why Fair Labels Can Yield Unfair Predictions: Graphical Conditions for ..."
[2]: https://arxiv.org/abs/2202.10816 "[2202.10816] Why Fair Labels Can Yield Unfair Predictions: Graphical ..."
[3]: https://arxiv.org/pdf/2202.10816v1.pdf "arXiv:2202.10816v1 [cs.LG] 22 Feb 2022"

Here is a list of the contributions of the paper:

```
- The paper proposes introduced total variation as a measure of introduced unfairness, and establishes graphical conditions under which it may be incentivised to occur.
- The paper shows that adding the sensitive attribute as a feature removes the incentive for introduced variation under well-behaved loss functions.
- The paper introduces introduced path-specific effects as a way of quantifying the causal influence of different paths on introduced unfairness, and discusses the issue of when specific paths should be considered fair.
- The paper provides examples and experiments to illustrate the concepts and results of the paper, and discusses their implications for fairness-aware machine learning.
```

## Method Summary

[1]: https://arxiv.org/pdf/2202.10816v2.pdf "Why Fair Labels Can Yield Unfair Predictions: Graphical Conditions for ..."
[2]: https://arxiv.org/abs/2202.10816 "[2202.10816] Why Fair Labels Can Yield Unfair Predictions: Graphical ..."
[3]: https://arxiv.org/pdf/2202.10816v1.pdf "arXiv:2202.10816v1 [cs.LG] 22 Feb 2022"

Here is a summary of the method section of the paper:

```
The paper uses structural causal models (SCMs) and their associated graphs to represent the relationships between the variables underlying the training data, such as the sensitive attribute, the features, and the labels. The paper also builds on influence diagrams, by including the predictor and the loss function of the machine learning system in the same graph. The paper defines introduced total variation as a measure of introduced unfairness, and establishes graphical conditions under which it may be incentivised to occur. The paper also introduces introduced path-specific effects as a way of quantifying the causal influence of different paths on introduced unfairness, and discusses the issue of when specific paths should be considered fair.
```

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```
# Input: a dataset D with features X, sensitive attribute S, and labels Y
# Output: a predictor f that minimises the loss L and the introduced total variation TV

# Define the SCM G that represents the causal relationships between X, S, Y, and other variables
# Define the influence diagram I that includes G, f, and L
# Define the measure of introduced total variation TV as the difference between TV(f(S),Y) and TV(S,Y)
# Define the measure of introduced path-specific effects PSE as the difference between PSE(f(S),Y) and PSE(S,Y) for each path in G

# Train f on D using gradient descent or other optimisation methods
# For each iteration:
  # Compute the loss L(f(X),Y) and its gradient
  # Compute the introduced total variation TV(f(S),Y) and its gradient
  # Compute the introduced path-specific effects PSE(f(S),Y) and their gradients for each path in G
  # Update f by taking a step in the direction that minimises L and TV, and respects the fairness constraints on PSE
# Return f
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```
# Input: a dataset D with features X, sensitive attribute S, and labels Y
# Output: a predictor f that minimises the loss L and the introduced total variation TV

# Define the SCM G that represents the causal relationships between X, S, Y, and other variables
# Define the influence diagram I that includes G, f, and L
# Define the measure of introduced total variation TV as the difference between TV(f(S),Y) and TV(S,Y)
# Define the measure of introduced path-specific effects PSE as the difference between PSE(f(S),Y) and PSE(S,Y) for each path in G
# Define the fairness constraints on PSE, such as bounding them by some threshold or requiring them to be zero

# Initialise f randomly or with some prior knowledge
# Initialise the learning rate alpha and the number of iterations T
# For t = 1 to T:
  # Compute the loss L(f(X),Y) and its gradient dL/df
  # Compute the introduced total variation TV(f(S),Y) and its gradient dTV/df
  # Compute the introduced path-specific effects PSE(f(S),Y) and their gradients dPSE/df for each path in G
  # Update f by taking a step in the direction that minimises L and TV, and respects the fairness constraints on PSE
  # f = f - alpha * (dL/df + lambda * dTV/df + mu * dPSE/df)
  # where lambda and mu are Lagrange multipliers for the constraints on TV and PSE
# Return f
```