---
title: 2012.05901v2 Robust Consistent Video Depth Estimation
date: 2020-12-06
---

# [Robust Consistent Video Depth Estimation](http://arxiv.org/abs/2012.05901v2)

authors: Johannes Kopf, Xuejian Rong, Jia-Bin Huang


## What, Why and How

[1]: https://arxiv.org/pdf/2012.05901v2.pdf "arXiv:2012.05901v2 [cs.CV] 22 Jun 2021"
[2]: https://arxiv.org/abs/2012.05901 "[2012.05901] Robust Consistent Video Depth Estimation - arXiv.org"
[3]: http://export.arxiv.org/abs/1601.05901v2 "[1601.05901v2] Systematic effects from an ambient-temperature ..."

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper presents an algorithm for estimating consistent dense depth maps and camera poses from a monocular video.
- **Why**: The paper aims to address the challenges of dense reconstruction for casually captured videos that contain noise, shake, motion blur, rolling shutter deformations, and dynamic objects.
- **How**: The paper integrates a learning-based depth prior, in the form of a convolutional neural network trained for single-image depth estimation, with geometric optimization, to estimate a smooth camera trajectory as well as detailed and stable depth reconstruction. The paper combines two complementary techniques: (1) flexible deformation-splines for low-frequency large-scale alignment and (2) geometry-aware depth filtering for high-frequency alignment of fine depth details. The paper does not require camera poses as input and achieves robust reconstruction for challenging hand-held cell phone captures. The paper quantitatively outperforms state-of-the-arts on the Sintel benchmark for both depth and pose estimations and attains favorable qualitative results across diverse wild datasets.

## Main Contributions

The paper claims the following contributions:

- A novel algorithm for robust consistent video depth estimation that integrates a learning-based depth prior with geometric optimization.
- A flexible deformation-spline technique for low-frequency large-scale alignment that can handle rolling shutter deformations and camera shake.
- A geometry-aware depth filtering technique for high-frequency alignment of fine depth details that can handle motion blur and dynamic objects.
- A comprehensive evaluation on the Sintel benchmark and diverse wild datasets that demonstrates the effectiveness and robustness of the proposed method.

## Method Summary

[1]: https://arxiv.org/pdf/2012.05901v2.pdf "arXiv:2012.05901v2 [cs.CV] 22 Jun 2021"
[2]: https://arxiv.org/abs/2012.05901v2 "[2012.05901v2] Robust Consistent Video Depth Estimation - arXiv.org"
[3]: https://info.arxiv.org/help/cs/index.html "Computer Science archive - arXiv info"

Here is a summary of the method section of the paper at [^1^][1]:

- The paper proposes a two-stage algorithm for robust consistent video depth estimation. The first stage estimates an initial depth map and camera pose for each frame using a convolutional neural network (CNN) trained for single-image depth estimation and a pose network trained on synthetic data. The second stage refines the depth maps and camera poses by minimizing a geometric energy function that consists of three terms: a photometric consistency term, a depth smoothness term, and a depth prior term. The paper introduces two novel techniques to improve the geometric optimization: flexible deformation-splines and geometry-aware depth filtering.
- The paper describes the flexible deformation-splines technique, which models the camera motion as a spline curve with control points that can be deformed to account for rolling shutter deformations and camera shake. The paper shows how to compute the Jacobian of the photometric consistency term with respect to the control points and how to optimize them using the Levenberg-Marquardt algorithm. The paper also shows how to handle occlusions and dynamic objects by using a visibility mask and a motion mask, respectively.
- The paper describes the geometry-aware depth filtering technique, which applies a bilateral filter to the depth maps to smooth out high-frequency noise and preserve fine depth details. The paper shows how to compute the filter weights using the photometric consistency and the depth prior terms, and how to update them iteratively during the optimization. The paper also shows how to handle occlusions and dynamic objects by using a visibility mask and a motion mask, respectively.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a monocular video V
# Output: a set of depth maps D and camera poses P
# Parameters: number of control points N, number of iterations M

# Stage 1: Initial depth and pose estimation
D0, P0 = CNN_depth_pose(V) # use a CNN to estimate depth and pose for each frame

# Stage 2: Geometric optimization
D, P = D0, P0 # initialize depth and pose with the CNN estimates
for i in range(M): # iterate M times
  C = spline_control_points(P, N) # compute N control points for the camera motion spline
  V, M = visibility_motion_masks(V, D, P) # compute visibility and motion masks for each frame
  for j in range(N): # optimize each control point
    C[j] = optimize_control_point(C[j], V, D, P, V, M) # use Levenberg-Marquardt to minimize the geometric energy function
  P = spline_poses(C) # update the camera poses from the control points
  W = filter_weights(V, D, P, V, M) # compute the filter weights for each pixel using the geometric energy function
  D = bilateral_filter(D, W) # apply a bilateral filter to the depth maps using the filter weights
return D, P # return the refined depth maps and camera poses
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a monocular video V of K frames
# Output: a set of depth maps D and camera poses P
# Parameters: number of control points N, number of iterations M, number of pyramid levels L, patch size S

# Stage 1: Initial depth and pose estimation
D0, P0 = CNN_depth_pose(V) # use a CNN to estimate depth and pose for each frame

# Stage 2: Geometric optimization
D, P = D0, P0 # initialize depth and pose with the CNN estimates
for l in range(L): # iterate over pyramid levels from coarse to fine
  Vl = downsample(V, l) # downsample the video to the current level
  Dl = downsample(D, l) # downsample the depth maps to the current level
  for i in range(M): # iterate M times
    Cl = spline_control_points(P, N) # compute N control points for the camera motion spline
    Vl, Ml = visibility_motion_masks(Vl, Dl, P) # compute visibility and motion masks for each frame
    for j in range(N): # optimize each control point
      J = jacobian_control_point(Cl[j], Vl, Dl, P, Vl, Ml) # compute the Jacobian of the geometric energy function with respect to the control point
      H = hessian_control_point(J) # compute the Hessian matrix of the geometric energy function with respect to the control point
      g = gradient_control_point(J) # compute the gradient vector of the geometric energy function with respect to the control point
      d = solve_linear_system(H, g) # solve the linear system Hd = -g using Cholesky decomposition
      Cl[j] = Cl[j] + d # update the control point using the step direction d
    P = spline_poses(Cl) # update the camera poses from the control points
    Wl = filter_weights(Vl, Dl, P, Vl, Ml) # compute the filter weights for each pixel using the geometric energy function
    Dl = bilateral_filter(Dl, Wl) # apply a bilateral filter to the depth maps using the filter weights
  D = upsample(Dl) # upsample the depth maps to the original resolution
return D, P # return the refined depth maps and camera poses
```