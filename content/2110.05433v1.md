---
title: 2110.05433v1 Mesh Draping  Parametrization-Free Neural Mesh Transfer
date: 2021-10-06
---

# [Mesh Draping: Parametrization-Free Neural Mesh Transfer](http://arxiv.org/abs/2110.05433v1)

authors: Amir Hertz, Or Perel, Raja Giryes, Olga Sorkine-Hornung, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/2110.05433 "Mesh Draping: Parametrization-Free Neural Mesh Transfer"
[2]: https://arxiv.org/abs/2211.05433 "[2211.05433] A classification performance evaluation measure ..."
[3]: https://arxiv.org/pdf/2111.05433v1.pdf "arXiv.org"
[4]: http://export.arxiv.org/abs/2101.05433v1 "[2101.05433v1] Eclipsing the X-ray emitting region in the active galaxy ..."

Here is a summary of the paper:

- **What**: The paper introduces Mesh Draping, a neural method for transferring existing mesh structure from one shape to another[^1^][1].
- **Why**: The paper aims to simplify 3D mesh modeling by reusing existing mesh designs and adapting them to different target geometries[^1^][1].
- **How**: The paper proposes to deform the source mesh using progressive positional encoding, which leverages gradually increasing frequencies to guide the neural optimization[^1^][1]. The paper also shows that Mesh Draping is parameterization-free and can handle various target shape representations, such as point clouds, polygon soups, and non-manifold meshes[^1^][1]. The paper demonstrates the effectiveness of Mesh Draping on several examples and compares it with existing surface mapping techniques[^1^][1].

## Main Contributions

According to the paper, the main contributions are:

- A novel neural method for transferring existing mesh structure from one shape to another, called Mesh Draping.
- A progressive positional encoding scheme that enables stable and high quality mesh deformation using neural optimization.
- A parameterization-free approach that can handle various target shape representations without requiring surface parametrization or manual tuning.
- A comprehensive evaluation of Mesh Draping on synthetic and real datasets, showing its advantages over existing surface mapping techniques.

## Method Summary

[1]: https://arxiv.org/abs/2110.05433 "Mesh Draping: Parametrization-Free Neural Mesh Transfer"
[2]: https://arxiv.org/abs/2211.05433 "[2211.05433] A classification performance evaluation measure ..."
[3]: http://export.arxiv.org/abs/2101.05433v1 "[2101.05433v1] Eclipsing the X-ray emitting region in the active galaxy ..."

Here is a summary of the method section of the paper:

- The paper formulates the mesh transfer problem as an optimization problem that minimizes a loss function composed of three terms: a **fitting term** that measures the distance between the deformed source mesh and the target shape, a **regularization term** that penalizes large deviations from the source mesh, and a **feature preservation term** that encourages the preservation of the source mesh characteristics[^1^][1].
- The paper proposes to use a neural network to parameterize the deformation function that maps each vertex of the source mesh to a new position on the target shape[^1^][1]. The network takes as input a progressive positional encoding (PPE) of each vertex, which is a concatenation of sine and cosine functions with different frequencies[^1^][1]. The network outputs a displacement vector for each vertex that is added to its original position[^1^][1].
- The paper introduces a novel scheme for choosing the frequencies of the PPE, which starts with low frequencies and gradually increases them during the optimization process[^1^][1]. The paper argues that this scheme helps to avoid local minima and achieve stable and high quality mesh transfer[^1^][1].
- The paper also shows that Mesh Draping is parameterization-free and can handle various target shape representations without requiring surface parametrization or manual tuning[^1^][1]. The paper explains how to compute the fitting term for different target shape representations, such as point clouds, polygon soups, and non-manifold meshes[^1^][1]. The paper also discusses how to handle cases where the target shape has different topology or scale than the source mesh[^1^][1].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: source mesh S, target shape T
# Output: deformed mesh D

# Initialize neural network f with random weights
# Initialize PPE frequencies F with low values
# Initialize displacement vectors D with zeros

# Repeat until convergence or maximum iterations:
  # Compute PPE of each vertex of S using F
  # Feed PPE to f and get displacement vectors D
  # Add D to S to get deformed mesh D
  # Compute loss function L(D, S, T) as a sum of fitting, regularization, and feature preservation terms
  # Update f using gradient descent to minimize L
  # Increase F to add higher frequencies to PPE
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: source mesh S with n vertices and m faces, target shape T
# Output: deformed mesh D

# Define hyperparameters: learning rate lr, maximum iterations max_iter, frequency increment factor alpha, initial frequency f0, number of PPE dimensions d

# Initialize neural network f with random weights
# f has d input units and 3 output units
# f can be any architecture, such as MLP or ResNet

# Initialize PPE frequencies F with low values
# F is a vector of length d/2
# F[i] = f0 * alpha^i for i = 0, ..., d/2 - 1

# Initialize displacement vectors D with zeros
# D is a matrix of size n x 3

# Repeat until convergence or maximum iterations:
  # Compute PPE of each vertex of S using F
  # PPE is a matrix of size n x d
  # PPE[i][j] = sin(2 * pi * F[j/2] * S[i][j%3]) if j is even
  # PPE[i][j] = cos(2 * pi * F[j/2] * S[i][j%3]) if j is odd
  
  # Feed PPE to f and get displacement vectors D
  # D = f(PPE)
  
  # Add D to S to get deformed mesh D
  # D = S + D
  
  # Compute loss function L(D, S, T) as a sum of fitting, regularization, and feature preservation terms
  # L = w1 * L_fit + w2 * L_reg + w3 * L_feat
  # w1, w2, w3 are weights that balance the terms
  
  # L_fit measures the distance between D and T
  # L_fit depends on the representation of T
  # If T is a point cloud, L_fit is the Chamfer distance between D and T
  # If T is a polygon soup or a non-manifold mesh, L_fit is the sum of squared distances from each vertex of D to its closest face in T
  
  # L_reg penalizes large deviations from S
  # L_reg is the sum of squared distances between each vertex of D and its corresponding vertex in S
  
  # L_feat encourages the preservation of the source mesh characteristics
  # L_feat is the sum of squared differences between the edge lengths and dihedral angles of D and S
  
  # Update f using gradient descent to minimize L
  # f = f - lr * grad_f(L)
  
  # Increase F to add higher frequencies to PPE
  # F = F * alpha
```