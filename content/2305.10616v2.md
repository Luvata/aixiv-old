---
title: 2305.10616v2 Evaluation Metrics for DNNs Compression
date: 2023-05-11
---

# [Evaluation Metrics for DNNs Compression](http://arxiv.org/abs/2305.10616v2)

authors: Abanoub Ghobrial, Samuel Budgett, Dieter Balemans, Hamid Asgari, Phil Reiter, Kerstin Eder


## What, Why and How

[1]: https://arxiv.org/pdf/2305.10616.pdf "Evaluation Metrics for CNNs Compression - arXiv.org"
[2]: https://arxiv.org/abs/2305.10616v1 "[2305.10616v1] Evaluation Metrics for CNNs Compression - arXiv.org"
[3]: https://arxiv-export1.library.cornell.edu/pdf/2305.10616 "PDF for 2305.10616 - arxiv-export1.library.cornell.edu"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper provides a review of evaluation metrics for CNNs compression techniques, which are methods to reduce the size and complexity of neural networks while maintaining their performance.
- **Why**: The paper aims to contribute towards standardisation of neural network compression by offering a comprehensive and consistent way of comparing different compression techniques and identifying the most suitable one for different applications.
- **How**: The paper implements the reviewed metrics into NetZIP, a standardised neural network compression bench. It also showcases some of the metrics using three case studies focusing on object classification, object detection, and edge devices.

## Main Contributions

[1]: https://arxiv.org/pdf/2305.10616.pdf "Evaluation Metrics for CNNs Compression - arXiv.org"
[2]: https://arxiv.org/abs/2305.10616v1 "[2305.10616v1] Evaluation Metrics for CNNs Compression - arXiv.org"
[3]: https://arxiv-export1.library.cornell.edu/pdf/2305.10616 "PDF for 2305.10616 - arxiv-export1.library.cornell.edu"

According to the paper[^1^][1], the main contributions are:

- **A review of evaluation metrics for CNNs compression**, covering different aspects such as accuracy, size, energy, latency, and robustness.
- **An implementation of the reviewed metrics into NetZIP**, a standardised neural network compression bench that allows users to easily compare different compression techniques and visualise their trade-offs.
- **Three case studies using NetZIP**, demonstrating the use of the metrics on different CNN models and tasks, such as object classification, object detection, and edge devices.

## Method Summary

[1]: https://arxiv.org/pdf/2305.10616.pdf "Evaluation Metrics for CNNs Compression - arXiv.org"
[2]: https://arxiv.org/abs/2305.10616v1 "[2305.10616v1] Evaluation Metrics for CNNs Compression - arXiv.org"
[3]: https://arxiv-export1.library.cornell.edu/pdf/2305.10616 "PDF for 2305.10616 - arxiv-export1.library.cornell.edu"

Here is a summary of the method section of the paper[^1^][1]:

- The paper first introduces NetZIP, a standardised neural network compression bench that allows users to apply different compression techniques to CNN models and evaluate them using various metrics.
- The paper then reviews different evaluation metrics for CNNs compression, categorising them into five aspects: accuracy, size, energy, latency, and robustness. For each aspect, the paper discusses the definition, importance, and challenges of the metrics, and provides examples of how to calculate them using NetZIP.
- The paper then presents three case studies using NetZIP to demonstrate the use of the metrics on different CNN models and tasks. The first case study compares pruning and quantisation techniques on ResNet-50 for object classification. The second case study compares knowledge distillation and tensor decomposition techniques on YOLOv3 for object detection. The third case study compares different compression techniques on MobileNetV2 for edge devices.

## Pseudo Code - High level

[1]: https://arxiv.org/pdf/2305.10616.pdf "Evaluation Metrics for CNNs Compression - arXiv.org"
[2]: https://arxiv.org/abs/2305.10616v1 "[2305.10616v1] Evaluation Metrics for CNNs Compression - arXiv.org"
[3]: https://arxiv-export1.library.cornell.edu/pdf/2305.10616 "PDF for 2305.10616 - arxiv-export1.library.cornell.edu"

Here is a high-level pseudo code for the paper[^1^][1]:

```python
# Define a CNN model and a compression technique
model = CNN(...)
compression = Pruning(...) or Quantisation(...) or KnowledgeDistillation(...) or TensorDecomposition(...)

# Apply the compression technique to the model
compressed_model = compression.apply(model)

# Evaluate the compressed model using NetZIP
netzip = NetZIP(...)
metrics = netzip.evaluate(compressed_model)

# Visualise the metrics using NetZIP
netzip.visualise(metrics)
```

## Pseudo Code - Detail

[1]: https://arxiv.org/abs/2305.10616v1 "[2305.10616v1] Evaluation Metrics for CNNs Compression - arXiv.org"
[2]: https://arxiv.org/pdf/2305.10616.pdf "Evaluation Metrics for CNNs Compression - arXiv.org"
[3]: http://export.arxiv.org/abs/1809.10616v2 "[1809.10616v2] Universal gaps for XOR games from estimates on tensor ..."

Here is a detailed pseudo code for the paper[^1^][1]:

```python
# Import the required libraries
import torch
import torchvision
import netzip

# Define a CNN model and a compression technique
model = torchvision.models.resnet50(pretrained=True) # ResNet-50 for object classification
compression = netzip.Pruning(method="l1-norm", ratio=0.5) # Pruning with l1-norm and 50% sparsity

# Apply the compression technique to the model
compressed_model = compression.apply(model)

# Evaluate the compressed model using NetZIP
netzip = netzip.NetZIP()
metrics = netzip.evaluate(compressed_model, dataset="imagenet", device="gpu")

# Visualise the metrics using NetZIP
netzip.visualise(metrics, plot_type="bar")
```