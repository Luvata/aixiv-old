---
title: 1803.08457v5 Clustering-driven Deep Embedding with Pairwise Constraints
date: 2018-03-09
---

# [Clustering-driven Deep Embedding with Pairwise Constraints](http://arxiv.org/abs/1803.08457v5)

authors: Sharon Fogel, Hadar Averbuch-Elor, Jacov Goldberger, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/1803.10122 "[1803.10122] World Models - arXiv.org"
[2]: https://arxiv.org/pdf/1803.01572v2.pdf "Abstract. arXiv:1803.01572v2 [math.NA] 3 Oct 2018"
[3]: http://export.arxiv.org/abs/1803.11081v3 "[1803.11081v3] On the distribution of rank and crank statistics for ..."

Here is a summary of the paper at [^1^][1]:

- **What**: The paper explores building generative neural network models of popular reinforcement learning environments. The authors introduce a world model that can learn a compressed spatial and temporal representation of the environment in an unsupervised manner. The authors also show that an agent can be trained entirely inside its own hallucinated dream generated by the world model, and transfer this policy back into the actual environment.
- **Why**: The paper aims to address the challenge of learning complex and diverse skills in high-dimensional and dynamic environments. The authors argue that a world model can provide a compact and abstract representation of the environment that can facilitate learning and generalization. The paper also demonstrates that dreaming can be a powerful tool for training agents without interacting with the real environment, which can save time and resources.
- **How**: The paper proposes a world model that consists of three components: a vision model (V), a memory model (M), and a controller (C). The vision model is a variational autoencoder that learns to encode the high-dimensional observations into a low-dimensional latent space. The memory model is a recurrent neural network that learns to predict the next latent state given the previous latent state and action. The controller is a simple linear model that learns to map the current latent state and memory state to an action. The authors train the vision and memory models on data collected from random rollouts in the environment, and then train the controller on data generated by the world model. The authors evaluate their approach on several reinforcement learning tasks, such as Car Racing, VizDoom, and Sonic the Hedgehog, and compare it with baseline methods.

## Main Contributions

Some of the contributions of this paper are:

- It introduces a novel world model that can learn a compressed and generative representation of the environment in an unsupervised manner.
- It shows that an agent can be trained entirely inside its own dream generated by the world model, and transfer this policy back into the actual environment.
- It demonstrates that a simple linear controller can achieve competitive results on various reinforcement learning tasks by using the features extracted from the world model.
- It provides an interactive version of the paper that allows readers to explore the world model and the agent's behavior in different environments.

## Method Summary

[1]: https://arxiv.org/pdf/1803.08457v5.pdf "arXiv:1803.08457v5 [cs.CV] 19 Oct 2018"
[2]: https://info.arxiv.org/help/cs/index.html "Computer Science archive - arXiv info"
[3]: https://arxiv.org/pdf/1803.08457v1.pdf "with Pairwise Constraints arXiv:1803.08457v1 [cs.CV] 22 Mar 2018"

Here is a summary of the method section of the paper at [^1^][1]:

- The paper proposes a **Clustering-driven deep embedding with PAirwise Constraints (CPAC)** framework for non-parametric clustering using a neural network.
- The paper adopts a **Siamese network** architecture that consists of two identical encoders that project pairs of data points into a latent space. The network is trained to minimize a **contrastive loss** that encourages similar pairs to have small distances and dissimilar pairs to have large distances in the latent space.
- The paper uses **robust continuous clustering (RCC)** to extract pairwise constraints from the data. RCC is a spectral clustering method that assigns soft labels to data points based on their mutual k-nearest neighbors. The paper uses these soft labels to define the similarity and dissimilarity of pairs, and to weight the contrastive loss accordingly.
- The paper introduces a **refinement scheme** that analyzes the losses associated with each pair and discards the ones that are likely to be noisy or inconsistent. The paper also allows the user to provide a small number of labeled pairs as additional constraints to improve the clustering performance.
- The paper adapts its framework for various types of data, such as images, text, and 3D shapes. The paper uses different encoder architectures for different data modalities, such as convolutional neural networks, recurrent neural networks, and point cloud networks. The paper also shows how to handle data with multiple labels or hierarchical labels.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: data X, number of clusters k, number of neighbors m, number of labeled pairs l
# Output: cluster assignments Y

# Step 1: Train a Siamese network to embed the data into a latent space
encoder = build_encoder(X) # choose an encoder architecture based on the data modality
pairs = sample_pairs(X) # sample pairs of data points randomly or using RCC
labels = get_labels(pairs) # get the similarity labels for the pairs using RCC or user input
loss = contrastive_loss(encoder, pairs, labels) # compute the contrastive loss for the pairs
train(encoder, loss) # train the encoder to minimize the loss

# Step 2: Refine the pairwise constraints using the losses
losses = evaluate(encoder, loss) # evaluate the losses for each pair
pairs = filter_pairs(pairs, losses) # filter out the pairs with high or low losses
labels = get_labels(pairs) # get the updated labels for the remaining pairs

# Step 3: Cluster the embedded data using RCC
Z = encoder(X) # embed the data into the latent space
W = compute_affinity_matrix(Z, m) # compute the affinity matrix using mutual k-nearest neighbors
Y = spectral_clustering(W, k) # perform spectral clustering on the affinity matrix
return Y # return the cluster assignments
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: data X, number of clusters k, number of neighbors m, number of labeled pairs l
# Output: cluster assignments Y

# Step 1: Train a Siamese network to embed the data into a latent space
encoder = build_encoder(X) # choose an encoder architecture based on the data modality
# for images, use a convolutional neural network (CNN)
# for text, use a recurrent neural network (RNN) or a transformer
# for 3D shapes, use a point cloud network (PCN) or a graph neural network (GNN)
optimizer = Adam() # choose an optimizer for training
batch_size = 64 # choose a batch size for training
epochs = 100 # choose a number of epochs for training
pairs = sample_pairs(X) # sample pairs of data points randomly or using RCC
# to use RCC, first compute the affinity matrix W using mutual k-nearest neighbors
# then compute the soft labels Y using spectral clustering on W
# then sample pairs of data points with probability proportional to Y[i,j]
labels = get_labels(pairs) # get the similarity labels for the pairs using RCC or user input
# if using RCC, use Y[i,j] as the label for pair (i,j)
# if using user input, ask the user to label l pairs as similar or dissimilar
loss = contrastive_loss(encoder, pairs, labels) # compute the contrastive loss for the pairs
# the contrastive loss is defined as:
# loss = (1/2N) * sum_{i,j} (Y[i,j] * D[i,j]^2 + (1 - Y[i,j]) * max(0, m - D[i,j])^2)
# where N is the number of pairs, D[i,j] is the Euclidean distance between encoder(X[i]) and encoder(X[j]),
# and m is a margin parameter
for epoch in range(epochs): # train the encoder for a number of epochs
    shuffle(pairs) # shuffle the pairs before each epoch
    for batch in split(pairs, batch_size): # iterate over batches of pairs
        optimizer.zero_grad() # reset the gradients
        batch_loss = loss(batch) # compute the loss for the batch
        batch_loss.backward() # compute the gradients
        optimizer.step() # update the encoder parameters

# Step 2: Refine the pairwise constraints using the losses
losses = evaluate(encoder, loss) # evaluate the losses for each pair
# losses[i,j] = loss((X[i], X[j]))
threshold = percentile(losses, 90) # choose a threshold to filter out high-loss pairs
pairs = filter_pairs(pairs, losses, threshold) # filter out the pairs with losses above the threshold
labels = get_labels(pairs) # get the updated labels for the remaining pairs

# Step 3: Cluster the embedded data using RCC
Z = encoder(X) # embed the data into the latent space
W = compute_affinity_matrix(Z, m) # compute the affinity matrix using mutual k-nearest neighbors
# W[i,j] = exp(-D[i,j]^2 / sigma^2) if i and j are mutual k-nearest neighbors, 0 otherwise
# where sigma is a scaling parameter
Y = spectral_clustering(W, k) # perform spectral clustering on the affinity matrix
# compute the normalized Laplacian L = D^(-1/2) * (I - W) * D^(-1/2), where D is a diagonal matrix with D[i,i] = sum_j W[i,j]
# compute the k smallest eigenvectors of L and stack them as columns of a matrix U
# normalize each row of U to have unit norm and treat them as new points in R^k
# apply k-means clustering on these points and assign each point to its nearest cluster center
return Y # return the cluster assignments

```