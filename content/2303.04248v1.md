---
title: 2303.04248v1 TRACT  Denoising Diffusion Models with Transitive Closure Time-Distillation
date: 2023-03-05
---

# [TRACT: Denoising Diffusion Models with Transitive Closure Time-Distillation](http://arxiv.org/abs/2303.04248v1)

authors: David Berthelot, Arnaud Autef, Jierui Lin, Dian Ang Yap, Shuangfei Zhai, Siyuan Hu, Daniel Zheng, Walter Talbott, Eric Gu


## What, Why and How

[1]: https://arxiv.org/abs/2303.04248 "[2303.04248] TRACT: Denoising Diffusion Models with Transitive Closure ..."
[2]: https://arxiv-export1.library.cornell.edu/abs/2303.04248 "[2303.04248] TRACT: Denoising Diffusion Models with Transitive Closure ..."
[3]: https://arxiv.org/pdf/2303.04248v1 "Abstract - arXiv.org"

Here is a summary of the paper:

- **What**: The paper proposes a new method called TRAnsitive Closure Time-distillation (TRACT) for improving the efficiency and quality of generative sampling using denoising diffusion models.
- **Why**: Denoising diffusion models are powerful generative models that can produce realistic samples, but they require many iterations and network calls to generate good samples. Existing methods such as binary time-distillation (BTD) can reduce the number of network calls, but they have limitations such as low resolution and high memory consumption.
- **How**: TRACT extends BTD by using a transitive closure operation that creates a deterministic mapping between the initial noise and the final generated result. This allows one to learn an efficient student model that approximates a given teacher model. TRACT also introduces a new loss function that balances the fidelity and diversity of the generated samples. The paper shows that TRACT improves the FID score by up to 2.4x on the same architecture, and achieves new state-of-the-art results for single-step denoising diffusion implicit models (DDIM) on ImageNet64 and CIFAR10 datasets[^1^][1].

## Main Contributions

The paper claims to make the following contributions:

- It introduces TRACT, a new method for time-distillation of denoising diffusion models that uses a transitive closure operation to create a deterministic mapping between the initial noise and the final generated result.
- It proposes a new loss function that balances the fidelity and diversity of the generated samples, and incorporates a regularization term that encourages the student model to learn from the teacher model.
- It demonstrates that TRACT improves the FID score by up to 2.4x on the same architecture, and achieves new state-of-the-art results for single-step DDIM on ImageNet64 and CIFAR10 datasets.
- It provides extensive ablations and analyses to understand the effects of different components of TRACT, such as the transitive closure operation, the loss function, and the regularization term.

## Method Summary

Here is a summary of the method section of the paper:

- The paper reviews the basics of denoising diffusion models and binary time-distillation, and then introduces TRACT as an extension of BTD.
- TRACT consists of two main components: a transitive closure operation and a loss function.
- The transitive closure operation creates a deterministic mapping between the initial noise and the final generated result by applying the teacher model recursively on the noise until convergence. This mapping can be approximated by a student model that learns to mimic the teacher model in a single step.
- The loss function consists of three terms: a fidelity term that measures the reconstruction error between the student and the teacher outputs, a diversity term that measures the KL divergence between the student and the teacher distributions, and a regularization term that measures the L2 distance between the student and the teacher parameters.
- The paper also discusses some implementation details and tricks for training TRACT, such as using a warm-up phase, a curriculum learning strategy, and a gradient clipping technique.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the teacher model T and the student model S
T = DenoisingDiffusionModel()
S = DenoisingDiffusionModel()

# Define the transitive closure operation TC
def TC(x):
  # Apply the teacher model T recursively on x until convergence
  while not converged:
    x = T(x)
  return x

# Define the loss function L
def L(x):
  # Compute the fidelity term F
  F = MSE(S(x), T(x))
  # Compute the diversity term D
  D = KL(S(x) || T(x))
  # Compute the regularization term R
  R = L2(S.parameters() - T.parameters())
  # Return the weighted sum of F, D, and R
  return alpha * F + beta * D + gamma * R

# Train the student model S using TRACT
for epoch in epochs:
  for batch in batches:
    # Sample a batch of noise x
    x = sample_noise(batch_size)
    # Compute the transitive closure of x using TC
    y = TC(x)
    # Compute the loss L on y
    loss = L(y)
    # Update the student model S using gradient descent
    S.update(loss)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# Define the hyperparameters
batch_size = 64 # The size of each batch
num_epochs = 100 # The number of epochs to train
num_steps = 1000 # The number of diffusion steps for the teacher model
num_classes = 10 # The number of classes for the dataset
image_size = 64 # The size of each image
image_channels = 3 # The number of channels for each image
hidden_size = 256 # The size of the hidden layer for the models
alpha = 0.1 # The weight for the fidelity term
beta = 0.01 # The weight for the diversity term
gamma = 0.001 # The weight for the regularization term
lr = 0.01 # The learning rate for the optimizer
clip_value = 1.0 # The value to clip the gradients

# Define the dataset and the dataloader
transform = transforms.Compose([
  transforms.Resize(image_size),
  transforms.ToTensor(),
  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)

# Define the teacher model T and the student model S
class DenoisingDiffusionModel(nn.Module):
  def __init__(self):
    super(DenoisingDiffusionModel, self).__init__()
    # Define the encoder network
    self.encoder = nn.Sequential(
      nn.Conv2d(image_channels, hidden_size, kernel_size=3, stride=2, padding=1),
      nn.ReLU(),
      nn.Conv2d(hidden_size, hidden_size, kernel_size=3, stride=2, padding=1),
      nn.ReLU(),
      nn.Conv2d(hidden_size, hidden_size, kernel_size=3, stride=2, padding=1),
      nn.ReLU(),
      nn.Flatten(),
      nn.Linear(hidden_size * (image_size // 8) * (image_size // 8), num_classes)
    )
    # Define the decoder network
    self.decoder = nn.Sequential(
      nn.Linear(num_classes, hidden_size * (image_size // 8) * (image_size // 8)),
      nn.Unflatten(1, (hidden_size, image_size // 8, image_size // 8)),
      nn.ConvTranspose2d(hidden_size, hidden_size, kernel_size=4, stride=2, padding=1),
      nn.ReLU(),
      nn.ConvTranspose2d(hidden_size, hidden_size, kernel_size=4, stride=2, padding=1),
      nn.ReLU(),
      nn.ConvTranspose2d(hidden_size, image_channels, kernel_size=4, stride=2, padding=1),
      nn.Tanh()
    )
  
  def forward(self, x):
    # Encode x into a latent code z
    z = self.encoder(x)
    # Decode z into a reconstructed image x_hat
    x_hat = self.decoder(z)
    return x_hat

T = DenoisingDiffusionModel()
S = DenoisingDiffusionModel()

# Define the transitive closure operation TC
def TC(x):
  # Apply the teacher model T recursively on x until convergence
  x_prev = x.clone()
  for t in range(num_steps):
    x_next = T(x_prev)
    if torch.allclose(x_next, x_prev):
      break
    x_prev = x_next.clone()
  return x_prev

# Define the loss function L
def L(x):
  # Compute the fidelity term F
  F = torch.mean(torch.square(S(x) - T(x)))
  # Compute the diversity term D
  D = torch.mean(torch.kl_div(torch.log_softmax(S(x), dim=1), torch.softmax(T(x), dim=1)))
  # Compute the regularization term R
  R = torch.mean(torch.square(S.parameters() - T.parameters()))
  # Return the weighted sum of F, D, and R
  return alpha * F + beta * D + gamma * R

# Define the optimizer for the student model S
optimizer = optim.SGD(S.parameters(), lr=lr)

# Train the student model S using TRACT
for epoch in range(num_epochs):
  for i, (images, labels) in enumerate(dataloader):
    # Sample a batch of noise x
    x = torch.randn(images.shape)
    # Compute the transitive closure of x using TC
    y = TC(x)
    # Compute the loss L on y
    loss = L(y)
    # Update the student model S using gradient descent
    optimizer.zero_grad()
    loss.backward()
    torch.nn.utils.clip_grad_value_(S.parameters(), clip_value)
    optimizer.step()
    # Print the loss every 200 batches
    if (i + 1) % 200 == 0:
      print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss {loss.item():.4f}')
```