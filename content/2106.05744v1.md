---
title: 2106.05744v1 Pivotal Tuning for Latent-based Editing of Real Images
date: 2021-06-06
---

# [Pivotal Tuning for Latent-based Editing of Real Images](http://arxiv.org/abs/2106.05744v1)

authors: Daniel Roich, Ron Mokady, Amit H. Bermano, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/2106.05744 "Title: Pivotal Tuning for Latent-based Editing of Real Images - arXiv.org"
[2]: https://arxiv.org/abs/2106.05974 "[2106.05974] Scaling Vision with Sparse Mixture of Experts - arXiv.org"
[3]: http://export.arxiv.org/abs/1810.05744v1 "[1810.05744v1] Characterization of Electro-Optical Devices with Low ..."

Here is a summary of the paper:

**What**: The paper presents a technique called **Pivotal Tuning** for latent-based editing of real images using a pre-trained StyleGAN[^1^][1].

**Why**: The paper aims to overcome the tradeoff between distortion and editability in StyleGAN's latent space, which makes it challenging to apply identity-preserving facial editing to out-of-domain images[^1^][1].

**How**: The paper proposes to fine-tune the generator around an initial inverted latent code that serves as a pivot, while keeping nearby identities intact with a regularization term. This way, the generator can alter appearance features that represent mostly identity, without affecting editing capabilities[^1^][1]. The paper validates the technique through inversion and editing metrics, and shows preferable scores to state-of-the-art methods. The paper also demonstrates the technique by applying advanced edits (such as pose, age, or expression) to numerous images of well-known and recognizable identities[^1^][1].

## Main Contributions

The paper claims to make the following contributions:

- It introduces **Pivotal Tuning**, a brief training process that preserves the editing quality of an in-domain latent region, while changing its portrayed identity and appearance.
- It proposes **Pivotal Tuning Inversion (PTI)**, an approach to bridge the gap between out-of-domain and in-domain images by slightly altering the generator.
- It demonstrates the effectiveness of PTI on various inversion and editing tasks, and shows that it outperforms state-of-the-art methods in terms of distortion and editability.
- It showcases the applicability of PTI to advanced facial editing techniques, such as pose, age, or expression manipulation, on numerous images of well-known and recognizable identities.
- It shows the resilience of PTI to harder cases, including heavy make-up, elaborate hairstyles and/or headwear, which otherwise could not have been successfully inverted and edited by state-of-the-art methods.

## Method Summary

The method section of the paper consists of three subsections:

- **Preliminaries**: This subsection reviews the basics of StyleGAN and its latent space, and defines the terms distortion and editability. It also introduces the concept of a pivot, which is an initial inverted latent code that serves as a reference point for fine-tuning the generator.
- **Pivotal Tuning**: This subsection describes the main idea of pivotal tuning, which is to fine-tune the generator around a pivot, while keeping nearby identities intact with a regularization term. It also explains how to choose the pivot and the regularization weight, and how to apply pivotal tuning to multiple layers of the generator.
- **Pivotal Tuning Inversion (PTI)**: This subsection presents the PTI algorithm, which consists of three steps: (1) inverting an out-of-domain image into a latent code using an encoder or an optimization method; (2) applying pivotal tuning to the generator using the inverted latent code as a pivot; and (3) re-inverting the image using the fine-tuned generator. It also discusses some implementation details and extensions of PTI.

## Pseudo Code - High level

Here is a possible high-level pseudo code for this paper:

```python
# Input: an out-of-domain image x, a pre-trained StyleGAN generator G, an encoder E or an optimization method O
# Output: a latent code z that can edit x with high fidelity and diversity

# Step 1: Invert x into a latent code z0 using E or O
z0 = E(x) or O(x, G)

# Step 2: Fine-tune G around z0 using pivotal tuning
for each layer l in G:
  # Choose a pivot zl from z0 or a random vector
  zl = z0[l] or random()
  # Choose a regularization weight lambda_l based on the layer index
  lambda_l = function(l)
  # Update the parameters of layer l by minimizing the pivotal tuning loss
  theta_l = theta_l - alpha * gradient(pivotal_tuning_loss(zl, G, lambda_l), theta_l)

# Step 3: Re-invert x using the fine-tuned G
z = E(x) or O(x, G)

# Return z
return z
```

## Pseudo Code - Detail

Here is a possible detailed pseudo code to implement this paper:

```python
# Input: an out-of-domain image x, a pre-trained StyleGAN generator G, an encoder E or an optimization method O
# Output: a latent code z that can edit x with high fidelity and diversity

# Define some constants
num_layers = 18 # the number of layers in G
num_samples = 100 # the number of samples for the regularization term
epsilon = 1e-4 # a small constant to avoid division by zero

# Step 1: Invert x into a latent code z0 using E or O
if E is given:
  # Use E to encode x into z0
  z0 = E(x)
else:
  # Use O to optimize z0 by minimizing the reconstruction loss
  z0 = random() # initialize z0 randomly
  for t in range(max_iterations):
    # Compute the reconstruction loss as the L2 distance between x and G(z0)
    rec_loss = L2(x, G(z0))
    # Update z0 by gradient descent
    z0 = z0 - alpha * gradient(rec_loss, z0)

# Step 2: Fine-tune G around z0 using pivotal tuning
for l in range(num_layers):
  # Choose a pivot zl from z0 or a random vector
  if l < 8: # for the first 8 layers, use z0 as the pivot
    zl = z0[l]
  else: # for the rest of the layers, use a random vector as the pivot
    zl = random()
  
  # Choose a regularization weight lambda_l based on the layer index
  if l < 8: # for the first 8 layers, use a small weight
    lambda_l = 1e-5
  else: # for the rest of the layers, use a larger weight
    lambda_l = 1e-3
  
  # Update the parameters of layer l by minimizing the pivotal tuning loss
  for t in range(max_iterations):
    # Compute the pivotal tuning loss as the sum of two terms
    # The first term is the L2 distance between G(zl) and G(z0)
    pt_loss_1 = L2(G(zl), G(z0))
    # The second term is the regularization term that penalizes changing nearby identities
    # Sample num_samples latent codes from a normal distribution around zl
    Z = normal(zl, sigma, num_samples)
    # Compute the mean and variance of G(Z) along the batch dimension
    mu_Z = mean(G(Z), axis=0)
    var_Z = var(G(Z), axis=0)
    # Compute the mean and variance of G(zl) along the channel dimension
    mu_zl = mean(G(zl), axis=-1)
    var_zl = var(G(zl), axis=-1)
    # Compute the regularization term as the KL divergence between G(Z) and G(zl)
    pt_loss_2 = KL(mu_Z, var_Z, mu_zl, var_zl)
    # Add epsilon to avoid division by zero
    pt_loss_2 = pt_loss_2 + epsilon
    # Combine the two terms with lambda_l as the weight
    pt_loss = pt_loss_1 + lambda_l * pt_loss_2
    # Update theta_l by gradient descent
    theta_l = theta_l - alpha * gradient(pt_loss, theta_l)

# Step 3: Re-invert x using the fine-tuned G
if E is given:
  # Use E to encode x into z
  z = E(x)
else:
  # Use O to optimize z by minimizing the reconstruction loss
  z = random() # initialize z randomly
  for t in range(max_iterations):
    # Compute the reconstruction loss as the L2 distance between x and G(z)
    rec_loss = L2(x, G(z))
    # Update z by gradient descent
    z = z - alpha * gradient(rec_loss, z)

# Return z
return z

```