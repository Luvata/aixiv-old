---
title: 1811.07441v4 CompoNet  Learning to Generate the Unseen by Part Synthesis and Composition
date: 2018-11-08
---

# [CompoNet: Learning to Generate the Unseen by Part Synthesis and Composition](http://arxiv.org/abs/1811.07441v4)

authors: Nadav Schor, Oren Katzir, Hao Zhang, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/1811.07441 "[1811.07441] CompoNet: Learning to Generate the Unseen by Part ..."
[2]: https://arxiv.org/pdf/1811.07441v4.pdf "arXiv:1811.07441v4 [cs.GR] 1 Sep 2019"
[3]: http://export.arxiv.org/abs/2212.07441v4 "[2212.07441v4] The accretion history of the Milky Way. I. How it shapes ..."

Here is a summary of the paper:

- **What**: The paper presents CompoNet, a generative neural network for 2D or 3D shapes that is based on a part-based prior, where the network synthesizes shapes by varying both the shape parts and their compositions[^1^][1].
- **Why**: The paper aims to address the challenge of enabling a generative model to go beyond the observed samples and learn to generate "unseen", yet still plausible, data from the entire target distribution[^1^][1].
- **How**: The paper introduces a part-based prior that treats a shape as a (re-)composable set of deformable parts, and uses a variational autoencoder (VAE) framework to learn the latent spaces of parts and compositions. The paper also proposes two quantitative metrics to evaluate the diversity of a generative model and its coverage of both the training data and unseen data from the same target distribution[^1^][1].

## Main Contributions

According to the paper, the main contributions are:

- A novel part-based generative model for 2D or 3D shapes that can synthesize shapes by varying both the shape parts and their compositions.
- A part-based prior that leverages a pre-trained part detector and a graph neural network to encode and decode the part structure and deformation of a shape.
- A VAE framework that learns the latent spaces of parts and compositions in an unsupervised manner, and allows for sampling and interpolation of novel shapes.
- Two new metrics to measure the diversity of a generative model and its coverage of both the training data and unseen data from the same target distribution.
- Extensive experiments and comparisons with baseline generative models on various shape datasets, demonstrating the effectiveness and superiority of the proposed method.

## Method Summary

Here is a summary of the method section:

- The method consists of three main components: a part-based prior, a part VAE, and a composition VAE.
- The part-based prior is a probabilistic model that defines the likelihood of a shape given its parts and their compositions. It uses a pre-trained part detector to segment a shape into parts, and a graph neural network to encode and decode the part structure and deformation of a shape.
- The part VAE is a generative model that learns the latent space of parts. It encodes each part into a low-dimensional vector, and decodes it back into a part shape. It also imposes a Gaussian prior on the part latent space to enable sampling and interpolation of novel parts.
- The composition VAE is a generative model that learns the latent space of compositions. It encodes the graph representation of a shape into a low-dimensional vector, and decodes it back into a graph structure. It also imposes a Gaussian prior on the composition latent space to enable sampling and interpolation of novel compositions.
- The method jointly optimizes the part VAE and the composition VAE by maximizing the evidence lower bound (ELBO) of the part-based prior. It also uses an adversarial loss to improve the realism of the generated shapes.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the part-based prior
def part_based_prior(shape):
  # Segment the shape into parts using a pre-trained part detector
  parts = part_detector(shape)
  # Encode the parts and their relations into a graph representation
  graph = graph_encoder(parts)
  # Decode the graph representation into a reconstructed shape
  shape_recon = graph_decoder(graph)
  # Compute the likelihood of the shape given its parts and compositions
  likelihood = compute_likelihood(shape, shape_recon)
  return likelihood

# Define the part VAE
def part_vae(part):
  # Encode the part into a low-dimensional vector
  part_latent = part_encoder(part)
  # Impose a Gaussian prior on the part latent space
  part_prior = Gaussian(part_latent)
  # Decode the part latent vector into a reconstructed part
  part_recon = part_decoder(part_latent)
  # Compute the reconstruction loss and the KL divergence
  recon_loss = compute_recon_loss(part, part_recon)
  kl_loss = compute_kl_loss(part_latent, part_prior)
  return recon_loss + kl_loss

# Define the composition VAE
def composition_vae(graph):
  # Encode the graph into a low-dimensional vector
  graph_latent = graph_encoder(graph)
  # Impose a Gaussian prior on the graph latent space
  graph_prior = Gaussian(graph_latent)
  # Decode the graph latent vector into a reconstructed graph
  graph_recon = graph_decoder(graph_latent)
  # Compute the reconstruction loss and the KL divergence
  recon_loss = compute_recon_loss(graph, graph_recon)
  kl_loss = compute_kl_loss(graph_latent, graph_prior)
  return recon_loss + kl_loss

# Define the adversarial loss
def adversarial_loss(shape):
  # Discriminate between real and generated shapes
  real_score = discriminator(shape)
  fake_score = discriminator(generator(shape))
  # Compute the binary cross entropy loss
  bce_loss = compute_bce_loss(real_score, fake_score)
  return bce_loss

# Jointly optimize the part VAE and the composition VAE
def optimize():
  # Sample a batch of shapes from the dataset
  shapes = sample_batch(dataset)
  # Initialize the losses
  elbo_loss = 0
  adv_loss = 0
  # Loop over each shape in the batch
  for shape in shapes:
    # Compute the ELBO of the part-based prior
    elbo_loss += -part_based_prior(shape)
    # Compute the adversarial loss
    adv_loss += adversarial_loss(shape)
    # Loop over each part in the shape
    for part in shape:
      # Compute the loss of the part VAE
      elbo_loss += part_vae(part)
    # Compute the loss of the composition VAE
    elbo_loss += composition_vae(shape)
  
  # Update the parameters of the models using gradient descent
  update_parameters(elbo_loss, adv_loss)

# Generate novel shapes by sampling and interpolation
def generate():
  # Sample a random vector from a Gaussian distribution
  z = sample_gaussian()
  # Decode it into a graph representation of a shape
  graph = graph_decoder(z)
  # Loop over each node in the graph
  for node in graph:
    # Sample a random vector from a Gaussian distribution
    z = sample_gaussian()
    # Decode it into a part shape and assign it to the node
    node.part = part_decoder(z)
  
  # Reconstruct the shape from its parts and compositions
  shape = graph_decoder(graph)
  
  return shape

```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

# Define the hyperparameters
batch_size = 64 # The number of shapes in a batch
latent_dim = 128 # The dimension of the latent space
hidden_dim = 256 # The dimension of the hidden layer
num_parts = 10 # The number of parts per shape
num_epochs = 100 # The number of training epochs
lr = 0.001 # The learning rate
beta = 0.1 # The weight of the KL term in the ELBO

# Define the part detector model (pre-trained)
class PartDetector(nn.Module):
  def __init__(self):
    super(PartDetector, self).__init__()
    # Define the convolutional layers
    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
    # Define the max pooling layer
    self.pool = nn.MaxPool2d(2, 2)
    # Define the fully connected layer
    self.fc = nn.Linear(128 * 8 * 8, num_parts)

  def forward(self, x):
    # Apply the convolutional layers and the pooling layer
    x = self.pool(F.relu(self.conv1(x)))
    x = self.pool(F.relu(self.conv2(x)))
    x = self.pool(F.relu(self.conv3(x)))
    # Flatten the output
    x = x.view(-1, 128 * 8 * 8)
    # Apply the fully connected layer and softmax activation
    x = F.softmax(self.fc(x), dim=1)
    return x

# Define the part encoder model
class PartEncoder(nn.Module):
  def __init__(self):
    super(PartEncoder, self).__init__()
    # Define the fully connected layers
    self.fc1 = nn.Linear(num_parts, hidden_dim)
    self.fc2 = nn.Linear(hidden_dim, latent_dim)

  def forward(self, x):
    # Apply the fully connected layers and relu activation
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    return x

# Define the part decoder model
class PartDecoder(nn.Module):
  def __init__(self):
    super(PartDecoder, self).__init__()
    # Define the fully connected layers
    self.fc1 = nn.Linear(latent_dim, hidden_dim)
    self.fc2 = nn.Linear(hidden_dim, num_parts)

  def forward(self, x):
    # Apply the fully connected layers and relu activation
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    return x

# Define the graph encoder model
class GraphEncoder(nn.Module):
  def __init__(self):
    super(GraphEncoder, self).__init__()
    # Define the graph convolutional layer
    self.gcn = nn.Linear(latent_dim + num_parts, hidden_dim)
    # Define the fully connected layer
    self.fc = nn.Linear(hidden_dim * num_parts, latent_dim)

  def forward(self, x):
    # Concatenate the part latent vectors and part labels along the feature dimension
    x = torch.cat((x[0], x[1]), dim=1)
    # Apply the graph convolutional layer and relu activation
    x = F.relu(self.gcn(x))
    # Flatten the output along the node dimension
    x = x.view(-1, hidden_dim * num_parts)
    # Apply the fully connected layer and relu activation
    x = F.relu(self.fc(x))
    return x

# Define the graph decoder model
class GraphDecoder(nn.Module):
  def __init__(self):
    super(GraphDecoder, self).__init__()
    # Define the fully connected layer
    self.fc = nn.Linear(latent_dim, hidden_dim * num_parts)
    # Define the graph deconvolutional layer
    self.gdcn = nn.Linear(hidden_dim + num_parts, latent_dim + num_parts)

  def forward(self, x):
    # Apply the fully connected layer and relu activation
    x = F.relu(self.fc(x))
    # Reshape the output along the node dimension
    x = x.view(-1, num_parts, hidden_dim)
    # Concatenate the part latent vectors and part labels along the feature dimension
    x = torch.cat((x, x[1]), dim=1)
    # Apply the graph deconvolutional layer and relu activation
    x = F.relu(self.gdcn(x))
    # Split the output into part latent vectors and part labels along the feature dimension
    x = torch.split(x, latent_dim, dim=1)
    return x

# Define the discriminator model
class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()
    # Define the convolutional layers
    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
    # Define the max pooling layer
    self.pool = nn.MaxPool2d(2, 2)
    # Define the fully connected layer
    self.fc = nn.Linear(128 * 8 * 8, 1)

  def forward(self, x):
    # Apply the convolutional layers and the pooling layer
    x = self.pool(F.relu(self.conv1(x)))
    x = self.pool(F.relu(self.conv2(x)))
    x = self.pool(F.relu(self.conv3(x)))
    # Flatten the output
    x = x.view(-1, 128 * 8 * 8)
    # Apply the fully connected layer and sigmoid activation
    x = torch.sigmoid(self.fc(x))
    return x

# Define the generator model
class Generator(nn.Module):
  def __init__(self):
    super(Generator, self).__init__()
    # Define the part encoder
    self.part_encoder = PartEncoder()
    # Define the part decoder
    self.part_decoder = PartDecoder()
    # Define the graph encoder
    self.graph_encoder = GraphEncoder()
    # Define the graph decoder
    self.graph_decoder = GraphDecoder()

  def forward(self, x):
    # Encode each part into a latent vector
    part_latents = [self.part_encoder(part) for part in x]
    # Encode the graph into a latent vector
    graph_latent = self.graph_encoder([part_latents, x])
    # Decode the graph latent vector into a reconstructed graph
    graph_recon = self.graph_decoder(graph_latent)
    # Decode each part latent vector into a reconstructed part
    part_recons = [self.part_decoder(part) for part in graph_recon[0]]
    
    return part_recons

# Load the dataset of shapes (assume it is a list of tensors of shape [3, 64, 64])
dataset = load_dataset()

# Instantiate the models
part_detector = PartDetector()
part_encoder = PartEncoder()
part_decoder = PartDecoder()
graph_encoder = GraphEncoder()
graph_decoder = GraphDecoder()
discriminator = Discriminator()
generator = Generator()

# Instantiate the optimizers
optimizer_elbo = optim.Adam(list(part_encoder.parameters()) + list(part_decoder.parameters()) + list(graph_encoder.parameters()) + list(graph_decoder.parameters()), lr=lr)
optimizer_adv = optim.Adam(list(discriminator.parameters()) + list(generator.parameters()), lr=lr)

# Define the loss functions
bce_loss = nn.BCELoss()
mse_loss = nn.MSELoss()

# Train the models
for epoch in range(num_epochs):
  # Shuffle the dataset
  np.random.shuffle(dataset)
  # Loop over each batch in the dataset
  for i in range(0, len(dataset), batch_size):
    
     # Sample a batch of shapes from the dataset
     shapes = dataset[i:i+batch_size]
     # Segment each shape into parts using the part detector
     parts = [part_detector(shape) for shape in shapes]
     # Initialize the losses
     elbo_loss = 0
     adv_loss = 0
     
     # Loop over each shape and its parts in the batch
     for shape, shape_parts in zip(shapes, parts):
       # Compute the ELBO of the part-based prior
       elbo_loss += -torch.log(part_based_prior(shape))
       # Compute the adversarial loss
       adv_loss += bce_loss(discriminator(shape), torch.ones(1)) + bce_loss(discriminator(generator(shape)), torch.zeros(1))
       # Loop over each part in the shape
       for part in shape_parts:
         # Compute the loss of the part VAE
         part_latent = part_encoder(part)
         part_recon = part_decoder(part_latent)
         elbo_loss += mse_loss(part_recon, part) + beta * torch.mean(torch.pow(part_latent, 2))
       # Compute the loss of the composition VAE
       graph_latent = graph_encoder([parts, shapes])
       graph_recon = graph_decoder(graph_latent)
       elbo_loss += mse_loss(graph_recon