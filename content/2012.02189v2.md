---
title: 2012.02189v2 Learned Initializations for Optimizing Coordinate-Based Neural Representations
date: 2020-12-03
---

# [Learned Initializations for Optimizing Coordinate-Based Neural Representations](http://arxiv.org/abs/2012.02189v2)

authors: Matthew Tancik, Ben Mildenhall, Terrance Wang, Divi Schmidt, Pratul P. Srinivasan, Jonathan T. Barron, Ren Ng


## What, Why and How

[1]: https://arxiv.org/abs/2012.02189 "Learned Initializations for Optimizing Coordinate-Based Neural ..."
[2]: https://arxiv.org/pdf/2012.02189 "arXiv.org"
[3]: http://export.arxiv.org/abs/1604.02189v2 "[1604.02189v2] Should Entanglement Measures be Monogamous or Faithful?"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a method to learn the initial weight parameters for coordinate-based neural networks that represent complex low dimensional signals, such as images, CT scans, and 3D shapes.
- **Why**: The paper aims to improve the efficiency and generalization of coordinate-based neural representations, which are an alternative to discrete, array-based representations that have limitations in scalability and expressiveness.
- **How**: The paper applies standard meta-learning algorithms, such as MAML and Reptile, to learn the initial weights based on the underlying class of signals being represented. The paper demonstrates that using these learned initial weights enables faster convergence during optimization and better generalization when only partial observations of a given signal are available. The paper evaluates the method on various tasks, such as representing 2D images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D image observations.

## Main Contributions

According to the paper, the main contributions are:

- The first application of meta-learning to learn the initial weights for coordinate-based neural representations.
- A demonstration of the benefits of using learned initial weights for faster convergence and better generalization across different tasks and signal classes.
- A comprehensive evaluation of the method on various datasets and baselines, showing state-of-the-art results on some tasks.

## Method Summary

[1]: https://arxiv.org/abs/2012.02189v2 "Learned Initializations for Optimizing Coordinate-Based Neural ..."
[2]: https://arxiv.org/pdf/2012.02189 "arXiv.org"
[3]: https://arxiv-export1.library.cornell.edu/abs/2209.02189v2 "[2209.02189v2] Object-Oriented Requirements: a Unified Framework for ..."

Here is a summary of the method section of the paper[^1^][1]:

- The paper uses a **coordinate-based neural representation** (CBR) to model a signal as a function that maps input coordinates (such as pixel locations or 3D points) to output values (such as RGB colors or voxel occupancy).
- The paper uses a **fully-connected network** (FCN) with sinusoidal activation functions to implement the CBR function, following the work of Sitzmann et al. [^2^][2].
- The paper applies **meta-learning algorithms** to learn the initial weight parameters of the FCN based on a large dataset of signals from the same class (such as images of faces or 3D models of chairs).
- The paper uses two meta-learning algorithms: **Model-Agnostic Meta-Learning (MAML)** [^3^][3] and **Reptile** , which are gradient-based methods that aim to find a good initialization point for fast adaptation to new tasks.
- The paper trains the meta-learning algorithms on a set of training signals, where each signal is treated as a separate task. For each task, the algorithm performs a few gradient steps on a subset of coordinates sampled from the signal, and then evaluates the loss on another subset of coordinates. The algorithm updates the initial weights by minimizing the meta-loss, which is the average loss across all tasks.
- The paper tests the method on a set of test signals, where each signal is optimized from the learned initial weights using gradient descent. The paper compares the performance of the method with random initialization and other baselines on various metrics, such as convergence speed, reconstruction quality, and generalization ability.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the CBR function as a FCN with sinusoidal activations
def CBR(x, w):
  # x: input coordinates
  # w: network weights
  # return: output values
  h = x # hidden layer
  for i in range(L): # L: number of layers
    h = sin(W[i] @ h + b[i]) # W[i], b[i]: weight matrix and bias vector for layer i
  y = W[L] @ h + b[L] # final layer
  return y

# Define the meta-learning algorithm (MAML or Reptile)
def meta_learn(D_train, alpha, beta):
  # D_train: training dataset of signals
  # alpha: inner learning rate
  # beta: outer learning rate
  # return: learned initial weights
  w_0 = random_init() # initialize weights randomly
  for epoch in range(E): # E: number of epochs
    w = w_0 # reset weights to initial point
    for S in D_train: # S: signal from training dataset
      x_S = sample(S) # sample a subset of coordinates from S
      y_S = S(x_S) # get the corresponding output values from S
      L_S = loss(CBR(x_S, w), y_S) # compute the loss on S
      w = w - alpha * grad(L_S, w) # update the weights by one gradient step
    L_meta = mean(L_S) # compute the meta-loss as the mean loss across signals
    w_0 = w_0 - beta * grad(L_meta, w_0) # update the initial weights by one gradient step
  return w_0

# Define the optimization procedure for a test signal
def optimize(S_test, w_0, alpha):
  # S_test: test signal to be optimized
  # w_0: learned initial weights
  # alpha: learning rate
  # return: optimized weights and reconstructed signal
  w = w_0 # initialize weights from learned initial point
  for iter in range(I): # I: number of iterations
    x_test = sample(S_test) # sample a subset of coordinates from test signal
    y_test = S_test(x_test) # get the corresponding output values from test signal
    L_test = loss(CBR(x_test, w), y_test) # compute the loss on test signal
    w = w - alpha * grad(L_test, w) # update the weights by one gradient step
  x_full = full(S_test) # get the full set of coordinates from test signal
  y_full = CBR(x_full, w) # get the reconstructed output values from CBR function
  return w, y_full

# Train the meta-learning algorithm on a training dataset of signals
w_0 = meta_learn(D_train, alpha, beta)

# Test the method on a test dataset of signals
for S_test in D_test: # S_test: signal from test dataset
  w, y_full = optimize(S_test, w_0, alpha) # optimize and reconstruct the test signal
  evaluate(w, y_full, S_test) # evaluate the performance on various metrics

```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torchmeta.modules import MetaModule, MetaLinear
from torchmeta.utils.gradient_based import gradient_update_parameters

# Define the CBR function as a FCN with sinusoidal activations
class CBR(MetaModule):
  # MetaModule: a wrapper class that enables meta-learning
  def __init__(self, in_dim, out_dim, hidden_dim, num_layers):
    # in_dim: dimension of input coordinates
    # out_dim: dimension of output values
    # hidden_dim: dimension of hidden layers
    # num_layers: number of hidden layers
    super(CBR, self).__init__() # initialize the parent class
    self.in_dim = in_dim
    self.out_dim = out_dim
    self.hidden_dim = hidden_dim
    self.num_layers = num_layers
    self.layers = nn.ModuleList() # a list of layers
    self.layers.append(MetaLinear(in_dim, hidden_dim)) # first layer
    for i in range(num_layers): # hidden layers
      self.layers.append(MetaLinear(hidden_dim, hidden_dim))
    self.layers.append(MetaLinear(hidden_dim, out_dim)) # final layer

  def forward(self, x, params=None):
    # x: input coordinates (batch_size x in_dim)
    # params: network weights (optional)
    # return: output values (batch_size x out_dim)
    h = x # hidden layer
    for i in range(self.num_layers + 1): # loop over layers
      h = torch.sin(self.layers[i](h, params=self.get_subdict(params, i))) # apply sinusoidal activation and linear transformation
    y = self.layers[-1](h, params=self.get_subdict(params, -1)) # final layer without activation
    return y

# Define the meta-learning algorithm (MAML or Reptile)
class MetaLearner(nn.Module):
  def __init__(self, cbr, inner_lr, outer_lr, first_order):
    # cbr: CBR function (an instance of CBR class)
    # inner_lr: inner learning rate (alpha)
    # outer_lr: outer learning rate (beta)
    # first_order: whether to use first-order approximation for MAML
    super(MetaLearner, self).__init__() # initialize the parent class
    self.cbr = cbr # CBR function
    self.inner_lr = inner_lr # inner learning rate
    self.outer_lr = outer_lr # outer learning rate
    self.first_order = first_order # first-order approximation flag
    self.optimizer = optim.Adam(self.cbr.parameters(), lr=outer_lr) # optimizer for outer loop

  def train(self, D_train, num_epochs):
    # D_train: training dataset of signals (a list of tuples of (x_S, y_S), where x_S and y_S are numpy arrays of coordinates and values)
    # num_epochs: number of epochs (E)
    for epoch in range(num_epochs): # loop over epochs
      epoch_loss = 0.0 # initialize epoch loss
      for x_S, y_S in D_train: # loop over signals in training dataset
        x_S = torch.from_numpy(x_S).float() # convert x_S to torch tensor
        y_S = torch.from_numpy(y_S).float() # convert y_S to torch tensor

        task_loss = nn.MSELoss() # define task loss as mean squared error

        train_indices = np.random.choice(len(x_S), size=len(x_S)//2, replace=False) # randomly select half of the indices for training
        test_indices = np.setdiff1d(np.arange(len(x_S)), train_indices) # select the remaining indices for testing

        x_train = x_S[train_indices] # get the training coordinates
        y_train = y_S[train_indices] # get the training values

        x_test = x_S[test_indices] # get the testing coordinates
        y_test = y_S[test_indices] # get the testing values

        params = None # initialize parameters as None

        if isinstance(self.cbr, MAML): 
          # if using MAML algorithm

          train_output = self.cbr(x_train)  # forward pass on training data with original parameters 
          train_loss = task_loss(train_output, y_train)  # compute training loss 
          params = gradient_update_parameters(self.cbr,
                                              train_loss,
                                              params=params,
                                              step_size=self.inner_lr,
                                              first_order=self.first_order)  # update parameters by one gradient step with inner learning rate

          test_output = self.cbr(x_test, params=params)  # forward pass on testing data with updated parameters
          test_loss = task_loss(test_output, y_test)  # compute testing loss

          self.optimizer.zero_grad()  # reset the gradients
          test_loss.backward()  # backpropagate the testing loss
          self.optimizer.step()  # update the original parameters by one gradient step with outer learning rate

        elif isinstance(self.cbr, Reptile):
          # if using Reptile algorithm

          old_params = self.cbr.clone_parameters()  # clone the original parameters

          train_output = self.cbr(x_train)  # forward pass on training data with original parameters
          train_loss = task_loss(train_output, y_train)  # compute training loss
          params = gradient_update_parameters(self.cbr,
                                              train_loss,
                                              params=params,
                                              step_size=self.inner_lr)  # update parameters by one gradient step with inner learning rate

          for name, param in self.cbr.named_parameters():  # loop over the original parameters
            old_param = old_params[name]  # get the corresponding cloned parameter
            new_param = param - old_param  # compute the difference between the updated and original parameter
            param.data.copy_(old_param + self.outer_lr * new_param)  # update the original parameter by a fraction of the difference with outer learning rate

        epoch_loss += test_loss.item()  # accumulate the testing loss to epoch loss

      epoch_loss /= len(D_train)  # compute the average epoch loss
      print(f"Epoch {epoch+1}, Loss: {epoch_loss:.4f}")  # print the epoch loss

    return self.cbr.parameters()  # return the learned initial weights

# Define the optimization procedure for a test signal
def optimize(S_test, cbr, params, lr, num_iters):
  # S_test: test signal to be optimized (a tuple of (x_test, y_test), where x_test and y_test are numpy arrays of coordinates and values)
  # cbr: CBR function (an instance of CBR class)
  # params: learned initial weights
  # lr: learning rate (alpha)
  # num_iters: number of iterations (I)
  # return: optimized weights and reconstructed signal
  x_test, y_test = S_test # unpack the test signal
  x_test = torch.from_numpy(x_test).float() # convert x_test to torch tensor
  y_test = torch.from_numpy(y_test).float() # convert y_test to torch tensor

  optimizer = optim.Adam(params, lr=lr) # optimizer for inner loop
  task_loss = nn.MSELoss() # task loss as mean squared error

  for iter in range(num_iters): # loop over iterations
    optimizer.zero_grad() # reset the gradients
    output = cbr(x_test, params=params) # forward pass on test data with current parameters
    loss = task_loss(output, y_test) # compute the loss on test data
    loss.backward() # backpropagate the loss
    optimizer.step() # update the parameters by one gradient step with learning rate
    print(f"Iteration {iter+1}, Loss: {loss.item():.4f}") # print the iteration loss

  x_full = torch.from_numpy(full(S_test)).float() # get the full set of coordinates from test signal as torch tensor
  y_full = cbr(x_full, params=params) # get the reconstructed output values from CBR function
  return params, y_full.detach().numpy() # return the optimized weights and reconstructed signal as numpy array

# Load the training dataset of signals (D_train)
D_train = load_data("train_data.pkl") 

# Load the test dataset of signals (D_test)
D_test = load_data("test_data.pkl")

# Initialize the CBR function with given dimensions and layers
cbr = CBR(in_dim=2, out_dim=3, hidden_dim=256, num_layers=4)

# Initialize the meta-learning algorithm with given learning rates and first-order flag
meta_learner = MetaLearner(cbr, inner_lr=0.01, outer_lr=0.001, first_order=False)

# Train the meta-learning algorithm on the training dataset of signals
w_0 = meta_learner.train(D_train, num_epochs=10)

# Test the method on the test dataset of signals
for S_test in D_test: 
  w, y_full = optimize(S_test, cbr, w_0, lr=0.01, num_iters=1000) 
  evaluate(w, y_full, S_test)

```