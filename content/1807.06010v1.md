---
title: 1807.06010v1 EC-Net  an Edge-aware Point set Consolidation Network
date: 2018-07-07
---

# [EC-Net: an Edge-aware Point set Consolidation Network](http://arxiv.org/abs/1807.06010v1)

authors: Lequan Yu, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, Pheng-Ann Heng


## What, Why and How

[1]: https://arxiv.org/abs/1807.06010 "EC-Net: an Edge-aware Point set Consolidation Network"
[2]: https://arxiv.org/pdf/1807.06010v1.pdf "arXiv.org"
[3]: http://export.arxiv.org/abs/1705.06010v1 "[1705.06010v1] Conformational Heterogeneity and FRET Data ..."

Here is a summary of the paper:

- **What**: The paper presents a deep learning based method for consolidating point clouds obtained from 3D scans, especially for preserving sharp edges.
- **Why**: Point clouds are sparse, irregular, and noisy, and need to be consolidated for better 3D reconstruction and surface analysis. Existing methods are not edge-aware and may blur or miss important features.
- **How**: The paper proposes an Edge-aware Point set Consolidation Network (EC-Net) that processes points in local patches and learns to recover their coordinates and distances to edges. The network is trained with a joint loss function that minimizes distances to 3D meshes and edges. The paper demonstrates the effectiveness of the method on synthetic and real point clouds and compares it with state-of-the-art methods.

The summary is based on the abstract and introduction of the paper[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/1807.06010 "EC-Net: an Edge-aware Point set Consolidation Network"
[2]: https://arxiv.org/pdf/1807.06010v1.pdf "arXiv.org"
[3]: http://export.arxiv.org/abs/1705.06010v1 "[1705.06010v1] Conformational Heterogeneity and FRET Data ..."

According to the paper, the main contributions are:

- **The first deep learning based edge-aware point set consolidation method** that can preserve sharp features and improve 3D reconstruction quality.
- **A novel regression component** that can simultaneously predict 3D point coordinates and point-to-edge distances from upsampled features.
- **An edge-aware joint loss function** that can directly minimize distances from output points to 3D meshes and to edges.
- **A virtual scanned point cloud dataset** that can be used for training and testing point set consolidation methods.
- **Extensive experiments** on both synthetic and real point clouds that demonstrate the effectiveness and superiority of the proposed method over state-of-the-art methods.

The contributions are based on section 1.2 of the paper[^1^][1].

## Method Summary

[1]: https://arxiv.org/abs/1807.06010 "EC-Net: an Edge-aware Point set Consolidation Network"
[2]: https://arxiv.org/pdf/1807.06010v1.pdf "arXiv.org"
[3]: http://export.arxiv.org/abs/1705.06010v1 "[1705.06010v1] Conformational Heterogeneity and FRET Data ..."

Here is a summary of the method section of the paper:

- The paper proposes a **network architecture** that consists of three modules: a feature extraction module, a feature upsampling module, and a regression module.
- The **feature extraction module** takes a point set patch as input and applies PointNet++ [^1^][2] to extract local and global features for each point. The output is a set of feature vectors with the same size as the input patch.
- The **feature upsampling module** upsamples the feature vectors by a factor of k using nearest neighbor interpolation. The output is a set of upsampled feature vectors with k times more points than the input patch.
- The **regression module** takes the upsampled feature vectors as input and predicts two outputs for each point: a 3D point coordinate and a point-to-edge distance. The point coordinate is obtained by adding a residual vector to the input feature vector. The point-to-edge distance is obtained by applying a fully connected layer followed by a sigmoid function. The output is a set of consolidated points with coordinates and edge distances.
- The paper defines an **edge-aware joint loss function** that combines two terms: a mesh loss and an edge loss. The mesh loss measures the distance between the output points and the ground truth mesh surface. The edge loss measures the difference between the output edge distances and the ground truth edge distances. The paper uses Chamfer distance [^2^][3] to compute both losses and weights them by a parameter lambda.
- The paper trains the network on a **virtual scanned point cloud dataset** that contains 10,000 synthetic shapes from ShapeNet  with different levels of noise and sparsity. The paper uses Poisson surface reconstruction  to generate ground truth meshes and edges for each shape.

The summary is based on section 3 of the paper[^3^][1].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a point set patch P with n points
# Output: a consolidated point set Q with k*n points

# Define network parameters
k = upsampling factor
lambda = edge loss weight

# Define network modules
FeatureExtraction = PointNet++(P) # extract features for each point
FeatureUpsampling = NearestNeighborInterpolation(k) # upsample features by k times
Regression = ResidualVector + FullyConnected + Sigmoid # predict point coordinates and edge distances

# Define loss function
MeshLoss = ChamferDistance(Q, M) # measure distance to ground truth mesh M
EdgeLoss = ChamferDistance(D, E) # measure difference to ground truth edge distances E
Loss = MeshLoss + lambda * EdgeLoss # combine mesh loss and edge loss

# Train the network on virtual scanned point cloud dataset
for each shape in dataset:
  P = sample a point set patch from shape
  M, E = generate ground truth mesh and edge distances for shape
  Q, D = Regression(FeatureUpsampling(FeatureExtraction(P))) # forward pass
  Loss = MeshLoss + lambda * EdgeLoss # compute loss
  Loss.backward() # backward pass
  update network parameters # gradient descent

# Test the network on synthetic and real point clouds
for each shape in test set:
  P = sample a point set patch from shape
  Q, D = Regression(FeatureUpsampling(FeatureExtraction(P))) # forward pass
  visualize Q and D # show consolidated points and edge distances
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import libraries
import torch # for tensor operations
import numpy as np # for numerical operations
import trimesh # for mesh processing
import pointnet2_ops # for PointNet++ operations

# Define network parameters
k = 4 # upsampling factor
lambda = 0.1 # edge loss weight
n = 256 # number of input points per patch
m = k * n # number of output points per patch
d = 3 # dimension of point coordinates
f = 128 # dimension of point features
h = 64 # dimension of hidden layer

# Define network modules
FeatureExtraction = pointnet2_ops.pointnet2_modules.PointnetSAModuleMSG( # PointNet++ module with multi-scale grouping
    npoint=n, # number of output points
    radii=[0.05, 0.1], # radii of ball query
    nsamples=[16, 32], # number of samples in each ball query
    mlps=[[d, f], [d, f]], # multi-layer perceptrons for each scale
    use_xyz=True # use point coordinates as input features
)

FeatureUpsampling = torch.nn.functional.interpolate # nearest neighbor interpolation

Regression = torch.nn.Sequential( # regression module
    torch.nn.Linear(f, d + h), # fully connected layer to predict residual vector and hidden vector
    torch.nn.ReLU(), # activation function
    torch.nn.Linear(h, 1), # fully connected layer to predict edge distance
    torch.nn.Sigmoid() # sigmoid function to map edge distance to [0, 1]
)

# Define loss function
def MeshLoss(Q, M):
  # Q: output point set (m x d)
  # M: ground truth mesh (trimesh object)
  dist1, _, dist2, _ = trimesh.proximity.closest_point(M, Q) # compute distances from Q to M and vice versa
  return torch.mean(dist1) + torch.mean(dist2) # return Chamfer distance

def EdgeLoss(D, E):
  # D: output edge distances (m x 1)
  # E: ground truth edge distances (m x 1)
  return torch.mean(torch.abs(D - E)) # return Chamfer distance

def Loss(Q, D, M, E):
  # Q: output point set (m x d)
  # D: output edge distances (m x 1)
  # M: ground truth mesh (trimesh object)
  # E: ground truth edge distances (m x 1)
  return MeshLoss(Q, M) + lambda * EdgeLoss(D, E) # return edge-aware joint loss

# Load virtual scanned point cloud dataset
dataset = load_dataset() # load dataset of synthetic shapes with noise and sparsity

# Train the network on virtual scanned point cloud dataset
optimizer = torch.optim.Adam(FeatureExtraction.parameters() + Regression.parameters()) # define optimizer
for epoch in range(num_epochs): # loop over epochs
  for shape in dataset: # loop over shapes in dataset
    P = sample_patch(shape) # sample a point set patch from shape (n x d)
    M, E = generate_mesh_and_edges(shape) # generate ground truth mesh and edge distances for shape (trimesh object and m x 1)
    F = FeatureExtraction(P) # extract features for each point (n x f)
    F = FeatureUpsampling(F, scale_factor=k) # upsample features by k times (m x f)
    R = Regression(F) # predict residual vector and edge distance for each point (m x (d + 1))
    Q = P + R[:, :d] # add residual vector to input point coordinates to get output point coordinates (m x d)
    D = R[:, d:] # get output edge distance (m x 1)
    loss = Loss(Q, D, M, E) # compute loss
    optimizer.zero_grad() # clear gradients
    loss.backward() # compute gradients
    optimizer.step() # update parameters

# Test the network on synthetic and real point clouds
test_set = load_test_set() # load test set of synthetic and real point clouds
for shape in test_set: # loop over shapes in test set
  P = sample_patch(shape) # sample a point set patch from shape (n x d)
  F = FeatureExtraction(P) # extract features for each point (n x f)
  F = FeatureUpsampling(F, scale_factor=k) # upsample features by k times (m x f)
  R = Regression(F) # predict residual vector and edge distance for each point (m x (d + 1))
  Q = P + R[:, :d] # add residual vector to input point coordinates to get output point coordinates (m x d)
  D = R[:, d:] # get output edge distance (m x 1)
  visualize(Q, D) # show consolidated points and edge distances
```