---
title: 2306.04744v1 WOUAF  Weight Modulation for User Attribution and Fingerprinting in Text-to-Image Diffusion Models
date: 2023-06-05
---

# [WOUAF: Weight Modulation for User Attribution and Fingerprinting in Text-to-Image Diffusion Models](http://arxiv.org/abs/2306.04744v1)

authors: Changhoon Kim, Kyle Min, Maitreya Patel, Sheng Cheng, Yezhou Yang


## What, Why and How

[1]: https://arxiv.org/abs/2306.04744 "[2306.04744] WOUAF: Weight Modulation for User Attribution and ..."
[2]: https://arxiv.org/pdf/2306.04741 "arXiv:2306.04741v1 [hep-th] 7 Jun 2023"
[3]: http://export.arxiv.org/abs/2306.04744 "[2306.04744] WOUAF: Weight Modulation for User Attribution and ..."

Here is a summary of the paper at [^1^][1]:

- What: The paper introduces a novel approach to model fingerprinting that assigns responsibility for the generated images, thereby serving as a potential countermeasure to model misuse. The method modifies generative models based on each user's unique digital fingerprint, imprinting a unique identifier onto the resultant content that can be traced back to the user.
- Why: The paper aims to address the critical societal concerns such as misinformation that arise from the rapid advancement of generative models, facilitating the creation of hyper-realistic images from textual descriptions. Traditional fake detection mechanisms, although providing some mitigation, fall short in attributing responsibility for the malicious use of synthetic images.
- How: The paper incorporates fine-tuning into Text-to-Image (T2I) tasks using the Stable Diffusion Model, a state-of-the-art generative model that produces high-quality images from textual descriptions. The paper demonstrates near-perfect attribution accuracy with a minimal impact on output quality. The paper also evaluates the secrecy and robustness of the method under various scenarios and manipulations.



## Main Contributions

[1]: https://arxiv.org/abs/2306.04744 "[2306.04744] WOUAF: Weight Modulation for User Attribution and ..."
[2]: https://arxiv.org/pdf/2306.04741 "arXiv:2306.04741v1 [hep-th] 7 Jun 2023"
[3]: http://export.arxiv.org/abs/2306.04744 "[2306.04744] WOUAF: Weight Modulation for User Attribution and ..."

According to the paper at [^1^][1], the main contributions are:

- The paper proposes a novel approach to model fingerprinting that assigns responsibility for the generated images, thereby serving as a potential countermeasure to model misuse.
- The paper modifies generative models based on each user's unique digital fingerprint, imprinting a unique identifier onto the resultant content that can be traced back to the user.
- The paper incorporates fine-tuning into Text-to-Image (T2I) tasks using the Stable Diffusion Model, a state-of-the-art generative model that produces high-quality images from textual descriptions.
- The paper demonstrates near-perfect attribution accuracy with a minimal impact on output quality.
- The paper rigorously scrutinizes the method's secrecy under two distinct scenarios: one where a malicious user attempts to detect the fingerprint, and another where a user possesses a comprehensive understanding of the method.
- The paper also evaluates the robustness of the method against various image post-processing manipulations typically executed by end-users.


## Method Summary

[1]: https://arxiv.org/abs/2306.04744 "[2306.04744] WOUAF: Weight Modulation for User Attribution and ..."
[2]: https://arxiv.org/pdf/2306.04741 "arXiv:2306.04741v1 [hep-th] 7 Jun 2023"
[3]: http://export.arxiv.org/abs/2306.04744 "[2306.04744] WOUAF: Weight Modulation for User Attribution and ..."

Here is a summary of the method section of the paper at [^1^][1]:

- The paper describes the proposed method of model fingerprinting in three steps: fingerprint generation, fingerprint embedding, and fingerprint extraction.
- Fingerprint generation: The paper generates a unique digital fingerprint for each user based on their user ID and a secret key. The fingerprint is a binary vector of length 64 that is randomly generated using a hash function.
- Fingerprint embedding: The paper embeds the fingerprint into the generative model by modulating the weights of the model using a fine-tuning process. The paper uses the Stable Diffusion Model (SDM) as the base generative model that produces high-quality images from textual descriptions. The paper modifies the SDM by adding a fingerprint layer that applies a linear transformation to the weights of the SDM based on the fingerprint vector. The paper fine-tunes the modified SDM on a small dataset of images and captions to imprint the fingerprint onto the generated images.
- Fingerprint extraction: The paper extracts the fingerprint from a given image by applying a reverse engineering process that recovers the weights of the modified SDM from the image. The paper uses an optimization algorithm that minimizes the difference between the original image and the reconstructed image produced by the modified SDM. The paper then applies an inverse linear transformation to the recovered weights to obtain the fingerprint vector. The paper compares the extracted fingerprint with a database of fingerprints to identify the user who generated the image.

## Pseudo Code - High level

Here is the high-level pseudo code for the paper at :

```python
# Define the hash function that generates a fingerprint from a user ID and a secret key
def hash_function(user_id, secret_key):
  # Concatenate the user ID and the secret key
  input = user_id + secret_key
  # Apply a cryptographic hash function such as SHA-256
  output = SHA-256(input)
  # Convert the output to a binary vector of length 64
  fingerprint = bin(output)[:64]
  # Return the fingerprint
  return fingerprint

# Define the fingerprint layer that modulates the weights of the SDM based on the fingerprint
class FingerprintLayer(nn.Module):
  # Initialize the layer with the fingerprint vector and the SDM weights
  def __init__(self, fingerprint, sdm_weights):
    # Store the fingerprint vector as an attribute
    self.fingerprint = fingerprint
    # Store the SDM weights as an attribute
    self.sdm_weights = sdm_weights
    # Define a linear transformation that maps the fingerprint vector to a weight modulation vector
    self.linear = nn.Linear(64, len(sdm_weights))

  # Define the forward pass of the layer
  def forward(self):
    # Apply the linear transformation to the fingerprint vector
    modulation = self.linear(self.fingerprint)
    # Multiply the SDM weights by the modulation vector element-wise
    modified_weights = self.sdm_weights * modulation
    # Return the modified weights
    return modified_weights

# Define the fine-tuning process that imprints the fingerprint onto the generated images
def fine_tune(fingerprint_layer, sdm_model, dataset):
  # Define a loss function such as cross-entropy
  loss_function = nn.CrossEntropyLoss()
  # Define an optimizer such as Adam
  optimizer = optim.Adam(fingerprint_layer.parameters())
  # Loop over a small number of epochs
  for epoch in range(num_epochs):
    # Loop over the dataset of images and captions
    for image, caption in dataset:
      # Forward pass: generate an image from the caption using the modified SDM model with the fingerprint layer
      generated_image = sdm_model(caption, fingerprint_layer)
      # Compute the loss between the generated image and the original image
      loss = loss_function(generated_image, image)
      # Backward pass: compute the gradients of the loss with respect to the fingerprint layer parameters
      loss.backward()
      # Update the fingerprint layer parameters using the optimizer
      optimizer.step()
      # Zero out the gradients for the next iteration
      optimizer.zero_grad()

# Define the reverse engineering process that recovers the weights of the modified SDM from an image
def reverse_engineer(image, sdm_model):
  # Initialize a random vector of weights for the modified SDM model
  modified_weights = torch.randn(len(sdm_model.weights))
  # Define an optimization algorithm such as gradient descent
  optimizer = optim.GradientDescent(modified_weights)
  # Loop until convergence or a maximum number of iterations
  while not converged or iteration < max_iterations:
    # Forward pass: generate an image from a random caption using the modified SDM model with the modified weights
    generated_image = sdm_model(random_caption, modified_weights)
    # Compute the difference between the generated image and the original image
    difference = image - generated_image
    # Backward pass: compute the gradients of the difference with respect to the modified weights
    difference.backward()
    # Update the modified weights using the optimizer
    optimizer.step()
    # Zero out the gradients for the next iteration
    optimizer.zero_grad()
    # Increment iteration counter
    iteration += 1

# Define an inverse linear transformation that recovers a fingerprint from a weight modulation vector 
def inverse_linear(modulation, sdm_weights):
  # Divide each element of modulation by its corresponding element in sdm_weights to obtain a ratio vector 
  ratio = modulation / sdm_weights 
  # Apply an inverse linear transformation to ratio to obtain a fingerprint vector 
  fingerprint = inverse_linear(ratio) 
  # Return fingerprint 
  return fingerprint 

# Define a database of fingerprints and user IDs 
database = {fingerprint_1: user_id_1, fingerprint_2: user_id_2, ...}

# Define a function that extracts a fingerprint from an image and identifies its user 
def extract_and_identify(image, sdm_model): 
  # Reverse engineer to recover modified weights from image 
  modified_weights = reverse_engineer(image, sdm_model) 
  # Inverse linear transform to recover fingerprint from modified weights 
  fingerprint = inverse_linear(modified_weights, sdm_model.weights) 
  # Compare fingerprint with database to find matching user ID 
  user_id = database[fingerprint] 
  # Return user ID 
  return user_id
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper at :

```python
# Import the necessary libraries
import torch # for tensor operations
import torch.nn as nn # for neural network modules
import torch.optim as optim # for optimization algorithms
import torchvision # for image processing
import hashlib # for hash function
import random # for random caption generation

# Define the hash function that generates a fingerprint from a user ID and a secret key
def hash_function(user_id, secret_key):
  # Concatenate the user ID and the secret key as bytes
  input = (user_id + secret_key).encode()
  # Apply a cryptographic hash function such as SHA-256
  output = hashlib.sha256(input).hexdigest()
  # Convert the output to a binary vector of length 64
  fingerprint = torch.tensor([int(bit) for bit in bin(int(output, 16))[2:66]])
  # Return the fingerprint
  return fingerprint

# Define the SDM model that produces high-quality images from textual descriptions
# For simplicity, we assume the SDM model is already trained and has a fixed set of weights
sdm_model = torchvision.models.SDM(pretrained=True)
sdm_model.eval() # set the model to evaluation mode

# Define the fingerprint layer that modulates the weights of the SDM based on the fingerprint
class FingerprintLayer(nn.Module):
  # Initialize the layer with the fingerprint vector and the SDM weights
  def __init__(self, fingerprint, sdm_weights):
    # Call the parent class constructor
    super(FingerprintLayer, self).__init__()
    # Store the fingerprint vector as an attribute
    self.fingerprint = fingerprint
    # Store the SDM weights as an attribute
    self.sdm_weights = sdm_weights
    # Define a linear transformation that maps the fingerprint vector to a weight modulation vector of the same size as the SDM weights
    self.linear = nn.Linear(64, len(sdm_weights))

  # Define the forward pass of the layer
  def forward(self):
    # Apply the linear transformation to the fingerprint vector
    modulation = self.linear(self.fingerprint)
    # Multiply the SDM weights by the modulation vector element-wise
    modified_weights = self.sdm_weights * modulation
    # Return the modified weights
    return modified_weights

# Define a function that generates a random caption from a vocabulary of words
def generate_random_caption(vocabulary):
  # Choose a random length between 1 and 10 words
  length = random.randint(1, 10)
  # Choose a random word from the vocabulary for each position in the caption
  caption = " ".join(random.choice(vocabulary) for _ in range(length))
  # Return the caption
  return caption

# Define a function that computes the difference between two images as a scalar value
def compute_difference(image_1, image_2):
  # Convert both images to tensors of shape (3, height, width)
  tensor_1 = torchvision.transforms.ToTensor()(image_1)
  tensor_2 = torchvision.transforms.ToTensor()(image_2)
  # Compute the mean squared error between the two tensors element-wise
  mse = nn.MSELoss()(tensor_1, tensor_2)
  # Return the mse value as a scalar
  return mse.item()

# Define a function that performs gradient descent on a vector of weights to minimize a loss function 
def gradient_descent(weights, loss_function, learning_rate): 
  # Initialize a variable to store the previous loss value 
  prev_loss = float("inf") 
  # Initialize a variable to store the current loss value 
  curr_loss = float("inf") 
  # Initialize a variable to store the convergence threshold 
  epsilon = 1e-6 
  # Loop until convergence or a maximum number of iterations 
  iteration = 0 
  max_iterations = 1000 
  while abs(curr_loss - prev_loss) > epsilon and iteration < max_iterations: 
    # Forward pass: compute the loss value using the loss function and the weights 
    curr_loss = loss_function(weights) 
    # Backward pass: compute the gradients of the loss with respect to the weights using autograd 
    curr_loss.backward() 
    # Update the weights using gradient descent: subtract the learning rate times the gradient from each weight element-wise 
    with torch.no_grad(): 
      weights -= learning_rate * weights.grad 
    # Zero out the gradients for the next iteration 
    weights.grad.zero_() 
    # Update the previous loss value 
    prev_loss = curr_loss 
    # Increment iteration counter 
    iteration += 1 
  # Return the optimized weights 
  return weights 

# Define an inverse linear transformation that recovers a fingerprint from a weight modulation vector 
def inverse_linear(modulation, sdm_weights): 
  # Divide each element of modulation by its corresponding element in sdm_weights to obtain a ratio vector 
  ratio = modulation / sdm_weights 
  # Apply an inverse linear transformation to ratio to obtain a fingerprint vector 
  # This can be done by solving a system of linear equations of the form Ax = b, where A is the weight matrix of the linear layer, x is the fingerprint vector, and b is the ratio vector 
  # We can use torch.solve to solve this system 
  A = fingerprint_layer.linear.weight # get the weight matrix of the linear layer 
  b = ratio # get the ratio vector 
  x, _ = torch.solve(b, A) # solve for x and ignore the second output which is the LU decomposition of A 
  fingerprint = x # get the fingerprint vector 
  # Return fingerprint 
  return fingerprint 

# Define a database of fingerprints and user IDs 
database = {fingerprint_1: user_id_1, fingerprint_2: user_id_2, ...}

# Define a function that extracts a fingerprint from an image and identifies its user 
def extract_and_identify(image, sdm_model): 
  # Reverse engineer to recover modified weights from image 
  # Define a loss function that measures the difference between the original image and the reconstructed image produced by the modified SDM model
  def loss_function(modified_weights):
    # Generate a random caption
    random_caption = generate_random_caption(vocabulary)
    # Generate an image from the random caption using the modified SDM model with the modified weights
    generated_image = sdm_model(random_caption, modified_weights)
    # Compute the difference between the generated image and the original image
    difference = compute_difference(generated_image, image)
    # Return the difference
    return difference

  # Initialize a random vector of weights for the modified SDM model
  modified_weights = torch.randn(len(sdm_model.weights), requires_grad=True)
  # Define a learning rate for gradient descent
  learning_rate = 0.01
  # Perform gradient descent on the modified weights to minimize the loss function
  modified_weights = gradient_descent(modified_weights, loss_function, learning_rate)
  
  # Inverse linear transform to recover fingerprint from modified weights 
  fingerprint = inverse_linear(modified_weights, sdm_model.weights) 
  # Compare fingerprint with database to find matching user ID 
  user_id = database[fingerprint] 
  # Return user ID 
  return user_id
```