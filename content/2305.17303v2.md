---
title: 2305.17303v2 Distilling BlackBox to Interpretable models for Efficient Transfer Learning
date: 2023-05-18
---

# [Distilling BlackBox to Interpretable models for Efficient Transfer Learning](http://arxiv.org/abs/2305.17303v2)

authors: Shantanu Ghosh, Ke Yu, Kayhan Batmanghelich


## What, Why and How

[1]: https://arxiv.org/pdf/2305.17303v2.pdf "arXiv:2305.17303v2 [cs.CV] 31 May 2023"
[2]: https://arxiv.org/abs/2305.17303v2 "[2305.17303v2] Distilling BlackBox to Interpretable models for ..."
[3]: http://arxiv-export3.library.cornell.edu/abs/2305.17303v2 "[2305.17303v2] Distilling BlackBox to Interpretable models for ..."

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a method to distill a black-box neural network (NN) model into a mixture of shallow interpretable models for efficient transfer learning in chest X-ray (CXR) classification.
- **Why**: The paper aims to address the challenge of building generalizable AI models for healthcare applications, where NN models are often brittle to small shifts in data distribution caused by different scanners or protocols. The paper also seeks to enhance the interpretability and transparency of NN models by using human-understandable concepts as intermediate features.
- **How**: The paper assumes that the interpretable component of NN is approximately domain-invariant, and uses a mixture of experts (MoE) framework to learn a set of interpretable models that cover different subsets of data. The paper uses clinical concepts such as lung opacity, cardiomegaly, etc. as the experts, and learns a concept classifier and a concept predictor for each concept. The paper then uses a pseudo-labeling technique from semi-supervised learning (SSL) to transfer the concept classifier to the target domain, followed by fine-tuning the concept predictors on the target domain. The paper evaluates the proposed method on a large-scale CXR dataset and shows that it achieves comparable performance as the original NN model while being more data- and computation-efficient for transfer learning.

## Main Contributions

According to the paper, the main contributions are:

- A novel method to distill a black-box NN model into a mixture of shallow interpretable models using clinical concepts as intermediate features.
- A pseudo-labeling technique to transfer the concept classifier to the target domain with minimal labeled data.
- A comprehensive evaluation of the proposed method on a large-scale CXR dataset, showing its effectiveness and efficiency for transfer learning.

## Method Summary

The method section of the paper can be summarized as follows:

- The paper assumes that there exists a set of clinical concepts that are approximately domain-invariant and can be used as intermediate features for CXR classification. The paper uses 14 concepts that are commonly used by radiologists, such as lung opacity, cardiomegaly, pleural effusion, etc.
- The paper proposes a mixture of experts (MoE) framework to distill a black-box NN model into a mixture of shallow interpretable models using the clinical concepts. The paper defines two types of models: a concept classifier and a concept predictor. The concept classifier is a binary classifier that predicts whether a concept is present or not in a CXR image. The concept predictor is a linear regression model that predicts the final output (e.g., disease label) given the concept score. The paper learns one concept classifier and one concept predictor for each concept, and uses a gating network to assign weights to each expert based on the input image.
- The paper uses the black-box NN model as a teacher to guide the learning of the MoE model. The paper uses two types of losses: a distillation loss and a consistency loss. The distillation loss measures the difference between the teacher's output and the MoE's output, and encourages the MoE to mimic the teacher. The consistency loss measures the difference between the concept classifier's output and the concept predictor's input, and encourages the MoE to use consistent concepts as intermediate features.
- The paper uses a pseudo-labeling technique to transfer the concept classifier to the target domain with minimal labeled data. The paper uses the source domain concept classifier to generate pseudo-labels for the unlabeled target domain images, and then trains a new concept classifier on the target domain using both the labeled and pseudo-labeled data. The paper then fine-tunes the concept predictors on the target domain using only the labeled data.
- The paper evaluates the proposed method on a large-scale CXR dataset that contains images from different scanners and protocols. The paper compares the performance of the MoE model with the original NN model and several baselines on various transfer learning scenarios. The paper also analyzes the interpretability and robustness of the MoE model by visualizing the concept scores and weights for different images.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the clinical concepts
concepts = ["lung opacity", "cardiomegaly", "pleural effusion", ...]

# Define the black-box NN model
teacher = NN_model()

# Define the MoE model
moe = MoE_model(concepts)

# Define the distillation loss
dist_loss = MSE(teacher.output, moe.output)

# Define the consistency loss
cons_loss = MSE(moe.concept_scores, moe.concept_inputs)

# Train the MoE model on the source domain
for epoch in range(num_epochs):
  for batch in source_data:
    # Forward pass
    teacher_output = teacher(batch)
    moe_output, concept_scores, concept_inputs = moe(batch)
    # Compute losses
    loss = dist_loss + cons_loss
    # Backward pass and update parameters
    loss.backward()
    optimizer.step()

# Generate pseudo-labels for the target domain using the source domain concept classifier
pseudo_labels = moe.concept_classifier(target_data)

# Train a new concept classifier on the target domain using both labeled and pseudo-labeled data
target_classifier = Concept_classifier(concepts)
for epoch in range(num_epochs):
  for batch in target_data:
    # Forward pass
    concept_scores = target_classifier(batch)
    # Compute loss
    loss = BCE(concept_scores, pseudo_labels)
    # Backward pass and update parameters
    loss.backward()
    optimizer.step()

# Fine-tune the concept predictors on the target domain using only labeled data
for epoch in range(num_epochs):
  for batch in target_data:
    # Forward pass
    concept_inputs = target_classifier(batch)
    moe_output = moe.concept_predictor(concept_inputs)
    # Compute loss
    loss = MSE(moe_output, batch.label)
    # Backward pass and update parameters
    loss.backward()
    optimizer.step()
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import libraries
import torch
import torchvision
import numpy as np

# Define the clinical concepts
concepts = ["lung opacity", "cardiomegaly", "pleural effusion", ...]

# Define the black-box NN model
teacher = torchvision.models.resnet50(pretrained=True)
teacher.fc = torch.nn.Linear(teacher.fc.in_features, num_classes)

# Define the MoE model
class MoE_model(torch.nn.Module):
  def __init__(self, concepts):
    super(MoE_model, self).__init__()
    # Define the concept classifier
    self.concept_classifier = torch.nn.Sequential(
      torch.nn.Conv2d(3, 64, 3, padding=1),
      torch.nn.ReLU(),
      torch.nn.MaxPool2d(2),
      torch.nn.Conv2d(64, 128, 3, padding=1),
      torch.nn.ReLU(),
      torch.nn.MaxPool2d(2),
      torch.nn.Flatten(),
      torch.nn.Linear(128*56*56, len(concepts)),
      torch.nn.Sigmoid()
    )
    # Define the concept predictor
    self.concept_predictor = torch.nn.ModuleList([
      torch.nn.Linear(1, num_classes) for _ in range(len(concepts))
    ])
    # Define the gating network
    self.gating_network = torch.nn.Sequential(
      torch.nn.Conv2d(3, 64, 3, padding=1),
      torch.nn.ReLU(),
      torch.nn.MaxPool2d(2),
      torch.nn.Conv2d(64, 128, 3, padding=1),
      torch.nn.ReLU(),
      torch.nn.MaxPool2d(2),
      torch.nn.Flatten(),
      torch.nn.Linear(128*56*56, len(concepts)),
      torch.nn.Softmax(dim=1)
    )

  def forward(self, x):
    # Get the concept scores
    concept_scores = self.concept_classifier(x)
    # Get the concept inputs
    concept_inputs = concept_scores.unsqueeze(-1)
    # Get the concept outputs
    concept_outputs = [self.concept_predictor[i](concept_inputs[:, i]) for i in range(len(concepts))]
    concept_outputs = torch.stack(concept_outputs, dim=1)
    # Get the gating weights
    gating_weights = self.gating_network(x)
    # Get the final output
    output = (gating_weights * concept_outputs).sum(dim=1)
    return output, concept_scores, concept_inputs

moe = MoE_model(concepts)

# Define the distillation loss
dist_loss = torch.nn.MSELoss()

# Define the consistency loss
cons_loss = torch.nn.MSELoss()

# Define the optimizer
optimizer = torch.optim.Adam(moe.parameters(), lr=0.001)

# Train the MoE model on the source domain
num_epochs = 10
for epoch in range(num_epochs):
  for batch in source_data:
    # Forward pass
    teacher_output = teacher(batch.image)
    moe_output, concept_scores, concept_inputs = moe(batch.image)
    # Compute losses
    loss = dist_loss(moe_output, teacher_output) + cons_loss(concept_scores, concept_inputs.squeeze(-1))
    # Backward pass and update parameters
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# Generate pseudo-labels for the target domain using the source domain concept classifier
pseudo_labels = moe.concept_classifier(target_data.image)

# Train a new concept classifier on the target domain using both labeled and pseudo-labeled data
target_classifier = Concept_classifier(concepts)
optimizer = torch.optim.Adam(target_classifier.parameters(), lr=0.001)
num_epochs = 10
for epoch in range(num_epochs):
  for batch in target_data:
    # Forward pass
    concept_scores = target_classifier(batch.image)
    # Compute loss
    loss = torch.nn.BCELoss()(concept_scores, pseudo_labels)
    # Backward pass and update parameters
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# Fine-tune the concept predictors on the target domain using only labeled data
optimizer = torch.optim.Adam(moe.concept_predictor.parameters(), lr=0.001)
num_epochs = 10
for epoch in range(num_epochs):
  for batch in target_data:
    # Forward pass
    concept_inputs = target_classifier(batch.image).unsqueeze(-1)
    moe_output = moe.concept_predictor(concept_inputs).sum(dim=1)
    # Compute loss
    loss = torch.nn.MSELoss()(moe_output, batch.label)
    # Backward pass and update parameters
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```