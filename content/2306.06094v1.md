---
title: 2306.06094v1 Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding
date: 2023-06-07
---

# [Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding](http://arxiv.org/abs/2306.06094v1)

authors: Mu Cai, Zeyi Huang, Yuheng Li, Haohan Wang, Yong Jae Lee


## What, Why and How

[1]: https://arxiv.org/pdf/2306.06094v1.pdf "1 arXiv:2306.06094v1 [cs.CV] 9 Jun 2023"
[2]: https://arxiv.org/abs/2306.06094 "[2306.06094] Leveraging Large Language Models for Scalable Vector ..."
[3]: http://export.arxiv.org/abs/2306.06094 "[2306.06094] Leveraging Large Language Models for Scalable Vector ..."

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- What: The paper introduces a new approach that enables large language models (LLMs) to process images using the Scalable Vector Graphics (SVG) format, which is a textual representation of geometric shapes and attributes.
- Why: The paper aims to bridge the gap between the visual and textual modalities, allowing LLMs to directly understand and manipulate images without the need for parameterized visual components. The paper also explores the potential of LLMs in computer vision tasks, such as image classification, generation, and in-context learning.
- How: The paper leverages the XML-based textual descriptions of SVG representations instead of raster images, and feeds them to LLMs as input. The paper demonstrates the promise of this approach across discriminative and generative tasks, highlighting its robustness against distribution shift, substantial improvements achieved by tapping into the in-context learning abilities of LLMs, and image understanding and generation capabilities with human guidance.


## Main Contributions

[1]: https://arxiv.org/pdf/2306.06094v1.pdf "1 arXiv:2306.06094v1 [cs.CV] 9 Jun 2023"
[2]: https://arxiv.org/abs/2306.06094 "[2306.06094] Leveraging Large Language Models for Scalable Vector ..."
[3]: http://export.arxiv.org/abs/2306.06094 "[2306.06094] Leveraging Large Language Models for Scalable Vector ..."

According to the paper[^1^][1], the main contributions are:

- The paper introduces a new, exploratory approach that enables LLMs to process images using the SVG format, which is a textual representation of geometric shapes and attributes.
- The paper demonstrates the promise of this approach across discriminative and generative tasks, highlighting its robustness against distribution shift, substantial improvements achieved by tapping into the in-context learning abilities of LLMs, and image understanding and generation capabilities with human guidance.
- The paper provides a new dataset of SVG images and their corresponding natural language descriptions, as well as a new evaluation protocol for SVG-driven image understanding and generation tasks.


## Method Summary

[1]: https://arxiv.org/pdf/2306.06094v1.pdf "1 arXiv:2306.06094v1 [cs.CV] 9 Jun 2023"
[2]: https://arxiv.org/abs/2306.06094 "[2306.06094] Leveraging Large Language Models for Scalable Vector ..."
[3]: http://export.arxiv.org/abs/2306.06094 "[2306.06094] Leveraging Large Language Models for Scalable Vector ..."

Here is a summary of the method section of the paper[^1^][1]:

- The paper describes how to convert raster images to SVG representations using a pre-trained segmentation model and a set of rules for shape and attribute extraction.
- The paper explains how to feed SVG representations to LLMs as input, using a special tokenization scheme that preserves the XML structure and semantics of SVG elements.
- The paper presents three tasks that leverage LLMs for SVG-driven image understanding and generation: (i) image classification, where LLMs predict the class label of an SVG image; (ii) image generation, where LLMs generate an SVG image given a natural language description; and (iii) in-context learning, where LLMs learn from human feedback and improve their image understanding and generation abilities.
- The paper introduces a new dataset of SVG images and their corresponding natural language descriptions, collected from various sources and domains. The paper also provides a new evaluation protocol for SVG-driven image understanding and generation tasks, using both automatic and human metrics.


## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```
# Input: a raster image or a natural language description
# Output: an SVG image or a class label

# Convert raster image to SVG representation
if input is raster image:
  segment image into regions using pre-trained model
  for each region:
    extract shape and attribute information using rules
    generate SVG element with shape and attribute information
  concatenate SVG elements into an SVG representation

# Feed SVG representation to LLM as input
tokenize SVG representation using special tokenization scheme
prepend task-specific prefix to input tokens
append end-of-sequence token to input tokens

# Perform image classification, generation, or in-context learning
if task is image classification:
  feed input tokens to LLM and get output logits
  apply softmax to output logits and get class probabilities
  return class with highest probability as output
elif task is image generation:
  feed input tokens to LLM and get output tokens
  decode output tokens into an SVG representation
  render SVG representation into an SVG image
  return SVG image as output
elif task is in-context learning:
  feed input tokens to LLM and get output tokens
  decode output tokens into an SVG representation or a class label
  get human feedback on the output and append it to the input tokens
  repeat until feedback is positive or maximum iterations reached
  return final output as output
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```
# Input: a raster image or a natural language description
# Output: an SVG image or a class label

# Define constants and hyperparameters
LLM = pre-trained large language model (e.g., GPT-4)
SEG = pre-trained segmentation model (e.g., Mask R-CNN)
SHAPE_TYPES = ["circle", "ellipse", "rect", "polygon", "line"]
ATTRIBUTE_TYPES = ["style", "cx", "cy", "r", "rx", "ry", "x1", "y1", "x2", "y2", "points"]
CLASS_LABELS = ["animal", "plant", "vehicle", ...]
PREFIXES = {"image classification": "[CLS]", "image generation": "[GEN]", "in-context learning": "[ICL]"}
MAX_ITERATIONS = 10
THRESHOLD = 0.5

# Convert raster image to SVG representation
if input is raster image:
  regions = SEG.predict(input) # get a list of regions with bounding boxes, masks, and labels
  svg_elements = [] # initialize an empty list of SVG elements
  for region in regions:
    shape_type = SHAPE_TYPES[region.label] # get the shape type based on the region label
    attributes = {} # initialize an empty dictionary of attributes
    for attribute_type in ATTRIBUTE_TYPES:
      attribute_value = extract_attribute_value(region, shape_type, attribute_type) # get the attribute value using rules based on the region mask and bounding box
      if attribute_value is not None:
        attributes[attribute_type] = attribute_value # add the attribute to the dictionary
    svg_element = generate_svg_element(shape_type, attributes) # generate an SVG element with the shape type and attributes
    svg_elements.append(svg_element) # add the SVG element to the list
  svg_representation = concatenate_svg_elements(svg_elements) # concatenate the SVG elements into an SVG representation

# Feed SVG representation to LLM as input
if input is natural language description:
  svg_representation = input # use the input as the SVG representation
tokens = tokenize_svg_representation(svg_representation) # tokenize the SVG representation using a special tokenization scheme that preserves the XML structure and semantics of SVG elements
prefix = PREFIXES[task] # get the task-specific prefix
input_tokens = [prefix] + tokens + ["<EOS>"] # prepend the prefix and append the end-of-sequence token to the input tokens

# Perform image classification, generation, or in-context learning
if task is image classification:
  output_logits = LLM.predict(input_tokens) # feed the input tokens to LLM and get output logits
  output_probs = softmax(output_logits) # apply softmax to output logits and get class probabilities
  output_class = argmax(output_probs) # get the class with highest probability as output
  output_label = CLASS_LABELS[output_class] # get the class label as output
  return output_label
elif task is image generation:
  output_tokens = LLM.generate(input_tokens) # feed the input tokens to LLM and generate output tokens
  output_svg_representation = decode_output_tokens(output_tokens) # decode output tokens into an SVG representation
  output_svg_image = render_svg_representation(output_svg_representation) # render SVG representation into an SVG image
  return output_svg_image
elif task is in-context learning:
  iteration = 0 # initialize iteration counter
  feedback = None # initialize feedback variable
  while feedback is not positive and iteration < MAX_ITERATIONS: # repeat until feedback is positive or maximum iterations reached
    output_tokens = LLM.generate(input_tokens) # feed the input tokens to LLM and generate output tokens
    output_svg_representation_or_label = decode_output_tokens(output_tokens) # decode output tokens into an SVG representation or a class label depending on the prefix
    feedback = get_human_feedback(output_svg_representation_or_label) # get human feedback on the output (e.g., using a rating scale or a binary choice)
    if feedback is positive: # if feedback is positive, break the loop and return the output
      break
    else: # if feedback is negative, append it to the input tokens and increase iteration counter
      input_tokens += [feedback]
      iteration += 1
  return output_svg_representation_or_label

# Helper functions

def extract_attribute_value(region, shape_type, attribute_type):
  """Extracts the attribute value for a given region, shape type, and attribute type using rules based on the region mask and bounding box."""
  
  mask = region.mask # get the region mask as a binary array
  bbox = region.bbox # get the region bounding box as a tuple of (x_min, y_min, x_max, y_max)
  x_min, y_min, x_max, y_max = bbox # unpack the bounding box coordinates
  width = x_max - x_min # get the width of the bounding box
  height = y_max - y_min # get the height of the bounding box
  x_center = (x_min + x_max) / 2 # get the x coordinate of the center of the bounding box
  y_center = (y_min + y_max) / 2 # get the y coordinate of the center of the bounding box
  
  if shape_type == "circle": # if shape type is circle
    if attribute_type == "style": # if attribute type is style
      return "fill:#FFFFFF;stroke:#000000;stroke-width:1" # return a default style with white fill and black stroke
    elif attribute_type == "cx": # if attribute type is cx
      return x_center # return the x coordinate of the center
    elif attribute_type == "cy": # if attribute type is cy
      return y_center # return the y coordinate of the center
    elif attribute_type == "r": # if attribute type is r
      return min(width, height) / 2 # return the minimum of width and height divided by 2 as the radius
    else: # if attribute type is not applicable for circle
      return None # return None
      
  elif shape_type == "ellipse": # if shape type is ellipse
    if attribute_type == "style": # if attribute type is style
      return "fill:#FFFFFF;stroke:#000000;stroke-width:1" # return a default style with white fill and black stroke
    elif attribute_type == "cx": # if attribute type is cx
      return x_center # return the x coordinate of the center
    elif attribute_type == "cy": # if attribute type is cy
      return y_center # return the y coordinate of the center
    elif attribute_type == "rx": # if attribute type is rx
      return width / 2 # return the width divided by 2 as the x radius
    elif attribute_type == "ry": # if attribute type is ry
      return height / 2 # return the height divided by 2 as the y radius
    else: # if attribute type is not applicable for ellipse
      return None # return None
      
  elif shape_type == "rect": # if shape type is rect
    if attribute_type == "style": # if attribute type is style
      return "fill:#FFFFFF;stroke:#000000;stroke-width:1" # return a default style with white fill and black stroke
    elif attribute_type == "x": # if attribute type is x
      return x_min # return the minimum x coordinate as the x position
    elif attribute_type == "y": # if attribute type is y
      return y_min # return the minimum y coordinate as the y position
    elif attribute_type == "width": # if attribute type is width
      return width # return the width of the bounding box as the width of the rectangle
    elif attribute_type == "height": # if attribute type is height
      return height # return the height of the bounding box as the height of the rectangle
    else: # if attribute type is not applicable for rect
      return None
      
  elif shape_type == "polygon": # if shape type is polygon
    
```