---
title: 2101.07922v2 LowKey  Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition
date: 2021-01-08
---

# [LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition](http://arxiv.org/abs/2101.07922v2)

authors: Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan Duan, John Dickerson, Gavin Taylor, Tom Goldstein


## What, Why and How

[1]: https://arxiv.org/abs/2101.07922 "LowKey: Leveraging Adversarial Attacks to Protect Social Media Users ..."
[2]: https://arxiv.org/pdf/2101.07922.pdf "LOWK : LEVERAGING ADVERSARIAL ATTACKS TO P S MEDIA USERS ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2011.07922v2 "[2011.07922v2] Mathieu Moonshine and Siegel Modular Forms"

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper presents LowKey, a tool that leverages adversarial attacks to protect social media users from facial recognition systems. LowKey applies an adversarial filter to user images before they are uploaded to social media platforms, making them unrecognizable by commercial facial recognition APIs.
- **Why**: The paper aims to address the privacy and fairness concerns of facial recognition systems that are widely deployed by private corporations, government agencies, and contractors for consumer services and mass surveillance programs. These systems often scrape social media profiles for user images without their consent or knowledge, exposing them to potential risks of identity theft, discrimination, or harassment.
- **How**: The paper develops an adversarial filter that accounts for the entire image processing pipeline and is demonstrably effective against industrial-grade pipelines that include face detection and large scale databases. The paper also releases an easy-to-use webtool that significantly degrades the accuracy of Amazon Rekognition and the Microsoft Azure Face Recognition API, reducing the accuracy of each to below 1%. The paper evaluates the performance of LowKey on several benchmarks and datasets, and shows that it preserves the perceptual quality of the images while fooling the facial recognition systems.

## Main Contributions

The paper claims the following contributions:

- It proposes LowKey, the first evasion tool that is effective against commercial facial recognition APIs.
- It develops an adversarial filter that accounts for the entire image processing pipeline and is robust to various transformations and distortions.
- It releases a webtool that allows users to easily apply LowKey to their own images and protect their privacy on social media platforms.
- It evaluates LowKey on several benchmarks and datasets, and demonstrates its effectiveness and efficiency.

## Method Summary

The method section of the paper consists of three subsections:

- **Adversarial Filter Design**: This subsection describes how LowKey designs an adversarial filter that is optimized to fool a facial recognition system while preserving the perceptual quality of the image. The filter is based on the Fast Gradient Sign Method (FGSM) (Goodfellow et al., 2015), but with several modifications to account for the image processing pipeline and the face detection module. The filter also incorporates a perceptual loss function that measures the similarity between the original and perturbed images in terms of color, texture, and style.
- **Webtool Implementation**: This subsection describes how LowKey implements a webtool that allows users to upload their own images and apply the adversarial filter to them. The webtool uses a Flask server and a PyTorch backend to process the images and generate the perturbations. The webtool also provides a user interface that allows users to adjust the strength of the filter and preview the results before downloading them.
- **Evaluation**: This subsection describes how LowKey evaluates its performance on various metrics and datasets. The paper uses two commercial facial recognition APIs, Amazon Rekognition and Microsoft Azure Face Recognition API, as the target systems to fool. The paper also uses several benchmarks and datasets to measure the success rate, robustness, and perceptual quality of LowKey. The paper compares LowKey with several baselines and state-of-the-art methods, and shows that LowKey outperforms them in terms of effectiveness and efficiency.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the adversarial filter function
def adversarial_filter(image, target_system):
  # Preprocess the image to match the target system's input format
  image = preprocess(image)
  # Apply face detection to locate the face region
  face_region = face_detection(image)
  # Compute the gradient of the target system's loss function with respect to the image
  gradient = compute_gradient(image, target_system)
  # Compute the perturbation based on the gradient and a scaling factor
  perturbation = scale(gradient)
  # Apply the perturbation to the face region only
  image[face_region] = image[face_region] + perturbation
  # Postprocess the image to restore the original format
  image = postprocess(image)
  # Return the perturbed image
  return image

# Define the webtool function
def webtool():
  # Initialize a Flask server and a PyTorch backend
  server = Flask()
  backend = PyTorch()
  # Define a user interface that allows users to upload images and adjust parameters
  ui = UserInterface()
  # Loop until the user exits the webtool
  while True:
    # Get the user's input image and parameters
    image, parameters = ui.get_input()
    # Apply the adversarial filter to the image using the parameters
    perturbed_image = adversarial_filter(image, parameters)
    # Show the perturbed image to the user and allow them to download it
    ui.show_output(perturbed_image)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torchvision
import numpy as np
import cv2
from flask import Flask, request, render_template, send_file
from PIL import Image

# Define the adversarial filter function
def adversarial_filter(image, target_system):
  # Preprocess the image to match the target system's input format
  # Convert the image to RGB mode and resize it to 224x224 pixels
  image = image.convert("RGB")
  image = image.resize((224, 224))
  # Normalize the image using the mean and standard deviation of ImageNet dataset
  mean = [0.485, 0.456, 0.406]
  std = [0.229, 0.224, 0.225]
  image = torchvision.transforms.Normalize(mean, std)(image)
  # Convert the image to a PyTorch tensor and add a batch dimension
  image = torchvision.transforms.ToTensor()(image)
  image = image.unsqueeze(0)
  
  # Apply face detection to locate the face region
  # Use a pre-trained face detection model from PyTorch Hub
  face_detector = torch.hub.load("ultralytics/yolov5", "yolov5s", pretrained=True)
  # Set the model to evaluation mode and disable gradient computation
  face_detector.eval()
  torch.set_grad_enabled(False)
  # Run the model on the image and get the bounding boxes of detected faces
  results = face_detector(image)
  boxes = results.xyxy[0][:, :4]
  # If no face is detected, return the original image
  if len(boxes) == 0:
    return image
  # If multiple faces are detected, choose the largest one
  elif len(boxes) > 1:
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    largest = torch.argmax(areas)
    box = boxes[largest]
  # If only one face is detected, use it as the box
  else:
    box = boxes[0]
  
  # Compute the gradient of the target system's loss function with respect to the image
  # Set the model to training mode and enable gradient computation
  target_system.train()
  torch.set_grad_enabled(True)
  # Run the model on the image and get the output logits
  logits = target_system(image)
  # Get the predicted label of the image
  label = torch.argmax(logits)
  # Compute the cross-entropy loss between the logits and the label
  loss = torch.nn.CrossEntropyLoss()(logits, label)
  # Compute the gradient of the loss with respect to the image
  loss.backward()
  gradient = image.grad
  
  
  # Compute the perturbation based on the gradient and a scaling factor
  # Use a scaling factor of epsilon=0.01 as a hyperparameter
  epsilon = 0.01
  # Compute the sign of the gradient and multiply it by epsilon
  perturbation = epsilon * torch.sign(gradient)
  
 
  
  
  
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  
 
  

  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   - Apply the perturbation to the face region only
   # Convert the box coordinates to integers and clamp them to the image size
   x1, y1, x2, y2 = box.int().clamp(0, 223).tolist()
   # Apply the perturbation to the pixels inside the box only
   image[:, :, y1:y2+1, x1:x2+1] = image[:, :, y1:y2+1, x1:x2+1] + perturbation[:, :, y1:y2+1, x1:x2+1]
   # Postprocess the image to restore the original format
   # Remove the batch dimension and convert the image to a numpy array
   image = image.squeeze(0).numpy()
   # Denormalize the image using the mean and standard deviation of ImageNet dataset
   image = image * std + mean
   # Clip the image values to the range [0, 1]
   image = np.clip(image, 0, 1)
   # Convert the image to BGR mode and multiply it by 255
   image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) * 255
   # Return the perturbed image
   return image

# Define the webtool function
def webtool():
  # Initialize a Flask server and a PyTorch backend
  server = Flask(__name__)
  backend = PyTorch()
  # Load the target system model from a checkpoint file
  target_system = torch.load("target_system.pth")
  # Define a user interface that allows users to upload images and adjust parameters
  @server.route("/", methods=["GET", "POST"])
  def user_interface():
    # If the user sends a GET request, render the index.html template
    if request.method == "GET":
      return render_template("index.html")
    # If the user sends a POST request, get the uploaded image and parameters
    elif request.method == "POST":
      image = request.files["image"]
      parameters = request.form["parameters"]
      # Apply the adversarial filter to the image using the parameters
      perturbed_image = adversarial_filter(image, parameters)
      # Save the perturbed image to a temporary file
      filename = "perturbed_image.jpg"
      cv2.imwrite(filename, perturbed_image)
      # Send the perturbed image file to the user as an attachment
      return send_file(filename, as_attachment=True)
  
  # Run the server on port 5000
  server.run(port=5000)
```