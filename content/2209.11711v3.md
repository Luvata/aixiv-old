---
title: 2209.11711v3 Best Prompts for Text-to-Image Models and How to Find Them
date: 2022-09-12
---

# [Best Prompts for Text-to-Image Models and How to Find Them](http://arxiv.org/abs/2209.11711v3)

authors: Nikita Pavlichenko, Dmitry Ustalov


## What, Why and How

[1]: https://arxiv.org/pdf/2209.11711v3.pdf "Best Prompts for Text-to-Image Models and How to Find Them - arXiv.org"
[2]: https://arxiv.org/abs/2209.11711 "[2209.11711] Best Prompts for Text-to-Image Models and How ... - arXiv.org"
[3]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2209.11711 "[2209.11711] Best Prompts for Text-to-Image Models and How to Find Them"

Here is a summary of the paper:

- **What**: The paper presents a method for finding the best prompts and keywords for text-to-image models, such as Stable Diffusion, that can generate realistic and appealing images from textual descriptions.
- **Why**: The paper argues that the quality of the generated images depends on the composition of the prompt and the keywords, which are often arbitrary and subjective. The paper also claims that there is a lack of evaluation tools and analysis for prompt engineering.
- **How**: The paper proposes a human-in-the-loop approach that uses a genetic algorithm to discover the most effective combination of prompt keywords based on crowd workers' ratings of the aesthetic appeal of the images. The paper also shows how this approach can improve the visual quality of the images generated from the same description.

## Main Contributions

[1]: https://arxiv.org/pdf/2209.11711v3.pdf "Best Prompts for Text-to-Image Models and How to Find Them - arXiv.org"
[2]: https://arxiv.org/abs/2209.11711 "[2209.11711] Best Prompts for Text-to-Image Models and How ... - arXiv.org"
[3]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2209.11711 "[2209.11711] Best Prompts for Text-to-Image Models and How to Find Them"

According to the paper[^1^][1], the contributions are:

- A method for evaluating the quality of generations produced by different prompt templates.
- A set of keywords for Stable Diffusion that improves the aesthetics of the images.
- All the data and code that allow to reproduce the results and build solutions on top of them.

## Method Summary

[1]: https://arxiv.org/pdf/2209.11711v3.pdf "Best Prompts for Text-to-Image Models and How to Find Them - arXiv.org"
[2]: https://arxiv.org/abs/2209.11711 "[2209.11711] Best Prompts for Text-to-Image Models and How ... - arXiv.org"
[3]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2209.11711 "[2209.11711] Best Prompts for Text-to-Image Models and How to Find Them"

Here is a summary of the method section of the paper:

- The paper uses Stable Diffusion as the text-to-image model and collects 100 image descriptions from various sources, such as Wikipedia and ArtStation.
- The paper defines a prompt template as a combination of a description and a set of keywords, separated by commas. The paper uses 10 keywords that are commonly used for text-to-image models, such as "highly detailed", "trending on ArtStation", etc.
- The paper uses a genetic algorithm to optimize the prompt template based on the aesthetic ratings of the generated images by crowd workers. The paper uses Toloka as the crowdsourcing platform and asks workers to rate the images on a scale of 1 to 5, where 5 is the most appealing.
- The paper initializes the population of prompt templates with random combinations of keywords and evaluates their fitness by generating images and collecting ratings. The paper then applies crossover and mutation operators to generate new prompt templates and repeats the process until convergence or a maximum number of iterations is reached.
- The paper compares the best prompt template found by the genetic algorithm with the baseline prompt template that has no keywords. The paper also analyzes the impact of different keywords on the image quality and diversity.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the text-to-image model and the image descriptions
model = StableDiffusion()
descriptions = load_descriptions()

# Define the keywords and the prompt template format
keywords = ["highly detailed", "trending on ArtStation", ...]
prompt_template = description + "," + keywords

# Define the genetic algorithm parameters
population_size = 100
crossover_rate = 0.8
mutation_rate = 0.2
max_iterations = 20

# Initialize the population of prompt templates with random keywords
population = []
for i in range(population_size):
  prompt = random_prompt_template()
  population.append(prompt)

# Evaluate the fitness of each prompt template by generating images and collecting ratings
fitness = []
for prompt in population:
  images = model.generate(prompt)
  ratings = collect_ratings(images)
  fitness.append(mean(ratings))

# Repeat until convergence or maximum iterations
for iteration in range(max_iterations):
  # Select the best prompt templates for crossover
  parents = select_parents(population, fitness, crossover_rate)

  # Apply crossover to generate new prompt templates
  offspring = []
  for i in range(0, len(parents), 2):
    child1, child2 = crossover(parents[i], parents[i+1])
    offspring.append(child1)
    offspring.append(child2)

  # Apply mutation to introduce diversity
  for i in range(len(offspring)):
    offspring[i] = mutate(offspring[i], mutation_rate)

  # Evaluate the fitness of the new prompt templates
  new_fitness = []
  for prompt in offspring:
    images = model.generate(prompt)
    ratings = collect_ratings(images)
    new_fitness.append(mean(ratings))

  # Replace the worst prompt templates with the best new ones
  population, fitness = replace(population, fitness, offspring, new_fitness)

# Return the best prompt template and its fitness
best_prompt = max(population, key=lambda x: fitness[population.index(x)])
best_fitness = max(fitness)
return best_prompt, best_fitness
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import random
import requests

# Define the text-to-image model and the image descriptions
model = StableDiffusion() # A class that implements the Stable Diffusion model
descriptions = load_descriptions() # A function that loads 100 image descriptions from various sources

# Define the keywords and the prompt template format
keywords = ["highly detailed", "trending on ArtStation", ...] # A list of 10 keywords that are commonly used for text-to-image models
prompt_template = description + "," + keywords # A string that concatenates a description and a set of keywords, separated by commas

# Define the genetic algorithm parameters
population_size = 100 # The number of prompt templates in the population
crossover_rate = 0.8 # The probability of applying crossover to two prompt templates
mutation_rate = 0.2 # The probability of mutating a keyword in a prompt template
max_iterations = 20 # The maximum number of iterations for the genetic algorithm
toloka_url = "https://toloka.ai" # The URL of the Toloka crowdsourcing platform

# Initialize the population of prompt templates with random keywords
population = [] # A list that stores the prompt templates in the population
for i in range(population_size):
  prompt = random_prompt_template() # A function that randomly selects a description and a set of keywords to form a prompt template
  population.append(prompt)

# Evaluate the fitness of each prompt template by generating images and collecting ratings
fitness = [] # A list that stores the fitness values of the prompt templates in the population
for prompt in population:
  images = model.generate(prompt) # A method that generates images from a prompt template using the Stable Diffusion model
  ratings = collect_ratings(images) # A function that collects ratings from crowd workers on Toloka based on the aesthetic appeal of the images
  fitness.append(mean(ratings)) # A function that calculates the mean rating of a set of images

# Repeat until convergence or maximum iterations
for iteration in range(max_iterations):
  # Select the best prompt templates for crossover
  parents = select_parents(population, fitness, crossover_rate) # A function that selects a subset of prompt templates from the population based on their fitness and crossover rate

  # Apply crossover to generate new prompt templates
  offspring = [] # A list that stores the new prompt templates generated by crossover
  for i in range(0, len(parents), 2):
    child1, child2 = crossover(parents[i], parents[i+1]) # A function that swaps some keywords between two prompt templates to create two new ones
    offspring.append(child1)
    offspring.append(child2)

  # Apply mutation to introduce diversity
  for i in range(len(offspring)):
    offspring[i] = mutate(offspring[i], mutation_rate) # A function that randomly changes a keyword in a prompt template with another one with some probability

  # Evaluate the fitness of the new prompt templates
  new_fitness = [] # A list that stores the fitness values of the new prompt templates
  for prompt in offspring:
    images = model.generate(prompt) # A method that generates images from a prompt template using the Stable Diffusion model
    ratings = collect_ratings(images) # A function that collects ratings from crowd workers on Toloka based on the aesthetic appeal of the images
    new_fitness.append(mean(ratings)) # A function that calculates the mean rating of a set of images

  # Replace the worst prompt templates with the best new ones
  population, fitness = replace(population, fitness, offspring, new_fitness) # A function that replaces some prompt templates in the population with some new ones based on their fitness values

# Return the best prompt template and its fitness
best_prompt = max(population, key=lambda x: fitness[population.index(x)]) # The prompt template with the highest fitness value in the population
best_fitness = max(fitness) # The highest fitness value in the population
return best_prompt, best_fitness 
```