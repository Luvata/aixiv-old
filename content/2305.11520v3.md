---
title: 2305.11520v3 Late-Constraint Diffusion Guidance for Controllable Image Synthesis
date: 2023-05-12
---

# [Late-Constraint Diffusion Guidance for Controllable Image Synthesis](http://arxiv.org/abs/2305.11520v3)

authors: Chang Liu, Dong Liu


## What, Why and How

[1]: https://arxiv.org/abs/2305.11520 "[2305.11520] Late-Constraint Diffusion Guidance for Controllable Image ..."
[2]: https://arxiv.org/pdf/2305.11520.pdf "Late-Constraint Diffusion Guidance for Controllable Image ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2103.11520v3 "[2103.11520v3] Unsupervised and self-adaptative techniques for cross ..."

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a new approach for controllable image synthesis using diffusion models, which can incorporate various external conditions such as layout, color, structure, object shape, etc. The approach is called **late-constraint diffusion guidance**, which constrains the output of the diffusion network to be aligned with the required conditions, rather than regularizing the intermediate features as in existing methods.
- **Why**: The paper aims to address the limitations of existing methods for controllable image synthesis using diffusion models, which are known as **early-constraint** methods. These methods have difficulties in handling multiple conditions with a single solution, and they tend to train separate models for each specific condition, which require much training cost and result in non-generalizable solutions.
- **How**: The paper introduces a lightweight **condition adapter** to establish the correlation between external conditions and internal representations of diffusion models. During the iterative denoising process, the conditional guidance is sent into corresponding condition adapter to manipulate the sampling process with the established correlation. The paper also equips the late-constraint strategy with a **timestep resampling** method and an **early stopping** technique, which boost the quality of synthesized image meanwhile complying with the guidance. The paper evaluates the proposed method on several datasets and tasks, and shows that it outperforms the early-constraint methods and demonstrates multiple applications with its plausible generalization ability and flexible controllability.

## Main Contributions

According to the paper, the main contributions are:

- The paper proposes a new approach for controllable image synthesis using diffusion models, which is called **late-constraint diffusion guidance**. It leaves the diffusion networks unchanged, but constrains its output to be aligned with the required conditions.
- The paper introduces a lightweight **condition adapter** to establish the correlation between external conditions and internal representations of diffusion models. It allows the proposed method to handle multiple conditions with a single solution and generalize better to unseen conditions.
- The paper equips the late-constraint strategy with a **timestep resampling** method and an **early stopping** technique, which improve the quality of synthesized image and reduce the sampling time.
- The paper evaluates the proposed method on several datasets and tasks, and shows that it outperforms the existing early-constraint methods and demonstrates multiple applications with its plausible generalization ability and flexible controllability.

## Method Summary

[1]: https://arxiv.org/abs/2305.11520 "[2305.11520] Late-Constraint Diffusion Guidance for Controllable Image ..."
[2]: https://arxiv.org/pdf/2305.11520.pdf "Late-Constraint Diffusion Guidance for Controllable Image ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2103.11520v3 "[2103.11520v3] Unsupervised and self-adaptative techniques for cross ..."

Here is a summary of the method section of the paper[^1^][2]:

- The paper first reviews the background of diffusion models and early-constraint methods for controllable image synthesis, and points out their limitations and challenges.
- The paper then introduces the proposed **late-constraint diffusion guidance** approach, which consists of three components: a **diffusion network**, a **condition adapter**, and a **condition sampler**. The paper explains how these components work together to generate images that comply with the external conditions.
- The paper also describes two techniques that enhance the late-constraint strategy: a **timestep resampling** method and an **early stopping** technique. The paper explains how these techniques improve the quality and efficiency of the sampling process.
- The paper finally presents the implementation details and the training procedure of the proposed method, and discusses some design choices and ablation studies.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a diffusion network D, a condition adapter C, a condition sampler S, and a set of external conditions E
# Output: a synthesized image x that complies with E

# Initialize x with Gaussian noise
x = sample_from_gaussian()

# Initialize the timestep t with the maximum value T
t = T

# Initialize the early stopping flag f with False
f = False

# Loop until t reaches 0 or f is True
while t > 0 and not f:

  # Resample t with a probability p
  t = resample_timestep(t, p)

  # Get the noise level epsilon for the current timestep t
  epsilon = get_noise_level(t)

  # Get the conditional guidance g for the current timestep t and external conditions E
  g = C(t, E)

  # Sample a new image x' from the conditional distribution p(x'|x, t, g)
  x' = S(x, t, g)

  # Check if x' satisfies the external conditions E with a threshold tau
  if check_satisfaction(x', E, tau):

    # Update x with x'
    x = x'

    # Check if x' is close enough to the output of D with a threshold delta
    if check_closeness(x', D(x'), delta):

      # Set f to True to stop the loop
      f = True

  # Decrease t by 1
  t = t - 1

# Return x as the final output
return x
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a diffusion network D, a condition adapter C, a condition sampler S, and a set of external conditions E
# Output: a synthesized image x that complies with E

# Define some hyperparameters
T = 1000 # the maximum number of timesteps
p = 0.9 # the probability of resampling timesteps
tau = 0.8 # the threshold of satisfaction
delta = 0.1 # the threshold of closeness

# Define some helper functions
def sample_from_gaussian():
  # Sample a random image from a standard Gaussian distribution
  return np.random.normal(size=(3, 256, 256))

def resample_timestep(t, p):
  # Resample t with probability p from a geometric distribution with mean t
  if np.random.uniform() < p:
    return np.random.geometric(1 / t)
  else:
    return t

def get_noise_level(t):
  # Get the noise level epsilon for timestep t using a predefined schedule
  return schedule[t]

def check_satisfaction(x, E, tau):
  # Check if x satisfies the external conditions E with threshold tau
  # For example, if E contains a layout condition, check if x matches the layout
  # Return True if x satisfies all conditions in E with a score higher than tau
  score = 0
  for e in E:
    score += e.evaluate(x)
  score /= len(E)
  return score > tau

def check_closeness(x, y, delta):
  # Check if x is close enough to y with threshold delta
  # Use L2 distance as a measure of closeness
  return np.linalg.norm(x - y) < delta

# Initialize x with Gaussian noise
x = sample_from_gaussian()

# Initialize the timestep t with the maximum value T
t = T

# Initialize the early stopping flag f with False
f = False

# Loop until t reaches 0 or f is True
while t > 0 and not f:

  # Resample t with a probability p
  t = resample_timestep(t, p)

  # Get the noise level epsilon for the current timestep t
  epsilon = get_noise_level(t)

  # Get the conditional guidance g for the current timestep t and external conditions E
  g = C(t, E)

  # Sample a new image x' from the conditional distribution p(x'|x, t, g)
  # Use Langevin dynamics as an approximation of the conditional sampler S
  x' = x + epsilon * D(x) + np.sqrt(2 * epsilon) * np.random.normal(size=(3, 256, 256))
  
  # Clip x' to the valid range [0, 1]
  x' = np.clip(x', 0, 1)

  # Check if x' satisfies the external conditions E with a threshold tau
  if check_satisfaction(x', E, tau):

    # Update x with x'
    x = x'

    # Check if x' is close enough to the output of D with a threshold delta
    if check_closeness(x', D(x'), delta):

      # Set f to True to stop the loop
      f = True

  # Decrease t by 1
  t = t - 1

# Return x as the final output
return x
```