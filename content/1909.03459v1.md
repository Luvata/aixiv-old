---
title: 1909.03459v1 Blind Geometric Distortion Correction on Images Through Deep Learning
date: 2019-09-04
---

# [Blind Geometric Distortion Correction on Images Through Deep Learning](http://arxiv.org/abs/1909.03459v1)

authors: Xiaoyu Li, Bo Zhang, Pedro V. Sander, Jing Liao


## What, Why and How

[1]: https://arxiv.org/pdf/1909.03459v1.pdf "Blind Geometric Distortion Correction on Images Through Deep Learning"
[2]: https://arxiv.org/abs/1909.03459 "[1909.03459] Blind Geometric Distortion Correction on Images Through ..."
[3]: https://www.researchgate.net/publication/335713162_Blind_Geometric_Distortion_Correction_on_Images_Through_Deep_Learning "(PDF) Blind Geometric Distortion Correction on Images ... - ResearchGate"

Here is a summary of the paper:

- **What**: The paper proposes a general framework to automatically correct different types of geometric distortion in a single input image, such as lens distortion, rotation, shear, perspective distortion and wave distortion.
- **Why**: The paper aims to address the common problem of geometric distortion in digital imagery, which can affect both photography and computer vision applications. The paper claims that existing methods are either limited to specific types of distortion or require user input or multiple images.
- **How**: The paper employs convolutional neural networks (CNNs) trained by using a large synthetic distortion dataset to predict the displacement field between distorted images and corrected images. A model fitting method uses the CNN output to estimate the distortion parameters, achieving a more accurate prediction. The final corrected image is generated based on the predicted flow using an efficient, high-quality resampling method. The paper evaluates the performance of the proposed method on various datasets and demonstrates its advantages over traditional correction methods and its potential for interesting applications such as distortion transfer, distortion exaggeration and co-occurring distortion correction.

This summary is based on the information from [^1^][1] [^2^][2] [^3^][3].

## Main Contributions

[1]: https://www.arxiv-vanity.com/papers/1909.03459/ "Blind Geometric Distortion Correction on Images Through Deep Learning ..."
[2]: https://ieeexplore.ieee.org/document/8953385/ "Blind Geometric Distortion Correction on Images Through Deep Learning ..."
[3]: https://arxiv.org/abs/1909.03459 "Blind Geometric Distortion Correction on Images Through Deep Learning"
[4]: https://arxiv.org/pdf/1909.03459v1 "Blind Geometric Distortion Correction on Images Through Deep Learning"
[5]: https://www.researchgate.net/figure/Our-proposed-learning-based-method-can-blindly-correct-images-with-different-types-of_fig1_338512775 "Our proposed learning-based method can blindly correct images with ..."

According to [^1^][1] [^2^][4], the contributions of this paper are:

- A **single-model network**, which implicitly learns the distortion parameters given the distortion type.
- A **multi-model network**, which explicitly predicts the distortion parameters for each distortion type.
- A **model fitting method**, which refines the CNN output by fitting a parametric model to the predicted displacement field, achieving a more accurate prediction.
- A **high-quality resampling method**, which generates the final corrected image based on the predicted flow using an efficient and adaptive algorithm.
- A **large synthetic distortion dataset**, which covers a wide range of geometric distortions and can be used to train and evaluate the proposed method.

## Method Summary

[1]: https://arxiv.org/abs/1909.03459 "Blind Geometric Distortion Correction on Images Through Deep Learning"
[2]: https://ieeexplore.ieee.org/document/8953385/ "Blind Geometric Distortion Correction on Images Through Deep Learning ..."
[3]: https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Li_Blind_Geometric_Distortion_CVPR_2019_supplemental.pdf "Blind Geometric Distortion Correction on Images Through Deep Learning ..."
[4]: https://www.cse.ust.hk/~psander/docs/blindgeo.pdf "Blind Geometric Distortion Correction on Images Through Deep Learning"

Here is a summary of the method section of the paper:

- The paper presents two CNN-based methods to predict the displacement field between distorted images and corrected images: a **single-model network** and a **multi-model network**.
- The single-model network takes the distorted image and the distortion type as input and outputs a displacement field that can be used to correct the image. The network is trained on a large synthetic distortion dataset that covers six types of distortion: barrel, pincushion, rotation, shear, perspective and wave.
- The multi-model network consists of six sub-networks, each specialized for one type of distortion. The sub-networks share the same architecture as the single-model network, but have different weights. The multi-model network can explicitly predict the distortion parameters for each type of distortion, such as focal length, rotation angle and perspective ratio.
- The paper also proposes a **model fitting method** to refine the CNN output by fitting a parametric model to the predicted displacement field. The model fitting method can estimate the distortion parameters more accurately and reduce the noise in the displacement field.
- The paper then describes a **high-quality resampling method** to generate the final corrected image based on the predicted flow using an efficient and adaptive algorithm. The resampling method can handle large displacements and preserve sharp edges and fine details in the image.
- The paper evaluates the performance of the proposed method on various datasets and demonstrates its advantages over traditional correction methods and its potential for interesting applications such as distortion transfer, distortion exaggeration and co-occurring distortion correction.

This summary is based on the information from [^1^][1] [^2^][2] [^3^][3] [^4^][4].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a distorted image I and its distortion type T
# Output: a corrected image C

# Step 1: Predict the displacement field D using either the single-model network or the multi-model network
if T == "single":
  D = single_model_network(I, T) # a single network for all types of distortion
else:
  D = multi_model_network(I, T) # a sub-network for each type of distortion

# Step 2: Refine the displacement field D and estimate the distortion parameters P using the model fitting method
P = model_fitting(D, T) # fit a parametric model to D and get P
D = refine(D, P, T) # update D based on P and T

# Step 3: Generate the corrected image C based on the displacement field D using the high-quality resampling method
C = resampling(I, D) # use an efficient and adaptive algorithm to resample I based on D
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a distorted image I and its distortion type T
# Output: a corrected image C

# Step 1: Predict the displacement field D using either the single-model network or the multi-model network
if T == "single":
  # The single-model network consists of an encoder-decoder architecture with skip connections
  # The encoder has six convolutional layers with ReLU activation and max pooling
  # The decoder has six deconvolutional layers with ReLU activation and bilinear upsampling
  # The output layer has two channels for the x and y components of the displacement field
  # The network takes a one-hot vector of the distortion type as an additional input and concatenates it with the feature maps at each layer
  # The network is trained on a large synthetic distortion dataset using L1 loss between the predicted and ground truth displacement fields
  D = single_model_network(I, T) # a single network for all types of distortion
else:
  # The multi-model network consists of six sub-networks, each specialized for one type of distortion
  # Each sub-network has the same architecture as the single-model network, but without the distortion type input
  # Each sub-network also outputs the distortion parameters for its corresponding type of distortion, such as focal length, rotation angle and perspective ratio
  # Each sub-network is trained on a subset of the synthetic distortion dataset using L1 loss for the displacement field and L2 loss for the distortion parameters
  D, P = multi_model_network(I, T) # a sub-network for each type of distortion

# Step 2: Refine the displacement field D and estimate the distortion parameters P using the model fitting method
if T == "single":
  # The model fitting method fits a parametric model to the predicted displacement field using RANSAC
  # The parametric model depends on the distortion type and has a closed-form solution for each case
  # For example, for barrel and pincushion distortion, the model is D(x,y) = k * (x^2 + y^2) * (x,y), where k is the focal length parameter
  # The model fitting method estimates the distortion parameters by solving a linear system of equations
  # The model fitting method also updates the displacement field by applying the inverse of the parametric model to remove any residual distortion
  P = model_fitting(D, T) # fit a parametric model to D and get P
  D = refine(D, P, T) # update D based on P and T
else:
  # The model fitting method is not needed for the multi-model network since it already outputs the distortion parameters
  # However, it can be optionally applied to further refine the displacement field and the distortion parameters if desired
  P = P # use the output of the multi-model network as P
  D = refine(D, P, T) # optionally update D based on P and T

# Step 3: Generate the corrected image C based on the displacement field D using the high-quality resampling method
# The resampling method uses an efficient and adaptive algorithm to resample the distorted image based on the displacement field
# The algorithm first computes a sparse set of control points on a regular grid and interpolates their displacements using bilinear interpolation
# Then, it computes a dense set of control points by subdividing each grid cell into four sub-cells and interpolating their displacements using bicubic interpolation
# Finally, it computes a corrected pixel value for each control point by applying a weighted average of its four nearest neighbors in the distorted image
# The weights are computed based on the distance and angle between the control point and its neighbors
# The resampling method can handle large displacements and preserve sharp edges and fine details in the image
C = resampling(I, D) # use an efficient and adaptive algorithm to resample I based on D

```