---
title: 2302.04638v2 Better Diffusion Models Further Improve Adversarial Training
date: 2023-02-05
---

# [Better Diffusion Models Further Improve Adversarial Training](http://arxiv.org/abs/2302.04638v2)

authors: Zekai Wang, Tianyu Pang, Chao Du, Min Lin, Weiwei Liu, Shuicheng Yan


## What, Why and How

[1]: https://arxiv.org/pdf/2302.04638v2.pdf "Better Diffusion Models Further Improve Adversarial Training - arXiv.org"
[2]: https://arxiv.org/abs/2302.04638 "Better Diffusion Models Further Improve Adversarial Training"
[3]: http://arxiv-export2.library.cornell.edu/abs/2302.04638v2 "[2302.04638v2] Better Diffusion Models Further Improve Adversarial Training"

Here is a summary of the paper:

- **What**: The paper proposes to use a better diffusion model (Karras et al., 2022) to generate data for adversarial training (AT) of neural networks against adversarial attacks.
- **Why**: The paper aims to improve the robustness and accuracy of AT models on various datasets and threat models, without using external data sources.
- **How**: The paper employs the diffusion model that has higher efficiency and image quality than the previous denoising diffusion probabilistic model (DDPM). The paper also introduces a new sampling strategy that balances diversity and quality of the generated data. The paper evaluates the proposed method on RobustBench and shows that it outperforms previous state-of-the-art models by a large margin.

## Main Contributions

The paper claims the following contributions:

- It is the first to use the latest diffusion model (Karras et al., 2022) for AT and show that it can further improve the performance of AT models compared with DDPM.
- It proposes a new sampling strategy that balances diversity and quality of the generated data and adapts to different threat models.
- It achieves state-of-the-art results on RobustBench using only generated data, without external data sources. It also provides results on SVHN and TinyImageNet datasets.

## Method Summary

The method section of the paper consists of three subsections:

- **Diffusion Models for AT**: This subsection reviews the background of diffusion models and AT, and introduces the notation and formulation of the proposed method. It also explains how to use the diffusion model to generate data for AT and how to train the AT model with the generated data.
- **Better Diffusion Models for AT**: This subsection describes the diffusion model used in this paper, which is based on Karras et al. (2022). It highlights the advantages of this model over DDPM, such as higher efficiency, image quality, and stability. It also discusses some implementation details and hyperparameters of the model.
- **Sampling Strategy for AT**: This subsection proposes a new sampling strategy that balances diversity and quality of the generated data. It argues that sampling from different steps of the diffusion process can achieve different trade-offs between diversity and quality, and that different threat models may require different sampling strategies. It also provides some empirical results to support the proposed strategy.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the diffusion model based on Karras et al. (2022)
diffusion_model = DiffusionModel()

# Define the AT model based on WRN-70-16
at_model = ATModel()

# Define the loss function for AT
loss_function = CrossEntropyLoss()

# Define the optimizer for AT
optimizer = SGD()

# Define the number of epochs and batch size for AT
num_epochs = 100
batch_size = 128

# Define the sampling strategy for AT
sampling_strategy = SamplingStrategy()

# Train the AT model with the generated data
for epoch in range(num_epochs):
  # Generate a batch of data from the diffusion model
  data_batch = diffusion_model.sample(batch_size, sampling_strategy)
  
  # Get the labels for the generated data
  label_batch = diffusion_model.get_labels(data_batch)
  
  # Forward pass the data batch through the AT model
  output_batch = at_model(data_batch)
  
  # Compute the loss
  loss = loss_function(output_batch, label_batch)
  
  # Backward pass and update the parameters
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torchvision
import numpy as np

# Define the diffusion model based on Karras et al. (2022)
class DiffusionModel(torch.nn.Module):
  def __init__(self):
    super().__init__()
    # Define the hyperparameters
    self.num_steps = 20 # The number of diffusion steps
    self.beta = 0.02 # The noise level
    self.alpha = 1 - self.beta # The reverse noise level
    self.sigma = np.sqrt(self.beta / (1 - self.alpha)) # The standard deviation of the noise
    self.eps = 1e-6 # A small constant for numerical stability
    
    # Define the network architecture
    self.embedder = torch.nn.Embedding(self.num_steps, 256) # An embedding layer for the step index
    self.encoder = torchvision.models.resnet50(pretrained=True) # A ResNet-50 encoder
    self.decoder = torchvision.models.resnet50(pretrained=True) # A ResNet-50 decoder
    
  def forward(self, x, t):
    # x: a batch of images of shape [batch_size, 3, 32, 32]
    # t: a batch of step indices of shape [batch_size]
    
    # Embed the step index
    e = self.embedder(t) # e: a batch of embeddings of shape [batch_size, 256]
    
    # Encode the image
    z = self.encoder(x) # z: a batch of latent vectors of shape [batch_size, 2048]
    
    # Concatenate the embedding and the latent vector
    h = torch.cat([e, z], dim=1) # h: a batch of hidden vectors of shape [batch_size, 2304]
    
    # Decode the hidden vector
    y = self.decoder(h) # y: a batch of predicted images of shape [batch_size, 3, 32, 32]
    
    return y
  
  def sample(self, batch_size, sampling_strategy):
    # batch_size: the number of images to generate
    # sampling_strategy: an instance of SamplingStrategy class
    
    # Initialize a batch of images with random noise
    x = torch.randn(batch_size, 3, 32, 32) # x: a batch of images of shape [batch_size, 3, 32, 32]
    
    # Sample a batch of step indices according to the sampling strategy
    t = sampling_strategy.sample(batch_size) # t: a batch of step indices of shape [batch_size]
    
    # Apply the reverse diffusion process to generate images
    for i in range(self.num_steps - 1, -1, -1):
      # Get the predicted image for the current step
      y = self.forward(x, t)
      
      # Get the noise scale for the current step
      s = torch.sqrt(self.alpha ** i + self.eps) # s: a scalar
      
      # Add noise to the predicted image and rescale it
      x = (x - y) / s + torch.randn_like(x) * self.sigma
      
      # Clamp the image values to [0, 1] range
      x = torch.clamp(x, 0, 1)
      
    return x
  
  def get_labels(self, x):
    # x: a batch of images of shape [batch_size, 3, 32, 32]
    
    # Use a pretrained classifier to get the labels for the images
    classifier = torchvision.models.resnet50(pretrained=True) # A ResNet-50 classifier
    classifier.eval() # Set the classifier to evaluation mode
    
    with torch.no_grad(): # Disable gradient computation
      logits = classifier(x) # logits: a batch of logits of shape [batch_size, num_classes]
      labels = torch.argmax(logits, dim=1) # labels: a batch of labels of shape [batch_size]
      
    return labels

# Define the AT model based on WRN-70-16
class ATModel(torch.nn.Module):
  def __init__(self):
    super().__init__()
    
    # Define the network architecture
    self.model = torchvision.models.wide_resnet50_2(pretrained=True) # A WRN-70-16 model
    
  def forward(self, x):
    # x: a batch of images of shape [batch_size, 3, 32, 32]
    
    # Pass the image through the model
    y = self.model(x) # y: a batch of logits of shape [batch_size, num_classes]
    
    return y

# Define the loss function for AT
loss_function = torch.nn.CrossEntropyLoss()

# Define the optimizer for AT
optimizer = torch.optim.SGD(at_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)

# Define the number of epochs and batch size for AT
num_epochs = 100
batch_size = 128

# Define the sampling strategy for AT
class SamplingStrategy():
  def __init__(self):
    # Define the hyperparameters
    self.min_step = 1 # The minimum step index to sample from
    self.max_step = 19 # The maximum step index to sample from
    self.prob_step = 0.5 # The probability of sampling from a different step index
    
  def sample(self, batch_size):
    # batch_size: the number of step indices to sample
    
    # Sample a batch of step indices uniformly from [min_step, max_step]
    t = torch.randint(self.min_step, self.max_step + 1, (batch_size,)) # t: a batch of step indices of shape [batch_size]
    
    # Randomly flip some step indices to the opposite end of the range
    mask = torch.bernoulli(torch.ones(batch_size) * self.prob_step) # mask: a batch of binary values of shape [batch_size]
    t = torch.where(mask == 1, self.max_step - t + self.min_step, t) # t: a batch of flipped step indices of shape [batch_size]
    
    return t

# Train the AT model with the generated data
for epoch in range(num_epochs):
  # Generate a batch of data from the diffusion model
  data_batch = diffusion_model.sample(batch_size, sampling_strategy)
  
  # Get the labels for the generated data
  label_batch = diffusion_model.get_labels(data_batch)
  
  # Forward pass the data batch through the AT model
  output_batch = at_model(data_batch)
  
  # Compute the loss
  loss = loss_function(output_batch, label_batch)
  
  # Backward pass and update the parameters
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()
```