---
title: 2112.09130v3 Ensembling Off-the-shelf Models for GAN Training
date: 2021-12-10
---

# [Ensembling Off-the-shelf Models for GAN Training](http://arxiv.org/abs/2112.09130v3)

authors: Nupur Kumari, Richard Zhang, Eli Shechtman, Jun-Yan Zhu


## What, Why and How

[1]: https://arxiv.org/abs/2112.09130 "[2112.09130] Ensembling Off-the-shelf Models for GAN Training - arXiv.org"
[2]: http://export.arxiv.org/abs/2112.09130 "[2112.09130] Ensembling Off-the-shelf Models for GAN Training - arXiv"
[3]: https://arxiv.org/pdf/2112.09130 "arXiv.org e-Print archive"

Hello, this is Bing. I can try to summarize the paper for you. Here is my attempt:

**What**: The paper titled **Ensembling Off-the-shelf Models for GAN Training**[^1^][1] proposes a method to improve generative adversarial network (GAN) training by using an ensemble of pretrained computer vision models as discriminators.

**Why**: The paper aims to leverage the collective "knowledge" from a large bank of pretrained vision models to improve GAN training, which has traditionally been done from scratch in an unsupervised manner. The paper also seeks to find an effective selection mechanism for choosing the most suitable models for the discriminator ensemble.

**How**: The paper introduces a method that probes the linear separability between real and fake samples in pretrained model embeddings, chooses the most accurate model, and progressively adds it to the discriminator ensemble. The paper evaluates the method on various datasets and shows that it can improve GAN performance in both limited data and large-scale settings, achieving better or comparable results to state-of-the-art methods.

## Main Contributions

[1]: https://arxiv.org/abs/2112.09130 "[2112.09130] Ensembling Off-the-shelf Models for GAN Training - arXiv.org"
[2]: http://export.arxiv.org/abs/2112.09130 "[2112.09130] Ensembling Off-the-shelf Models for GAN Training - arXiv"
[3]: https://arxiv.org/pdf/2112.09130 "arXiv.org e-Print archive"

According to the paper[^1^][1], the main contributions are:

- They propose a novel method to improve GAN training by using an ensemble of pretrained computer vision models as discriminators, which can leverage the collective "knowledge" from a large bank of models.
- They introduce a simple and effective selection mechanism for choosing the most suitable models for the discriminator ensemble, based on probing the linear separability between real and fake samples in pretrained model embeddings.
- They demonstrate that their method can improve GAN performance in both limited data and large-scale settings, achieving better or comparable results to state-of-the-art methods on various datasets and metrics.

## Method Summary

[1]: https://arxiv.org/abs/2112.09130 "[2112.09130] Ensembling Off-the-shelf Models for GAN Training - arXiv.org"
[2]: http://export.arxiv.org/abs/2112.09130 "[2112.09130] Ensembling Off-the-shelf Models for GAN Training - arXiv"
[3]: https://arxiv.org/pdf/2112.09130 "arXiv.org e-Print archive"

Here is my attempt to summarize the method section of the paper[^1^][1]:

The paper proposes a method to improve GAN training by using an ensemble of pretrained computer vision models as discriminators. The method consists of three main steps:

- **Model Selection**: The paper introduces a simple and effective selection mechanism for choosing the most suitable models for the discriminator ensemble, based on probing the linear separability between real and fake samples in pretrained model embeddings. The paper defines a metric called **Linear Separability Score (LSS)**, which measures how well a pretrained model can distinguish between real and fake samples using a linear classifier. The paper selects the model with the highest LSS and adds it to the discriminator ensemble. The paper repeats this process until a desired number of models are selected or no further improvement is observed.
- **Model Adaptation**: The paper adapts the selected models to the target domain by fine-tuning them on real samples using a self-supervised contrastive loss. The paper also applies a spectral normalization layer to each model to stabilize the training and avoid mode collapse.
- **Model Ensembling**: The paper combines the outputs of the adapted models using a weighted average, where the weights are proportional to the LSS of each model. The paper trains the GAN using the standard hinge loss, where the generator tries to minimize the ensemble output and the discriminator tries to maximize it.

The paper evaluates the method on various datasets and shows that it can improve GAN performance in both limited data and large-scale settings, achieving better or comparable results to state-of-the-art methods on various metrics.

## Pseudo Code - High level

Here is my attempt to give the high-level pseudo code for this paper:

```python
# Initialize a generator G and an empty discriminator ensemble D
G = Generator()
D = []

# Load a large bank of pretrained computer vision models M
M = load_pretrained_models()

# Define a linear separability score (LSS) function
def LSS(model):
  # Train a linear classifier on real and fake samples using model embeddings
  classifier = train_linear_classifier(model, real_samples, fake_samples)
  # Evaluate the classifier accuracy on a validation set
  accuracy = evaluate_classifier(classifier, model, val_real_samples, val_fake_samples)
  # Return the accuracy as the LSS
  return accuracy

# Select models for the discriminator ensemble using LSS
while len(D) < max_models and improvement > threshold:
  # Compute the LSS for each model in M
  scores = [LSS(model) for model in M]
  # Select the model with the highest LSS
  best_model = M[argmax(scores)]
  # Add the best model to the discriminator ensemble
  D.append(best_model)
  # Remove the best model from the bank of models
  M.remove(best_model)
  # Update the improvement criterion
  improvement = compute_improvement(D)

# Adapt the selected models to the target domain by fine-tuning on real samples
for model in D:
  # Apply spectral normalization to model parameters
  model = spectral_normalize(model)
  # Fine-tune model on real samples using a contrastive loss
  model = fine_tune(model, real_samples, contrastive_loss)

# Define an ensemble output function that combines the outputs of the adapted models
def ensemble_output(samples):
  # Compute the outputs of each model in D for the given samples
  outputs = [model(samples) for model in D]
  # Compute the weights for each model based on their LSS
  weights = [LSS(model) / sum(LSS(m) for m in D) for model in D]
  # Compute the weighted average of the outputs
  average = sum(weight * output for weight, output in zip(weights, outputs))
  # Return the average as the ensemble output
  return average

# Train the GAN using the hinge loss and the ensemble output
for epoch in epochs:
  for batch in batches:
    # Sample real and fake images
    real_images = sample_real_images(batch)
    fake_images = G(sample_noise(batch))
    # Compute the hinge loss for the generator and the discriminator
    g_loss = -ensemble_output(fake_images).mean()
    d_loss = -(ensemble_output(real_images).mean() - ensemble_output(fake_images).mean())
    # Update the generator and discriminator parameters using gradient descent
    update_parameters(G, g_loss)
    update_parameters(D, d_loss)
```

## Pseudo Code - Detail

Here is my attempt to give the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torchvision
import numpy as np

# Define the generator and discriminator architectures
# Assume they are standard convolutional neural networks
class Generator(torch.nn.Module):
  def __init__(self):
    super(Generator, self).__init__()
    # Define the generator layers
    self.layers = torch.nn.Sequential(
      # Input layer: takes a noise vector of size 128 and outputs a feature map of size 512 x 4 x 4
      torch.nn.Linear(128, 512 * 4 * 4),
      torch.nn.BatchNorm1d(512 * 4 * 4),
      torch.nn.ReLU(),
      # Reshape layer: reshapes the feature map to a 4D tensor of size 512 x 4 x 4
      torch.nn.Unflatten(1, (512, 4, 4)),
      # Convolutional layer: takes a feature map of size 512 x 4 x 4 and outputs a feature map of size 256 x 8 x 8
      torch.nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),
      torch.nn.BatchNorm2d(256),
      torch.nn.ReLU(),
      # Convolutional layer: takes a feature map of size 256 x 8 x 8 and outputs a feature map of size 128 x 16 x 16
      torch.nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
      torch.nn.BatchNorm2d(128),
      torch.nn.ReLU(),
      # Convolutional layer: takes a feature map of size 128 x 16 x 16 and outputs a feature map of size 64 x 32 x 32
      torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
      torch.nn.BatchNorm2d(64),
      torch.nn.ReLU(),
      # Convolutional layer: takes a feature map of size 64 x 32 x 32 and outputs a feature map of size 3 x 64 x 64
      torch.nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),
      # Output layer: applies a tanh activation to the feature map to get an image in the range [-1, 1]
      torch.nn.Tanh()
    )

  def forward(self, x):
    # Pass the input through the generator layers and return the output
    return self.layers(x)

class Discriminator(torch.nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()
    # Define the discriminator layers
    self.layers = torch.nn.Sequential(
      # Input layer: takes an image of size 3 x 64 x 64 and outputs a feature map of size 64 x 32 x 32
      torch.nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),
      torch.nn.LeakyReLU(0.2),
      # Convolutional layer: takes a feature map of size 64 x 32 x 32 and outputs a feature map of size 128 x 16 x 16
      torch.nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
      torch.nn.BatchNorm2d(128),
      torch.nn.LeakyReLU(0.2),
      # Convolutional layer: takes a feature map of size 128 x 16 x 16 and outputs a feature map of size 256 x 8 x8
      torch.nn.Conv2d(128,256,kernel_size=4,stride=2,padding=1),
      torch.nn.BatchNorm2d(256),
      torch.nn.LeakyReLU(0.2),
      # Convolutional layer: takes a feature map of size 
256x8x8and outputs a feature map of size 
512x4x4
torch.nn.Conv2d(256,
512,kernel_size=4,stride=2,padding=1),torch.nn.BatchNorm2d(
512),torch.nn.LeakyReLU(
0.2),# Reshape layer: reshapes the feature map to a 
1D tensor of size 
512x4x4torch.nn.Flatten(),# Output layer: takes a 
1D tensor of size 
512x4x4and outputs a scalar value 
torch.nn.Linear(
512x4x4,
1))

def forward(self, x):
# Pass the input through the discriminator layers and return the output
return self.layers(x)

# Define the spectral normalization function
# Assume it is a standard implementation of the paper https://arxiv.org/abs/1802.05957
def spectral_normalize(module):
# Apply spectral normalization to the module parameters and return the module
return torch.nn.utils.spectral_norm(module)

# Define the contrastive loss function
# Assume it is a standard implementation of the paper https://arxiv.org/abs/2002.05709
def contrastive_loss(model, images):
# Compute the contrastive loss for the model and the images and return the loss
return torch.nn.functional.cross_entropy(model(images), labels)

# Define the hinge loss function
def hinge_loss(real_output, fake_output):
# Compute the hinge loss for the real and fake outputs and return the loss
return torch.mean(torch.relu(1 - real_output)) + torch.mean(torch.relu(1 + fake_output))

# Load a large bank of pretrained computer vision models M
# Assume they are standard models from torchvision such as ResNet, VGG, etc.
M = [torchvision.models.resnet18(pretrained=True),
torchvision.models.resnet50(pretrained=True),
torchvision.models.vgg16(pretrained=True),
torchvision.models.vgg19(pretrained=True),
torchvision.models.alexnet(pretrained=True),
torchvision.models.densenet121(pretrained=True),
torchvision.models.densenet201(pretrained=True),
torchvision.models.inception_v3(pretrained=True),
torchvision.models.googlenet(pretrained=True),
torchvision.models.mobilenet_v2(pretrained=True)]

# Initialize a generator G and an empty discriminator ensemble D
G = Generator()
D = []

# Define some hyperparameters
max_models = 5 # The maximum number of models to select for the discriminator ensemble
threshold = 0.01 # The improvement threshold for selecting models
batch_size = 64 # The batch size for training
epochs = 100 # The number of epochs for training
lr = 0.0002 # The learning rate for training
beta1 = 0.5 # The beta1 parameter for Adam optimizer
beta2 = 0.999 # The beta2 parameter for Adam optimizer

# Define some data loaders for training and validation
# Assume they are standard data loaders from torchvision.datasets such as LSUN, CIFAR10, etc.
train_loader = torch.utils.data.DataLoader(torchvision.datasets.LSUN(root='./data', classes=['cat_train'], transform=torchvision.transforms.ToTensor()), batch_size=batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(torchvision.datasets.LSUN(root='./data', classes=['cat_val'], transform=torchvision.transforms.ToTensor()), batch_size=batch_size, shuffle=False)

# Define a device to run the code on (CPU or GPU)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Move the generator to the device
G.to(device)

# Define an optimizer for the generator
g_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))

# Select models for the discriminator ensemble using LSS
while len(D) < max_models and improvement > threshold:
  # Compute the LSS for each model in M
  scores = []
  for model in M:
    # Move the model to the device
    model.to(device)
    # Set the model to evaluation mode
    model.eval()
    # Initialize a list to store the model embeddings
    embeddings = []
    # Initialize a list to store the labels (0 for real, 1 for fake)
    labels = []
    # Loop through the validation data loader
    for images, _ in val_loader:
      # Move the images to the device
      images = images.to(device)
      # Generate fake images using the generator
      fake_images = G(sample_noise(batch_size)).detach()
      # Compute the model embeddings for real and fake images
      real_embeddings = model(images)
      fake_embeddings = model(fake_images)
      # Append the embeddings and labels to the lists
      embeddings.append(torch.cat([real_embeddings, fake_embeddings], dim=0))
      labels.append(torch.cat([torch.zeros(batch_size), torch.ones(batch_size)], dim=0))
    # Concatenate the embeddings and labels along the batch dimension
    embeddings = torch.cat(embeddings, dim=0)
    labels = torch.cat(labels, dim=0)
    # Train a linear classifier on real and fake embeddings using logistic regression
    classifier = torch.nn.Linear(embeddings.size(1), 2)
    classifier.to(device)
    classifier_optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01)
    classifier_criterion = torch.nn.CrossEntropyLoss()
    classifier_epochs = 10
    for epoch in range(classifier_epochs):
      classifier_optimizer.zero_grad()
      classifier_output = classifier(embeddings)
      classifier_loss = classifier