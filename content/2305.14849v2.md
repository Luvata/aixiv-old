---
title: 2305.14849v2 DuDGAN  Improving Class-Conditional GANs via Dual-Diffusion
date: 2023-05-15
---

# [DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion](http://arxiv.org/abs/2305.14849v2)

authors: Taesun Yeom, Minhyeok Lee


## What, Why and How

[1]: https://arxiv.org/abs/2305.14849 "DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion"
[2]: https://arxiv.org/pdf/2303.14849v2.pdf "arXiv:2303.14849v2 [astro-ph.EP] 31 May 2023"
[3]: http://export.arxiv.org/abs/2305.14849 "[2305.14849] DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion"

Here is a summary of the paper in terms of What, Why, and How:

- **What**: The paper proposes a novel approach for class-conditional image generation using GANs called DuDGAN, which incorporates a dual diffusion-based noise injection process.
- **Why**: The paper aims to overcome the limitations of existing class-conditional GANs, such as mode collapse, training instability, and low-quality output in cases of datasets with high intra-class variation. The paper also aims to improve the iteration efficacy of GANs by converging faster than previous methods.
- **How**: The paper introduces three unique networks: a discriminator, a generator, and a classifier. During the training process, Gaussian-mixture noises are injected into the two noise-aware networks, the discriminator and the classifier, in distinct ways. This noisy data helps to prevent overfitting by gradually introducing more challenging tasks, leading to improved model performance. The paper evaluates the method using the AFHQ, Food-101, and CIFAR-10 datasets and compares it with state-of-the-art conditional GAN models for image generation in terms of FID, KID, Precision, and Recall score[^1^][1].


## Main Contributions

[1]: https://arxiv.org/abs/2305.14849 "DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion"
[2]: https://arxiv.org/pdf/2303.14849v2.pdf "arXiv:2303.14849v2 [astro-ph.EP] 31 May 2023"
[3]: http://export.arxiv.org/abs/2305.14849 "[2305.14849] DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion"

The paper lists the following contributions:

- **A novel class-conditional GAN model called DuDGAN that incorporates a dual diffusion-based noise injection process into the discriminator and the classifier networks.**
- **A theoretical analysis of the dual diffusion process and its effects on the model performance and stability.**
- **An extensive experimental evaluation of DuDGAN on three image datasets (AFHQ, Food-101, and CIFAR-10) and a comparison with state-of-the-art conditional GAN models in terms of various metrics (FID, KID, Precision, and Recall score).**
- **A qualitative analysis of the generated images and the noise injection process using visualization techniques.**


## Method Summary

[1]: https://arxiv.org/abs/2305.14849 "DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion"
[2]: https://arxiv.org/pdf/2303.14849v2.pdf "arXiv:2303.14849v2 [astro-ph.EP] 31 May 2023"
[3]: http://export.arxiv.org/abs/2305.14849 "[2305.14849] DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion"

Here is a summary of the method section of the paper:

- **The paper introduces three unique networks: a discriminator, a generator, and a classifier. The discriminator and the generator are based on the SNGAN architecture [14], while the classifier is based on the ResNet-18 architecture [15].**
- **The paper defines two types of Gaussian-mixture noises: a global noise that is shared across all classes and a local noise that is specific to each class. The global noise has a fixed variance, while the local noise has a class-dependent variance that is learned during training.**
- **The paper proposes a dual diffusion process that injects the Gaussian-mixture noises into the discriminator and the classifier networks in distinct ways. The discriminator receives both global and local noises, while the classifier receives only global noise. The noise injection is done by adding the noise to the input images or by replacing some of the convolutional layers with noisy convolutional layers.**
- **The paper defines three loss functions: an adversarial loss that measures the discrepancy between real and generated images, a classification loss that measures the accuracy of classifying real and generated images, and a regularization loss that penalizes large variances of local noises. The total loss is a weighted sum of these three losses.**
- **The paper trains the model using an alternating optimization scheme that updates the generator and the classifier networks in one step and then updates the discriminator network in another step. The paper uses Adam optimizer [16] with a learning rate of 0.0002 and a batch size of 64 for all experiments.**


## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the discriminator, generator, and classifier networks
D = SNGAN_Discriminator()
G = SNGAN_Generator()
C = ResNet18_Classifier()

# Define the Gaussian-mixture noises
global_noise = Normal(0, sigma_g) # sigma_g is a fixed parameter
local_noise = Normal(0, sigma_l) # sigma_l is a learnable parameter for each class

# Define the loss functions
adversarial_loss = hinge_loss(D(G(z, y)), D(x)) # z is a latent vector, y is a class label, x is a real image
classification_loss = cross_entropy_loss(C(G(z, y)), y) + cross_entropy_loss(C(x), y)
regularization_loss = L2_loss(sigma_l)

# Define the total loss
total_loss = adversarial_loss + lambda_1 * classification_loss + lambda_2 * regularization_loss # lambda_1 and lambda_2 are hyperparameters

# Define the optimizers
optimizer_D = Adam(D.parameters(), lr=0.0002)
optimizer_G = Adam(G.parameters(), lr=0.0002)
optimizer_C = Adam(C.parameters(), lr=0.0002)

# Train the model
for epoch in range(num_epochs):
  for batch in data_loader:
    # Sample z and y
    z = sample_from_normal(0, 1)
    y = sample_from_uniform(0, num_classes)

    # Inject global and local noises to the discriminator
    D.inject_noise(global_noise, local_noise)

    # Inject global noise to the classifier
    C.inject_noise(global_noise)

    # Update the generator and the classifier networks
    optimizer_G.zero_grad()
    optimizer_C.zero_grad()
    total_loss.backward()
    optimizer_G.step()
    optimizer_C.step()

    # Update the discriminator network
    optimizer_D.zero_grad()
    adversarial_loss.backward()
    optimizer_D.step()
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# Define the hyperparameters
num_epochs = 100 # number of training epochs
num_classes = 10 # number of classes in the dataset
latent_dim = 128 # dimension of the latent vector z
sigma_g = 0.1 # variance of the global noise
lambda_1 = 0.1 # weight for the classification loss
lambda_2 = 0.01 # weight for the regularization loss
beta_1 = 0.5 # beta1 parameter for Adam optimizer
beta_2 = 0.999 # beta2 parameter for Adam optimizer

# Define the SNGAN discriminator network
class SNGAN_Discriminator(nn.Module):
  def __init__(self):
    super(SNGAN_Discriminator, self).__init__()
    # Define the convolutional layers with spectral normalization
    self.conv1 = nn.utils.spectral_norm(nn.Conv2d(3, 64, 3, 1, 1)) # input: (3, 32, 32), output: (64, 32, 32)
    self.conv2 = nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, 2, 1)) # input: (64, 32, 32), output: (128, 16, 16)
    self.conv3 = nn.utils.spectral_norm(nn.Conv2d(128, 256, 4, 2, 1)) # input: (128, 16, 16), output: (256, 8, 8)
    self.conv4 = nn.utils.spectral_norm(nn.Conv2d(256, 512, 4, 2, 1)) # input: (256, 8, 8), output: (512, 4, 4)
    self.conv5 = nn.utils.spectral_norm(nn.Conv2d(512 + num_classes, 1024, 4)) # input: (512 + num_classes, 4 ,4), output: (1024 ,1 ,1)
    self.conv6 = nn.utils.spectral_norm(nn.Conv2d(1024 ,1 ,1)) # input: (1024 ,1 ,1), output: (1 ,1 ,1)

    # Define the activation functions
    self.relu = nn.ReLU()
    self.sigmoid = nn.Sigmoid()

    # Define a flag to indicate whether to inject noise or not
    self.inject_noise = False

    # Define a list to store the noisy convolutional layers
    self.noisy_convs = []

  
  def forward(self, x):
    # x is a tensor of shape (batch_size ,3 ,32 ,32)
    x = self.relu(self.conv1(x)) # x is now of shape (batch_size ,64 ,32 ,32)
    x = self.relu(self.conv2(x)) # x is now of shape (batch_size ,128 ,16 ,16)
    x = self.relu(self.conv3(x)) # x is now of shape (batch_size ,256 ,8 ,8)
    x = self.relu(self.conv4(x)) # x is now of shape (batch_size ,512 ,4 ,4)

    if self.inject_noise:
      # Inject global and local noises to x by adding or replacing some convolutional layers with noisy convolutional layers
      for noisy_conv in self.noisy_convs:
        x = noisy_conv(x)

      # Reset the flag and the list after injecting noise
      self.inject_noise = False
      self.noisy_convs = []

    else:
      # Concatenate the class label y to x along the channel dimension
      y = y.view(-1 ,num_classes ,1 ,1) # y is a tensor of shape (batch_size ,num_classes ,1 ,1)
      y = y.repeat(1 ,1 ,4 ,4) # y is now of shape (batch_size ,num_classes ,4 ,4)
      x = torch.cat([x ,y] ,-3) # x is now of shape (batch_size ,(512 + num_classes) ,4 ,4)

      x = self.relu(self.conv5(x)) # x is now of shape (batch_size ,1024 ,1 ,1)
      x = self.sigmoid(self.conv6(x)) # x is now of shape (batch_size ,1 ,1)

      return x.squeeze() # return a tensor of shape (batch_size)


# Define a function to inject global and local noises to the discriminator network
def inject_noise(self, global_noise, local_noise):
  # Set the flag to True
  self.inject_noise = True

  # Sample global and local noises from Gaussian distributions
  global_noise = global_noise.sample() # a tensor of shape (batch_size ,1 ,32 ,32)
  local_noise = local_noise.sample() # a tensor of shape (batch_size ,num_classes ,32 ,32)

  # Add global noise to the input image
  self.noisy_convs.append(lambda x: x + global_noise)

  # Replace the first convolutional layer with a noisy convolutional layer that adds local noise
  self.noisy_convs.append(lambda x: self.relu(self.conv1(x + local_noise)))

  # Replace the fourth convolutional layer with a noisy convolutional layer that concatenates local noise
  self.noisy_convs.append(lambda x: self.relu(self.conv4(torch.cat([x ,local_noise] ,-3))))


# Define the SNGAN generator network
class SNGAN_Generator(nn.Module):
  def __init__(self):
    super(SNGAN_Generator, self).__init__()
    # Define the linear layer that maps the latent vector z and the class label y to a feature vector
    self.linear = nn.utils.spectral_norm(nn.Linear(latent_dim + num_classes, 4 * 4 * 512)) # input: (latent_dim + num_classes), output: (4 * 4 * 512)

    # Define the deconvolutional layers with spectral normalization
    self.deconv1 = nn.utils.spectral_norm(nn.ConvTranspose2d(512, 256, 4, 2, 1)) # input: (512, 4, 4), output: (256, 8, 8)
    self.deconv2 = nn.utils.spectral_norm(nn.ConvTranspose2d(256, 128, 4, 2, 1)) # input: (256, 8, 8), output: (128, 16, 16)
    self.deconv3 = nn.utils.spectral_norm(nn.ConvTranspose2d(128, 64, 4, 2, 1)) # input: (128, 16, 16), output: (64, 32, 32)
    self.deconv4 = nn.utils.spectral_norm(nn.ConvTranspose2d(64, 3, 3, 1, 1)) # input: (64, 32, 32), output: (3, 32, 32)

    # Define the activation functions
    self.relu = nn.ReLU()
    self.tanh = nn.Tanh()

  
  def forward(self, z):
    # z is a tensor of shape (batch_size ,latent_dim)
    y = y.view(-1 ,num_classes) # y is a tensor of shape (batch_size ,num_classes)
    z = torch.cat([z ,y] ,-1) # z is now of shape (batch_size ,(latent_dim + num_classes))

    x = self.relu(self.linear(z)) # x is now of shape (batch_size ,4 * 4 *512)
    x = x.view(-1 ,512 ,4 ,4) # x is now of shape (batch_size ,512 ,4 ,4)

    x = self.relu(self.deconv1(x)) # x is now of shape (batch_size ,256 ,8 ,8)
    x = self.relu(self.deconv2(x)) # x is now of shape (batch_size ,128 ,16 ,16)
    x = self.relu(self.deconv3(x)) # x is now of shape (batch_size ,64 ,32 ,32)
    x = self.tanh(self.deconv4(x)) # x is now of shape (batch_size ,3 ,32 ,32)

    return x


# Define the ResNet-18 classifier network
class ResNet18_Classifier(nn.Module):
  
```