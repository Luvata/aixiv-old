---
title: 2206.08954v2 Bag of Image Patch Embedding Behind the Success of Self-Supervised Learning
date: 2022-06-09
---

# [Bag of Image Patch Embedding Behind the Success of Self-Supervised Learning](http://arxiv.org/abs/2206.08954v2)

authors: Yubei Chen, Adrien Bardes, Zengyi Li, Yann LeCun


## What, Why and How

[1]: https://arxiv.org/abs/2206.00272 "[2206.00272] Vision GNN: An Image is Worth Graph of Nodes - arXiv.org"
[2]: http://export.arxiv.org/abs/2006.08954v2 "[2006.08954v2] Fractal dimension of premixed flames in multifractal ..."
[3]: https://arxiv.org/pdf/2206.09455.pdf "arXiv.org e-Print archive"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a new Vision GNN (ViG) architecture that represents images as graphs and extracts graph-level features for visual tasks.
- **Why**: The paper argues that the existing convolutional neural network and transformer models are not flexible enough to capture irregular and complex objects in images, and that graph neural networks (GNNs) can better model the relationships among image patches.
- **How**: The paper introduces two basic modules for ViG: Grapher module with graph convolution for aggregating and updating graph information, and FFN module with two linear layers for node feature transformation. The paper also builds isotropic and pyramid architectures of ViG with different model sizes. The paper evaluates ViG on image recognition and object detection tasks and shows its superiority over baseline models.



## Main Contributions

[1]: https://arxiv.org/abs/2206.00272 "[2206.00272] Vision GNN: An Image is Worth Graph of Nodes - arXiv.org"
[2]: http://export.arxiv.org/abs/2006.08954v2 "[2006.08954v2] Fractal dimension of premixed flames in multifractal ..."
[3]: https://arxiv.org/pdf/2206.09455.pdf "arXiv.org e-Print archive"

According to the paper[^1^][1], the main contributions are:

- **Proposing a new Vision GNN (ViG) architecture** that represents images as graphs and extracts graph-level features for visual tasks.
- **Introducing two basic modules for ViG**: Grapher module with graph convolution for aggregating and updating graph information, and FFN module with two linear layers for node feature transformation.
- **Building isotropic and pyramid architectures of ViG** with different model sizes and showing their trade-offs between performance and efficiency.
- **Evaluating ViG on image recognition and object detection tasks** and demonstrating its superiority over baseline models such as CNNs, Transformers, and other GNNs.
- **Providing PyTorch and MindSpore code** for reproducing the experiments and facilitating future research on GNNs for general visual tasks.


## Method Summary

[1]: https://arxiv.org/abs/2206.00272 "[2206.00272] Vision GNN: An Image is Worth Graph of Nodes - arXiv.org"
[2]: http://export.arxiv.org/abs/2006.08954v2 "[2006.08954v2] Fractal dimension of premixed flames in multifractal ..."
[3]: https://arxiv.org/pdf/2206.09455.pdf "arXiv.org e-Print archive"

Here is a summary of the method section of the paper[^1^][1]:

- The paper first describes how to **construct a graph from an image** by splitting the image into patches and connecting them with edges based on their spatial proximity and feature similarity.
- The paper then introduces the **Vision GNN (ViG) model** that consists of two basic modules: Grapher module and FFN module. The Grapher module applies graph convolution to aggregate and update the node features, while the FFN module applies two linear layers to transform the node features. The paper also describes how to use residual connections, layer normalization, and dropout in the ViG model.
- The paper then presents two variants of ViG: **isotropic ViG and pyramid ViG**. The isotropic ViG applies the same number of Grapher and FFN modules to all nodes, while the pyramid ViG applies different numbers of modules to different levels of nodes based on their resolution. The paper also discusses how to adjust the model size by changing the number of nodes, channels, heads, and layers.
- The paper then explains how to **adapt ViG to different visual tasks** such as image recognition and object detection. For image recognition, the paper uses a global average pooling layer and a linear classifier on top of the ViG model. For object detection, the paper uses a region proposal network (RPN) and a region-based convolutional neural network (R-CNN) on top of the ViG model.


## Pseudo Code - High level

[1]: https://arxiv.org/abs/2206.00272 "[2206.00272] Vision GNN: An Image is Worth Graph of Nodes - arXiv.org"
[2]: http://export.arxiv.org/abs/2006.08954v2 "[2006.08954v2] Fractal dimension of premixed flames in multifractal ..."
[3]: https://arxiv.org/pdf/2206.09455.pdf "arXiv.org e-Print archive"

Here is a high-level pseudo code for the paper[^1^][1]:

```python
# Input: an image x
# Output: a graph-level feature z

# Construct a graph from the image
patches = split_image(x) # split the image into patches
nodes = embed_patches(patches) # embed the patches into node features
edges = connect_nodes(nodes) # connect the nodes based on proximity and similarity

# Initialize the graph-level feature
z = global_average_pooling(nodes)

# Apply Vision GNN (ViG) model
for L in range(num_layers):
  # Apply Grapher module
  nodes = graph_convolution(nodes, edges) # aggregate and update node features
  nodes = layer_norm(nodes) # apply layer normalization
  nodes = dropout(nodes) # apply dropout
  
  # Apply FFN module
  nodes = linear(nodes) # apply linear transformation
  nodes = gelu(nodes) # apply gelu activation
  nodes = linear(nodes) # apply linear transformation
  nodes = layer_norm(nodes) # apply layer normalization
  nodes = dropout(nodes) # apply dropout
  
  # Update the graph-level feature
  z = z + global_average_pooling(nodes)

# Return the graph-level feature
return z
```


## Pseudo Code - Detail

[1]: https://arxiv.org/abs/2206.00272 "[2206.00272] Vision GNN: An Image is Worth Graph of Nodes - arXiv.org"
[2]: http://export.arxiv.org/abs/2006.08954v2 "[2006.08954v2] Fractal dimension of premixed flames in multifractal ..."
[3]: https://arxiv.org/pdf/2206.09455.pdf "arXiv.org e-Print archive"

Here is a detailed pseudo code for the paper[^1^][1]:

```python
# Input: an image x
# Output: a graph-level feature z

# Define the hyperparameters
num_nodes = 196 # number of nodes in the graph
num_channels = 768 # number of channels in the node features
num_heads = 12 # number of heads in the graph convolution
num_layers = 12 # number of layers in the ViG model
dropout_rate = 0.1 # dropout rate

# Define the embedding layer
embedding_layer = Linear(num_channels) # linear layer for patch embedding

# Define the Grapher module
grapher_module = Grapher(num_channels, num_heads, dropout_rate) # graph convolution layer

# Define the FFN module
ffn_module = FFN(num_channels, dropout_rate) # feed-forward network layer

# Define the pooling layer
pooling_layer = GlobalAveragePooling() # global average pooling layer

# Define the classifier layer
classifier_layer = Linear(num_classes) # linear layer for classification

# Construct a graph from the image
patches = split_image(x, num_nodes) # split the image into patches of size sqrt(num_nodes) x sqrt(num_nodes)
nodes = embedding_layer(patches) # embed the patches into node features of size num_channels
edges = connect_nodes(nodes) # connect the nodes based on proximity and similarity using KNN algorithm

# Initialize the graph-level feature
z = pooling_layer(nodes) # apply global average pooling to get a feature vector of size num_channels

# Apply Vision GNN (ViG) model
for L in range(num_layers):
  # Apply Grapher module
  nodes_res = nodes # store the node features as residual
  nodes = grapher_module(nodes, edges) # apply graph convolution to aggregate and update node features
  nodes = nodes + nodes_res # add residual connection
  nodes = layer_norm(nodes) # apply layer normalization
  nodes = dropout(nodes, dropout_rate) # apply dropout
  
  # Apply FFN module
  nodes_res = nodes # store the node features as residual
  nodes = ffn_module(nodes) # apply feed-forward network to transform node features
  nodes = nodes + nodes_res # add residual connection
  nodes = layer_norm(nodes) # apply layer normalization
  nodes = dropout(nodes, dropout_rate) # apply dropout
  
  # Update the graph-level feature
  z = z + pooling_layer(nodes) # add global average pooling of node features to the graph-level feature

# Apply classifier layer
y = classifier_layer(z) # apply linear transformation to get a prediction vector of size num_classes

# Return the graph-level feature and the prediction vector
return z, y
```