---
title: 1707.05572v1 Fast Feature Fool  A data independent approach to universal adversarial perturbations
date: 2017-07-06
---

# [Fast Feature Fool: A data independent approach to universal adversarial perturbations](http://arxiv.org/abs/1707.05572v1)

authors: Konda Reddy Mopuri, Utsav Garg, R. Venkatesh Babu


## What, Why and How

[1]: https://arxiv.org/abs/1707.05572 "[1707.05572] Fast Feature Fool: A data independent approach to ..."
[2]: https://arxiv.org/pdf/1707.05572 "Fast Feature Fool: A data independent approach to universal ... - arXiv.org"
[3]: http://export.arxiv.org/abs/1701.05572v1 "[1701.05572v1] Transplanckian Censorship and Global Cosmic Strings"

Here is a summary of the paper:

- **What**: The paper proposes a novel data independent approach to generate universal adversarial perturbations for a range of CNNs trained for object recognition. Universal adversarial perturbations are image agnostic perturbations that can fool CNNs to misclassify any input image.
- **Why**: The paper aims to address the limitations of existing methods that require access to the training data of the CNNs and compute adversarial perturbations via complex optimization. The paper also aims to demonstrate the transferability of the proposed perturbations across multiple network architectures trained either on same or different data.
- **How**: The paper introduces a method called Fast Feature Fool (FFF) that generates universal perturbations by fooling the features learned at multiple layers of the CNNs. FFF does not require any training data and can be applied to any CNN without knowing its architecture or parameters. FFF iteratively updates the perturbation by maximizing the feature difference between clean and perturbed images at each layer. FFF also incorporates a projection step to ensure that the perturbation is quasi-imperceptible and bounded by a norm constraint. The paper evaluates FFF on various CNNs trained on ImageNet and CIFAR-10 datasets and shows that it achieves high fooling rates and transferability.

## Main Contributions

The paper claims the following contributions:

- It proposes the first data independent approach to generate universal adversarial perturbations for a range of CNNs trained for object recognition.
- It introduces a novel method called Fast Feature Fool (FFF) that fools the features learned at multiple layers of the CNNs without requiring any training data or knowledge of the CNN architecture or parameters.
- It demonstrates the impressive fooling rates and surprising transferability of the proposed universal perturbations across multiple network architectures trained either on same or different data.

## Method Summary

[1]: https://arxiv.org/abs/1707.05572 "[1707.05572] Fast Feature Fool: A data independent approach to ..."
[2]: https://arxiv.org/pdf/1707.05572 "Fast Feature Fool: A data independent approach to universal ... - arXiv.org"
[3]: http://export.arxiv.org/abs/1701.05572v1 "[1701.05572v1] Transplanckian Censorship and Global Cosmic Strings"

Here is a summary of the method section of the paper:

- The paper introduces a method called **Fast Feature Fool (FFF)** that generates universal adversarial perturbations by fooling the features learned at multiple layers of the CNNs.
- FFF does not require any training data and can be applied to any CNN without knowing its architecture or parameters.
- FFF iteratively updates the perturbation by maximizing the feature difference between clean and perturbed images at each layer. The feature difference is measured by the cosine distance between the feature vectors extracted from the CNN.
- FFF also incorporates a projection step to ensure that the perturbation is quasi-imperceptible and bounded by a norm constraint. The projection step minimizes the L2 norm of the perturbation while preserving its direction.
- FFF terminates when either the fooling rate reaches a desired threshold or the maximum number of iterations is reached. The fooling rate is defined as the fraction of images that are misclassified by the CNN after adding the perturbation.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a CNN model F, a set of layers L, a norm bound xi, a fooling rate threshold rho, and a maximum number of iterations T
# Output: a universal adversarial perturbation v

# Initialize v to zero
v = 0

# Initialize the fooling rate to zero
fr = 0

# Initialize the iteration counter to zero
t = 0

# Loop until the fooling rate reaches the threshold or the maximum number of iterations is reached
while fr < rho and t < T:

  # Sample a clean image x from any distribution
  x = sample_image()

  # Add the perturbation to the image
  x_adv = x + v

  # Loop over the layers in L
  for l in L:

    # Extract the feature vectors from the clean and perturbed images at layer l
    f_x = F(x, l)
    f_x_adv = F(x_adv, l)

    # Compute the cosine distance between the feature vectors
    d = cosine_distance(f_x, f_x_adv)

    # Compute the gradient of the distance with respect to the perturbation
    g = gradient(d, v)

    # Update the perturbation by adding a small step in the direction of the gradient
    v = v + epsilon * g

    # Project the perturbation onto the L2 ball of radius xi
    v = project(v, xi)

  # Compute the fooling rate on a validation set of images
  fr = fooling_rate(F, v)

  # Increment the iteration counter
  t = t + 1

# Return the perturbation
return v
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import torch
import torchvision
import torchvision.transforms as transforms

# Define the CNN model F (e.g., VGG-16)
F = torchvision.models.vgg16(pretrained=True)

# Define the set of layers L (e.g., conv1_1, conv2_1, conv3_1, conv4_1, conv5_1)
L = [F.features[0], F.features[5], F.features[10], F.features[17], F.features[24]]

# Define the norm bound xi (e.g., 10)
xi = 10

# Define the fooling rate threshold rho (e.g., 0.9)
rho = 0.9

# Define the maximum number of iterations T (e.g., 1000)
T = 1000

# Define the step size epsilon (e.g., 0.01)
epsilon = 0.01

# Define the image size (e.g., 224 x 224 x 3)
img_size = (224, 224, 3)

# Define the image transform function to normalize and resize the images
transform = transforms.Compose([
    transforms.Resize(img_size[:2]),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

# Load a validation set of images (e.g., ImageNet validation set)
val_set = torchvision.datasets.ImageFolder(root='imagenet_val', transform=transform)
val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True)

# Initialize v to zero
v = torch.zeros(img_size)

# Initialize the fooling rate to zero
fr = 0

# Initialize the iteration counter to zero
t = 0

# Loop until the fooling rate reaches the threshold or the maximum number of iterations is reached
while fr < rho and t < T:

  # Sample a clean image x from any distribution (e.g., uniform random noise)
  x = torch.rand(img_size)

  # Add the perturbation to the image
  x_adv = x + v

  # Loop over the layers in L
  for l in L:

    # Extract the feature vectors from the clean and perturbed images at layer l
    f_x = l(x.unsqueeze(0))
    f_x_adv = l(x_adv.unsqueeze(0))

    # Compute the cosine distance between the feature vectors
    d = torch.nn.functional.cosine_similarity(f_x, f_x_adv)

    # Compute the gradient of the distance with respect to the perturbation
    d.backward()
    g = v.grad

    # Update the perturbation by adding a small step in the direction of the gradient
    v = v + epsilon * g

    # Project the perturbation onto the L2 ball of radius xi
    v = v / torch.max(torch.norm(v), xi)

    # Detach the perturbation from the computation graph and clear the gradients
    v = v.detach()
    v.grad.zero_()

  # Compute the fooling rate on a validation set of images
  fr = 0
  n = 0
  for x, y in val_loader:
    # Add the perturbation to the images
    x_adv = x + v

    # Get the predictions from the CNN model
    y_pred = F(x)
    y_pred_adv = F(x_adv)

    # Get the top-1 labels from the predictions
    y_label = torch.argmax(y_pred, dim=1)
    y_label_adv = torch.argmax(y_pred_adv, dim=1)

    # Count the number of images that are misclassified by the perturbation
    n += x.size(0)
    fr += torch.sum(y_label != y_label_adv).item()

  # Normalize the fooling rate by the number of images
  fr /= n

  # Increment the iteration counter
  t += 1

# Return the perturbation
return v
```