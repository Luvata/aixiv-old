---
title: 2305.17493v2 The Curse of Recursion  Training on Generated Data Makes Models Forget
date: 2023-05-18
---

# [The Curse of Recursion: Training on Generated Data Makes Models Forget](http://arxiv.org/abs/2305.17493v2)

authors: Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, Ross Anderson


## What, Why and How

[1]: https://arxiv.org/pdf/2305.17493v2.pdf "Yiren Zhao Yarin Gal arXiv:2305.17493v2 [cs.LG] 31 May 2023"
[2]: https://arxiv.org/abs/2305.17493 "The Curse of Recursion: Training on Generated Data Makes Models Forget"
[3]: http://export.arxiv.org/abs/2305.17493v2 "[2305.17493v2] The Curse of Recursion: Training on Generated Data Makes ..."

Here is a summary of the paper:

- **What**: The paper studies the effect of training generative models on data that contains output from previous generative models. It calls this effect **model collapse**, where the models lose diversity and forget the original data distribution.
- **Why**: The paper aims to understand the future implications of large language models (LLMs) that are trained on web data that may contain a lot of text generated by other LLMs. It argues that this may lead to irreversible defects in the models and degrade their performance and usefulness.
- **How**: The paper demonstrates the phenomenon of model collapse in various generative models, such as variational autoencoders, Gaussian mixture models and LLMs. It provides theoretical analysis and empirical evidence to explain why model collapse occurs and how it affects the models' quality and diversity. It also discusses some possible solutions and challenges to mitigate model collapse.


## Main Contributions

[1]: https://arxiv.org/pdf/2305.17493v2.pdf "Yiren Zhao Yarin Gal arXiv:2305.17493v2 [cs.LG] 31 May 2023"
[2]: https://arxiv.org/abs/2305.17493 "[2305.17493] Model Dementia: Generated Data Makes Models Forget - arXiv.org"
[3]: http://export.arxiv.org/abs/2305.17493v2 "[2305.17493v2] The Curse of Recursion: Training on Generated Data Makes ..."

According to the paper, some of its contributions are:

- It introduces the concept of **model collapse**, where generative models trained on data that contains output from previous generative models lose diversity and forget the original data distribution.
- It shows that model collapse can occur in various generative models, such as **variational autoencoders, Gaussian mixture models and large language models**.
- It provides **theoretical analysis** and **empirical evidence** to explain why model collapse occurs and how it affects the models' quality and diversity.
- It discusses some **possible solutions** and **challenges** to mitigate model collapse and preserve the benefits of training from large-scale web data.

## Method Summary

[1]: https://arxiv.org/pdf/2305.17493v2.pdf "Yiren Zhao Yarin Gal arXiv:2305.17493v2 [cs.LG] 31 May 2023"
[2]: https://arxiv.org/abs/2305.17493 "[2305.17493] Model Dementia: Generated Data Makes Models Forget - arXiv.org"
[3]: http://export.arxiv.org/abs/2305.17493v2 "[2305.17493v2] The Curse of Recursion: Training on Generated Data Makes ..."

Here is a summary of the method section of the paper:

- The paper uses three types of generative models to illustrate the phenomenon of model collapse: **variational autoencoders (VAEs)**, **Gaussian mixture models (GMMs)** and **large language models (LLMs)**.
- The paper defines model collapse as the situation where a generative model trained on data that contains output from a previous generative model loses diversity and forgets the original data distribution. It formalizes this notion using the **Kullback-Leibler divergence (KL-divergence)** and the **Jensen-Shannon divergence (JS-divergence)** as measures of similarity between data distributions.
- The paper provides theoretical analysis to explain why model collapse occurs and how it affects the models' quality and diversity. It shows that model collapse is inevitable for any learned generative model under certain conditions, such as when the data contains a mixture of human-generated and model-generated content, or when the model is trained with a fixed learning rate or a fixed number of iterations.
- The paper also provides empirical evidence to support its theoretical claims. It conducts experiments on synthetic and real-world datasets using VAEs, GMMs and LLMs. It shows that model collapse leads to reduced quality and diversity of the generated samples, as well as increased vulnerability to adversarial attacks. It also shows that model collapse can be mitigated by using different training strategies, such as increasing the learning rate, reducing the number of iterations, or using human feedback.

## Pseudo Code - High level

[1]: https://arxiv.org/pdf/2305.17493v2.pdf "Yiren Zhao Yarin Gal arXiv:2305.17493v2 [cs.LG] 31 May 2023"
[2]: https://arxiv.org/abs/2305.17493 "[2305.17493] Model Dementia: Generated Data Makes Models Forget - arXiv.org"
[3]: http://export.arxiv.org/abs/2305.17493v2 "[2305.17493v2] The Curse of Recursion: Training on Generated Data Makes ..."

Here is a high-level pseudo code for the paper:

- Define three types of generative models: VAEs, GMMs and LLMs
- Define model collapse as the loss of diversity and originality in generative models trained on data that contains output from previous generative models
- Define KL-divergence and JS-divergence as measures of similarity between data distributions
- For each type of generative model:
  - Provide theoretical analysis to show why model collapse occurs and how it affects the model's quality and diversity
  - Conduct experiments on synthetic and real-world datasets to demonstrate model collapse empirically
  - Discuss possible solutions and challenges to mitigate model collapse


## Pseudo Code - Detail

[1]: https://arxiv.org/pdf/2305.17493v2.pdf "Yiren Zhao Yarin Gal arXiv:2305.17493v2 [cs.LG] 31 May 2023"
[2]: https://arxiv.org/abs/2305.17493 "[2305.17493] Model Dementia: Generated Data Makes Models Forget - arXiv.org"
[3]: http://export.arxiv.org/abs/2305.17493v2 "[2305.17493v2] The Curse of Recursion: Training on Generated Data Makes ..."

Here is a detailed pseudo code to implement the paper:

- Import libraries for generative models, data processing and evaluation metrics
- Define three types of generative models: VAEs, GMMs and LLMs
  - For VAEs, define the encoder, decoder and loss functions
  - For GMMs, define the mixture components, parameters and likelihood function
  - For LLMs, define the transformer architecture, tokenizer and loss function
- Define model collapse as the loss of diversity and originality in generative models trained on data that contains output from previous generative models
  - Define KL-divergence and JS-divergence as measures of similarity between data distributions
  - Define quality and diversity metrics for evaluating generative models, such as perplexity, BLEU score, self-BLEU score and inception score
- For each type of generative model:
  - Load a synthetic or real-world dataset that contains human-generated and model-generated content
  - Split the dataset into training and test sets
  - Train the generative model on the training set using gradient descent with a fixed learning rate or a fixed number of iterations
  - Generate samples from the trained model and compare them with the test set using KL-divergence, JS-divergence, quality and diversity metrics
  - Plot the results and analyze the effect of model collapse on the model's performance
  - Repeat the experiment with different training strategies, such as increasing the learning rate, reducing the number of iterations, or using human feedback
  - Compare the results and discuss the possible solutions and challenges to mitigate model collapse