---
title: 2305.18035v2 Physics-Informed Computer Vision  A Review and Perspectives
date: 2023-05-19
---

# [Physics-Informed Computer Vision: A Review and Perspectives](http://arxiv.org/abs/2305.18035v2)

authors: Chayan Banerjee, Kien Nguyen, Clinton Fookes, George Karniadakis


## What, Why and How

[1]: https://arxiv.org/pdf/2305.18035v2 "arXiv:2305.18035v2 [eess.IV] 1 Jun 2023"
[2]: https://arxiv.org/abs/2305.18035 "Physics-Informed Computer Vision: A Review and Perspectives"
[3]: https://arxiv-export-lb.library.cornell.edu/abs/2305.18035v2 "[2305.18035v2] Physics-Informed Computer Vision: A Review and Perspectives"

Here is a summary of the paper:

- **What**: The paper is a review and perspective of physics-informed computer vision (PICV), which is the incorporation of physical laws and knowledge into machine learning frameworks for computer vision tasks[^1^][1].
- **Why**: The paper aims to explore the utility and challenges of PICV for interpreting and understanding visual data, as well as to highlight the gaps and opportunities for future research[^1^][1].
- **How**: The paper presents a systematic literature review of PICV approaches, organized by a taxonomy of stages in the computer vision pipeline. The paper analyzes how PICV methods modify data, networks, or losses to include physical rules, and what physical processes are modeled and formulated for integration. The paper also discusses open problems and examples of PICV applications[^1^][1].

## Main Contributions

According to the paper, the main contributions are:

- A comprehensive survey of PICV methods, covering a wide range of computer vision tasks and physical domains.
- A novel taxonomy of PICV stages, based on how physical information is incorporated into data, networks, or losses.
- A critical analysis of the strengths and limitations of PICV methods, as well as the challenges and opportunities for future research.

## Method Summary

The method section of the paper consists of four subsections:

- **PICV Taxonomy**: This subsection introduces the proposed taxonomy of PICV stages, which are data-driven, physics-driven, and hybrid. Data-driven stages use physical information to modify the data or observation, such as data augmentation, preprocessing, or postprocessing. Physics-driven stages use physical information to modify the network or model, such as network architecture, regularization, or initialization. Hybrid stages use physical information to modify the loss or objective function, such as physics-based losses, constraints, or priors.
- **PICV Formulation**: This subsection describes how physical information is formulated and integrated into PICV methods. It distinguishes between explicit and implicit formulations, where explicit formulations directly use physical equations or models in the learning process, and implicit formulations indirectly use physical features or properties in the learning process. It also discusses different types of physical information sources, such as analytical models, numerical simulations, or empirical measurements.
- **PICV Analysis**: This subsection analyzes the existing PICV methods according to the proposed taxonomy and formulation. It provides a table that summarizes the PICV methods for each computer vision task and physical domain, as well as the type of physical information source and formulation used. It also provides a graphical illustration of the distribution of PICV methods across the taxonomy stages and the computer vision tasks.
- **PICV Challenges and Opportunities**: This subsection discusses the open problems and future directions for PICV research. It identifies four main challenges: data scarcity and quality, model complexity and scalability, interpretability and explainability, and evaluation and validation. It also suggests some potential opportunities for PICV research, such as multimodal and multiscale learning, transfer learning and domain adaptation, uncertainty quantification and robustness, and physics-informed generative models.

## Pseudo Code - High level

Here is a possible high-level pseudo code for this paper:

```python
# Define the computer vision task and the physical domain
task = "image segmentation"
domain = "fluid dynamics"

# Define the physical information source and formulation
source = "numerical simulation"
formulation = "explicit"

# Choose the PICV stage and method
stage = "hybrid"
method = "physics-based loss"

# Define the network architecture and parameters
network = "U-Net"
parameters = ...

# Define the data and preprocessing
data = ...
preprocess(data)

# Define the physics-based loss function
def physics_loss(output):
  # Compute the divergence of the output segmentation mask
  divergence = ...
  # Penalize the divergence to enforce mass conservation
  loss = ...
  return loss

# Train the network with the physics-based loss
train(network, data, physics_loss)

# Evaluate the network on test data
test(network, data)
```

## Pseudo Code - Detail

Here is a possible detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Define the computer vision task and the physical domain
task = "image segmentation"
domain = "fluid dynamics"

# Define the physical information source and formulation
source = "numerical simulation"
formulation = "explicit"

# Choose the PICV stage and method
stage = "hybrid"
method = "physics-based loss"

# Define the network architecture and parameters
network = tf.keras.models.Sequential([
  # Encoder layers
  tf.keras.layers.Conv2D(64, 3, activation="relu", padding="same"),
  tf.keras.layers.MaxPooling2D(2),
  tf.keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
  tf.keras.layers.MaxPooling2D(2),
  tf.keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
  tf.keras.layers.MaxPooling2D(2),
  # Decoder layers
  tf.keras.layers.Conv2DTranspose(256, 3, strides=2, activation="relu", padding="same"),
  tf.keras.layers.Conv2DTranspose(128, 3, strides=2, activation="relu", padding="same"),
  tf.keras.layers.Conv2DTranspose(64, 3, strides=2, activation="relu", padding="same"),
  # Output layer
  tf.keras.layers.Conv2D(1, 1, activation="sigmoid", padding="same")
])

# Define the network optimizer and metrics
optimizer = tf.keras.optimizers.Adam()
metrics = ["accuracy", "dice_coefficient"]

# Define the data and preprocessing
data = np.load("fluid_data.npy") # Load the data from a numpy file
x_train, y_train, x_test, y_test = split(data) # Split the data into train and test sets
x_train, x_test = normalize(x_train, x_test) # Normalize the input images to [0,1] range
y_train, y_test = binarize(y_train, y_test) # Binarize the output masks to {0,1} values

# Define the physics-based loss function
def physics_loss(output):
  # Compute the divergence of the output segmentation mask using central finite difference
  dx = output[:, :, 1:-1, :] - output[:, :, :-2, :] # Forward difference along x-axis
  dy = output[:, :, :, 1:-1] - output[:, :, :, :-2] # Forward difference along y-axis
  divergence = dx + dy # Sum of differences
  # Penalize the divergence to enforce mass conservation using mean squared error
  loss = tf.reduce_mean(tf.square(divergence))
  return loss

# Train the network with the physics-based loss
network.compile(optimizer=optimizer, loss=physics_loss, metrics=metrics)
network.fit(x_train, y_train, epochs=10, batch_size=32)

# Evaluate the network on test data
network.evaluate(x_test, y_test)

# Visualize some predictions on test data
predictions = network.predict(x_test)
for i in range(10):
  plt.subplot(1,3,1)
  plt.imshow(x_test[i])
  plt.title("Input image")
  plt.subplot(1,3,2)
  plt.imshow(y_test[i])
  plt.title("Ground truth mask")
  plt.subplot(1,3,3)
  plt.imshow(predictions[i])
  plt.title("Predicted mask")
plt.show()
```