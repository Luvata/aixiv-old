---
title: 2305.19693v2 Spontaneous symmetry breaking in generative diffusion models
date: 2023-05-20
---

# [Spontaneous symmetry breaking in generative diffusion models](http://arxiv.org/abs/2305.19693v2)

authors: Gabriel Raya, Luca Ambrogioni


## What, Why and How

[1]: https://arxiv.org/abs/2305.19693 "Spontaneous symmetry breaking in generative diffusion models"
[2]: https://arxiv.org/pdf/2305.19693v2.pdf "arXiv.org"
[3]: https://arxiv-export2.library.cornell.edu/abs/2305.19693v2 "[2305.19693v2] Spontaneous symmetry breaking in generative diffusion models"

Here is a summary of the paper:

- **What**: The paper is about **generative diffusion models**, which are a type of machine learning models that can generate high-dimensional data such as images or text by simulating a stochastic process that starts from noise and gradually approaches the data distribution[^1^][1].
- **Why**: The paper aims to **understand the generative dynamics** of these models and how they can be improved. The paper claims that the dynamics exhibit a **spontaneous symmetry breaking** that separates the generation into two phases: a linear phase around a central fixed point and an attractor phase towards the data manifold[^1^][1]. The paper also proposes a **Gaussian late initialization scheme** that leverages this insight to improve model performance and sample diversity[^1^][1].
- **How**: The paper uses both **theoretical analysis** and **empirical experiments** to support its claims. The paper derives a linearized approximation of the generative dynamics and shows that the central fixed point changes stability at some point during the generation[^1^][1]. The paper also conducts experiments on various datasets and shows that the proposed initialization scheme can achieve up to 3x FID improvements on fast samplers, while also increasing sample diversity (e.g., racial composition of generated CelebA images)[^1^][1].

## Main Contributions

The paper makes the following contributions:

- It provides a new way to understand the generative dynamics of diffusion models by showing that they exhibit a spontaneous symmetry breaking that divides the generation into two phases.
- It proposes a Gaussian late initialization scheme that leverages this insight to improve model performance and sample diversity.
- It demonstrates the effectiveness of the proposed scheme on various datasets and shows that it can achieve up to 3x FID improvements on fast samplers, while also increasing sample diversity (e.g., racial composition of generated CelebA images).


## Method Summary

[1]: https://arxiv.org/abs/2305.16936 "[2305.16936] CRoSS: Diffusion Model Makes Controllable, Robust and ..."
[2]: https://arxiv.org/abs/2209.00796 "Diffusion Models: A Comprehensive Survey of Methods and Applications"
[3]: https://www.kaggle.com/datasets/Cornell-University/arxiv "arXiv Dataset | Kaggle"

Here is a summary of the method section of the paper:

- The paper first introduces the **background** of generative diffusion models, which are based on the idea of reversing a Markov chain that starts from the data and ends at noise[^1^][1]. The paper also reviews some existing methods to improve the sampling efficiency and quality of these models[^1^][1].
- The paper then presents its main **theoretical analysis** of the generative dynamics of diffusion models. The paper derives a linearized approximation of the dynamics around a central fixed point, which is the mean of the data distribution[^1^][1]. The paper shows that this fixed point changes stability at some point during the generation, leading to a spontaneous symmetry breaking that divides the generation into two phases: a linear phase and an attractor phase[^1^][1]. The paper also analyzes the effects of different noise schedules and initialization schemes on the generative dynamics[^1^][1].
- The paper then proposes a **Gaussian late initialization scheme**, which initializes the generation from a Gaussian distribution instead of uniform noise. The paper argues that this scheme can improve model performance and sample diversity by avoiding wasting computation on the early linear dynamics, which do not contribute much to the final generation[^1^][1]. The paper also shows how to choose an optimal initialization distribution based on the data statistics[^1^][1].
- The paper finally conducts **empirical experiments** to validate its theoretical findings and demonstrate the effectiveness of its proposed scheme. The paper uses various datasets such as CIFAR-10, CelebA, LSUN, and ImageNet to compare its scheme with other methods in terms of FID scores, sample quality, and sample diversity[^1^][1]. The paper also shows some qualitative results such as interpolation, editing, and out-of-distribution generation using its scheme[^1^][1].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define a diffusion model with parameters theta
model = DiffusionModel(theta)

# Define a data distribution p(x)
p_x = DataDistribution()

# Define a Gaussian distribution N(mu, sigma^2)
N = GaussianDistribution(mu, sigma)

# Define a noise schedule beta_1, ..., beta_T
beta = NoiseSchedule()

# Define a Gaussian late initialization scheme with parameters alpha and gamma
def GaussianLateInitialization(x_0):
  # Compute the mean and variance of the data distribution
  mu_x = p_x.mean()
  sigma_x = p_x.std()
  # Compute the initialization distribution q(x_0 | x_T)
  mu_0 = alpha * mu_x + (1 - alpha) * x_T
  sigma_0 = gamma * sigma_x
  q = GaussianDistribution(mu_0, sigma_0)
  # Sample x_0 from q
  x_0 = q.sample()
  return x_0

# Define a forward diffusion process
def ForwardDiffusion(x):
  # Initialize x_0 from the data distribution
  x_0 = p_x.sample()
  # Loop over T steps
  for t in range(1, T+1):
    # Add Gaussian noise to x_t-1
    epsilon_t = N.sample()
    x_t = sqrt(1 - beta_t) * x_t-1 + sqrt(beta_t) * epsilon_t
  return x_T

# Define a reverse diffusion process
def ReverseDiffusion(x_T):
  # Initialize x_T from noise or Gaussian late initialization
  if use_gaussian_late_init:
    x_T = GaussianLateInitialization(x_T)
  else:
    x_T = N.sample()
  # Loop over T steps in reverse order
  for t in range(T, 0, -1):
    # Predict the mean and variance of p(x_t-1 | x_t)
    mu_t-1, sigma_t-1 = model.predict(x_t)
    # Sample x_t-1 from p(x_t-1 | x_t)
    epsilon_t-1 = N.sample()
    x_t-1 = (x_t - sqrt(beta_t) * epsilon_t-1) / sqrt(1 - beta_t)
    # Optionally apply denoising or annealing to improve sampling quality
    if use_denoising:
      x_t-1 = model.denoise(x_t-1)
    if use_annealing:
      x_t-1 = model.anneal(x_t-1)
  return x_0

# Train the diffusion model by maximizing the log-likelihood of the reverse process
def TrainModel():
  # Loop over epochs
  for epoch in range(num_epochs):
    # Loop over batches of data
    for batch in data_loader:
      # Apply forward diffusion to get x_T
      x_T = ForwardDiffusion(batch)
      # Apply reverse diffusion to get x_0
      x_0 = ReverseDiffusion(x_T)
      # Compute the log-likelihood of p(x_0 | x_T)
      log_likelihood = model.log_prob(x_0, x_T)
      # Update the model parameters by gradient ascent
      theta = theta + learning_rate * grad(log_likelihood, theta)

# Generate samples from the diffusion model by applying reverse diffusion from noise
def GenerateSamples():
  # Initialize a list of samples
  samples = []
  # Loop over the number of samples to generate
  for i in range(num_samples):
    # Sample x_T from noise or Gaussian late initialization
    if use_gaussian_late_init:
      x_T = GaussianLateInitialization()
    else:
      x_T = N.sample()
    # Apply reverse diffusion to get x_0
    x_0 = ReverseDiffusion(x_T)
    # Append x_0 to the list of samples
    samples.append(x_0)
  return samples

```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# Define some hyperparameters
num_epochs = 100 # number of training epochs
batch_size = 64 # size of mini-batches
learning_rate = 1e-4 # learning rate for gradient ascent
T = 1000 # number of diffusion steps
beta_min = 0.0001 # minimum noise level
beta_max = 0.02 # maximum noise level
alpha = 0.9 # weight for data mean in Gaussian late initialization
gamma = 0.9 # weight for data variance in Gaussian late initialization
use_gaussian_late_init = True # whether to use Gaussian late initialization or not
use_denoising = True # whether to use denoising or not
use_annealing = True # whether to use annealing or not
num_samples = 16 # number of samples to generate

# Define a diffusion model as a convolutional neural network with residual blocks
class DiffusionModel(nn.Module):
  def __init__(self):
    super(DiffusionModel, self).__init__()
    # Define the convolutional layers with ReLU activation and batch normalization
    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
    self.relu1 = nn.ReLU()
    self.bn1 = nn.BatchNorm2d(64)
    self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
    self.relu2 = nn.ReLU()
    self.bn2 = nn.BatchNorm2d(128)
    self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
    self.relu3 = nn.ReLU()
    self.bn3 = nn.BatchNorm2d(256)
    # Define the residual blocks with skip connections and ReLU activation
    self.resblock1 = ResBlock(256)
    self.resblock2 = ResBlock(256)
    self.resblock3 = ResBlock(256)
    self.resblock4 = ResBlock(256)
    # Define the deconvolutional layers with ReLU activation and batch normalization
    self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size=3, padding=1)
    self.relu4 = nn.ReLU()
    self.bn4 = nn.BatchNorm2d(128)
    self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)
    self.relu5 = nn.ReLU()
    self.bn5 = nn.BatchNorm2d(64)
    self.deconv3 = nn.ConvTranspose2d(64, 3, kernel_size=3, padding=1)
    # Define the output layers for predicting the mean and variance of p(x_t-1 | x_t)
    self.mean_layer = nn.Linear(3 * 32 * 32, 3 * 32 * 32)
    self.var_layer = nn.Linear(3 * 32 * 32, 3 * 32 * 32)

  def forward(self, x):
    # Apply the convolutional layers
    x = self.conv1(x)
    x = self.relu1(x)
    x = self.bn1(x)
    x = self.conv2(x)
    x = self.relu2(x)
    x = self.bn2(x)
    x = self.conv3(x)
    x = self.relu3(x)
    x = self.bn3(x)
    # Apply the residual blocks
    x = self.resblock1(x)
    x = self.resblock2(x)
    x = self.resblock3(x)
    x = self.resblock4(x)
    # Apply the deconvolutional layers
    x = self.deconv1(x)
    x = self.relu4(x)
    x = self.bn4(x)
    x = self.deconv2(x)
    x = self.relu5(x)
    x = self.bn5(x)
    x = self.deconv3(x) 
   
   # Flatten the output and predict the mean and variance of p(x_t-1 | x_t) 
   x_flat=x.view(-1,3*32*32) 
   mu=self.mean_layer(x_flat) 
   sigma=self.var_layer(x_flat) 
   return mu,sigma

# Define a residual block as a convolutional neural network with skip connections and ReLU activation
class ResBlock(nn.Module):
  def __init__(self, channels):
    super(ResBlock, self).__init__()
    # Define the convolutional layers with ReLU activation and batch normalization
    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
    self.relu1 = nn.ReLU()
    self.bn1 = nn.BatchNorm2d(channels)
    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
    self.relu2 = nn.ReLU()
    self.bn2 = nn.BatchNorm2d(channels)

  def forward(self, x):
    # Save the input as a skip connection
    skip = x
    # Apply the convolutional layers
    x = self.conv1(x)
    x = self.relu1(x)
    x = self.bn1(x)
    x = self.conv2(x)
    x = self.relu2(x)
    x = self.bn2(x)
    # Add the skip connection to the output
    x = x + skip
    return x

# Define a denoising function that applies a Gaussian filter to the input
def denoise(x):
  # Define a Gaussian kernel
  kernel = torch.tensor([[1, 4, 6, 4, 1],
                         [4, 16, 24, 16, 4],
                         [6, 24, 36, 24, 6],
                         [4, 16, 24, 16, 4],
                         [1, 4, 6, 4, 1]]) / 256.0
  # Expand the kernel to match the input channels
  kernel = kernel.expand(3, -1, -1).unsqueeze(0)
  # Apply the Gaussian filter to the input using convolution
  x = nn.functional.conv2d(x, kernel, padding=2)
  return x

# Define an annealing function that applies a temperature scaling to the input
def anneal(x):
  # Define a temperature parameter
  tau = 0.9
  # Apply the temperature scaling to the input
  x = x / tau
  return x

# Define a data distribution p(x) as the CIFAR-10 dataset
p_x = torchvision.datasets.CIFAR10(root='./data', train=True,
                                   download=True,
                                   transform=transforms.ToTensor())

# Define a data loader for mini-batches of data
data_loader = torch.utils.data.DataLoader(p_x,
                                          batch_size=batch_size,
                                          shuffle=True,
                                          num_workers=2)

# Define a Gaussian distribution N(mu, sigma^2) as a normal distribution with zero mean and unit variance
N = torch.distributions.Normal(0.0, 1.0)

# Define a noise schedule beta_1, ..., beta_T as a geometric sequence with beta_min and beta_max as endpoints
beta = torch.linspace(beta_min ** (1 / T), beta_max ** (1 / T), T) ** T

# Define a Gaussian late initialization scheme with parameters alpha and gamma
def GaussianLateInitialization(x_0):
  # Compute the mean and variance of the data distribution using the empirical statistics of the dataset
  mu_x = torch.mean(p_x.data)
  sigma_x = torch.std(p_x.data)
  
   # Compute the initialization distribution q(x_0 | x_T) 
   mu_0=alpha*mu_x+(1-alpha)*x_T 
   sigma_0=gamma*sigma_x 
   q=torch.distributions.Normal(mu_0,sigma_0) 
   
   # Sample x_0 from q 
   x_0=q.sample() 
   return x_0

# Define a forward diffusion process that applies noise to the data and returns x_T
def ForwardDiffusion(x):
  
   # Loop over T steps 
   for t in range(1,T+1): 
     # Add Gaussian noise to x_t-1 
     epsilon_t=N.sample() 
     x_t=sqrt(1-beta_t)*x_t-1+sqrt(beta_t)*epsilon_t 
   return x_T

# Define a reverse diffusion process that predicts and samples from p(x_t-1 | x_t) and returns x_0
def ReverseDiffusion(x_T):
  
   # Initialize x_T from noise or Gaussian late initialization 
   if use_gaussian_late_init: 
     x_T=GaussianLateInitialization(x_T) 
   else: 
     x_T=N.sample() 
   
   # Loop over T steps in reverse order 
   for t in range(T,0,-1): 
     # Predict the mean and variance of p(x_t-1 | x_t) using the diffusion model 
     mu_t-1,sigma_t-1=model(x_t) 
     # Sample x_t-1 from p(x_t-1 | x_t) using the reparameterization trick 
     epsilon_t-1=N.sample() 
     x_t-1=(