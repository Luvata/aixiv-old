---
title: 2306.12790v1 DiffWA  Diffusion Models for Watermark Attack
date: 2023-06-13
---

# [DiffWA: Diffusion Models for Watermark Attack](http://arxiv.org/abs/2306.12790v1)

authors: Xinyu Li


## What, Why and How

[1]: https://arxiv.org/pdf/2306.12790v1.pdf "arXiv:2306.12790v1 [cs.MM] 22 Jun 2023"
[2]: https://arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack"

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a new method for watermark attack, called DiffWA, which uses a conditional diffusion model with distance guidance to remove the watermark from an image while preserving its quality.
- **Why**: The paper aims to address the limitations of existing watermark attack algorithms, which either cause great visual loss to the image or require prior knowledge of the watermarking algorithm. The paper also wants to challenge the robustness of blind watermarking algorithms, which are widely used for copyright protection.
- **How**: The paper trains a conditional diffusion model on unwatermarked images, which can generate realistic images from noise. The paper then guides the model to sample unwatermarked images that are similar to the watermarked ones using a distance guidance term, which measures the difference between the two images in a feature space. The paper evaluates the proposed method on CIFAR-10 dataset and shows that it can achieve high bit error rate for watermark extraction and high PSNR and SSIM for image quality.

[^1^][1]: https://arxiv.org/pdf/2306.12790v1.pdf


## Main Contributions

[1]: https://arxiv.org/pdf/2306.12790v1.pdf "arXiv:2306.12790v1 [cs.MM] 22 Jun 2023"
[2]: https://arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack"

According to the paper at [^1^][1], the main contributions are:

- **Proposing a new method for watermark attack based on conditional diffusion models**, which can generate realistic unwatermarked images from watermarked ones using a distance guidance term.
- **Demonstrating the effectiveness of the proposed method on CIFAR-10 dataset**, showing that it can achieve high bit error rate for watermark extraction and high PSNR and SSIM for image quality.
- **Providing a novel perspective on watermark attack using generative models**, which can challenge the robustness of blind watermarking algorithms and inspire future research.

[^1^][1]: https://arxiv.org/pdf/2306.12790v1.pdf


## Method Summary

[1]: https://arxiv.org/pdf/2306.12790v1.pdf "arXiv:2306.12790v1 [cs.MM] 22 Jun 2023"
[2]: https://arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack"

Here is a summary of the method section of the paper at [^1^][1]:

- The paper introduces the **conditional diffusion model**, which is a generative model that can learn to sample realistic images from noise by reversing a Markov chain of Gaussian diffusion steps.
- The paper describes the **distance guidance term**, which is a loss function that measures the difference between the watermarked image and the unwatermarked image in a feature space extracted by a pretrained VGG network.
- The paper explains how to use the **distance guidance term** to guide the **conditional diffusion model** to sample unwatermarked images that are similar to the watermarked ones, by adding it to the reverse KL divergence loss of the model.
- The paper details the **training and sampling procedures** of the proposed method, which involve training the model on unwatermarked images and using the distance guidance term during sampling to remove the watermark from watermarked images.

[^1^][1]: https://arxiv.org/pdf/2306.12790v1.pdf


## Pseudo Code - High level

[1]: https://arxiv.org/pdf/2306.12790v1.pdf "arXiv:2306.12790v1 [cs.MM] 22 Jun 2023"
[2]: https://arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack"

Here is the high-level pseudo code for the paper at [^1^][1]:

- Define a **conditional diffusion model** that takes an image x and a noise level t as inputs and outputs a distribution over the next noise level s and the next image y
- Define a **distance guidance term** that takes a watermarked image x_w and an unwatermarked image x_u as inputs and outputs a scalar value that measures the difference between them in a feature space
- Train the **conditional diffusion model** on a dataset of unwatermarked images using reverse KL divergence loss
- For each watermarked image x_w, sample an unwatermarked image x_u from the **conditional diffusion model** by starting from noise and adding the **distance guidance term** to the reverse KL divergence loss at each step

[^1^][1]: https://arxiv.org/pdf/2306.12790v1.pdf


## Pseudo Code - Detail

[1]: https://arxiv.org/pdf/2306.12790v1.pdf "arXiv:2306.12790v1 [cs.MM] 22 Jun 2023"
[2]: https://arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.12790 "[2306.12790] DiffWA: Diffusion Models for Watermark Attack"

Here is the detailed pseudo code for the paper at [^1^][1]:

- Import the necessary libraries and modules, such as PyTorch, torchvision, VGG network, etc.
- Define the hyperparameters, such as number of diffusion steps, noise schedule, learning rate, batch size, etc.
- Define the **conditional diffusion model** as a neural network that consists of an encoder and a decoder with skip connections
- Define the **distance guidance term** as a function that takes a watermarked image x_w and an unwatermarked image x_u as inputs and outputs the L2 norm of the difference between their features extracted by a pretrained VGG network
- Define the loss function for the **conditional diffusion model** as the reverse KL divergence between the predicted distribution and the true distribution of the next noise level and image
- Load the dataset of unwatermarked images and split it into training and validation sets
- Train the **conditional diffusion model** on the training set using the loss function and an optimizer
- For each watermarked image x_w in the validation set, do the following:
  - Initialize an unwatermarked image x_u as a random noise image
  - For each diffusion step from t = T to t = 1, where T is the number of diffusion steps, do the following:
    - Predict the next noise level s_t and image y_t from x_u and t using the **conditional diffusion model**
    - Sample a noise vector epsilon_t from a Gaussian distribution with mean 0 and variance s_t
    - Update x_u as y_t + epsilon_t
    - Add the **distance guidance term** multiplied by a weight lambda to the loss function
  - Save x_u as the final output image
- Evaluate the performance of the proposed method on the validation set using metrics such as bit error rate, PSNR and SSIM

[^1^][1]: https://arxiv.org/pdf/2306.12790v1.pdf