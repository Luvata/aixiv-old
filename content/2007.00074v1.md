---
title: 2007.00074v1 Deep Geometric Texture Synthesis
date: 2020-07-01
---

# [Deep Geometric Texture Synthesis](http://arxiv.org/abs/2007.00074v1)

authors: Amir Hertz, Rana Hanocka, Raja Giryes, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/pdf/2007.00074v1 "Deep Geometric Texture Synthesis - arXiv.org"
[2]: https://arxiv.org/abs/2007.00074v1 "[2007.00074v1] Deep Geometric Texture Synthesis - arXiv.org"
[3]: http://export.arxiv.org/abs/1907.00074v1 "[1907.00074v1] Forensic Analysis of Third Party Location Applications ..."

Here is a summary of the paper at [^1^][1]:

- **What**: The paper proposes a novel framework for synthesizing geometric textures on meshes using deep generative adversarial networks (GANs).
- **Why**: The paper aims to address the challenges of mesh generation and synthesis, which are fundamental topics in computer graphics, but have received less attention than image generation in deep learning research.
- **How**: The paper learns geometric texture statistics from local triangular patches of a single reference 3D model, and uses them to subdivide and generate offsets across multiple scales, without parameterization of the reference or target mesh. The paper also displaces mesh vertices in any direction, enabling synthesis of geometric textures that cannot be expressed by a simple 2D displacement map. The paper demonstrates texture transfer between shapes of different genus using a genus-oblivious framework.

## Main Contributions

According to the paper, the main contributions are:

- A novel framework for synthesizing geometric textures on meshes using deep GANs.
- A method for learning and synthesizing on local geometric patches, which enables a genus-oblivious framework for texture transfer.
- A network that displaces mesh vertices in any direction, enabling synthesis of geometric textures that cannot be expressed by a simple 2D displacement map.
- A comprehensive evaluation of the proposed method on various geometric textures and shapes, demonstrating its effectiveness and versatility.

## Method Summary

[1]: https://arxiv.org/pdf/2007.00074v1 "Deep Geometric Texture Synthesis - arXiv.org"
[2]: https://arxiv.org/pdf/2007.00074 "arXiv.org"
[3]: https://www.researchgate.net/publication/349704228_Density_of_Periodic_Points_for_Lattes_maps_over_Finite_Fields/fulltext/603dac37a6fdcc9c78081949/Density-of-Periodic-Points-for-Latt-es-maps-over-Finite-Fields.pdf "Abstract. L d E arXiv:2103.00074v1 [math.NT] 26 Feb 2021 - ResearchGate"

Here is a summary of the method section of the paper at [^1^][1]:

- The paper introduces a framework for synthesizing geometric textures on meshes using deep GANs, which consists of three main components: a **feature extractor**, a **generator**, and a **discriminator**.
- The **feature extractor** is a mesh convolutional network that learns deep features on the faces of the input triangulation, which capture the local geometric texture statistics of a single reference 3D model. The features are then used to subdivide and generate offsets across multiple scales, without parameterization of the reference or target mesh.
- The **generator** is a multi-scale network that takes as input a coarse mesh and the features from the feature extractor, and outputs a finer mesh with displaced vertices. The generator displaces mesh vertices in any direction (i.e., in the normal and tangential direction), enabling synthesis of geometric textures that cannot be expressed by a simple 2D displacement map. The generator is trained with an adversarial loss, a feature matching loss, and a Laplacian regularization loss.
- The **discriminator** is also a multi-scale network that takes as input a mesh and outputs a scalar value indicating whether the mesh is real or fake. The discriminator is trained with an adversarial loss and a gradient penalty loss to enforce the Lipschitz continuity condition.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the feature extractor network F
# Define the generator network G
# Define the discriminator network D
# Define the adversarial loss L_adv
# Define the feature matching loss L_fm
# Define the Laplacian regularization loss L_lap
# Define the gradient penalty loss L_gp

# Initialize the network parameters randomly
# Load a reference 3D model M_ref and a target coarse mesh M_0

# Extract features from M_ref using F
features = F(M_ref)

# Train the generator and discriminator networks using alternating gradient descent
for epoch in range(num_epochs):
  # Sample a batch of real meshes from M_ref
  real_meshes = sample(M_ref, batch_size)
  
  # Generate a batch of fake meshes from M_0 and features using G
  fake_meshes = G(M_0, features)
  
  # Compute the discriminator outputs for real and fake meshes using D
  real_outputs = D(real_meshes)
  fake_outputs = D(fake_meshes)
  
  # Compute the generator and discriminator losses
  g_loss = L_adv(fake_outputs) + L_fm(real_outputs, fake_outputs) + L_lap(fake_meshes)
  d_loss = L_adv(real_outputs, fake_outputs) + L_gp(real_meshes, fake_meshes)
  
  # Update the generator and discriminator parameters using gradient descent
  g_params = g_params - learning_rate * grad(g_loss, g_params)
  d_params = d_params - learning_rate * grad(d_loss, d_params)

# Output the final generated mesh
M_final = G(M_0, features)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
import meshcnn

# Define the feature extractor network F
# F is a mesh convolutional network that consists of several mesh convolution layers and global average pooling layer
# F takes as input a mesh and outputs a feature vector for each face
class FeatureExtractor(nn.Module):
  def __init__(self, num_features):
    super(FeatureExtractor, self).__init__()
    # Define the mesh convolution layers
    self.conv1 = meshcnn.MeshConv(5, 32)
    self.conv2 = meshcnn.MeshConv(32, 64)
    self.conv3 = meshcnn.MeshConv(64, 128)
    self.conv4 = meshcnn.MeshConv(128, 256)
    # Define the global average pooling layer
    self.gap = nn.AdaptiveAvgPool1d(1)
    # Define the output layer
    self.fc = nn.Linear(256, num_features)

  def forward(self, x):
    # x is a mesh with edge features
    # Apply the mesh convolution layers with ReLU activation and edge collapse
    x = self.conv1(x)
    x = nn.ReLU()(x)
    x = x.collapse()
    x = self.conv2(x)
    x = nn.ReLU()(x)
    x = x.collapse()
    x = self.conv3(x)
    x = nn.ReLU()(x)
    x = x.collapse()
    x = self.conv4(x)
    x = nn.ReLU()(x)
    # Apply the global average pooling layer to get a feature vector for each face
    x = self.gap(x.edge_features)
    # Apply the output layer to get the final feature vector
    x = self.fc(x.squeeze())
    return x

# Define the generator network G
# G is a multi-scale network that consists of several sub-generators that operate on different levels of detail
# G takes as input a coarse mesh and a feature vector for each face, and outputs a finer mesh with displaced vertices
class Generator(nn.Module):
  def __init__(self, num_scales):
    super(Generator, self).__init__()
    # Define the sub-generators for each scale
    self.sub_generators = nn.ModuleList()
    for i in range(num_scales):
      # Each sub-generator is a mesh convolutional network that consists of several mesh convolution layers and a displacement layer
      # The displacement layer displaces the vertices of the mesh in any direction using the learned features
      sub_generator = nn.Sequential(
        meshcnn.MeshConv(5 + num_features, 64),
        nn.ReLU(),
        meshcnn.MeshConv(64, 128),
        nn.ReLU(),
        meshcnn.MeshConv(128, 256),
        nn.ReLU(),
        meshcnn.MeshDisplacement(256)
      )
      self.sub_generators.append(sub_generator)

  def forward(self, x, features):
    # x is a coarse mesh with edge features
    # features is a feature vector for each face of the coarse mesh
    # Concatenate the features with the edge features of the coarse mesh
    x.edge_features = torch.cat([x.edge_features, features], dim=1)
    # For each scale, apply the sub-generator to get a finer mesh and subdivide it
    for sub_generator in self.sub_generators:
      x = sub_generator(x)
      x = x.subdivide()
    return x

# Define the discriminator network D
# D is also a multi-scale network that consists of several sub-discriminators that operate on different levels of detail
# D takes as input a mesh and outputs a scalar value indicating whether the mesh is real or fake
class Discriminator(nn.Module):
  def __init__(self, num_scales):
    super(Discriminator, self).__init__()
    # Define the sub-discriminators for each scale
    self.sub_discriminators = nn.ModuleList()
    for i in range(num_scales):
      # Each sub-discriminator is a mesh convolutional network that consists of several mesh convolution layers and a global average pooling layer
      # The final output is obtained by applying a linear layer to the pooled features
      sub_discriminator = nn.Sequential(
        meshcnn.MeshConv(5, 32),
        nn.ReLU(),
        meshcnn.MeshConv(32, 64),
        nn.ReLU(),
        meshcnn.MeshConv(64, 128),
        nn.ReLU(),
        meshcnn.MeshConv(128, 256),
        nn.ReLU(),
        nn.AdaptiveAvgPool1d(1),
        nn.Flatten(),
        nn.Linear(256, 1)
      )
      self.sub_discriminators.append(sub_discriminator)

  def forward(self, x):
    # x is a mesh with edge features
    # Initialize the output as zero
    output = 0
    # For each scale, apply the sub-discriminator to get a scalar value and add it to the output
    for sub_discriminator in self.sub_discriminators:
      output += sub_discriminator(x)
      # If not the last scale, collapse the mesh to reduce the number of faces
      if sub_discriminator != self.sub_discriminators[-1]:
        x = x.collapse()
    return output

# Define the adversarial loss L_adv
# L_adv is the hinge loss for the generator and discriminator networks
def L_adv(real_outputs, fake_outputs):
  # real_outputs and fake_outputs are the discriminator outputs for real and fake meshes
  # Compute the generator loss as the negative mean of the fake outputs
  g_loss = -torch.mean(fake_outputs)
  # Compute the discriminator loss as the mean of the hinge loss for real and fake outputs
  d_loss = torch.mean(nn.ReLU()(1 - real_outputs)) + torch.mean(nn.ReLU()(1 + fake_outputs))
  return g_loss, d_loss

# Define the feature matching loss L_fm
# L_fm is the mean squared error between the intermediate features of the discriminator for real and fake meshes
def L_fm(real_outputs, fake_outputs):
  # real_outputs and fake_outputs are lists of intermediate features of the discriminator for real and fake meshes
  # Compute the feature matching loss as the mean squared error between the corresponding features
  fm_loss = 0
  for real_output, fake_output in zip(real_outputs, fake_outputs):
    fm_loss += torch.mean((real_output - fake_output) ** 2)
  return fm_loss

# Define the Laplacian regularization loss L_lap
# L_lap is the mean squared error between the Laplacian coordinates of the input and output meshes
def L_lap(input_mesh, output_mesh):
  # input_mesh and output_mesh are meshes with edge features
  # Compute the Laplacian coordinates of the input and output meshes using meshcnn
  input_laplacian = meshcnn.MeshLaplacian(input_mesh)
  output_laplacian = meshcnn.MeshLaplacian(output_mesh)
  # Compute the Laplacian regularization loss as the mean squared error between the Laplacian coordinates
  lap_loss = torch.mean((input_laplacian - output_laplacian) ** 2)
  return lap_loss

# Define the gradient penalty loss L_gp
# L_gp is the penalty for violating the Lipschitz continuity condition of the discriminator network
def L_gp(real_meshes, fake_meshes):
  # real_meshes and fake_meshes are batches of meshes with edge features
  # Sample a batch of random numbers between 0 and 1
  alpha = torch.rand(batch_size, device=device)
  # Interpolate between real and fake meshes using alpha
  interpolated_meshes = alpha * real_meshes + (1 - alpha) * fake_meshes
  # Compute the discriminator outputs for interpolated meshes using D
  interpolated_outputs = D(interpolated_meshes)
  # Compute the gradients of interpolated outputs with respect to interpolated meshes using autograd
  gradients = torch.autograd.grad(outputs=interpolated_outputs, inputs=interpolated_meshes,
                                  grad_outputs=torch.ones(interpolated_outputs.size(), device=device),
                                  create_graph=True, retain_graph=True)[0]
  # Compute the gradient penalty loss as the mean squared error between the gradient norms and 1
  gp_loss = torch.mean((gradients.norm(2, dim=1) - 1) ** 2)
  return gp_loss

# Initialize the network parameters randomly
F = FeatureExtractor(num_features).to(device)
G = Generator(num_scales).to(device)
D = Discriminator(num_scales).to(device)

# Load a reference 3D model M_ref and a target coarse mesh M_0 using meshcnn
M_ref = meshcnn.Mesh(filename=reference_model_path, device=device)
M_0 = meshcnn.Mesh(filename=target_coarse_mesh_path, device=device)

# Extract features from M_ref using F
features = F(M_ref)

# Train the generator and discriminator networks using alternating gradient descent
g_optimizer = optim.Adam(G.parameters(), lr=learning_rate)
d_optimizer = optim.Adam(D.parameters(), lr=learning_rate)

for epoch in range(num_epochs):
  
  # Sample a batch of real meshes from M_ref using meshcnn
  real_meshes = M_ref.sample(batch_size)

  # Generate a batch of fake meshes from M_0 and features using G