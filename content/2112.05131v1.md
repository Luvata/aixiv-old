---
title: 2112.05131v1 Plenoxels  Radiance Fields without Neural Networks
date: 2021-12-06
---

# [Plenoxels: Radiance Fields without Neural Networks](http://arxiv.org/abs/2112.05131v1)

authors: Alex Yu, Sara Fridovich-Keil, Matthew Tancik, Qinhong Chen, Benjamin Recht, Angjoo Kanazawa


## What, Why and How

[1]: https://arxiv.org/abs/2112.05131 "[2112.05131] Plenoxels: Radiance Fields without Neural Networks - arXiv.org"
[2]: https://arxiv.org/pdf/2111.05131v1.pdf "arXiv:2111.05131v1 [hep-th] 9 Nov 2021"
[3]: https://arxiv.org/pdf/2112.05131.pdf "arXiv.org e-Print archive"
[4]: http://export.arxiv.org/abs/2111.05131v1 "[2111.05131v1] PT symmetric fermionic field theories with axions ..."

Here is a summary of the paper:

- **What**: The paper introduces **Plenoxels** (plenoptic voxels), a system for **photorealistic view synthesis**[^1^][1].
- **Why**: The paper aims to overcome the limitations of existing methods such as **Neural Radiance Fields (NeRFs)**, which require **neural networks**, **large memory**, and **long optimization time**[^1^][1].
- **How**: The paper proposes to represent a scene as a **sparse 3D grid** with **spherical harmonics**. This representation can be optimized from **calibrated images** via **gradient methods** and **regularization** without any neural components. The paper shows that Plenoxels are optimized **two orders of magnitude faster** than NeRFs with **no loss in visual quality**[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/2112.05131 "[2112.05131] Plenoxels: Radiance Fields without Neural Networks - arXiv.org"
[2]: https://arxiv.org/pdf/2111.05131v1.pdf "arXiv:2111.05131v1 [hep-th] 9 Nov 2021"
[3]: https://arxiv.org/pdf/2112.05131.pdf "arXiv.org e-Print archive"
[4]: http://export.arxiv.org/abs/2111.05131v1 "[2111.05131v1] PT symmetric fermionic field theories with axions ..."

The paper claims the following contributions[^1^][1]:

- **A novel representation for view synthesis** that uses spherical harmonics to model the radiance field of a scene as a sparse 3D grid.
- **A fast and simple optimization algorithm** that does not require any neural networks, and can leverage existing calibration methods and regularization techniques.
- **A comprehensive evaluation** of Plenoxels on standard benchmarks, showing that they achieve comparable or better results than NeRFs in terms of visual quality, generalization, and robustness, while being orders of magnitude faster.

## Method Summary

[1]: https://arxiv.org/abs/2112.05131 "[2112.05131] Plenoxels: Radiance Fields without Neural Networks - arXiv.org"
[2]: https://arxiv.org/pdf/2111.05131v1.pdf "arXiv:2111.05131v1 [hep-th] 9 Nov 2021"
[3]: https://arxiv.org/pdf/2112.05131.pdf "arXiv.org e-Print archive"
[4]: http://export.arxiv.org/abs/2111.05131v1 "[2111.05131v1] PT symmetric fermionic field theories with axions ..."

Here is a summary of the method section of the paper:

- The paper defines the **plenoptic function** as a function that maps a 5D ray to a radiance value, and the **radiance field** as the set of all plenoptic functions for a scene[^1^][1].
- The paper approximates the radiance field using **spherical harmonics**, which are a set of orthogonal basis functions that can represent any function on a sphere[^1^][1].
- The paper discretizes the 3D space into a **sparse grid** of **voxels**, each of which stores a spherical harmonic coefficient vector that encodes the radiance field within the voxel[^1^][1].
- The paper optimizes the spherical harmonic coefficients using **gradient descent** on a loss function that measures the difference between the observed images and the rendered images from the plenoptic function[^1^][1].
- The paper uses **calibrated cameras** to obtain the intrinsic and extrinsic parameters of the images, and applies **regularization** techniques such as sparsity, smoothness, and occlusion to improve the optimization[^1^][1].
- The paper renders novel views from the plenoptic function using **ray marching**, which samples the radiance field along each ray and accumulates the color and opacity values[^1^][1].

## Pseudo Code - High level

[1]: https://arxiv.org/abs/2112.05131 "[2112.05131] Plenoxels: Radiance Fields without Neural Networks - arXiv.org"
[2]: https://arxiv.org/pdf/2111.05131v1.pdf "arXiv:2111.05131v1 [hep-th] 9 Nov 2021"
[3]: https://arxiv.org/pdf/2112.05131.pdf "arXiv.org e-Print archive"
[4]: http://export.arxiv.org/abs/2111.05131v1 "[2111.05131v1] PT symmetric fermionic field theories with axions ..."

Here is the high-level pseudo code for this paper:

```python
# Input: a set of calibrated images I and their camera parameters C
# Output: a plenoptic function P that can render novel views

# Initialize a sparse 3D grid G with spherical harmonic coefficients
G = initialize_grid()

# Define a loss function L that measures the difference between observed and rendered images
L = define_loss()

# Define a regularization function R that encourages sparsity, smoothness, and occlusion
R = define_regularization()

# Optimize the spherical harmonic coefficients using gradient descent
for epoch in range(num_epochs):
  # Sample a batch of images and rays
  batch_I, batch_R = sample_batch(I, C)
  # Render the images from the plenoptic function
  batch_P = render_images(P, batch_R)
  # Compute the loss and the regularization
  loss = L(batch_I, batch_P) + R(G)
  # Update the spherical harmonic coefficients using gradients
  G = update_grid(G, loss)

# Return the plenoptic function
P = plenoptic_function(G)
return P
```

## Pseudo Code - Detail

[1]: https://arxiv.org/abs/2112.05131 "[2112.05131] Plenoxels: Radiance Fields without Neural Networks - arXiv.org"
[2]: https://arxiv.org/pdf/2111.05131v1.pdf "arXiv:2111.05131v1 [hep-th] 9 Nov 2021"
[3]: https://arxiv.org/pdf/2112.05131.pdf "arXiv.org e-Print archive"
[4]: http://export.arxiv.org/abs/2111.05131v1 "[2111.05131v1] PT symmetric fermionic field theories with axions ..."

Here is the detailed pseudo code for this paper:

```python
# Input: a set of calibrated images I and their camera parameters C
# Output: a plenoptic function P that can render novel views

# Initialize a sparse 3D grid G with spherical harmonic coefficients
G = initialize_grid()

# Define a loss function L that measures the difference between observed and rendered images
def L(I, P):
  # Initialize the loss to zero
  loss = 0
  # Loop over each image and its camera parameters
  for i, c in zip(I, C):
    # Project the image pixels to rays
    R = project_to_rays(i, c)
    # Render the image from the plenoptic function
    P_i = render_images(P, R)
    # Compute the mean squared error between the observed and rendered images
    mse = mean_squared_error(i, P_i)
    # Add the mse to the loss
    loss += mse
  # Return the loss
  return loss

# Define a regularization function R that encourages sparsity, smoothness, and occlusion
def R(G):
  # Initialize the regularization to zero
  reg = 0
  # Loop over each voxel and its spherical harmonic coefficients
  for v, s in G.items():
    # Compute the L1 norm of the coefficients to encourage sparsity
    l1 = l1_norm(s)
    # Compute the Laplacian of the coefficients to encourage smoothness
    lap = laplacian(s)
    # Compute the occlusion penalty of the voxel to encourage occlusion
    occ = occlusion_penalty(v, G)
    # Add the weighted sum of the terms to the regularization
    reg += alpha * l1 + beta * lap + gamma * occ
  # Return the regularization
  return reg

# Optimize the spherical harmonic coefficients using gradient descent
for epoch in range(num_epochs):
  # Sample a batch of images and rays
  batch_I, batch_R = sample_batch(I, C)
  # Render the images from the plenoptic function
  batch_P = render_images(P, batch_R)
  # Compute the loss and the regularization
  loss = L(batch_I, batch_P) + R(G)
  # Compute the gradients of the loss with respect to the spherical harmonic coefficients
  grads = compute_gradients(loss, G)
  # Update the spherical harmonic coefficients using gradients and a learning rate
  G = update_grid(G, grads, lr)

# Return the plenoptic function
P = plenoptic_function(G)
return P

# Define a function that renders images from the plenoptic function using ray marching
def render_images(P, R):
  # Initialize an empty list of rendered images
  images = []
  # Loop over each ray in R
  for r in R:
    # Initialize the color and opacity values to zero
    color = 0
    opacity = 0
    # Sample points along the ray with a step size delta_t
    for t in range(0, T, delta_t):
      # Get the point p at distance t from the ray origin o along direction d 
      p = o + t * d 
      # Get the voxel v that contains p from G 
      v = get_voxel(p, G) 
      # If v exists, get its spherical harmonic coefficients s 
      if v:
        s = G[v] 
        # Evaluate the radiance field at p using s 
        r_p = evaluate_radiance_field(p, s) 
        # Get the color c_p and density sigma_p from r_p 
        c_p, sigma_p = r_p 
        # Update the color and opacity values using alpha compositing 
        color += (1 - opacity) * sigma_p * c_p * delta_t 
        opacity += (1 - opacity) * sigma_p * delta_t 
      # If opacity is close to one, stop marching 
      if opacity > threshold:
        break 
    # Append the color value to images 
    images.append(color) 
  # Return images 
  return images

```