---
title: 2306.00386v1 Symmetric Uncertainty-Aware Feature Transmission for Depth Super-Resolution
date: 2023-06-01
---

# [Symmetric Uncertainty-Aware Feature Transmission for Depth Super-Resolution](http://arxiv.org/abs/2306.00386v1)

authors: Wuxuan Shi, Mang Ye, Bo Du


## What, Why and How

[1]: https://arxiv.org/pdf/2306.00386v1.pdf "Symmetric Uncertainty-Aware Feature Transmission for Depth ... - arXiv.org"
[2]: https://arxiv.org/abs/2306.00386 "[2306.00386] Symmetric Uncertainty-Aware Feature ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2305.00386v1 "[2305.00386v1] Importance Weighted Expectation-Maximization for Protein ..."

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a novel method for color-guided depth super-resolution (DSR), which is the task of enhancing a low-resolution depth map using a high-resolution RGB image from the same scene.
- **Why**: The paper aims to address two challenges in color-guided DSR: the resolution gap and the cross-modality gap. The resolution gap refers to the mismatch between the spatial resolutions of the depth and RGB images, which can cause noise amplification and blurring when using interpolation to upscale the depth maps. The cross-modality gap refers to the difference between the visual features of the depth and RGB images, which can lead to unwanted textures or artifacts when transferring high-frequency information from RGB to depth.
- **How**: The paper introduces a Symmetric Uncertainty-aware Feature Transmission (SUFT) method, which consists of two main components: (1) an iterative up-and-down sampling pipeline, which alternates between upscaling and downscaling the depth features to match the spatial resolution of the RGB features, while suppressing noise and blurring by avoiding interpolation; (2) a symmetric uncertainty scheme, which estimates the uncertainty of both depth and RGB features and uses it to filter out harmful information that can degrade the quality of the depth reconstruction. The paper evaluates the proposed method on benchmark datasets and real-world scenarios and shows that it outperforms state-of-the-art methods in terms of quantitative and qualitative metrics.

## Main Contributions

According to the paper, the main contributions are:

- A novel Symmetric Uncertainty-aware Feature Transmission (SUFT) method for color-guided depth super-resolution, which tackles the resolution gap and the cross-modality gap in a unified framework.
- An iterative up-and-down sampling pipeline, which makes the depth and RGB features spatially consistent without using interpolation and preserves the low-frequency information of the depth maps.
- A symmetric uncertainty scheme, which estimates the uncertainty of both depth and RGB features and uses it to filter out harmful information that can degrade the depth reconstruction.
- Extensive experiments on benchmark datasets and challenging real-world settings, which demonstrate the superiority of the proposed method over state-of-the-art methods.

## Method Summary

Here is a summary of the method section of the paper:

- The paper formulates the color-guided depth super-resolution problem as a conditional image generation task, where the goal is to generate a high-resolution depth map D given a low-resolution depth map L and a high-resolution RGB image R.
- The paper proposes a Symmetric Uncertainty-aware Feature Transmission (SUFT) method, which consists of two main components: an iterative up-and-down sampling pipeline and a symmetric uncertainty scheme.
- The iterative up-and-down sampling pipeline is designed to make the depth and RGB features spatially consistent without using interpolation. It consists of three stages: (1) an initial upscaling stage, which uses a sub-pixel convolution layer to upscale the low-resolution depth map L to the same resolution as R; (2) an iterative up-and-down sampling stage, which alternates between upscaling and downscaling the depth features using sub-pixel convolution and average pooling layers, respectively; (3) a final downscaling stage, which uses an average pooling layer to downscale the depth features to the original resolution of L. The pipeline preserves the low-frequency information of the depth maps and suppresses noise and blurring by avoiding interpolation.
- The symmetric uncertainty scheme is designed to filter out harmful information that can degrade the depth reconstruction. It consists of two steps: (1) an uncertainty estimation step, which uses two uncertainty estimation networks to estimate the uncertainty of both depth and RGB features; (2) an uncertainty filtering step, which uses two attention modules to filter out the uncertain regions of both depth and RGB features based on their uncertainty maps. The scheme removes unwanted textures or artifacts that can result from the cross-modality gap.

## Pseudo Code

Here is the detailed pseudo code to implement this paper:

```python
# Input: low-resolution depth map L, high-resolution RGB image R
# Output: high-resolution depth map D

# Define the network parameters
N = number of iterations in the up-and-down sampling pipeline
C = number of channels in the depth and RGB features
H = height of the high-resolution RGB image R
W = width of the high-resolution RGB image R
h = height of the low-resolution depth map L
w = width of the low-resolution depth map L
s = scaling factor between H and h (or W and w)

# Define the network modules
sub_pixel_conv = sub-pixel convolution layer with C input channels and C output channels
avg_pool = average pooling layer with kernel size s and stride s
uncertainty_net = uncertainty estimation network with C input channels and 1 output channel
attention_module = attention module with C input channels and 1 attention map
depth_generator = depth generator network with 2C input channels and 1 output channel

# Initial upscaling stage
L_up = sub_pixel_conv(L) # upscale L to H x W using sub-pixel convolution
D_0 = L_up # initialize D_0 as L_up

# Iterative up-and-down sampling stage
for i in range(1, N+1):
  D_i_up = sub_pixel_conv(D_i-1) # upscale D_i-1 to H x W using sub-pixel convolution
  D_i_down = avg_pool(D_i_up) # downscale D_i_up to h x w using average pooling
  D_i = D_i_down # update D_i as D_i_down

# Final downscaling stage
D_N_down = avg_pool(D_N) # downscale D_N to h x w using average pooling

# Uncertainty estimation step
U_D = uncertainty_net(D_N_down) # estimate the uncertainty of D_N_down using uncertainty_net
U_R = uncertainty_net(R) # estimate the uncertainty of R using uncertainty_net

# Uncertainty filtering step
A_D = attention_module(D_N_down, U_D) # filter out the uncertain regions of D_N_down using attention_module
A_R = attention_module(R, U_R) # filter out the uncertain regions of R using attention_module

# Depth generation step
D = depth_generator(A_D, A_R) # generate the high-resolution depth map D using depth_generator

# Return the output
return D
```