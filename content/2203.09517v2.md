---
title: 2203.09517v2 TensoRF  Tensorial Radiance Fields
date: 2022-03-10
---

# [TensoRF: Tensorial Radiance Fields](http://arxiv.org/abs/2203.09517v2)

authors: Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, Hao Su


## What, Why and How

[1]: https://arxiv.org/abs/2203.09517 "[2203.09517] TensoRF: Tensorial Radiance Fields - arXiv.org"
[2]: https://arxiv-export1.library.cornell.edu/abs/2203.09517v2 "[2203.09517v2] TensoRF: Tensorial Radiance Fields"
[3]: https://arxiv.org/pdf/2203.09517v2.pdf "arXiv.org"

Here is a summary of the paper[^1^][1] [^2^][2]:

- **What**: The paper presents TensoRF, a novel approach to model and reconstruct radiance fields using tensor decomposition techniques.
- **Why**: The paper aims to improve the rendering quality, memory efficiency and reconstruction speed of radiance field modeling compared to existing methods such as NeRF that use MLPs.
- **How**: The paper proposes to represent the radiance field of a scene as a 4D tensor, which is a 3D voxel grid with per-voxel multi-channel features. The paper then introduces two ways to factorize the 4D tensor into compact low-rank components: CP decomposition and VM decomposition. The paper shows that these methods can achieve better results than NeRF and other state-of-the-art methods on various datasets and metrics.

## Main Contributions

According to the paper , the main contributions are:

- The paper proposes TensoRF, a novel framework to model and reconstruct radiance fields using tensor decomposition techniques.
- The paper introduces CP decomposition and VM decomposition, two methods to factorize the 4D scene tensor into compact low-rank components with different trade-offs between rendering quality and memory efficiency.
- The paper demonstrates that TensoRF with CP decomposition can achieve fast reconstruction (<30 min) with better rendering quality and even a smaller model size (<4 MB) compared to NeRF.
- The paper shows that TensoRF with VM decomposition can further boost rendering quality and outperform previous state-of-the-art methods, while reducing the reconstruction time (<10 min) and retaining a compact model size (<75 MB).
- The paper provides extensive experiments and ablation studies to validate the effectiveness and robustness of TensoRF on various datasets and metrics.

## Method Summary

[1]: https://arxiv.org/abs/2203.09517 "[2203.09517] TensoRF: Tensorial Radiance Fields - arXiv.org"
[2]: https://arxiv-export1.library.cornell.edu/abs/2203.09517v2 "[2203.09517v2] TensoRF: Tensorial Radiance Fields"
[3]: https://arxiv.org/pdf/2203.09517v2.pdf "arXiv.org"

Here is a summary of the method section of the paper[^1^][1] [^2^][2]:

- The paper first reviews the background of radiance field modeling and NeRF, which uses MLPs to map 5D coordinates (3D location and 2D viewing direction) to radiance and density values.
- The paper then introduces the tensor representation of radiance fields, which is a 4D tensor that stores per-voxel multi-channel features. The paper explains how to use a linear layer to map the 2D viewing direction to a channel index and then use bilinear interpolation to extract the radiance value from the tensor.
- The paper then proposes two methods to factorize the 4D tensor into compact low-rank components: CP decomposition and VM decomposition. The paper explains the mathematical formulation and implementation details of each method, as well as their advantages and disadvantages.
- The paper then describes the training procedure of TensoRF, which follows the same pipeline as NeRF but with different loss functions and regularization terms for different decomposition methods. The paper also discusses some implementation details such as voxelization, initialization and optimization.


## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the tensor representation of radiance fields
def tensor_radiance_field(voxel_grid, linear_layer):
  # voxel_grid: a 4D tensor of shape (H, W, D, C) that stores per-voxel multi-channel features
  # linear_layer: a linear layer that maps 2D viewing direction to a channel index
  def radiance_field(location, direction):
    # location: a 3D vector that represents the location in the scene
    # direction: a 2D vector that represents the viewing direction
    # Return the radiance and density values at the given location and direction
    # Use trilinear interpolation to extract the voxel features from the voxel grid
    voxel_features = trilinear_interpolation(voxel_grid, location)
    # Use the linear layer to map the direction to a channel index
    channel_index = linear_layer(direction)
    # Use bilinear interpolation to extract the radiance value from the voxel features
    radiance = bilinear_interpolation(voxel_features, channel_index)
    # Use a sigmoid function to compute the density value from the voxel features
    density = sigmoid(voxel_features)
    return radiance, density
  return radiance_field

# Define the CP decomposition method
def cp_decomposition(voxel_grid, rank):
  # voxel_grid: a 4D tensor of shape (H, W, D, C) that stores per-voxel multi-channel features
  # rank: an integer that represents the rank of the decomposition
  # Return a list of rank-one tensors that are the components of the decomposition
  # Initialize four factor matrices randomly
  A = random_matrix(H, rank)
  B = random_matrix(W, rank)
  C = random_matrix(D, rank)
  D = random_matrix(C, rank)
  # Use alternating least squares to optimize the factor matrices
  for iteration in range(max_iterations):
    # Fix A, B, C and update D by solving a least squares problem
    D = solve_least_squares(voxel_grid, A, B, C)
    # Fix A, B, D and update C by solving a least squares problem
    C = solve_least_squares(voxel_grid, A, B, D)
    # Fix A, C, D and update B by solving a least squares problem
    B = solve_least_squares(voxel_grid, A, C, D)
    # Fix B, C, D and update A by solving a least squares problem
    A = solve_least_squares(voxel_grid, B, C, D)
  # Construct the rank-one tensors from the factor matrices
  components = []
  for r in range(rank):
    component = outer_product(A[:, r], B[:, r], C[:, r], D[:, r])
    components.append(component)
  return components

# Define the VM decomposition method
def vm_decomposition(voxel_grid, rank):
  # voxel_grid: a 4D tensor of shape (H, W, D, C) that stores per-voxel multi-channel features
  # rank: an integer that represents the rank of the decomposition
  # Return a list of vector-matrix tensors that are the components of the decomposition
  # Initialize three factor matrices randomly
  A = random_matrix(H * W * D * C / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank / rank , H * W * D * C) 
B = random_matrix(rank , H * W * D * C) 
C = random_matrix(rank , H * W * D * C) 
# Use gradient descent to optimize the factor matrices
for iteration in range(max_iterations):
  # Compute the gradient of the loss function with respect to A, B and C
  grad_A = gradient_of_loss_with_respect_to_A(voxel_grid , A , B , C) 
grad_B = gradient_of_loss_with_respect_to_B(voxel_grid , A , B , C) 
grad_C = gradient_of_loss_with_respect_to_C(voxel_grid , A , B , C) 
# Update A , B and C by taking a step in the opposite direction of the gradient 
A = A - learning_rate * grad_A 
B = B - learning_rate * grad_B 
C = C - learning_rate * grad_C 
# Construct the vector-matrix tensors from the factor matrices 
components = [] 
for r in range(rank): 
  component = outer_product(A[:, r], B[r, :], C[r, :]) 
  components.append(component) 
return components

# Define the training procedure of TensoRF
def train_tensoRF(dataset, decomposition_method, rank):
  # dataset: a collection of images and camera poses of a scene
  # decomposition_method: either cp_decomposition or vm_decomposition
  # rank: an integer that represents the rank of the decomposition
  # Return a trained tensor radiance field model
  # Initialize a voxel grid randomly
  voxel_grid = random_tensor(H, W, D, C)
  # Decompose the voxel grid using the decomposition method
  components = decomposition_method(voxel_grid, rank)
  # Initialize a linear layer randomly
  linear_layer = random_linear_layer(C)
  # Construct the tensor radiance field model from the components and the linear layer
  model = tensor_radiance_field(components, linear_layer)
  # Use ray marching to render images from the model
  for image, pose in dataset:
    # Sample rays from the camera pose
    rays = sample_rays(pose)
    # Render the image from the model using ray marching
    rendered_image = ray_marching(model, rays)
    # Compute the loss function between the rendered image and the ground truth image
    loss = compute_loss(rendered_image, image)
    # Compute the gradient of the loss function with respect to the model parameters
    grad = compute_gradient(loss, model.parameters())
    # Update the model parameters by taking a step in the opposite direction of the gradient
    model.parameters() = model.parameters() - learning_rate * grad
  return model
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision

# Define some constants
H = 128 # the height of the voxel grid
W = 128 # the width of the voxel grid
D = 128 # the depth of the voxel grid
C = 64 # the number of channels of the voxel grid
rank = 16 # the rank of the decomposition
learning_rate = 0.001 # the learning rate for optimization
max_iterations = 1000 # the maximum number of iterations for optimization
num_samples = 64 # the number of samples per ray for ray marching
sigma = 1.0 # the standard deviation for density regularization

# Define a function to perform trilinear interpolation on a 4D tensor
def trilinear_interpolation(tensor, location):
  # tensor: a 4D tensor of shape (H, W, D, C) that stores per-voxel multi-channel features
  # location: a 3D vector that represents the location in the scene
  # Return a 1D vector of shape (C,) that represents the interpolated voxel features at the given location
  # Get the fractional and integer parts of the location coordinates
  x, y, z = location
  x0, x1 = int(np.floor(x)), int(np.ceil(x))
  y0, y1 = int(np.floor(y)), int(np.ceil(y))
  z0, z1 = int(np.floor(z)), int(np.ceil(z))
  xd, yd, zd = x - x0, y - y0, z - z0
  # Get the eight voxel features that surround the location
  c000 = tensor[x0, y0, z0]
  c001 = tensor[x0, y0, z1]
  c010 = tensor[x0, y1, z0]
  c011 = tensor[x0, y1, z1]
  c100 = tensor[x1, y0, z0]
  c101 = tensor[x1, y0, z1]
  c110 = tensor[x1, y1, z0]
  c111 = tensor[x1, y1, z1]
  # Perform trilinear interpolation using the fractional parts
  c00 = c000 * (1 - xd) + c100 * xd
  c01 = c001 * (1 - xd) + c101 * xd
  c10 = c010 * (1 - xd) + c110 * xd
  c11 = c011 * (1 - xd) + c111 * xd
  c0 = c00 * (1 - yd) + c10 * yd
  c1 = c01 * (1 - yd) + c11 * yd
  c = c0 * (1 - zd) + c1 * zd
  return c

# Define a function to perform bilinear interpolation on a 2D vector-matrix pair
def bilinear_interpolation(vector_matrix_pair, channel_index):
  # vector_matrix_pair: a pair of a vector and a matrix that represents a vector-matrix tensor component
  # channel_index: a scalar that represents the channel index to extract from the vector-matrix pair
  # Return a scalar that represents the interpolated radiance value at the given channel index
  # Get the vector and matrix from the pair
  vector, matrix = vector_matrix_pair
  # Get the fractional and integer parts of the channel index
  i0, i1 = int(np.floor(channel_index)), int(np.ceil(channel_index))
  id = channel_index - i0
  # Get the two radiance values that surround the channel index from the vector-matrix pair
  r0 = np.dot(vector, matrix[:, i0])
  r1 = np.dot(vector, matrix[:, i1])
  # Perform bilinear interpolation using the fractional part
  r = r0 * (1 - id) + r1 * id
  return r

# Define a function to perform outer product on four vectors or matrices to form a rank-one or vector-matrix tensor component 
def outer_product(*args):
    # args: four vectors or matrices that represent the factors of a rank-one or vector-matrix tensor component 
    # Return a rank-one or vector-matrix tensor component 
    # Use torch.outer to compute the outer product of two tensors 
    result = torch.outer(args[0], args[1]) 
    for arg in args[2:]: 
        result = torch.outer(result, arg) 
    return result

# Define a function to solve a least squares problem for CP decomposition
def solve_least_squares(tensor, *args):
  # tensor: a 4D tensor of shape (H, W, D, C) that stores per-voxel multi-channel features
  # args: three factor matrices that are fixed for CP decomposition
  # Return a factor matrix that is updated for CP decomposition
  # Reshape the tensor into a 2D matrix by combining the modes that are not fixed
  matrix = tensor.reshape(-1, tensor.shape[-1])
  # Compute the Khatri-Rao product of the fixed factor matrices
  kr_product = torch.khatri_rao(*args)
  # Solve the least squares problem using torch.lstsq
  solution, _ = torch.lstsq(matrix, kr_product)
  # Reshape the solution into a factor matrix by splitting the modes that are not fixed
  factor_matrix = solution.reshape(tensor.shape[:-1] + (-1,))
  return factor_matrix

# Define a function to compute the gradient of the loss function with respect to a factor matrix for VM decomposition
def gradient_of_loss_with_respect_to_factor_matrix(tensor, factor_matrix, *args):
  # tensor: a 4D tensor of shape (H, W, D, C) that stores per-voxel multi-channel features
  # factor_matrix: a factor matrix that is updated for VM decomposition
  # args: two factor matrices that are fixed for VM decomposition
  # Return a gradient tensor that has the same shape as the factor matrix
  # Reshape the tensor into a 2D matrix by combining the modes that are not fixed
  matrix = tensor.reshape(-1, tensor.shape[-1])
  # Compute the Khatri-Rao product of the fixed factor matrices
  kr_product = torch.khatri_rao(*args)
  # Compute the reconstructed matrix from the factor matrices
  reconstructed_matrix = torch.matmul(factor_matrix, kr_product.t())
  # Compute the residual matrix between the original and reconstructed matrices
  residual_matrix = matrix - reconstructed_matrix
  # Compute the gradient of the loss function with respect to the factor matrix using torch.matmul
  gradient = -2 * torch.matmul(residual_matrix.t(), kr_product)
  # Reshape the gradient into a tensor by splitting the modes that are not fixed
  gradient_tensor = gradient.reshape(tensor.shape[:-1] + (-1,))
  return gradient_tensor

# Define a function to sample rays from a camera pose
def sample_rays(pose):
  # pose: a 4x4 matrix that represents the camera pose (rotation and translation)
  # Return a list of rays that are sampled from the camera pose
  # Get the camera intrinsic parameters (focal length and principal point)
  f = ... # some predefined value
  cx = ... # some predefined value
  cy = ... # some predefined value
  # Get the camera extrinsic parameters (rotation and translation) from the pose matrix
  R = pose[:3, :3]
  t = pose[:3, -1]
  # Get the inverse of the camera extrinsic parameters
  R_inv = R.t()
  t_inv = -R_inv @ t
  # Initialize an empty list to store the rays
  rays = []
  # Loop over the pixels of the image plane
  for x in range(W):
    for y in range(H):
      # Compute the normalized image coordinates of the pixel
      u = (x - cx) / f
      v = (y - cy) / f
      # Compute the direction vector of the ray in camera coordinates
      d_c = np.array([u, v, -1])
      # Transform the direction vector to world coordinates using the inverse of the camera extrinsic parameters
      d_w = R_inv @ d_c
      # Normalize the direction vector to unit length
      d_w = d_w / np.linalg.norm(d_w)
      # Construct a ray object with origin and direction in world coordinates
      ray = Ray(o=t_inv, d=d_w)
      # Append the ray to the list of rays
      rays.append(ray)
   return rays

# Define a function to perform ray marching on a tensor radiance field model 
def ray_marching(model , rays): 
    # model: a tensor radiance field model that maps location and direction to radiance and density 
    # rays: a list of rays that are sampled from the camera pose 
    # Return an image that is rendered from the model using ray marching 
    # Initialize an empty image to store the rendered pixels 
    image = np.zeros((H , W , C)) 
    # Loop over the rays in the list 
    for i , ray in enumerate(rays): 
        # Get the origin and direction of the ray in world coordinates 
        o , d = ray.o , ray.d