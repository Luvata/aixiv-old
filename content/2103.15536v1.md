---
title: 2103.15536v1 Cloud2Curve  Generation and Vectorization of Parametric Sketches
date: 2021-03-16
---

# [Cloud2Curve: Generation and Vectorization of Parametric Sketches](http://arxiv.org/abs/2103.15536v1)

authors: Ayan Das, Yongxin Yang, Timothy Hospedales, Tao Xiang, Yi-Zhe Song


## What, Why and How

[1]: https://arxiv.org/pdf/2103.15536v1.pdf "arXiv:2103.15536v1 [cs.CV] 29 Mar 2021"
[2]: https://arxiv.org/abs/2103.15536 "[2103.15536] Cloud2Curve: Generation and Vectorization of Parametric ..."
[3]: http://export.arxiv.org/abs/2305.15536v1 "[2305.15536v1] RAND: Robustness Aware Norm Decay For Quantized Seq2seq ..."

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper presents Cloud2Curve, a framework that can generate and vectorize parametric sketches from point-cloud data.
- **Why**: The paper aims to model sketches as a sequence of low-dimensional parametric curves, such as Bézier curves, which are scalable and high-resolution. This can advance the generative sketch modeling paradigm and enable applications such as sketch vectorization and sketch-based image retrieval.
- **How**: The paper proposes an inverse graphics framework that can approximate a raster or waypoint based stroke encoded as a point-cloud with a variable-degree Bézier curve. The paper also proposes a generative model that can be trained end-to-end using point-cloud data alone and can produce parametric sketches. The paper evaluates the generation and vectorization capabilities of the model on Quick, Draw! and K-MNIST datasets.

## Main Contributions

[1]: https://arxiv.org/pdf/2103.15536v1.pdf "arXiv:2103.15536v1 [cs.CV] 29 Mar 2021"
[2]: https://arxiv.org/abs/2103.15536 "[2103.15536] Cloud2Curve: Generation and Vectorization of Parametric ..."
[3]: http://export.arxiv.org/abs/2305.15536v1 "[2305.15536v1] RAND: Robustness Aware Norm Decay For Quantized Seq2seq ..."

The paper claims the following contributions[^1^][1]:

- **A novel inverse graphics framework** that can approximate a raster or waypoint based stroke encoded as a point-cloud with a variable-degree Bézier curve.
- **A generative model for scalable high-resolution vector sketches** that can be trained end-to-end using point-cloud data alone and can produce parametric sketches.
- **A deterministic vectorization capability** that can map novel raster or waypoint based sketches to their corresponding high-resolution scalable Bézier equivalent.
- **Extensive experiments on Quick, Draw! and K-MNIST datasets** to demonstrate the generation and vectorization capabilities of the model and compare it with existing methods.

## Method Summary

[1]: https://arxiv.org/pdf/2103.15536v1.pdf "arXiv:2103.15536v1 [cs.CV] 29 Mar 2021"
[2]: https://arxiv.org/abs/2103.15536 "[2103.15536] Cloud2Curve: Generation and Vectorization of Parametric ..."
[3]: http://export.arxiv.org/abs/2305.15536v1 "[2305.15536v1] RAND: Robustness Aware Norm Decay For Quantized Seq2seq ..."

Here is a summary of the method section of the paper at [^1^][1]:

- The paper proposes a two-stage framework for generating and vectorizing parametric sketches from point-cloud data. The first stage is an inverse graphics module that can approximate a single stroke encoded as a point-cloud with a variable-degree Bézier curve. The second stage is a generative model that can produce a sequence of parametric curves given a latent code or a sketch class label.
- The inverse graphics module consists of three components: a point-cloud encoder, a curve decoder, and a curve sampler. The point-cloud encoder maps the input point-cloud to a latent representation using a PointNet-like architecture. The curve decoder predicts the degree and control points of the Bézier curve from the latent representation using fully connected layers. The curve sampler samples points along the predicted curve using De Casteljau's algorithm and computes the reconstruction loss with respect to the input point-cloud.
- The generative model consists of two components: a sketch encoder and a sketch decoder. The sketch encoder maps a sequence of point-clouds representing a sketch to a latent code using an LSTM network. The sketch decoder generates a sequence of parametric curves from the latent code or a sketch class label using another LSTM network. The sketch decoder shares the curve decoder and curve sampler modules with the inverse graphics module. The generative model is trained with a combination of reconstruction loss, KL-divergence loss, and adversarial loss.
- The paper also introduces a deterministic vectorization capability that can map novel raster or waypoint based sketches to their corresponding high-resolution scalable Bézier equivalent. This is achieved by applying the inverse graphics module to each stroke of the input sketch and concatenating the resulting parametric curves.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the inverse graphics module
class InverseGraphics(nn.Module):
  def __init__(self):
    # Initialize the point-cloud encoder, curve decoder, and curve sampler
    self.point_cloud_encoder = PointCloudEncoder()
    self.curve_decoder = CurveDecoder()
    self.curve_sampler = CurveSampler()

  def forward(self, point_cloud):
    # Encode the point-cloud to a latent representation
    latent = self.point_cloud_encoder(point_cloud)
    # Decode the latent representation to a Bézier curve
    degree, control_points = self.curve_decoder(latent)
    # Sample points along the Bézier curve
    curve_points = self.curve_sampler(degree, control_points)
    # Compute the reconstruction loss
    loss = mse_loss(curve_points, point_cloud)
    return loss, degree, control_points

# Define the generative model
class GenerativeModel(nn.Module):
  def __init__(self):
    # Initialize the sketch encoder, sketch decoder, and discriminator
    self.sketch_encoder = SketchEncoder()
    self.sketch_decoder = SketchDecoder()
    self.discriminator = Discriminator()
    # Share the curve decoder and curve sampler with the inverse graphics module
    self.curve_decoder = inverse_graphics_module.curve_decoder
    self.curve_sampler = inverse_graphics_module.curve_sampler

  def forward(self, sketch, label):
    # Encode the sketch to a latent code
    latent = self.sketch_encoder(sketch)
    # Decode the latent code or label to a sequence of Bézier curves
    degrees, control_points = self.sketch_decoder(latent, label)
    # Sample points along each Bézier curve
    sketch_points = [self.curve_sampler(d, c) for d, c in zip(degrees, control_points)]
    # Compute the reconstruction loss
    recon_loss = mse_loss(sketch_points, sketch)
    # Compute the KL-divergence loss
    kl_loss = kl_divergence(latent, prior)
    # Compute the adversarial loss
    real_score = self.discriminator(sketch)
    fake_score = self.discriminator(sketch_points)
    adv_loss = bce_loss(fake_score, 1) + bce_loss(real_score, 0)
    # Compute the total loss
    loss = recon_loss + kl_loss + adv_loss
    return loss, degrees, control_points

# Define the vectorization capability
def vectorize(sketch):
  # Split the sketch into strokes
  strokes = split_sketch(sketch)
  # Apply the inverse graphics module to each stroke
  curves = [inverse_graphics_module(stroke)[1:] for stroke in strokes]
  # Concatenate the resulting parametric curves
  vector_sketch = concatenate_curves(curves)
  return vector_sketch

```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# Define the hyperparameters
latent_dim = 128 # The dimension of the latent code
hidden_dim = 256 # The dimension of the hidden state of LSTM
max_degree = 5 # The maximum degree of the Bézier curve
num_classes = 10 # The number of sketch classes
batch_size = 64 # The batch size for training
num_epochs = 100 # The number of epochs for training
learning_rate = 0.001 # The learning rate for optimization

# Define the point-cloud encoder
class PointCloudEncoder(nn.Module):
  def __init__(self):
    super(PointCloudEncoder, self).__init__()
    # Initialize the PointNet-like architecture
    self.conv1 = nn.Conv1d(2, 64, 1) # Convolution layer for input point-cloud (x, y)
    self.conv2 = nn.Conv1d(64, 128, 1) # Convolution layer for feature extraction
    self.conv3 = nn.Conv1d(128, latent_dim, 1) # Convolution layer for latent representation
    self.maxpool = nn.MaxPool1d(1000) # Max pooling layer for global feature aggregation

  def forward(self, point_cloud):
    # point_cloud: (batch_size, 2, num_points)
    x = self.conv1(point_cloud) # x: (batch_size, 64, num_points)
    x = self.conv2(x) # x: (batch_size, 128, num_points)
    x = self.conv3(x) # x: (batch_size, latent_dim, num_points)
    x = self.maxpool(x) # x: (batch_size, latent_dim, 1)
    x = x.squeeze(-1) # x: (batch_size, latent_dim)
    return x

# Define the curve decoder
class CurveDecoder(nn.Module):
  def __init__(self):
    super(CurveDecoder, self).__init__()
    # Initialize the fully connected layers
    self.fc1 = nn.Linear(latent_dim, hidden_dim) # Linear layer for hidden representation
    self.fc2 = nn.Linear(hidden_dim, max_degree + 1) # Linear layer for degree prediction
    self.fc3 = nn.Linear(hidden_dim, (max_degree + 1) * 2) # Linear layer for control point prediction

  def forward(self, latent):
    # latent: (batch_size, latent_dim)
    x = self.fc1(latent) # x: (batch_size, hidden_dim)
    x = torch.relu(x) # x: (batch_size, hidden_dim)
    degree_logits = self.fc2(x) # degree_logits: (batch_size, max_degree + 1)
    degree_probs = torch.softmax(degree_logits, dim=-1) # degree_probs: (batch_size, max_degree + 1)
    degree = torch.argmax(degree_probs, dim=-1) # degree: (batch_size,)
    control_points = self.fc3(x) # control_points: (batch_size, (max_degree + 1) * 2)
    control_points = control_points.view(batch_size, max_degree + 1, 2) # control_points: (batch_size, max_degree + 1, 2)
    return degree, control_points

# Define the curve sampler
class CurveSampler(nn.Module):
  def __init__(self):
    super(CurveSampler, self).__init__()

  def forward(self, degree, control_points):
    # degree: (batch_size,)
    # control_points: (batch_size, max_degree + 1 ,2)
    num_points = control_points.size(1) # num_points: max_degree + 1
    t = torch.linspace(0.0, 1.0, num_points).unsqueeze(0).unsqueeze(-1).to(control_points.device) 
      # t: (1 ,num_points ,1)
    curve_points = [] 
      # curve_points: a list of tensors of shape (batch_size ,num_points ,2), one for each degree
    for d in range(num_points): 
      # Loop over each possible degree from 0 to max_degree
      c = control_points[:, :d+1] 
        # c: (batch_size ,d+1 ,2), the first d+1 control points
      b = c.unsqueeze(1).repeat(1 ,num_points ,1 ,1) 
        # b: (batch_size ,num_points ,d+1 ,2), the repeated control points
      for i in range(d): 
        # Loop over each iteration of De Casteljau's algorithm
        b = (1 - t) * b[:, :, :-1] + t * b[:, :, 1:] 
          # b: (batch_size ,num_points ,d-i ,2), the updated control points
      curve_points.append(b.squeeze(-2)) 
        # curve_points[d]: (batch_size ,num_points ,2), the sampled points for degree d
    curve_points = torch.stack(curve_points, dim=1) 
      # curve_points: (batch_size ,num_points ,num_points ,2)
    degree = degree.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1) 
      # degree: (batch_size ,1 ,1 ,1)
    curve_points = torch.gather(curve_points, 1, degree.repeat(1, 1, num_points, 2)) 
      # curve_points: (batch_size ,1 ,num_points ,2), the sampled points for the predicted degree
    curve_points = curve_points.squeeze(1) 
      # curve_points: (batch_size ,num_points ,2)
    return curve_points

# Define the sketch encoder
class SketchEncoder(nn.Module):
  def __init__(self):
    super(SketchEncoder, self).__init__()
    # Initialize the LSTM network
    self.lstm = nn.LSTM(latent_dim, hidden_dim, batch_first=True) # LSTM layer for sequential encoding

  def forward(self, sketch):
    # sketch: (batch_size, num_strokes, num_points, 2)
    batch_size, num_strokes, _, _ = sketch.size()
    sketch = sketch.view(batch_size * num_strokes, -1, 2) # sketch: (batch_size * num_strokes, num_points, 2)
    latent = point_cloud_encoder(sketch) # latent: (batch_size * num_strokes, latent_dim)
    latent = latent.view(batch_size, num_strokes, -1) # latent: (batch_size, num_strokes, latent_dim)
    _, (hidden, _) = self.lstm(latent) # hidden: (1, batch_size, hidden_dim)
    hidden = hidden.squeeze(0) # hidden: (batch_size, hidden_dim)
    return hidden

# Define the sketch decoder
class SketchDecoder(nn.Module):
  def __init__(self):
    super(SketchDecoder, self).__init__()
    # Initialize the LSTM network
    self.lstm = nn.LSTM(latent_dim + num_classes, hidden_dim, batch_first=True) # LSTM layer for sequential decoding
    # Share the curve decoder and curve sampler with the inverse graphics module
    self.curve_decoder = inverse_graphics_module.curve_decoder
    self.curve_sampler = inverse_graphics_module.curve_sampler

  def forward(self, latent=None, label=None):
    # latent: (batch_size, latent_dim) or None
    # label: (batch_size,) or None
    if latent is not None and label is not None:
      raise ValueError("Only one of latent or label can be given as input")
    if latent is None and label is None:
      raise ValueError("At least one of latent or label must be given as input")
    if latent is not None:
      # Use the latent code as the initial input
      input = latent.unsqueeze(1) # input: (batch_size, 1, latent_dim)
      label = torch.zeros(batch_size).long().to(latent.device) # label: (batch_size,)
    if label is not None:
      # Use the label as the initial input
      input = torch.zeros(batch_size, 1).to(label.device) # input: (batch_size, 1)
      input = torch.nn.functional.one_hot(input.long(), num_classes=num_classes).float() 
        # input: (batch_size, 1, num_classes)
      label = label.to(input.device) # label: (batch_size,)
    degrees = [] 
      # degrees: a list of tensors of shape (batch_size,), one for each stroke
    control_points = [] 
      # control_points: a list of tensors of shape (batch_size ,max_degree + 1 ,2), one for each stroke
    hidden = None 
      # hidden: the hidden state of the LSTM network
    for i in range(num_strokes): 
      # Loop over each stroke to generate
      output, hidden = self.lstm(input, hidden) 
        # output: (batch_size ,1 ,hidden_dim), hidden: a tuple of two tensors of shape (1 ,batch_size ,hidden_dim)
      degree, control_point = self.curve_decoder(output.squeeze(1)) 
        # degree: (batch_size,), control_point: (batch_size ,max_degree + 1 ,2)
      degrees.append(degree)