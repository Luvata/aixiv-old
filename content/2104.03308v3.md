---
title: 2104.03308v3 Warp Consistency for Unsupervised Learning of Dense Correspondences
date: 2021-04-04
---

# [Warp Consistency for Unsupervised Learning of Dense Correspondences](http://arxiv.org/abs/2104.03308v3)

authors: Prune Truong, Martin Danelljan, Fisher Yu, Luc Van Gool


## What, Why and How

[1]: https://arxiv.org/abs/2104.03308 "[2104.03308] Warp Consistency for Unsupervised Learning of Dense ..."
[2]: https://arxiv.org/abs/2109.03308 "[2109.03308] Hybridized Methods for Quantum Simulation in the ..."
[3]: http://export.arxiv.org/abs/2109.03308v3 "[2109.03308v3] Hybridized Methods for Quantum Simulation in the ..."

Here is a summary of the paper:

**What**: The paper proposes a new unsupervised learning objective for dense correspondence regression, called Warp Consistency. It also applies this objective to three recent dense correspondence networks and evaluates them on several benchmarks.

**Why**: The paper aims to address the key challenge in learning dense correspondences, which is the lack of ground-truth matches for real image pairs. Existing methods based on photometric consistency losses struggle with large appearance and view-point changes, which are common in geometric and semantic matching tasks. Moreover, methods relying on synthetic training pairs often suffer from poor generalisation to real data.

**How**: The paper introduces Warp Consistency, which leverages a randomly sampled warp to construct an image triplet from a pair of real images. It then derives and analyzes all flow-consistency constraints arising between the triplet, and selects two of them to design a general unsupervised objective. The paper also shows how to combine Warp Consistency with other losses, such as cycle consistency and self-supervision. The paper trains three state-of-the-art dense correspondence networks (RAFT, DGC-Net and GOCor) with Warp Consistency and compares them with their original versions and other baselines on several datasets, such as MegaDepth, RobotCar and TSS. The paper reports significant improvements in performance and generalisation for the geometric and semantic matching tasks.

The summary is based on the abstract and introduction of the paper[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/2104.03308 "[2104.03308] Warp Consistency for Unsupervised Learning of Dense ..."
[2]: https://arxiv.org/abs/2109.03308 "[2109.03308] Hybridized Methods for Quantum Simulation in the ..."
[3]: http://export.arxiv.org/abs/2109.03308v3 "[2109.03308v3] Hybridized Methods for Quantum Simulation in the ..."

According to the paper, the main contributions are:

- **Warp Consistency**, a novel unsupervised learning objective for dense correspondence regression that leverages a randomly sampled warp to construct an image triplet and enforces flow-consistency constraints between them.
- A theoretical analysis of the flow-consistency constraints and their properties, as well as a practical implementation of Warp Consistency that combines two of the derived constraints with other losses, such as cycle consistency and self-supervision.
- An extensive evaluation of Warp Consistency on three state-of-the-art dense correspondence networks (RAFT, DGC-Net and GOCor) and several challenging benchmarks (MegaDepth, RobotCar and TSS), demonstrating significant improvements in performance and generalisation for the geometric and semantic matching tasks.
- A new state-of-the-art on several benchmarks, including MegaDepth, RobotCar and TSS, as well as competitive results on KITTI and Sintel.

The contributions are listed in section 1.1 of the paper[^1^][1].

## Method Summary

[1]: https://arxiv.org/abs/2104.03308 "[2104.03308] Warp Consistency for Unsupervised Learning of Dense ..."
[2]: https://arxiv.org/abs/2109.03308 "[2109.03308] Hybridized Methods for Quantum Simulation in the ..."
[3]: http://export.arxiv.org/abs/2109.03308v3 "[2109.03308v3] Hybridized Methods for Quantum Simulation in the ..."

Here is a summary of the method section of the paper:

The method section consists of four subsections: 3.1 Warp Consistency, 3.2 Flow-Consistency Constraints, 3.3 Warp Consistency Loss, and 3.4 Implementation Details.

- In subsection 3.1, the paper introduces the concept of Warp Consistency, which is based on the idea of constructing an image triplet from a pair of real images by applying a randomly sampled warp to one of them. The paper defines a warp as a function that maps pixels from one image to another, and assumes that the warp is invertible and differentiable. The paper also defines a flow as a vector field that represents the displacement of pixels between two images, and assumes that the flow is consistent with the warp.
- In subsection 3.2, the paper derives and analyzes all possible flow-consistency constraints arising between the image triplet. The paper shows that there are six constraints in total, and that they can be grouped into three categories: forward-backward consistency, cycle consistency, and warp consistency. The paper also discusses the properties and limitations of each constraint, such as symmetry, transitivity, robustness to occlusions, and sensitivity to appearance changes.
- In subsection 3.3, the paper proposes a general unsupervised objective for dense correspondence regression that employs two of the derived constraints: forward-backward consistency and warp consistency. The paper argues that these two constraints are complementary and effective for learning dense correspondences in settings with large appearance and view-point changes. The paper also shows how to combine Warp Consistency with other losses, such as cycle consistency and self-supervision, to further improve the performance and generalisation of the method.
- In subsection 3.4, the paper provides some implementation details of Warp Consistency, such as how to sample warps, how to compute flows, how to handle occlusions and invalid pixels, and how to balance different loss terms. The paper also describes how to apply Warp Consistency to three state-of-the-art dense correspondence networks: RAFT , DGC-Net , and GOCor .

The summary is based on section 3 of the paper[^1^][1].

## Pseudo Code - High level

Here is a possible high-level pseudo code for this paper:

```python
# Input: a pair of real images I1 and I2
# Output: a dense correspondence map F12 from I1 to I2

# Step 1: Sample a random warp W and apply it to I2 to get I3
W = sample_warp()
I3 = warp(I2, W)

# Step 2: Compute the flows F13 and F32 between I1 and I3, and I3 and I2, using a dense correspondence network
F13 = network(I1, I3)
F32 = network(I3, I2)

# Step 3: Compute the flow F12 between I1 and I2 by composing F13 and F32
F12 = compose(F13, F32)

# Step 4: Compute the losses based on the flow-consistency constraints and other terms
L_fb = forward_backward_consistency_loss(F12, F21) # F21 is the flow from I2 to I1
L_wc = warp_consistency_loss(F12, W) # W is the warp from I2 to I1
L_cc = cycle_consistency_loss(F12, F23, F31) # F23 and F31 are the flows from I2 to I3 and I3 to I1
L_ss = self_supervision_loss(F12, F_gt) # F_gt is the ground-truth flow from synthetic data
L_total = L_fb + L_wc + L_cc + L_ss

# Step 5: Update the network parameters using gradient descent
network.update(L_total)
```


## Pseudo Code - Detail

Here is a possible detailed pseudo code to implement this paper:

```python
# Input: a pair of real images I1 and I2
# Output: a dense correspondence map F12 from I1 to I2

# Step 1: Sample a random warp W and apply it to I2 to get I3
W = sample_warp()
I3 = warp(I2, W)

# Step 2: Compute the flows F13 and F32 between I1 and I3, and I3 and I2, using a dense correspondence network
F13 = network(I1, I3)
F32 = network(I3, I2)

# Step 3: Compute the flow F12 between I1 and I2 by composing F13 and F32
F12 = compose(F13, F32)

# Step 4: Compute the losses based on the flow-consistency constraints and other terms
L_fb = forward_backward_consistency_loss(F12, F21) # F21 is the flow from I2 to I1
L_wc = warp_consistency_loss(F12, W) # W is the warp from I2 to I1
L_cc = cycle_consistency_loss(F12, F23, F31) # F23 and F31 are the flows from I2 to I3 and I3 to I1
L_ss = self_supervision_loss(F12, F_gt) # F_gt is the ground-truth flow from synthetic data
L_total = L_fb + L_wc + L_cc + L_ss

# Step 5: Update the network parameters using gradient descent
network.update(L_total)

# Functions used in the pseudo code:

def sample_warp():
  # Sample a random warp from a predefined distribution
  # The warp can be affine, homography, or thin-plate spline
  # The warp parameters can be sampled from uniform or normal distributions
  # Return the warp as a function that maps pixels from one image to another

def warp(I, W):
  # Apply the warp W to the image I
  # Use bilinear interpolation to get the pixel values at the warped locations
  # Handle boundary conditions by padding or cropping the image
  # Return the warped image

def network(I1, I2):
  # Use a dense correspondence network to compute the flow between I1 and I2
  # The network can be RAFT, DGC-Net, or GOCor
  # Use a pretrained model or train from scratch with Warp Consistency
  # Return the flow as a tensor of shape (H, W, 2), where H and W are the height and width of the images

def compose(F1, F2):
  # Compose two flows F1 and F2 using bilinear sampling
  # F1 is a flow from image A to image B
  # F2 is a flow from image B to image C
  # The composition is F1(F2(x)), where x is a pixel location in image A
  # Return the composed flow as a tensor of shape (H, W, 2), where H and W are the height and width of image A

def forward_backward_consistency_loss(F12, F21):
  # Compute the forward-backward consistency loss between two flows F12 and F21
  # F12 is a flow from image A to image B
  # F21 is a flow from image B to image A
  # The loss is defined as L_fb = E[|F12 + F21(F12)|], where E is the mean over all pixels
  # Use an occlusion mask to exclude invalid pixels from the loss computation
  # Return the loss as a scalar

def warp_consistency_loss(F12, W):
  # Compute the warp consistency loss between a flow F12 and a warp W
  # F12 is a flow from image A to image B
  # W is a warp from image B to image A
  # The loss is defined as L_wc = E[|F12 - W|], where E is the mean over all pixels
  # Use an occlusion mask to exclude invalid pixels from the loss computation
  # Return the loss as a scalar

def cycle_consistency_loss(F12, F23, F31):
  # Compute the cycle consistency loss between three flows F12, F23, and F31
  # F12 is a flow from image A to image B
  # F23 is a flow from image B to image C
  # F31 is a flow from image C to image A
  # The loss is defined as L_cc = E[|F31 + F12(F23)|], where E is the mean over all pixels
  # Use an occlusion mask to exclude invalid pixels from the loss computation
  # Return the loss as a scalar

def self_supervision_loss(F12, F_gt):
  # Compute the self-supervision loss between a flow F12 and a ground-truth flow F_gt
  # F12 is a flow from image A to image B
  # F_gt is a ground-truth flow from image A to image B, obtained from synthetic data
  # The loss is defined as L_ss = E[|F12 - F_gt|], where E is the mean over all pixels
  # Use an occlusion mask to exclude invalid pixels from the loss computation
  # Return the loss as a scalar
```