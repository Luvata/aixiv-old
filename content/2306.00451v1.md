---
title: 2306.00451v1 S$^2$ME  Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-supervised Polyp Segmentation
date: 2023-06-01
---

# [S$^2$ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-supervised Polyp Segmentation](http://arxiv.org/abs/2306.00451v1)

authors: An Wang, Mengya Xu, Yang Zhang, Mobarakol Islam, Hongliang Ren


## What, Why and How

[1]: https://arxiv.org/abs/2306.00451 "[2306.00451] S$^2$ME: Spatial-Spectral Mutual Teaching and ... - arXiv.org"
[2]: https://arxiv.org/pdf/2303.00451v1.pdf "A Variational Approach to Mutual Information-Based Coordination for ..."
[3]: http://export.arxiv.org/abs/2305.00451v1 "[2305.00451v1] Speckle Interferometry with CMOS Detector"

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a framework of Spatial-Spectral Dual-branch Mutual Teaching and Entropy-guided Pseudo Label Ensemble Learning (S$^2$ME) for scribble-supervised polyp segmentation.
- **Why**: The paper aims to address the challenges of label-efficiency, data shifts, and corruption in medical image segmentation, which are important for the early diagnosis of colorectal cancer.
- **How**: The paper leverages the intrinsic complementarity of features extracted from the spatial and spectral domains and encourages cross-space consistency through collaborative optimization. The paper also introduces a novel adaptive pixel-wise fusion technique based on the entropy guidance from the spatial and spectral branches to produce reliable mixed pseudo labels. The paper formulates a holistic optimization objective to learn from the hybrid supervision of scribbles and pseudo labels. The paper evaluates the proposed method on four public datasets and demonstrates its superiority regarding in-distribution accuracy, out-of-distribution generalization, and robustness.

## Main Contributions

According to the paper, the main contributions are:

- The first application of dual-branch co-teaching framework in weakly-supervised medical image segmentation, which exploits the spatial and spectral features of polyp images and enforces cross-space consistency.
- A novel entropy-guided pixel-wise fusion technique for generating reliable mixed pseudo labels from the spatial and spectral branches, which improves the effectiveness of ensemble learning and mitigates the noise and uncertainty in pseudo labels.
- A holistic optimization objective that combines the hybrid supervision of scribbles and pseudo labels with a regularization term that balances the trade-off between accuracy and diversity of the ensemble models.
- Extensive experiments and evaluation on four public datasets that show the superiority of the proposed method over existing methods in terms of in-distribution accuracy, out-of-distribution generalization, and robustness.

## Method Summary

The method section of the paper consists of four subsections:

- **Spatial-Spectral Dual-branch Mutual Teaching (S$^2$MT)**: This subsection describes the dual-branch co-teaching framework that consists of two branches: a spatial branch that extracts features from the RGB images and a spectral branch that extracts features from the HSI images. The two branches are trained simultaneously and mutually by exchanging pseudo labels and enforcing cross-space consistency. The pseudo labels are generated by applying a threshold to the softmax output of each branch. The cross-space consistency is achieved by minimizing the KL divergence between the softmax outputs of the two branches.
- **Entropy-guided Pixel-wise Fusion (EPF)**: This subsection introduces the entropy-guided pixel-wise fusion technique that generates mixed pseudo labels from the spatial and spectral pseudo labels. The mixed pseudo labels are obtained by fusing the spatial and spectral pseudo labels according to their entropy values. The entropy values reflect the uncertainty and confidence of each branch for each pixel. The fusion technique assigns higher weights to the pseudo labels with lower entropy and vice versa. The fusion technique also incorporates a background prior to avoid over-segmentation.
- **Pseudo Label Ensemble Learning (PLE)**: This subsection presents the pseudo label ensemble learning technique that learns from the hybrid supervision of scribbles and mixed pseudo labels. The scribbles are sparse and noisy annotations provided by human experts. The mixed pseudo labels are dense and reliable annotations generated by the EPF technique. The PLE technique combines the scribble loss and the pseudo label loss to optimize the dual-branch network. The scribble loss is computed by applying a cross-entropy loss to the pixels that are annotated by scribbles. The pseudo label loss is computed by applying a cross-entropy loss to the pixels that are not annotated by scribbles but have mixed pseudo labels.
- **Optimization Objective**: This subsection formulates the optimization objective that incorporates a regularization term to balance the trade-off between accuracy and diversity of the ensemble models. The regularization term is based on the mutual information between the spatial and spectral branches, which measures the dependency and complementarity of the two branches. The optimization objective aims to maximize the mutual information between the two branches while minimizing their individual losses. The optimization objective is solved by using stochastic gradient descent with momentum.


## Pseudo Code

Here is the detailed pseudo code to implement this paper:

```python
# Define the spatial and spectral branches of the dual-branch network
spatial_branch = UNet(input_channels=3, output_channels=2) # RGB images
spectral_branch = UNet(input_channels=31, output_channels=2) # HSI images

# Define the loss functions for scribbles and pseudo labels
scribble_loss = CrossEntropyLoss()
pseudo_label_loss = CrossEntropyLoss()

# Define the optimizer and the hyperparameters
optimizer = SGD(lr=0.01, momentum=0.9)
epochs = 100
batch_size = 16
threshold = 0.5 # for generating pseudo labels
alpha = 0.1 # for balancing the trade-off between accuracy and diversity

# Load the training data and the scribbles
train_data = load_data()
scribbles = load_scribbles()

# Train the dual-branch network
for epoch in range(epochs):
  # Shuffle the training data
  train_data.shuffle()
  # Loop over the batches of training data
  for batch in train_data.batch(batch_size):
    # Get the RGB and HSI images and the ground truth masks
    rgb_images, hsi_images, masks = batch
    # Forward pass the RGB and HSI images through the spatial and spectral branches
    spatial_output = spatial_branch(rgb_images)
    spectral_output = spectral_branch(hsi_images)
    # Compute the softmax outputs of the two branches
    spatial_softmax = softmax(spatial_output)
    spectral_softmax = softmax(spectral_output)
    # Generate pseudo labels by applying a threshold to the softmax outputs
    spatial_pseudo_labels = (spatial_softmax > threshold).astype(int)
    spectral_pseudo_labels = (spectral_softmax > threshold).astype(int)
    # Fuse the spatial and spectral pseudo labels using entropy-guided pixel-wise fusion technique
    mixed_pseudo_labels = fuse(spatial_pseudo_labels, spectral_pseudo_labels, spatial_softmax, spectral_softmax, scribbles)
    # Compute the scribble loss for the two branches
    spatial_scribble_loss = scribble_loss(spatial_output, masks, scribbles)
    spectral_scribble_loss = scribble_loss(spectral_output, masks, scribbles)
    # Compute the pseudo label loss for the two branches
    spatial_pseudo_label_loss = pseudo_label_loss(spatial_output, mixed_pseudo_labels, scribbles)
    spectral_pseudo_label_loss = pseudo_label_loss(spectral_output, mixed_pseudo_labels, scribbles)
    # Compute the cross-space consistency loss for the two branches using KL divergence
    spatial_consistency_loss = kl_divergence(spatial_softmax, spectral_softmax)
    spectral_consistency_loss = kl_divergence(spectral_softmax, spatial_softmax)
    # Compute the mutual information regularization term for the two branches using variational bound
    mutual_information_term = mutual_information(spatial_output, spectral_output)
    # Compute the total loss for each branch by combining all the loss terms and the regularization term
    spatial_loss = spatial_scribble_loss + spatial_pseudo_label_loss + spatial_consistency_loss - alpha * mutual_information_term
    spectral_loss = spectral_scribble_loss + spectral_pseudo_label_loss + spectral_consistency_loss - alpha * mutual_information_term
    # Backpropagate the gradients and update the parameters of both branches
    optimizer.zero_grad()
    spatial_loss.backward(retain_graph=True)
    spectral_loss.backward()
    optimizer.step()
```