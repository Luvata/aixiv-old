---
title: 1801.06761v2 PU-Net  Point Cloud Upsampling Network
date: 2018-01-07
---

# [PU-Net: Point Cloud Upsampling Network](http://arxiv.org/abs/1801.06761v2)

authors: Lequan Yu, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, Pheng-Ann Heng


## What, Why and How

[1]: https://arxiv.org/abs/1801.06761 "[1801.06761] PU-Net: Point Cloud Upsampling Network - arXiv.org"
[2]: https://arxiv.org/pdf/1901.06761v2.pdf "HYPERBOLIC METRIC, PUNCTURED RIEMANN SPHERE AND MODULAR FUNCTIONS arXiv ..."
[3]: https://arxiv.org/pdf/1801.06761v2.pdf "arXiv.org e-Print archive"
[4]: http://export.arxiv.org/abs/1802.06761v2 "[1802.06761v2] Efficient integrand reduction for particles with spin"

Here is a summary of the paper:

- **What**: The paper presents a data-driven point cloud upsampling technique that uses a deep neural network to learn multi-level features per point and expand the point set in feature space.
- **Why**: The paper aims to address the challenge of learning and analyzing 3D point clouds with deep networks due to the sparseness and irregularity of the data. The paper also aims to improve the uniformity and accuracy of the upsampled points compared to some baseline methods and an optimization-based method.
- **How**: The paper proposes a network called PU-Net that operates at a patch-level and consists of three main components: a feature extraction unit, a multi-branch convolution unit, and a reconstruction unit. The network is trained with a joint loss function that encourages the upsampled points to remain on the underlying surface with a uniform distribution. The paper evaluates the method on synthetic and scan data and demonstrates its superiority over some baseline methods and an optimization-based method[^1^][1].

[^1^][1]: [1801.06761] PU-Net: Point Cloud Upsampling Network - arXiv.org

## Main Contributions

[1]: https://arxiv.org/abs/1801.06761 "[1801.06761] PU-Net: Point Cloud Upsampling Network - arXiv.org"
[2]: https://arxiv.org/pdf/1901.06761v2.pdf "HYPERBOLIC METRIC, PUNCTURED RIEMANN SPHERE AND MODULAR FUNCTIONS arXiv ..."
[3]: https://arxiv.org/pdf/1801.06761v2.pdf "arXiv.org e-Print archive"
[4]: http://export.arxiv.org/abs/1802.06761v2 "[1802.06761v2] Efficient integrand reduction for particles with spin"

Some of the contributions of this paper are:

- It proposes a novel network architecture called **PU-Net** that can learn multi-level features per point and expand the point set in feature space via a multi-branch convolution unit[^1^][1].
- It introduces a joint loss function that combines **chamfer distance**, **repulsion loss**, and **normal consistency loss** to encourage the upsampled points to remain on the underlying surface with a uniform distribution[^1^][1].
- It conducts extensive experiments on synthetic and scan data and shows that the proposed method outperforms some baseline methods and an optimization-based method in terms of **uniformity**, **accuracy**, and **efficiency**[^1^][1].

[^1^][1]: [1801.06761] PU-Net: Point Cloud Upsampling Network - arXiv.org


## Method Summary

[1]: https://arxiv.org/abs/1801.06761 "[1801.06761] PU-Net: Point Cloud Upsampling Network - arXiv.org"
[2]: https://arxiv.org/pdf/1901.06761v2.pdf "HYPERBOLIC METRIC, PUNCTURED RIEMANN SPHERE AND MODULAR FUNCTIONS arXiv ..."
[3]: https://arxiv.org/pdf/1801.06761v2.pdf "arXiv.org e-Print archive"
[4]: http://export.arxiv.org/abs/1802.06761v2 "[1802.06761v2] Efficient integrand reduction for particles with spin"

Here is a summary of the method section of the paper:

- The paper proposes a network architecture called **PU-Net** that consists of three main components: a feature extraction unit, a multi-branch convolution unit, and a reconstruction unit[^1^][1].
- The feature extraction unit uses a series of **1D convolution layers** and **max pooling layers** to learn multi-level features per point from the input point cloud patch[^1^][1].
- The multi-branch convolution unit uses **four parallel branches** with different dilation rates to expand the feature vector of each point by a factor of four, resulting in four times more points in feature space[^1^][1].
- The reconstruction unit uses a **splitting layer** to divide the expanded feature vector into four sub-vectors, each corresponding to one upsampled point. Then, it uses a **fully connected layer** to map each sub-vector to a 3D coordinate[^1^][1].
- The paper introduces a joint loss function that combines three terms: **chamfer distance**, **repulsion loss**, and **normal consistency loss**[^1^][1].
- The chamfer distance measures the average distance between the upsampled points and the ground truth points, and vice versa[^1^][1].
- The repulsion loss penalizes the upsampled points that are too close to each other, which helps to improve the uniformity of the point distribution[^1^][1].
- The normal consistency loss encourages the upsampled points to have similar normals as the ground truth points, which helps to preserve the surface details[^1^][1].

[^1^][1]: [1801.06761] PU-Net: Point Cloud Upsampling Network - arXiv.org


## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the network architecture
def PU-Net(input):
  # Input: a point cloud patch of size N x 3
  # Output: an upsampled point cloud patch of size 4N x 3

  # Feature extraction unit
  features = conv1d(input, filters=64) # N x 64
  features = max_pool(features) # N/2 x 64
  features = conv1d(features, filters=128) # N/2 x 128
  features = max_pool(features) # N/4 x 128
  features = conv1d(features, filters=256) # N/4 x 256
  features = max_pool(features) # N/8 x 256
  features = conv1d(features, filters=512) # N/8 x 512

  # Multi-branch convolution unit
  branch1 = conv1d(features, filters=512, dilation_rate=1) # N/8 x 512
  branch2 = conv1d(features, filters=512, dilation_rate=2) # N/8 x 512
  branch3 = conv1d(features, filters=512, dilation_rate=4) # N/8 x 512
  branch4 = conv1d(features, filters=512, dilation_rate=8) # N/8 x 512
  expanded_features = concatenate(branch1, branch2, branch3, branch4) # N/8 x 2048

  # Reconstruction unit
  upsampled_features = reshape(expanded_features, shape=(N/2, -1)) # N/2 x (2048 * 4)
  upsampled_points = fully_connected(upsampled_features, units=3) # N/2 x (3 * 4)
  upsampled_points = reshape(upsampled_points, shape=(N * 2, -1)) # N * 2 x (3 * 2)
  
  return upsampled_points

# Define the loss function
def loss_function(upsampled_points, ground_truth_points):
  
  # Chamfer distance
  cd_loss = average(minimum_distance(upsampled_points, ground_truth_points)) + average(minimum_distance(ground_truth_points, upsampled_points))

  # Repulsion loss
  rep_loss = average(maximum_distance(upsampled_points))

  # Normal consistency loss
  nc_loss = average(cosine_distance(upsampled_normals, ground_truth_normals))

  # Joint loss function
  joint_loss = cd_loss + lambda * rep_loss + gamma * nc_loss

  return joint_loss

# Train the network
for epoch in epochs:
  
  for batch in batches:

    # Sample point cloud patches from the input data
    input_patches = sample_patches(input_data)

    # Upsample the point cloud patches using the network
    upsampled_patches = PU-Net(input_patches)

    # Compute the loss function using the ground truth patches
    loss = loss_function(upsampled_patches, ground_truth_patches)

    # Update the network parameters using backpropagation and gradient descent
    update_parameters(loss)

# Test the network on new data
test_patches = sample_patches(test_data)
test_upsampled_patches = PU-Net(test_patches)
evaluate(test_upsampled_patches)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import tensorflow as tf

# Define some hyperparameters
N = 256 # The number of points in each input patch
M = 1024 # The number of points in each ground truth patch
lambda = 0.001 # The weight for the repulsion loss
gamma = 0.01 # The weight for the normal consistency loss
learning_rate = 0.0001 # The learning rate for gradient descent
epochs = 100 # The number of epochs for training
batch_size = 32 # The batch size for training

# Define the network architecture
def PU-Net(input):
  # Input: a point cloud patch of size N x 3
  # Output: an upsampled point cloud patch of size 4N x 3

  # Feature extraction unit
  features = tf.keras.layers.Conv1D(filters=64, kernel_size=1, activation='relu')(input) # N x 64
  features = tf.keras.layers.MaxPool1D(pool_size=2)(features) # N/2 x 64
  features = tf.keras.layers.Conv1D(filters=128, kernel_size=1, activation='relu')(features) # N/2 x 128
  features = tf.keras.layers.MaxPool1D(pool_size=2)(features) # N/4 x 128
  features = tf.keras.layers.Conv1D(filters=256, kernel_size=1, activation='relu')(features) # N/4 x 256
  features = tf.keras.layers.MaxPool1D(pool_size=2)(features) # N/8 x 256
  features = tf.keras.layers.Conv1D(filters=512, kernel_size=1, activation='relu')(features) # N/8 x 512

  # Multi-branch convolution unit
  branch1 = tf.keras.layers.Conv1D(filters=512, kernel_size=1, dilation_rate=1, activation='relu')(features) # N/8 x 512
  branch2 = tf.keras.layers.Conv1D(filters=512, kernel_size=1, dilation_rate=2, activation='relu')(features) # N/8 x 512
  branch3 = tf.keras.layers.Conv1D(filters=512, kernel_size=1, dilation_rate=4, activation='relu')(features) # N/8 x 512
  branch4 = tf.keras.layers.Conv1D(filters=512, kernel_size=1, dilation_rate=8, activation='relu')(features) # N/8 x 512
  expanded_features = tf.concat([branch1, branch2, branch3, branch4], axis=-1) # N/8 x 2048

  # Reconstruction unit
  upsampled_features = tf.reshape(expanded_features, shape=(-1, N/2, -1)) # N/2 x (2048 * 4)
  upsampled_points = tf.keras.layers.Dense(units=3)(upsampled_features) # N/2 x (3 * 4)
  upsampled_points = tf.reshape(upsampled_points, shape=(-1, N * 2, -1)) # N * 2 x (3 * 2)
  
  return upsampled_points

# Define the loss function
def loss_function(upsampled_points, ground_truth_points):
  
  # Chamfer distance
  cd_loss = tf.reduce_mean(tf.reduce_min(tf.norm(upsampled_points[:, :, None] - ground_truth_points[:, None], axis=-1), axis=-1)) + \
            tf.reduce_mean(tf.reduce_min(tf.norm(ground_truth_points[:, :, None] - upsampled_points[:, None], axis=-1), axis=-1))

  # Repulsion loss
  rep_loss = tf.reduce_mean(tf.reduce_max(tf.norm(upsampled_points[:, :, None] - upsampled_points[:, None], axis=-1), axis=-1))

  # Normal consistency loss
  upsampled_normals = compute_normals(upsampled_points) # Use some function to compute the normals of the upsampled points
  ground_truth_normals = compute_normals(ground_truth_points) # Use some function to compute the normals of the ground truth points
  nc_loss = tf.reduce_mean(tf.abs(tf.reduce_sum(upsampled_normals * ground_truth_normals)))

  # Joint loss function
  joint_loss = cd_loss + lambda * rep_loss + gamma * nc_loss

  return joint_loss

# Define the optimizer
optimizer = tf.keras.optimizers.Adam(learning_rate)

# Define the network model
model = PU-Net

# Train the network
for epoch in range(epochs):
  
  for batch in range(batches):

    # Sample point cloud patches from the input data
    input_patches = sample_patches(input_data, size=N, batch_size=batch_size)

    # Sample ground truth patches from the input data
    ground_truth_patches = sample_patches(input_data, size=M, batch_size=batch_size)

    # Compute the gradients and update the network parameters
    with tf.GradientTape() as tape:
      upsampled_patches = model(input_patches)
      loss = loss_function(upsampled_patches, ground_truth_patches)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))

    # Print the loss value
    print("Epoch: {}, Batch: {}, Loss: {}".format(epoch, batch, loss))

# Test the network on new data
test_patches = sample_patches(test_data, size=N, batch_size=batch_size)
test_upsampled_patches = model(test_patches)
evaluate(test_upsampled_patches) # Use some function to evaluate the performance of the upsampled patches
```