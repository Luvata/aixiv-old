---
title: 2112.07804v2 Tackling the Generative Learning Trilemma with Denoising Diffusion GANs
date: 2021-12-08
---

# [Tackling the Generative Learning Trilemma with Denoising Diffusion GANs](http://arxiv.org/abs/2112.07804v2)

authors: Zhisheng Xiao, Karsten Kreis, Arash Vahdat


## What, Why and How

[1]: https://arxiv.org/abs/2112.07804 "[2112.07804] Tackling the Generative Learning Trilemma with Denoising ..."
[2]: https://arxiv.org/pdf/2112.07804v2.pdf "TACKLING THE GENERATIVE LEARNING TRILEMMA WITH DIFFUSION GANS - arXiv.org"
[3]: https://arxiv-export2.library.cornell.edu/abs/2212.07804v2 "[2212.07804v2] Martingale Type, the Gamlen-Gaudet Construction and a ..."

Here is a summary of the paper at [^1^][1]:

- **What**: The paper introduces a new generative model called denoising diffusion GANs (DD-GANs) that combines denoising diffusion models with generative adversarial networks (GANs).
- **Why**: The paper aims to tackle the generative learning trilemma, which is the challenge of achieving high sample quality, mode coverage and fast sampling in deep generative models. The paper argues that existing models often trade some of these requirements for others, and that denoising diffusion models have slow sampling due to the Gaussian assumption in the denoising step.
- **How**: The paper proposes to model the denoising distribution using a complex multimodal distribution, and to use a conditional GAN to learn this distribution at each denoising step. The paper shows that DD-GANs can achieve competitive sample quality and diversity with original diffusion models while being much faster, and can also exhibit better mode coverage and diversity than traditional GANs.

## Main Contributions

According to the paper, the main contributions are:

- They introduce the generative learning trilemma as a framework to evaluate deep generative models on three key requirements: sample quality, mode coverage and sampling speed.
- They identify the Gaussian assumption in the denoising step of diffusion models as the main bottleneck for fast sampling, and propose to model the denoising distribution using a complex multimodal distribution.
- They present denoising diffusion GANs (DD-GANs) as a novel generative model that combines denoising diffusion models with conditional GANs to learn the multimodal denoising distribution at each step.
- They demonstrate that DD-GANs can achieve competitive sample quality and diversity with original diffusion models while being 2000 times faster on the CIFAR-10 dataset, and can also outperform traditional GANs on mode coverage and diversity.

## Method Summary

The method section of the paper consists of four subsections:

- In the first subsection, the paper reviews the basics of denoising diffusion models, which are generative models that learn to reverse a diffusion process that gradually adds noise to the data. The paper explains how denoising diffusion models can be trained using a score matching objective or a variational lower bound, and how they can sample new data by applying a series of denoising steps.
- In the second subsection, the paper introduces the generative learning trilemma, which is the challenge of achieving high sample quality, mode coverage and fast sampling in deep generative models. The paper argues that existing models often trade some of these requirements for others, and that denoising diffusion models have slow sampling due to the Gaussian assumption in the denoising step.
- In the third subsection, the paper proposes to model the denoising distribution using a complex multimodal distribution, and to use a conditional GAN to learn this distribution at each denoising step. The paper shows how to formulate the conditional GAN objective as a variational lower bound on the log-likelihood of the data, and how to train the generator and discriminator networks using gradient descent.
- In the fourth subsection, the paper presents denoising diffusion GANs (DD-GANs) as a novel generative model that combines denoising diffusion models with conditional GANs to learn the multimodal denoising distribution at each step. The paper describes how to initialize and update the generator and discriminator networks at each step, and how to sample new data from DD-GANs using fewer steps than original diffusion models.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the diffusion process parameters
T = total number of diffusion steps
beta = noise level at each step
sigma = standard deviation of noise at each step

# Define the generator and discriminator networks
G = a conditional GAN generator that takes an image and a noise level as input and outputs a denoised image
D = a conditional GAN discriminator that takes an image pair and a noise level as input and outputs a score

# Initialize the generator and discriminator networks
for t in range(T):
  G_t = copy of G initialized randomly
  D_t = copy of D initialized randomly

# Train the generator and discriminator networks
for each training iteration:
  # Sample a batch of data images x
  x = sample_data()
  # Apply the forward diffusion process to x to get noisy images x_t and epsilon_t
  x_t, epsilon_t = forward_diffusion(x, t)
  # Generate denoised images x_hat_t using G_t
  x_hat_t = G_t(x_t, sigma[t])
  # Compute the discriminator scores for real and fake pairs using D_t
  s_real = D_t(x, x_t, sigma[t])
  s_fake = D_t(x_hat_t, x_t, sigma[t])
  # Compute the generator and discriminator losses using the variational lower bound
  L_G = -log(s_fake) + KL(epsilon_t || N(0, I))
  L_D = -log(s_real) + log(1 - s_fake)
  # Update the generator and discriminator networks using gradient descent
  G_t = G_t - lr * grad(L_G, G_t)
  D_t = D_t - lr * grad(L_D, D_t)

# Sample new data from DD-GANs
# Start from a random image z_0
z_0 = sample_noise()
# Apply the reverse diffusion process to z_0 using G_t
for t in range(T-1, -1, -1):
  # Generate denoised image z_hat_t using G_t
  z_hat_t = G_t(z_0, sigma[t])
  # Sample z_{t-1} from the denoising distribution using z_hat_t and z_0
  z_{t-1} = z_hat_t + sqrt(1 - beta[t]) * (z_0 - z_hat_t)
# Return the final image z_{-1} as the sample
return z_{-1}
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# Define the hyperparameters
batch_size = 64 # batch size for training and sampling
T = 1000 # total number of diffusion steps
beta_min = 0.0001 # minimum noise level at each step
beta_max = 0.02 # maximum noise level at each step
lr = 0.0002 # learning rate for gradient descent
num_epochs = 100 # number of epochs for training
num_samples = 16 # number of samples to generate

# Define the diffusion process parameters
beta = torch.linspace(beta_min, beta_max, T) # noise level at each step
sigma = torch.sqrt(beta * (1 - beta.cumprod(dim=0))) # standard deviation of noise at each step
alpha = 1 - beta # probability of keeping the original pixel value at each step
alpha_bar = alpha.cumprod(dim=0) # cumulative product of alpha

# Define the generator network G
class Generator(nn.Module):
  def __init__(self):
    super(Generator, self).__init__()
    # Define the convolutional layers with residual connections
    self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
    self.conv2 = nn.Conv2d(64, 64, 3, padding=1)
    self.conv3 = nn.Conv2d(64, 64, 3, padding=1)
    self.conv4 = nn.Conv2d(64, 64, 3, padding=1)
    self.conv5 = nn.Conv2d(64, 3, 3, padding=1)
    # Define the batch normalization layers
    self.bn1 = nn.BatchNorm2d(64)
    self.bn2 = nn.BatchNorm2d(64)
    self.bn3 = nn.BatchNorm2d(64)
    self.bn4 = nn.BatchNorm2d(64)
    # Define the activation function
    self.relu = nn.ReLU()

  def forward(self, x, s):
    # x: noisy image of shape (batch_size, 3, 32, 32)
    # s: noise level of shape (batch_size,)
    # Concatenate x and s along the channel dimension
    s = s.view(-1, 1, 1, 1).repeat(1, 3, 32, 32)
    x_s = torch.cat([x, s], dim=1)
    # Apply the convolutional layers with residual connections
    h1 = self.relu(self.bn1(self.conv1(x_s)))
    h2 = h1 + self.relu(self.bn2(self.conv2(h1)))
    h3 = h2 + self.relu(self.bn3(self.conv3(h2)))
    h4 = h3 + self.relu(self.bn4(self.conv4(h3)))
    h5 = self.conv5(h4)
    # Return the denoised image
    return x + h5

# Define the discriminator network D
class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()
    # Define the convolutional layers with residual connections and spectral normalization
    self.conv1 = nn.utils.spectral_norm(nn.Conv2d(6, 64, 3, padding=1))
    self.conv2 = nn.utils.spectral_norm(nn.Conv2d(64, 64, 3, padding=1))
    self.conv3 = nn.utils.spectral_norm(nn.Conv2d(64, 64, 3, padding=1))
    self.conv4 = nn.utils.spectral_norm(nn.Conv2d(64, 64, 3, padding=1))
    self.conv5 = nn.utils.spectral_norm(nn.Conv2d(67, 1, 3))
    # Define the activation function
    self.relu = nn.ReLU()

  def forward(self, x_0, x_t, s):
    # x_0: original image of shape (batch_size, 3, 32, 32)
    # x_t: noisy image of shape (batch_size, 3, 32, 32)
    # s: noise level of shape (batch_size,)
    # Concatenate x_0 and x_t along the channel dimension
    x_0_x_t = torch.cat([x_0,x_t], dim=1)
    # Apply the convolutional layers with residual connections and spectral normalization
    h1 = self.relu(self.conv1(x_0_x_t))
    h2 = h1 + self.relu(self.conv2(h1))
    h3 = h2 + self.relu(self.conv3(h2))
    h4 = h3 + self.relu(self.conv4(h3))
    # Concatenate h4 and s along the channel dimension
    s = s.view(-1, 1, 1, 1).repeat(1, 3, 32, 32)
    h4_s = torch.cat([h4, s], dim=1)
    # Apply the final convolutional layer
    h5 = self.conv5(h4_s)
    # Return the score
    return h5

# Initialize the generator and discriminator networks
G = Generator()
D = Discriminator()
# Copy the generator and discriminator networks for each step
G_t = [G for _ in range(T)]
D_t = [D for _ in range(T)]

# Define the optimizer for gradient descent
optimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))

# Define the data loader for CIFAR-10 dataset
transform = transforms.Compose([transforms.ToTensor()])
dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Train the generator and discriminator networks
for epoch in range(num_epochs):
  for i, (x, _) in enumerate(dataloader):
    # Move x to device
    x = x.to(device)
    # Sample a random step t
    t = torch.randint(low=0, high=T, size=(1,))
    # Apply the forward diffusion process to x to get noisy images x_t and epsilon_t
    epsilon_t = torch.randn_like(x) * sigma[t]
    x_t = alpha_bar[t] * x + (1 - alpha_bar[t]) * epsilon_t
    # Generate denoised images x_hat_t using G_t
    x_hat_t = G_t[t](x_t, sigma[t])
    # Compute the discriminator scores for real and fake pairs using D_t
    s_real = D_t[t](x, x_t, sigma[t])
    s_fake = D_t[t](x_hat_t, x_t, sigma[t])
    # Compute the generator and discriminator losses using the variational lower bound
    L_G = -torch.mean(torch.log(s_fake + 1e-8)) + torch.mean(F.mse_loss(epsilon_t, x - x_hat_t))
    L_D = -torch.mean(torch.log(s_real + 1e-8)) + torch.mean(torch.log(1 - s_fake + 1e-8))
    # Update the generator and discriminator networks using gradient descent
    optimizer_G.zero_grad()
    L_G.backward()
    optimizer_G.step()
    optimizer_D.zero_grad()
    L_D.backward()
    optimizer_D.step()
  # Print the losses at the end of each epoch
  print(f'Epoch {epoch}, L_G: {L_G.item()}, L_D: {L_D.item()}')

# Sample new data from DD-GANs
# Start from a random image z_0
z_0 = torch.randn(num_samples, 3, 32, 32).to(device)
# Apply the reverse diffusion process to z_0 using G_t
for t in range(T-1, -1, -1):
  # Generate denoised image z_hat_t using G_t
  z_hat_t = G_t[t](z_0, sigma[t])
  # Sample z_{t-1} from the denoising distribution using z_hat_t and z_0
  z_{t-1} = z_hat_t + torch.sqrt(1 - beta[t]) * (z_0 - z_hat_t)
  # Update z_0 to z_{t-1}
  z_0 = z_{t-1}
# Return the final image z_{-1} as the sample
samples = z_{-1}
```