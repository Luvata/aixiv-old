---
title: 2202.01344v1 Formal Mathematics Statement Curriculum Learning
date: 2022-02-02
---

# [Formal Mathematics Statement Curriculum Learning](http://arxiv.org/abs/2202.01344v1)

authors: Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin, Ilya Sutskever


## What, Why and How

[1]: https://arxiv.org/abs/2202.01344 "[2202.01344] Formal Mathematics Statement Curriculum Learning - arXiv.org"
[2]: https://arxiv.org/pdf/2202.01344v1.pdf "Formal Mathematics Statement Curriculum Learning - arXiv.org"
[3]: http://arxiv-export3.library.cornell.edu/abs/2205.01344v1 "[2205.01344v1] Non-equilibrium phase transitions in coupled nonlinear ..."

Here is a summary of the paper:

- **What**: The paper explores the use of expert iteration in the context of language modeling applied to formal mathematics. Expert iteration is a technique that combines proof search with learning to improve the performance and efficiency of theorem proving.
- **Why**: The paper aims to address two main challenges in formal mathematics: infinite action space and lack of ground-truth proofs. Expert iteration can overcome these challenges by using a learned model to guide the proof search and by finding and solving a curriculum of increasingly difficult problems without requiring human annotations.
- **How**: The paper proposes a framework that consists of three components: a language model, a proof search algorithm, and a problem generator. The language model is trained on a large corpus of formal statements and proofs. The proof search algorithm uses the language model to generate and evaluate candidate tactics at each step of the proof. The problem generator samples formal statements from a collection of sources with varying difficulty levels. The framework alternates between proof search and learning, using the generated problems as training data for the language model. The paper evaluates the framework on the miniF2F benchmark, which consists of challenging problems drawn from high school olympiads, and achieves state-of-the-art results.

## Main Contributions

[1]: https://arxiv.org/abs/2202.01344 "[2202.01344] Formal Mathematics Statement Curriculum Learning - arXiv.org"
[2]: https://arxiv.org/pdf/2202.01344v1.pdf "Formal Mathematics Statement Curriculum Learning - arXiv.org"
[3]: http://arxiv-export3.library.cornell.edu/abs/2205.01344v1 "[2205.01344v1] Non-equilibrium phase transitions in coupled nonlinear ..."

The paper claims the following contributions:

- **A framework for expert iteration in formal mathematics**: The paper proposes a novel framework that combines a language model, a proof search algorithm, and a problem generator to perform expert iteration in formal mathematics. The framework can handle infinite action spaces and does not require ground-truth proofs for training.
- **A demonstration of curriculum learning in formal mathematics**: The paper shows that the framework can automatically find and solve a curriculum of increasingly difficult problems from a collection of formal statements with varied difficulty levels. The paper also analyzes the properties of the learned curriculum and the factors that influence its effectiveness.
- **State-of-the-art results on the miniF2F benchmark**: The paper applies the framework to a manually curated set of problem statements from the miniF2F benchmark, which consists of challenging problems drawn from high school olympiads. The paper reports state-of-the-art results on this benchmark, solving multiple problems that were previously unsolved by automated methods.

## Method Summary

[1]: https://arxiv.org/abs/2202.01344 "[2202.01344] Formal Mathematics Statement Curriculum Learning - arXiv.org"
[2]: https://arxiv.org/pdf/2202.01344v1.pdf "Formal Mathematics Statement Curriculum Learning - arXiv.org"
[3]: http://arxiv-export3.library.cornell.edu/abs/2205.01344v1 "[2205.01344v1] Non-equilibrium phase transitions in coupled nonlinear ..."

Here is a summary of the method section of the paper:

- **Language model**: The paper uses a transformer-based language model that is pre-trained on a large corpus of formal statements and proofs from various sources, such as the Lean theorem prover library and the Metamath proof database. The language model is fine-tuned on the generated problems during expert iteration. The language model outputs a distribution over possible tactics at each step of the proof, as well as a termination probability that indicates whether the proof is complete or not.
- **Proof search algorithm**: The paper uses a beam search algorithm that leverages the language model to generate and evaluate candidate tactics at each step of the proof. The algorithm maintains a beam of partial proofs, each with a score that reflects the likelihood of being correct and complete. The algorithm expands each partial proof by sampling a tactic from the language model and applying it to the current goal. The algorithm then prunes the beam by keeping only the top-k partial proofs according to their scores. The algorithm terminates when either a complete proof is found or a maximum number of steps is reached.
- **Problem generator**: The paper uses a problem generator that samples formal statements from a collection of sources with varying difficulty levels. The sources include the Lean theorem prover library, the Metamath proof database, and a manually curated set of problem statements from the miniF2F benchmark. The problem generator assigns a difficulty score to each statement based on its length, depth, and number of dependencies. The problem generator then samples statements according to a distribution that favors more difficult statements over time, creating a curriculum of problems for expert iteration.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Pre-train a language model on a large corpus of formal statements and proofs
language_model = pre_train(corpus)

# Initialize a problem generator that samples formal statements from various sources
problem_generator = ProblemGenerator(sources)

# Repeat expert iteration for a fixed number of iterations
for i in range(num_iterations):

  # Sample a problem statement from the problem generator
  problem = problem_generator.sample()

  # Initialize a beam search algorithm that uses the language model to generate and evaluate tactics
  beam_search = BeamSearch(language_model, problem)

  # Run the beam search algorithm until a proof is found or a maximum number of steps is reached
  proof = beam_search.run()

  # If a proof is found, add it to the training data for the language model
  if proof is not None:
    training_data.append((problem, proof))

  # Fine-tune the language model on the training data
  language_model = fine_tune(language_model, training_data)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch # for deep learning
import transformers # for language modeling
import lean # for formal mathematics

# Pre-train a language model on a large corpus of formal statements and proofs
corpus = lean.load_corpus() # load the corpus from the Lean theorem prover library and the Metamath proof database
tokenizer = transformers.AutoTokenizer.from_pretrained("gpt2") # use a pre-trained tokenizer for natural language processing
language_model = transformers.AutoModelForCausalLM.from_pretrained("gpt2") # use a pre-trained transformer model for causal language modeling
language_model = language_model.to("cuda") # move the model to GPU for faster training
optimizer = torch.optim.Adam(language_model.parameters(), lr=0.0001) # use Adam optimizer with a small learning rate
for epoch in range(num_epochs): # repeat the pre-training for a fixed number of epochs
  for batch in corpus: # iterate over the batches of statements and proofs in the corpus
    inputs = tokenizer(batch["statements"], return_tensors="pt", padding=True) # tokenize the statements and convert them to tensors
    labels = tokenizer(batch["proofs"], return_tensors="pt", padding=True) # tokenize the proofs and convert them to tensors
    inputs = inputs.to("cuda") # move the inputs to GPU
    labels = labels.to("cuda") # move the labels to GPU
    outputs = language_model(**inputs, labels=labels) # pass the inputs and labels to the language model and get the outputs
    loss = outputs.loss # get the loss from the outputs
    loss.backward() # compute the gradients
    optimizer.step() # update the parameters
    optimizer.zero_grad() # reset the gradients

# Initialize a problem generator that samples formal statements from various sources
sources = lean.load_sources() # load the sources of formal statements from various sources, such as the Lean theorem prover library, the Metamath proof database, and the miniF2F benchmark
problem_generator = ProblemGenerator(sources) # create a problem generator object that takes the sources as input

# Define a function that assigns a difficulty score to a statement based on its length, depth, and number of dependencies
def score(statement):
  length = len(statement) # get the length of the statement
  depth = lean.get_depth(statement) # get the depth of the statement in the dependency graph
  dependencies = lean.get_dependencies(statement) # get the number of dependencies of the statement
  return length + depth + dependencies # return the sum of these three factors as the score

# Define a function that samples a statement from the problem generator according to a distribution that favors more difficult statements over time
def sample():
  statements = problem_generator.get_statements() # get all the statements from the problem generator
  scores = [score(statement) for statement in statements] # get the scores for each statement
  temperature = problem_generator.get_temperature() # get the temperature parameter that controls the sampling distribution
  probabilities = torch.softmax(torch.tensor(scores) / temperature, dim=0) # compute the probabilities for each statement using softmax with temperature
  index = torch.multinomial(probabilities, 1).item() # sample an index from the probabilities using multinomial sampling
  statement = statements[index] # get the statement corresponding to the sampled index
  problem_generator.update_temperature() # update the temperature parameter according to some schedule
  return statement # return the sampled statement

# Repeat expert iteration for a fixed number of iterations
training_data = [] # initialize an empty list to store the training data for fine-tuning
for i in range(num_iterations): # repeat expert iteration for a fixed number of iterations

  # Sample a problem statement from the problem generator
  problem = sample() # sample a statement using the sample function defined above

  # Initialize a beam search algorithm that uses the language model to generate and evaluate tactics at each step of the proof
  beam_search = BeamSearch(language_model, problem, beam_size, max_steps) # create a beam search object that takes the language model, the problem statement, the beam size, and the maximum number of steps as input

  # Define a function that generates a tactic from the language model given a partial proof and a goal
  def generate(partial_proof, goal):
    context = partial_proof + "\n" + goal + "\n" + "Tactic: " # concatenate the partial proof, the goal, and a prefix for generating a tactic as context 
    context_ids = tokenizer(context, return_tensors="pt").input_ids.to("cuda") # tokenize and convert context to tensor and move to GPU
    output_ids = language_model.generate(context_ids, max_length=50, do_sample=True, top_k=10) # generate a sequence of tokens from the language model using sampling with top-k
    output = tokenizer.decode(output_ids[0]) # decode the generated tokens to text
    tactic = output[len(context):] # extract the tactic from the output by removing the context
    return tactic # return the generated tactic

  # Define a function that evaluates a tactic using the language model given a partial proof and a goal
  def evaluate(partial_proof, goal, tactic):
    context = partial_proof + "\n" + goal + "\n" + "Tactic: " + tactic # concatenate the partial proof, the goal, and the tactic as context
    context_ids = tokenizer(context, return_tensors="pt").input_ids.to("cuda") # tokenize and convert context to tensor and move to GPU
    logits = language_model(context_ids).logits # get the logits from the language model
    termination_probability = torch.sigmoid(logits[0, -1, 0]) # get the termination probability from the first token of the last position of the logits
    score = torch.logsumexp(logits[0, -1, 1:], dim=0) # get the score from the logsumexp of the remaining tokens of the last position of the logits
    return score, termination_probability # return the score and the termination probability

  # Define a function that applies a tactic to a goal using the Lean theorem prover and returns the new subgoals or an error message
  def apply(goal, tactic):
    try:
      subgoals = lean.apply_tactic(goal, tactic) # use the Lean theorem prover to apply the tactic to the goal and get the subgoals
      return subgoals # return the subgoals
    except Exception as e:
      error = str(e) # get the error message from the exception
      return error # return the error message

  # Run the beam search algorithm until a proof is found or a maximum number of steps is reached
  proof = beam_search.run(generate, evaluate, apply) # run the beam search algorithm using the generate, evaluate, and apply functions defined above

  # If a proof is found, add it to the training data for the language model
  if proof is not None:
    training_data.append((problem, proof)) # append the problem statement and the proof as a tuple to the training data list

  # Fine-tune the language model on the training data
  for epoch in range(num_epochs): # repeat fine-tuning for a fixed number of epochs
    for batch in training_data: # iterate over batches of problem statements and proofs in training data
      inputs = tokenizer(batch["statements"], return_tensors="pt", padding=True) # tokenize statements and convert them to tensors
      labels = tokenizer(batch["proofs"], return_tensors="pt", padding=True) # tokenize proofs and convert them to tensors
      inputs = inputs.to("cuda") # move inputs to GPU
      labels = labels.to("cuda") # move labels to GPU
      outputs = language_model(**inputs, labels=labels) # pass inputs and labels to language model and get outputs
      loss = outputs.loss # get loss from outputs
      loss.backward() # compute gradients
      optimizer.step() # update parameters
      optimizer.zero_grad() # reset gradients

```