---
title: 2109.13912v2 PDC-Net+  Enhanced Probabilistic Dense Correspondence Network
date: 2021-09-14
---

# [PDC-Net+: Enhanced Probabilistic Dense Correspondence Network](http://arxiv.org/abs/2109.13912v2)

authors: Prune Truong, Martin Danelljan, Radu Timofte, Luc Van Gool


## What, Why and How

[1]: https://arxiv.org/abs/2109.13912v2 "PDC-Net+: Enhanced Probabilistic Dense Correspondence Network"
[2]: https://arxiv.org/pdf/2109.13912v2.pdf "arXiv.org e-Print archive"
[3]: https://www.researcher-app.com/paper/9093690 "PDC-Net+: Enhanced Probabilistic Dense Correspondence Network. (arXiv ..."

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes an enhanced probabilistic dense correspondence network, PDC-Net+, that can estimate accurate dense correspondences between a pair of images along with a reliable confidence map.
- **Why**: The paper aims to address the challenges of dense flow estimation in the case of large displacements, occlusions, or homogeneous regions, which are common in real-world applications such as pose estimation, image manipulation, or 3D reconstruction.
- **How**: The paper develops a flexible probabilistic approach that jointly learns the flow prediction and its uncertainty. It parametrizes the predictive distribution as a constrained mixture model, ensuring better modelling of both accurate flow predictions and outliers. It also develops an architecture and an enhanced training strategy tailored for robust and generalizable uncertainty prediction in the context of self-supervised training. It evaluates its approach on multiple challenging geometric matching and optical flow datasets and demonstrates its usefulness for the tasks of pose estimation and image manipulation.

## Main Contributions

[1]: https://arxiv.org/abs/2109.13912 "PDC-Net+: Enhanced Probabilistic Dense Correspondence Network"
[2]: https://ieeexplore.ieee.org/document/10054148 "PDC-Net+: Enhanced Probabilistic Dense Correspondence Network"

The paper[^1^][1] lists the following contributions:

- It proposes a **flexible probabilistic approach** that jointly learns the flow prediction and its uncertainty, parametrized as a constrained mixture model.
- It develops an **architecture and an enhanced training strategy** tailored for robust and generalizable uncertainty prediction in the context of self-supervised training.
- It obtains **state-of-the-art results** on multiple challenging geometric matching and optical flow datasets.
- It validates the **usefulness of its probabilistic confidence estimation** for the tasks of pose estimation, 3D reconstruction, image-based localization, and image retrieval.

## Method Summary

[1]: https://arxiv.org/abs/2109.13912 "PDC-Net+: Enhanced Probabilistic Dense Correspondence Network"
[2]: https://ieeexplore.ieee.org/document/10054148 "PDC-Net+: Enhanced Probabilistic Dense Correspondence Network"
[3]: https://prunetruong.com/research/pdcnet+/ "Gmail - Prune Truong"

Here is a summary of the method section of the paper[^1^][1]:

- The paper introduces a **probabilistic dense correspondence network (PDC-Net+)** that consists of two main components: a **feature extraction network** and a **probabilistic matching network**.
- The feature extraction network is based on a **pre-trained ResNet-50** that extracts deep features from a pair of images. The features are then **normalized** and **concatenated** along the channel dimension to form a 4D cost volume.
- The probabilistic matching network takes the cost volume as input and outputs a **predictive distribution** over the flow field. The predictive distribution is parametrized as a **constrained mixture model** with two components: a **Gaussian component** that models the accurate flow predictions and an **outlier component** that models the uncertain or incorrect predictions. The mixture model is constrained by enforcing that the mean and variance of the Gaussian component are equal to the predicted flow and its uncertainty, respectively, and that the sum of the mixture weights is equal to one.
- The paper proposes a **self-supervised learning framework** that leverages synthetic and real-world data to train the PDC-Net+. The synthetic data consists of pairs of images generated by applying random geometric transformations to images from COCO dataset. The real-world data consists of pairs of images from HPatches dataset that contain natural changes in illumination, viewpoint, and occlusion. The paper uses two types of losses to train the network: a **flow loss** that measures the difference between the predicted flow and the ground-truth flow, and an **uncertainty loss** that measures the difference between the predicted uncertainty and the empirical uncertainty. The paper also introduces an **adaptive weighting scheme** that balances the contribution of synthetic and real-world data during training.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the feature extraction network based on ResNet-50
def feature_extraction_network(image):
  # Extract deep features using ResNet-50
  features = resnet50(image)
  # Normalize the features
  features = normalize(features)
  return features

# Define the probabilistic matching network
def probabilistic_matching_network(cost_volume):
  # Apply several convolutional layers to the cost volume
  output = conv_layers(cost_volume)
  # Split the output into four channels: flow, uncertainty, inlier weight, and outlier weight
  flow, uncertainty, inlier_weight, outlier_weight = split(output)
  # Constrain the uncertainty to be positive
  uncertainty = exp(uncertainty)
  # Constrain the mixture weights to sum to one
  inlier_weight = sigmoid(inlier_weight)
  outlier_weight = 1 - inlier_weight
  # Parametrize the predictive distribution as a constrained mixture model
  predictive_distribution = mixture_model(flow, uncertainty, inlier_weight, outlier_weight)
  return predictive_distribution

# Define the PDC-Net+ network
def pdc_net_plus(image_pair):
  # Extract features from each image using the feature extraction network
  features_1 = feature_extraction_network(image_pair[0])
  features_2 = feature_extraction_network(image_pair[1])
  # Concatenate the features along the channel dimension to form a cost volume
  cost_volume = concatenate(features_1, features_2)
  # Estimate the predictive distribution over the flow field using the probabilistic matching network
  predictive_distribution = probabilistic_matching_network(cost_volume)
  return predictive_distribution

# Define the self-supervised learning framework
def self_supervised_learning():
  # Initialize the PDC-Net+ network with random weights
  pdc_net_plus = initialize()
  # Loop over the training epochs
  for epoch in range(num_epochs):
    # Sample a batch of synthetic image pairs and their ground-truth flows
    synthetic_image_pairs, synthetic_flows = sample_synthetic_data()
    # Sample a batch of real-world image pairs and their ground-truth flows
    real_image_pairs, real_flows = sample_real_data()
    # Concatenate the synthetic and real-world data
    image_pairs = concatenate(synthetic_image_pairs, real_image_pairs)
    flows = concatenate(synthetic_flows, real_flows)
    # Predict the flow and uncertainty using PDC-Net+
    predicted_flow, predicted_uncertainty = pdc_net_plus(image_pairs)
    # Compute the flow loss using L1 norm
    flow_loss = L1(predicted_flow - flows)
    # Compute the empirical uncertainty using robust norm
    empirical_uncertainty = robust_norm(predicted_flow - flows)
    # Compute the uncertainty loss using L2 norm
    uncertainty_loss = L2(predicted_uncertainty - empirical_uncertainty)
    # Compute the total loss as a weighted sum of flow loss and uncertainty loss
    total_loss = alpha * flow_loss + beta * uncertainty_loss
    # Update the network weights using gradient descent
    pdc_net_plus.update(total_loss)
    # Adapt the weights alpha and beta based on the ratio of synthetic and real-world data
    alpha, beta = adapt_weights(synthetic_image_pairs, real_image_pairs)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import torch # for tensor operations
import torchvision # for ResNet-50 model
import numpy as np # for mathematical operations
import cv2 # for image processing

# Define the hyperparameters
num_epochs = 100 # number of training epochs
batch_size = 16 # size of each training batch
learning_rate = 0.001 # learning rate for gradient descent
height = 240 # height of the input images
width = 240 # width of the input images
num_channels = 3 # number of channels of the input images
num_features = 256 # number of features extracted by ResNet-50
max_displacement = 64 # maximum displacement for cost volume computation

# Define the feature extraction network based on ResNet-50
def feature_extraction_network(image):
  # Resize the image to (height, width)
  image = cv2.resize(image, (height, width))
  # Convert the image to a tensor
  image = torch.from_numpy(image)
  # Normalize the image using ImageNet statistics
  image = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)
  # Add a batch dimension to the image
  image = image.unsqueeze(0)
  # Load the pre-trained ResNet-50 model
  resnet50 = torchvision.models.resnet50(pretrained=True)
  # Remove the last layer of ResNet-50
  resnet50 = torch.nn.Sequential(*list(resnet50.children())[:-1])
  # Extract deep features using ResNet-50
  features = resnet50(image)
  # Squeeze the features to remove the singleton dimensions
  features = features.squeeze()
  # Normalize the features using L2 norm
  features = torch.nn.functional.normalize(features, dim=0)
  return features

# Define the probabilistic matching network
def probabilistic_matching_network(cost_volume):
  # Define the convolutional layers with kernel size 3x3 and padding 1
  conv1 = torch.nn.Conv2d(in_channels=num_features*2, out_channels=128, kernel_size=3, padding=1)
  conv2 = torch.nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1)
  conv3 = torch.nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1)
  conv4 = torch.nn.Conv2d(in_channels=32, out_channels=4, kernel_size=3, padding=1)
  # Apply the convolutional layers to the cost volume with ReLU activation
  output = torch.nn.functional.relu(conv1(cost_volume))
  output = torch.nn.functional.relu(conv2(output))
  output = torch.nn.functional.relu(conv3(output))
  output = conv4(output)
  # Split the output into four channels: flow_x, flow_y, uncertainty_x, uncertainty_y
  flow_x, flow_y, uncertainty_x, uncertainty_y = torch.split(output, split_size_or_sections=1, dim=0)
  # Constrain the uncertainty to be positive by applying exponential function
  uncertainty_x = torch.exp(uncertainty_x)
  uncertainty_y = torch.exp(uncertainty_y)
  # Constrain the mixture weights to sum to one by applying sigmoid function
  inlier_weight_x = torch.sigmoid(flow_x)
  inlier_weight_y = torch.sigmoid(flow_y)
  outlier_weight_x = 1 - inlier_weight_x
  outlier_weight_y = 1 - inlier_weight_y
  # Parametrize the predictive distribution as a constrained mixture model with two components: Gaussian and outlier
  predictive_distribution_x = inlier_weight_x * torch.distributions.Normal(loc=flow_x, scale=uncertainty_x) + outlier_weight_x * torch.distributions.Uniform(low=-max_displacement, high=max_displacement)
  predictive_distribution_y = inlier_weight_y * torch.distributions.Normal(loc=flow_y, scale=uncertainty_y) + outlier_weight_y * torch.distributions.Uniform(low=-max_displacement, high=max_displacement)
  
```