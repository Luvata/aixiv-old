---
title: 2302.04578v1 Adversarial Example Does Good  Preventing Painting Imitation from Diffusion Models via Adversarial Examples
date: 2023-02-05
---

# [Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples](http://arxiv.org/abs/2302.04578v1)

authors: Chumeng Liang, Xiaoyu Wu, Yang Hua, Jiaru Zhang, Yiming Xue, Tao Song, Zhengui Xue, Ruhui Ma, Haibing Guan


## What, Why and How

[1]: https://arxiv.org/abs/2302.04578 "[2302.04578] Adversarial Example Does Good: Preventing Painting ..."
[2]: https://arxiv-export1.library.cornell.edu/abs/2302.04578v1 "[2302.04578v1] Adversarial Example Does Good: Preventing Painting ..."
[3]: https://arxiv.org/pdf/2302.04578 "arXiv.org e-Print archive"

Here is a summary of the paper[^1^][1] [^2^][2]:

- **What**: The paper proposes a method to generate adversarial examples for diffusion models (DMs), which are a type of generative model that can create realistic images such as paintings.
- **Why**: The paper aims to prevent painting imitation from DMs, which can violate the copyright of human artists who create original paintings. The paper argues that human artists should have the right to protect their artistic style and expression from being copied by DMs.
- **How**: The paper introduces a framework to define and evaluate adversarial examples for DMs, which are images that look similar to human eyes but are unrecognizable for DMs. The paper also presents AdvDM, an algorithm that generates adversarial examples for DMs by optimizing upon different latent variables sampled from the reverse process of DMs. The paper shows that the adversarial examples can effectively hinder DMs from extracting the features of the original paintings.

## Main Contributions

[1]: https://arxiv.org/abs/2302.04578 "[2302.04578] Adversarial Example Does Good: Preventing Painting ..."
[2]: https://arxiv-export1.library.cornell.edu/abs/2302.04578v1 "[2302.04578v1] Adversarial Example Does Good: Preventing Painting ..."
[3]: https://arxiv.org/pdf/2302.04578 "arXiv.org e-Print archive"

According to the paper[^1^][1] [^2^][2], the main contributions are:

- **A framework to define and evaluate adversarial examples for diffusion models**, which are images that look similar to human eyes but are unrecognizable for DMs. The framework consists of three components: a similarity metric, a recognition metric, and an adversarial example generator.
- **An algorithm to generate adversarial examples for diffusion models**, called AdvDM, which optimizes upon different latent variables sampled from the reverse process of DMs. AdvDM conducts a Monte-Carlo estimation of adversarial examples for DMs and can handle different types of DMs such as unconditional, class-conditional, and style-conditional DMs.
- **Extensive experiments to demonstrate the effectiveness of AdvDM**, which show that the adversarial examples generated by AdvDM can significantly reduce the recognition accuracy of DMs on various datasets and tasks, such as painting style transfer, painting classification, and painting generation. The experiments also show that the adversarial examples are visually similar to the original images and can fool human observers.

## Method Summary

[1]: https://arxiv.org/abs/2302.04578 "[2302.04578] Adversarial Example Does Good: Preventing Painting ..."
[2]: https://arxiv-export1.library.cornell.edu/abs/2302.04578v1 "[2302.04578v1] Adversarial Example Does Good: Preventing Painting ..."
[3]: https://arxiv.org/pdf/2302.04578 "arXiv.org e-Print archive"

Here is a summary of the method section of the paper[^1^][1] [^2^][2]:

- **Framework for adversarial examples for diffusion models**: The paper defines an adversarial example for DMs as an image x' that satisfies two conditions: (1) x' is similar to an original image x according to a similarity metric S(x,x'), and (2) x' is unrecognizable for DMs according to a recognition metric R(x,x'). The paper uses structural similarity index (SSIM) as the similarity metric and cosine similarity between feature vectors as the recognition metric. The paper also defines an adversarial example generator G(x) as a function that maps an original image x to an adversarial example x' = G(x).
- **Algorithm for generating adversarial examples for diffusion models**: The paper proposes AdvDM, an algorithm that generates adversarial examples for DMs by optimizing upon different latent variables sampled from the reverse process of DMs. AdvDM consists of three steps: (1) sampling latent variables z_t from the reverse process of DMs, where t = 0, ..., T and z_0 is the original image x; (2) perturbing z_t by adding Gaussian noise n_t with a small variance; and (3) reconstructing the adversarial example x' = z'_0 from the perturbed latent variables z'_t using the forward process of DMs. AdvDM aims to minimize the recognition metric R(x,x') while maintaining the similarity metric S(x,x') above a threshold.
- **Experiments on various datasets and tasks**: The paper evaluates AdvDM on three datasets: WikiArt, CelebA, and CIFAR-10, and four tasks: painting style transfer, painting classification, painting generation, and image generation. The paper compares AdvDM with two baselines: FGSM and PGD, which are gradient-based methods for generating adversarial examples for discriminative models. The paper uses different types of DMs for different tasks, such as unconditional, class-conditional, and style-conditional DMs. The paper measures the performance of AdvDM and the baselines using three metrics: recognition accuracy, similarity score, and human perceptual score. The paper shows that AdvDM outperforms the baselines in terms of reducing the recognition accuracy of DMs while preserving the similarity and perceptual quality of the original images.

## Pseudo Code - High level

Here is the high-level pseudo code for the paper:

```python
# Input: an original image x, a diffusion model DM, a similarity threshold s
# Output: an adversarial example x' for DM
def AdvDM(x, DM, s):
  # Sample latent variables z_t from the reverse process of DM
  z_0 = x
  for t in range(1, T+1):
    z_t = DM.reverse(z_t-1)
  # Perturb z_t by adding Gaussian noise n_t
  for t in range(0, T+1):
    n_t = sample_gaussian_noise(variance)
    z'_t = z_t + n_t
  # Reconstruct x' from z'_t using the forward process of DM
  x' = z'_0
  for t in range(1, T+1):
    x' = DM.forward(x', z'_t)
  # Optimize x' to minimize R(x,x') while maintaining S(x,x') >= s
  while R(x,x') > 0 and S(x,x') >= s:
    # Update x' by gradient descent on R(x,x')
    x' = x' - alpha * grad(R(x,x'), x')
    # Project x' to the feasible set of S(x,x') >= s
    if S(x,x') < s:
      x' = project_to_feasible_set(x, x', s)
  # Return x'
  return x'
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper:

```python
# Import libraries
import torch
import numpy as np
from skimage.metrics import structural_similarity as ssim
from scipy.optimize import linear_sum_assignment

# Define constants
T = 1000 # number of diffusion steps
variance = 0.01 # variance of Gaussian noise
alpha = 0.01 # learning rate for gradient descent
s = 0.9 # similarity threshold

# Define functions
def sample_gaussian_noise(variance):
  # Sample Gaussian noise with zero mean and given variance
  return torch.randn_like(variance) * torch.sqrt(variance)

def cosine_similarity(x, y):
  # Compute the cosine similarity between two feature vectors x and y
  return torch.dot(x, y) / (torch.norm(x) * torch.norm(y))

def R(x, x'):
  # Compute the recognition metric R(x,x') as the average cosine similarity between feature vectors of x and x' extracted by DM
  # Assume DM has a feature extractor function that returns a list of feature vectors for each image
  features_x = DM.feature_extractor(x)
  features_x' = DM.feature_extractor(x')
  # Align the feature vectors using the Hungarian algorithm
  cost_matrix = -torch.matmul(features_x, features_x'.T)
  row_ind, col_ind = linear_sum_assignment(cost_matrix.numpy())
  # Compute the average cosine similarity
  return torch.mean(cosine_similarity(features_x[row_ind], features_x'[col_ind]))

def S(x, x'):
  # Compute the similarity metric S(x,x') as the SSIM score between x and x'
  return ssim(x.numpy(), x'.numpy(), multichannel=True)

def project_to_feasible_set(x, x', s):
  # Project x' to the feasible set of S(x,x') >= s using binary search
  # Assume x and x' are normalized to [0,1]
  low = 0
  high = 1
  while high - low > 1e-6:
    mid = (low + high) / 2
    y = mid * x + (1 - mid) * x'
    if S(x, y) >= s:
      low = mid
    else:
      high = mid
  return y

def AdvDM(x, DM, s):
  # Generate an adversarial example x' for DM given an original image x and a similarity threshold s
  # Assume DM has reverse and forward functions that implement the reverse and forward process of diffusion
  # Initialize z_0 as x
  z_0 = x
  # Sample z_t from the reverse process of DM for t = 1,...,T
  z = [z_0]
  for t in range(1, T+1):
    z_t = DM.reverse(z[t-1])
    z.append(z_t)
  # Perturb z_t by adding Gaussian noise n_t for t = 0,...,T
  z' = []
  for t in range(0, T+1):
    n_t = sample_gaussian_noise(variance)
    z'_t = z[t] + n_t
    z'.append(z'_t)
  # Reconstruct x' from z'_t using the forward process of DM for t = T,...,0
  x' = z'[0]
  for t in range(1, T+1):
    x' = DM.forward(x', z'[t])
  # Optimize x' to minimize R(x,x') while maintaining S(x,x') >= s using gradient descent and projection
  while R(x,x') > 0 and S(x,x') >= s:
    # Update x' by gradient descent on R(x,x')
    x' = x' - alpha * torch.autograd.grad(R(x,x'), x')[0]
    # Project x' to the feasible set of S(x,x') >= s
    if S(x,x') < s:
      x' = project_to_feasible_set(x, x', s)
    # Clip x' to [0,1]
    x' = torch.clamp(x', min=0, max=1)
  # Return x'
  return x'
```