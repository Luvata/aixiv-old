---
title: 2108.03489v1 Impact of Aliasing on Generalization in Deep Convolutional Networks
date: 2021-08-04
---

# [Impact of Aliasing on Generalization in Deep Convolutional Networks](http://arxiv.org/abs/2108.03489v1)

authors: Cristina Vasconcelos, Hugo Larochelle, Vincent Dumoulin, Rob Romijnders, Nicolas Le Roux, Ross Goroshin


## What, Why and How

[1]: https://arxiv.org/pdf/2108.03489v1 "Impact of Aliasing on Generalization in Deep Convolutional Networks"
[2]: https://arxiv.org/abs/2108.03489v1 "[2108.03489v1] Impact of Aliasing on Generalization in Deep ... - arXiv.org"
[3]: http://export.arxiv.org/abs/1810.03489v1 "[1810.03489v1] Modeling and Simulation of Macroscopic Pedestrian Flow ..."

Here is a summary of the paper:

- **What**: The paper investigates the impact of aliasing on generalization in deep convolutional networks and proposes simple architectural modifications to mitigate it.
- **Why**: The paper argues that aliasing is a common source of distortion and noise in deep convolutional networks that can degrade their performance under out-of-distribution conditions, such as image classification under natural corruptions or few-shot learning.
- **How**: The paper draws insights from frequency analysis theory and reviews the trade-off between aliasing and information loss in each of the major components of ResNet and EfficientNet architectures. The paper shows how to insert non-trainable low-pass filters at key locations, particularly where networks lack the capacity to learn them, to reduce aliasing and improve generalization. The paper demonstrates state-of-the-art results on ImageNet-C and Meta-Dataset benchmarks without introducing additional trainable parameters or changing the default hyper-parameters.

## Main Contributions

The paper claims to make the following contributions:

- It provides a comprehensive analysis of the impact of aliasing on generalization in deep convolutional networks and shows that data augmentation schemes alone are unable to prevent it due to structural limitations in widely used architectures.
- It proposes simple architectural modifications to mitigate aliasing by inserting non-trainable low-pass filters at key locations, particularly where networks lack the capacity to learn them.
- It achieves state-of-the-art results on i.i.d. and out-of-distribution benchmarks, such as image classification under natural corruptions on ImageNet-C and few-shot learning on Meta-Dataset, without introducing additional trainable parameters and using the default hyper-parameters of open source codebases.
- It shows that this architectural improvement complements other techniques for improving generalization, such as data augmentation, regularization, and self-distillation.

## Method Summary

[1]: https://arxiv.org/pdf/2108.03489v1 "Impact of Aliasing on Generalization in Deep Convolutional Networks"
[2]: https://arxiv.org/abs/2108.03489v1 "[2108.03489v1] Impact of Aliasing on Generalization in Deep ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2305.03489v1 "[2305.03489v1] Catalysis cannot overcome bound entanglement"

Here is a summary of the method section of the paper:

- The paper reviews the basics of spectral aliasing and how it occurs when subsampling any signal, such as images or feature maps in convolutional networks.
- The paper analyzes the trade-off between aliasing and information loss in each of the major components of ResNet and EfficientNet architectures, such as convolutional layers, pooling layers, skip connections, and squeeze-and-excitation modules.
- The paper proposes to insert non-trainable low-pass filters at key locations in the architectures, particularly where networks lack the capacity to learn them, to reduce aliasing and improve generalization. The paper uses Gaussian blur filters with fixed standard deviation and kernel size as low-pass filters.
- The paper evaluates the proposed method on two benchmarks: ImageNet-C for image classification under natural corruptions and Meta-Dataset for few-shot learning. The paper compares the proposed method with baseline architectures and other techniques for improving generalization, such as data augmentation, regularization, and self-distillation.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define a function to insert a low-pass filter before a subsampling layer
def insert_low_pass_filter(layer):
  # Get the input and output shapes of the layer
  input_shape = layer.input_shape
  output_shape = layer.output_shape
  # Compute the subsampling factor
  subsampling_factor = input_shape / output_shape
  # Compute the standard deviation and kernel size of the Gaussian blur filter
  sigma = subsampling_factor / 6
  kernel_size = ceil(2 * sigma + 1)
  # Create a Gaussian blur filter with fixed parameters
  filter = GaussianBlur(sigma, kernel_size)
  # Insert the filter before the layer and return the modified layer
  return Sequential([filter, layer])

# Define a function to modify an architecture with low-pass filters
def modify_architecture(architecture):
  # Iterate over the layers of the architecture
  for layer in architecture.layers:
    # If the layer is a subsampling layer, such as max pooling or strided convolution
    if layer.is_subsampling():
      # Insert a low-pass filter before the layer
      layer = insert_low_pass_filter(layer)
    # If the layer is a skip connection, such as in ResNet blocks
    if layer.is_skip_connection():
      # Insert a low-pass filter before the skip connection
      layer = insert_low_pass_filter(layer)
    # If the layer is a squeeze-and-excitation module, such as in EfficientNet blocks
    if layer.is_squeeze_and_excitation():
      # Insert a low-pass filter before the squeeze-and-excitation module
      layer = insert_low_pass_filter(layer)
  # Return the modified architecture
  return architecture

# Define a function to train and evaluate an architecture on a benchmark
def train_and_evaluate(architecture, benchmark):
  # Modify the architecture with low-pass filters
  architecture = modify_architecture(architecture)
  # Train the architecture on the training data of the benchmark
  architecture.train(benchmark.train_data)
  # Evaluate the architecture on the test data of the benchmark
  architecture.evaluate(benchmark.test_data)

# Define two architectures: ResNet and EfficientNet
resnet = ResNet()
efficientnet = EfficientNet()

# Define two benchmarks: ImageNet-C and Meta-Dataset
imagenet_c = ImageNetC()
meta_dataset = MetaDataset()

# Train and evaluate ResNet on ImageNet-C
train_and_evaluate(resnet, imagenet_c)

# Train and evaluate EfficientNet on Meta-Dataset
train_and_evaluate(efficientnet, meta_dataset)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import the necessary libraries
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, losses, metrics
from tensorflow.keras.applications import resnet, efficientnet
from tensorflow_addons.layers import GaussianBlur2D
from tensorflow_datasets import load

# Define a function to insert a low-pass filter before a subsampling layer
def insert_low_pass_filter(layer):
  # Get the input and output shapes of the layer
  input_shape = layer.input_shape[1:]
  output_shape = layer.output_shape[1:]
  # Compute the subsampling factor along each dimension
  subsampling_factor = np.array(input_shape) / np.array(output_shape)
  # Compute the standard deviation and kernel size of the Gaussian blur filter along each dimension
  sigma = subsampling_factor / 6
  kernel_size = np.ceil(2 * sigma + 1).astype(int)
  # Create a Gaussian blur filter with fixed parameters and same padding
  filter = GaussianBlur2D(sigma, kernel_size, padding='same')
  # Insert the filter before the layer and return the modified layer
  return models.Sequential([filter, layer])

# Define a function to modify an architecture with low-pass filters
def modify_architecture(architecture):
  # Create an empty list to store the modified layers
  modified_layers = []
  # Iterate over the layers of the architecture
  for layer in architecture.layers:
    # If the layer is a subsampling layer, such as max pooling or strided convolution
    if isinstance(layer, (layers.MaxPooling2D, layers.Conv2D)) and any(np.array(layer.strides) > 1):
      # Insert a low-pass filter before the layer and append it to the list
      modified_layers.append(insert_low_pass_filter(layer))
    # If the layer is a skip connection, such as in ResNet blocks
    elif isinstance(layer, layers.Add):
      # Insert a low-pass filter before the skip connection and append it to the list
      modified_layers.append(insert_low_pass_filter(layer))
    # If the layer is a squeeze-and-excitation module, such as in EfficientNet blocks
    elif isinstance(layer, efficientnet.layers.SqueezeExcite):
      # Insert a low-pass filter before the squeeze-and-excitation module and append it to the list
      modified_layers.append(insert_low_pass_filter(layer))
    # Otherwise, append the layer as it is to the list
    else:
      modified_layers.append(layer)
  # Return a new model with the modified layers
  return models.Sequential(modified_layers)

# Define a function to train and evaluate an architecture on a benchmark
def train_and_evaluate(architecture, benchmark):
  # Modify the architecture with low-pass filters
  architecture = modify_architecture(architecture)
  # Compile the architecture with an optimizer, a loss function, and a metric
  architecture.compile(optimizer=optimizers.Adam(), loss=losses.SparseCategoricalCrossentropy(), metrics=[metrics.SparseCategoricalAccuracy()])
  # Load the training and test data of the benchmark
  train_data = load(benchmark + '/train', split='train', as_supervised=True)
  test_data = load(benchmark + '/test', split='test', as_supervised=True)
  # Train the architecture on the training data for a fixed number of epochs and batch size
  epochs = 10
  batch_size = 32
  architecture.fit(train_data.batch(batch_size), epochs=epochs)
  # Evaluate the architecture on the test data and print the results
  results = architecture.evaluate(test_data.batch(batch_size))
  print('Test loss:', results[0])
  print('Test accuracy:', results[1])

# Define two architectures: ResNet and EfficientNet with pretrained weights on ImageNet
resnet = resnet.ResNet50(weights='imagenet')
efficientnet = efficientnet.EfficientNetB0(weights='imagenet')

# Define two benchmarks: ImageNet-C and Meta-Dataset (only using ImageNet subset for simplicity)
imagenet_c = 'imagenet_c'
meta_dataset = 'meta_dataset/imagenet'

# Train and evaluate ResNet on ImageNet-C
train_and_evaluate(resnet, imagenet_c)

# Train and evaluate EfficientNet on Meta-Dataset
train_and_evaluate(efficientnet, meta_dataset)
```