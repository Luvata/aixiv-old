---
title: 2306.00031v1 Morphological Classification of Radio Galaxies using Semi-Supervised Group Equivariant CNNs
date: 2023-06-01
---

# [Morphological Classification of Radio Galaxies using Semi-Supervised Group Equivariant CNNs](http://arxiv.org/abs/2306.00031v1)

authors: Mir Sazzat Hossain, Sugandha Roy, K. M. B. Asad, Arshad Momen, Amin Ahsan Ali, M Ashraful Amin, A. K. M. Mahbubur Rahman


## What, Why and How

[1]: https://arxiv.org/abs/2206.00031 "On the coset graph construction of distance-regular graphs"
[2]: https://arxiv.org/pdf/2306.00031v1 "Morphological Classification of Radio Galaxies using Semi-Supervised ..."
[3]: http://export.arxiv.org/abs/2306.00031 "[2306.00031] Morphological Classification of Radio Galaxies using Semi ..."

Here is a summary of the paper at [^1^][2] in terms of What, Why, and How:

- **What**: The paper proposes a semi-supervised learning approach to classify radio galaxies into the known Fanaroff-Riley Type I and II (FR-I and FR-II) morphologies using group equivariant convolutional neural networks (G-CNNs).
- **Why**: The paper aims to address the challenge of having a large number of unlabeled images of radio galaxies and a small number of labeled ones, and to exploit the rotational symmetry of radio galaxies to improve the classification accuracy and robustness.
- **How**: The paper uses a semi-supervised G-CNN model that consists of two parts: a supervised part that learns from the labeled images using cross-entropy loss, and an unsupervised part that learns from the unlabeled images using contrastive loss. The paper also introduces a novel data augmentation technique called random rotation augmentation (RRA) that randomly rotates the images by multiples of 90 degrees to increase the diversity and size of the training data. The paper evaluates the proposed model on two datasets: FIRST and TGSS, and compares it with other baseline models such as CNNs and CapsNets. The paper reports that the proposed model achieves state-of-the-art results on both datasets, and shows that RRA improves the performance and generalization of the model.

## Main Contributions

The paper claims to make the following contributions:

- It proposes a semi-supervised learning approach to classify radio galaxies using G-CNNs that leverages both labeled and unlabeled data.
- It introduces a novel data augmentation technique called RRA that randomly rotates the images by multiples of 90 degrees to increase the diversity and size of the training data.
- It achieves state-of-the-art results on two datasets: FIRST and TGSS, and shows that RRA improves the performance and generalization of the model.

## Method Summary

[1]: https://arxiv.org/abs/2306.00031 "[2306.00031] Morphological Classification of Radio Galaxies using Semi ..."
[2]: https://arxiv.org/pdf/2306.00031v1 "Morphological Classification of Radio Galaxies using Semi-Supervised ..."
[3]: http://export.arxiv.org/abs/2305.00031v1 "[2305.00031v1] Dissipative Boundary State Preparation"

Here is a summary of the method section of the paper at [^1^][2]:

- The paper uses a semi-supervised learning approach that consists of two parts: a self-supervised part that learns from the unlabeled images using contrastive loss, and a supervised part that learns from the labeled images using cross-entropy loss.
- The paper uses a G-CNN as an encoder for the self-supervised part, which preserves the equivariance for the Euclidean Group E(2), enabling it to effectively learn the representation of globally oriented feature maps. The paper uses two state-of-the-art self-supervised methods: SimCLR and BYOL, as the contrastive learning frameworks for the G-CNN encoder.
- The paper introduces a novel data augmentation technique called RRA that randomly rotates the images by multiples of 90 degrees to increase the diversity and size of the training data. The paper applies RRA to both labeled and unlabeled images before feeding them to the G-CNN encoder.
- The paper trains a fully-connected classifier on top of the G-CNN encoder using the labeled data, and fine-tunes the encoder with cross-entropy loss. The paper also uses dropout and weight decay as regularization techniques to prevent overfitting.

## Pseudo Code

Here is a possible pseudo code to implement the paper:

```python
# Import the necessary libraries
import torch
import torchvision
import numpy as np

# Define the hyperparameters
batch_size = 256 # The size of each mini-batch
num_epochs = 100 # The number of epochs to train the model
learning_rate = 0.01 # The learning rate for the optimizer
weight_decay = 0.0001 # The weight decay for the optimizer
temperature = 0.5 # The temperature parameter for the contrastive loss
projection_dim = 128 # The dimension of the projection head
dropout_rate = 0.5 # The dropout rate for the classifier

# Load the labeled and unlabeled datasets
labeled_dataset = torchvision.datasets.ImageFolder("path/to/labeled/data")
unlabeled_dataset = torchvision.datasets.ImageFolder("path/to/unlabeled/data")

# Define the data augmentation transforms
transform = torchvision.transforms.Compose([
    torchvision.transforms.RandomRotation([0, 90, 180, 270]), # Apply RRA
    torchvision.transforms.RandomResizedCrop(224), # Crop and resize the images
    torchvision.transforms.RandomHorizontalFlip(), # Flip the images horizontally
    torchvision.transforms.ToTensor(), # Convert the images to tensors
    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normalize the images
])

# Apply the transforms to both datasets
labeled_dataset = labeled_dataset.map(transform)
unlabeled_dataset = unlabeled_dataset.map(transform)

# Create data loaders for both datasets
labeled_loader = torch.utils.data.DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True)
unlabeled_loader = torch.utils.data.DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True)

# Define the G-CNN encoder model
encoder = torchvision.models.resnet18(pretrained=True) # Use a pretrained ResNet-18 as the backbone
encoder.fc = torch.nn.Identity() # Remove the last fully-connected layer

# Define the projection head model
projection_head = torch.nn.Sequential(
    torch.nn.Linear(512, projection_dim), # A linear layer with projection_dim units
    torch.nn.ReLU(), # A ReLU activation function
    torch.nn.Linear(projection_dim, projection_dim) # Another linear layer with projection_dim units
)

# Define the classifier model
classifier = torch.nn.Sequential(
    torch.nn.Dropout(dropout_rate), # A dropout layer with dropout_rate probability
    torch.nn.Linear(512, 2) # A linear layer with 2 units (one for each class)
)

# Define the contrastive loss function (using SimCLR as an example)
def contrastive_loss(x1, x2):
    # x1 and x2 are batches of projected features from two augmented views of the same image
    x1 = torch.nn.functional.normalize(x1, dim=1) # Normalize x1 along the feature dimension
    x2 = torch.nn.functional.normalize(x2, dim=1) # Normalize x2 along the feature dimension
    similarity_matrix = torch.matmul(x1, x2.T) # Compute the cosine similarity matrix between x1 and x2
    similarity_matrix = similarity_matrix / temperature # Divide the similarity matrix by the temperature parameter
    labels = torch.arange(batch_size).to(device) # Create the labels for positive pairs (diagonal elements)
    loss = torch.nn.functional.cross_entropy(similarity_matrix, labels) # Compute the cross-entropy loss 
    return loss

# Define the cross-entropy loss function for classification
cross_entropy_loss = torch.nn.CrossEntropyLoss()

# Define the optimizer for both encoder and classifier models (using SGD as an example)
optimizer = torch.optim.SGD([{"params": encoder.parameters()}, {"params": classifier.parameters()}], lr=learning_rate, weight_decay=weight_decay)

# Move the models and loss functions to device (GPU or CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
encoder.to(device)
projection_head.to(device)
classifier.to(device)
contrastive_loss.to(device)
cross_entropy_loss.to(device)

# Train the model using semi-supervised learning approach
for epoch in range(num_epochs):
    # Train the encoder and projection head using contrastive loss on unlabeled data
    encoder.train()
    projection_head.train()
    for (x1, _), (x2, _) in zip(unlabeled_loader, unlabeled_loader): # Iterate over two augmented views of unlabeled data
        x1 = x1.to(device) # Move x1 to device
        x2 = x2.to(device) # Move x2 to device
        optimizer.zero_grad() # Zero the gradients
        z1 = encoder(x1) # Encode x1 using the encoder
        z2 = encoder(x2) # Encode x2 using the encoder
        p1 = projection_head(z1) # Project z1 using the projection head
        p2 = projection_head(z2) # Project z2 using the projection head
        loss = contrastive_loss(p1, p2) # Compute the contrastive loss
        loss.backward() # Backpropagate the loss
        optimizer.step() # Update the parameters
    
    # Train the classifier and fine-tune the encoder using cross-entropy loss on labeled data
    encoder.train()
    classifier.train()
    for x, y in labeled_loader: # Iterate over labeled data
        x = x.to(device) # Move x to device
        y = y.to(device) # Move y to device
        optimizer.zero_grad() # Zero the gradients
        z = encoder(x) # Encode x using the encoder
        y_pred = classifier(z) # Predict y using the classifier
        loss = cross_entropy_loss(y_pred, y) # Compute the cross-entropy loss
        loss.backward() # Backpropagate the loss
        optimizer.step() # Update the parameters
    
    # Evaluate the model on labeled data
    encoder.eval()
    classifier.eval()
    correct = 0 # Initialize the number of correct predictions
    total = 0 # Initialize the total number of predictions
    for x, y in labeled_loader: # Iterate over labeled data
        x = x.to(device) # Move x to device
        y = y.to(device) # Move y to device
        z = encoder(x) # Encode x using the encoder
        y_pred = classifier(z) # Predict y using the classifier
        _, y_pred = torch.max(y_pred, 1) # Get the predicted class labels
        correct += (y_pred == y).sum().item() # Count the number of correct predictions
        total += y.size(0) # Count the total number of predictions
    
    accuracy = correct / total # Compute the accuracy
    print(f"Epoch {epoch}, Accuracy {accuracy}") # Print the accuracy

```