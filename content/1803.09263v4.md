---
title: 1803.09263v4 P2P-NET  Bidirectional Point Displacement Net for Shape Transform
date: 2018-03-10
---

# [P2P-NET: Bidirectional Point Displacement Net for Shape Transform](http://arxiv.org/abs/1803.09263v4)

authors: Kangxue Yin, Hui Huang, Daniel Cohen-Or, Hao Zhang


## What, Why and How

[1]: https://arxiv.org/abs/1803.09263 "[1803.09263] P2P-NET: Bidirectional Point Displacement Net for Shape ..."
[2]: https://arxiv.org/pdf/1803.09263v4.pdf "arXiv.org e-Print archive"
[3]: https://arxiv-export-lb.library.cornell.edu/abs/2201.09263v4 "[2201.09263v4] Exploring Differential Geometry in Neural Implicits"

Here is a summary of the paper:

**What**: The paper introduces **P2P-NET**, a general-purpose deep neural network which learns geometric transformations between point-based shape representations from two domains, e.g., meso-skeletons and surfaces, partial and complete scans, etc[^1^][1].

**Why**: The paper aims to solve a variety of point-based shape transformation problems, such as shape completion, shape abstraction, shape interpolation, etc., without relying on point-to-point correspondences between the source and target point sets[^1^][1].

**How**: The paper proposes a **bi-directional point displacement network**, which transforms a source point set to a target point set with the same cardinality, and vice versa, by applying point-wise displacement vectors learned from data. The paper also proposes a **training loss** that combines two uni-directional geometric losses, each enforcing a shape-wise similarity between the predicted and the target point sets, and a cross-regularization term to encourage consistency between displacement vectors going in opposite directions[^1^][1]. The paper demonstrates the effectiveness, versatility, and potential of the network in several applications on different datasets[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/1803.09263 "[1803.09263] P2P-NET: Bidirectional Point Displacement Net for Shape ..."
[2]: https://arxiv.org/pdf/1803.09263v4.pdf "arXiv.org e-Print archive"
[3]: https://arxiv-export-lb.library.cornell.edu/abs/2201.09263v4 "[2201.09263v4] Exploring Differential Geometry in Neural Implicits"

According to the paper[^1^][1], the main contributions are:

- A **general-purpose deep neural network** that can learn geometric transformations between point-based shape representations from two domains without point-to-point correspondences.
- A **bi-directional point displacement network** that can transform a source point set to a target point set with the same cardinality, and vice versa, by applying point-wise displacement vectors learned from data.
- A **training loss** that combines two uni-directional geometric losses and a cross-regularization term to enforce shape-wise similarity and consistency between displacement vectors.
- Several **applications** that demonstrate the effectiveness, versatility, and potential of the network in solving a variety of point-based shape transformation problems.

## Method Summary

[1]: https://arxiv.org/abs/1803.09263 "[1803.09263] P2P-NET: Bidirectional Point Displacement Net for Shape ..."
[2]: https://arxiv.org/pdf/1803.09263v4.pdf "arXiv.org e-Print archive"
[3]: https://arxiv-export-lb.library.cornell.edu/abs/2201.09263v4 "[2201.09263v4] Exploring Differential Geometry in Neural Implicits"

Here is a summary of the method section of the paper:

The paper proposes a **P2P-NET** that consists of two sub-networks: a **source-to-target network (S2T)** and a **target-to-source network (T2S)**. Each sub-network takes a point set as input and outputs a point set with the same cardinality by applying point-wise displacement vectors. The displacement vectors are learned from data by minimizing a **training loss** that has three components:

- A **geometric loss** that measures the shape-wise similarity between the predicted and the target point sets using Chamfer distance and Earth Mover's distance.
- A **cross-regularization term** that encourages consistency between the displacement vectors going in opposite directions by minimizing their L2 norm difference.
- A **regularization term** that prevents overfitting by penalizing large displacement vectors.

The paper also describes how to sample point sets from different shape representations, such as meshes, point clouds, and meso-skeletons, using Poisson disk sampling and farthest point sampling. The paper also explains how to handle different point set cardinalities using random sampling or upsampling techniques. The paper also provides details on the network architecture, hyperparameters, and training procedure.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Define the P2P-NET
P2P-NET = S2T + T2S # S2T and T2S are sub-networks that transform point sets in opposite directions

# Define the training loss
L = L_S2T + L_T2S + L_cross # L_S2T and L_T2S are geometric losses for each sub-network, L_cross is the cross-regularization term

# Sample point sets from source and target domains
X = sample_points(source_shape) # X is the source point set
Y = sample_points(target_shape) # Y is the target point set

# Train the P2P-NET
for epoch in epochs:
  # Forward pass
  X_hat = S2T(X) # X_hat is the predicted target point set
  Y_hat = T2S(Y) # Y_hat is the predicted source point set
  
  # Compute the loss
  loss = L(X, Y, X_hat, Y_hat)
  
  # Backward pass
  update_parameters(P2P-NET, loss)
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import libraries
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

# Define the network parameters
N = 1024 # number of points per point set
D = 3 # dimension of points
H = 256 # hidden size of MLPs
K = 4 # number of MLP layers

# Define the P2P-NET
class P2P_NET(nn.Module):
  def __init__(self):
    super(P2P_NET, self).__init__()
    # Define the sub-networks
    self.S2T = PointDisplacementNet() # source-to-target network
    self.T2S = PointDisplacementNet() # target-to-source network
  
  def forward(self, X, Y):
    # Transform the point sets in both directions
    X_hat = self.S2T(X) # predicted target point set
    Y_hat = self.T2S(Y) # predicted source point set
    return X_hat, Y_hat

# Define the PointDisplacementNet
class PointDisplacementNet(nn.Module):
  def __init__(self):
    super(PointDisplacementNet, self).__init__()
    # Define the MLPs
    self.MLPs = nn.ModuleList([nn.Linear(D, H)] + [nn.Linear(H, H) for _ in range(K-2)] + [nn.Linear(H, D)])
  
  def forward(self, P):
    # Apply point-wise displacement vectors to each point
    Q = P.clone() # copy the input point set
    for MLP in self.MLPs:
      Q = Q + MLP(Q) # add the displacement vector from each MLP layer
    return Q

# Define the training loss
def loss_function(X, Y, X_hat, Y_hat):
  # Compute the geometric losses using Chamfer distance and Earth Mover's distance
  L_S2T = CD(X_hat, Y) + EMD(X_hat, Y) # geometric loss for S2T network
  L_T2S = CD(Y_hat, X) + EMD(Y_hat, X) # geometric loss for T2S network
  
  # Compute the cross-regularization term using L2 norm difference
  L_cross = torch.mean(torch.norm(X - Y_hat, dim=1) - torch.norm(Y - X_hat, dim=1))**2
  
  # Compute the regularization term using L2 norm penalty
  L_reg = torch.mean(torch.norm(X - Y_hat, dim=1)) + torch.mean(torch.norm(Y - X_hat, dim=1))
  
  # Combine the loss components with weights
  alpha = 0.01 # weight for cross-regularization term
  beta = 0.001 # weight for regularization term
  L = L_S2T + L_T2S + alpha * L_cross + beta * L_reg
  
  return L

# Define the Chamfer distance function
def CD(P1, P2):
  # Compute the pairwise distances between two point sets
  D = torch.cdist(P1, P2)
  
  # Compute the minimum distances along each dimension
  D1, _ = torch.min(D, dim=1)
  D2, _ = torch.min(D, dim=0)
  
  # Compute the mean of the minimum distances
  CD = torch.mean(D1) + torch.mean(D2)
  
  return CD

# Define the Earth Mover's distance function (using approximation)
def EMD(P1, P2):
  # Compute the pairwise distances between two point sets
  D = torch.cdist(P1, P2)
  
  # Compute the optimal assignment using Hungarian algorithm (using scipy library)
  from scipy.optimize import linear_sum_assignment
  row_ind, col_ind = linear_sum_assignment(D.detach().cpu().numpy())
  
  # Compute the mean of the assigned distances
  EMD = torch.mean(D[row_ind, col_ind])
  
  return EMD

# Sample point sets from source and target domains (using synthetic data for illustration)
def sample_points(shape):
  # Generate a random point set with N points and D dimensions
  P = torch.rand(N, D)
  
  # Apply some transformation to the point set based on the shape representation (e.g., mesh, point cloud, meso-skeleton)
  # This step is omitted here for simplicity
  
  return P

# Create a P2P-NET instance
p2p_net = P2P_NET()

# Create an optimizer instance (using Adam optimizer for illustration)
optimizer = optim.Adam(p2p_net.parameters(), lr=0.001)

# Train the P2P-NET
epochs = 100 # number of training epochs
for epoch in range(epochs):
  # Sample point sets from source and target domains
  X = sample_points(source_shape) # source point set
  Y = sample_points(target_shape) # target point set
  
  # Forward pass
  X_hat, Y_hat = p2p_net(X, Y) # predicted point sets
  
  # Compute the loss
  loss = loss_function(X, Y, X_hat, Y_hat)
  
  # Backward pass
  optimizer.zero_grad() # clear the gradients
  loss.backward() # compute the gradients
  optimizer.step() # update the parameters
  
  # Print the loss
  print(f"Epoch {epoch}, Loss {loss.item()}")
```