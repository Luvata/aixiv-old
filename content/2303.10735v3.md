---
title: 2303.10735v3 SKED  Sketch-guided Text-based 3D Editing
date: 2023-03-11
---

# [SKED: Sketch-guided Text-based 3D Editing](http://arxiv.org/abs/2303.10735v3)

authors: Aryan Mikaeili, Or Perel, Mehdi Safaee, Daniel Cohen-Or, Ali Mahdavi-Amiri


## What, Why and How

[1]: https://arxiv.org/pdf/2303.10735.pdf "SKED: Sketch-guided Text-based 3D Editing - arXiv.org"
[2]: https://arxiv.org/abs/2303.10735v1 "[2303.10735v1] SKED: Sketch-guided Text-based 3D Editing - arXiv.org"
[3]: https://arxiv-export2.library.cornell.edu/abs/2303.10735v3 "[2303.10735v3] SKED: Sketch-guided Text-based 3D Editing"

Here is a summary of the paper at [^1^][1]:

- What: The paper presents **SKED**, a technique for editing 3D shapes represented by **Neural Radiance Fields (NeRFs)** using **text prompts** and **user-guided sketches** from different views.
- Why: The paper aims to enable more intuitive and fine-grained control for manipulating 3D content in an open domain, by combining the power of text-to-image diffusion models with the flexibility of sketch-based editing.
- How: The paper proposes novel loss functions to generate localized and meaningful edits that respect the prompt semantics and adhere to the provided sketches, while preserving the density and radiance of the base instance. The paper also demonstrates the effectiveness of the proposed method through qualitative and quantitative experiments.

## Main Contributions

[1]: https://arxiv.org/pdf/2303.10735.pdf "SKED: Sketch-guided Text-based 3D Editing - arXiv.org"
[2]: https://arxiv.org/abs/2303.10735v1 "[2303.10735v1] SKED: Sketch-guided Text-based 3D Editing - arXiv.org"
[3]: https://arxiv-export2.library.cornell.edu/abs/2303.10735v3 "[2303.10735v3] SKED: Sketch-guided Text-based 3D Editing"

According to the paper at [^1^][1], the main contributions are:

- The paper introduces **SKED**, a novel technique for sketch-guided text-based 3D editing of NeRFs in an open domain.
- The paper proposes novel loss functions to generate localized and meaningful edits that respect the prompt semantics and adhere to the provided sketches, while preserving the density and radiance of the base instance.
- The paper demonstrates the effectiveness of the proposed method through qualitative and quantitative experiments, showing that it can produce diverse and realistic edits for various 3D shapes and scenes.

## Method Summary

[1]: https://arxiv.org/pdf/2303.10735.pdf "SKED: Sketch-guided Text-based 3D Editing - arXiv.org"
[2]: https://arxiv.org/abs/2303.10735v1 "[2303.10735v1] SKED: Sketch-guided Text-based 3D Editing - arXiv.org"
[3]: https://arxiv-export2.library.cornell.edu/abs/2303.10735v3 "[2303.10735v3] SKED: Sketch-guided Text-based 3D Editing"

Here is a summary of the method section of the paper at [^1^][1]:

- The paper proposes a technique for editing 3D shapes represented by NeRFs using text prompts and user-guided sketches from different views.
- The paper assumes that a pretrained NeRF model and a pretrained text-to-image diffusion model are available, and that the user provides a text prompt and two sketches from orthogonal views to specify the desired edit.
- The paper defines a sketch-guided region of interest (ROI) that determines the coarse region where the edit should take place, based on the intersection of the projected sketches on the NeRF volume.
- The paper optimizes a new NeRF model that minimizes a combination of losses: a sketch loss that measures the similarity between the rendered views and the sketches, a text loss that measures the semantic consistency between the rendered views and the text prompt, a radiance loss that preserves the appearance of the base instance outside the ROI, and a density loss that preserves the shape of the base instance outside the ROI.
- The paper renders the final edited shape by blending the outputs of the base and edited NeRF models according to a soft mask that is computed from the ROI.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a base NeRF model, a text prompt, and two sketches from orthogonal views
# Output: an edited NeRF model and a soft mask

# Preprocess the sketches to extract contours and fill holes
sketches = preprocess(sketches)

# Project the sketches onto the NeRF volume and compute the ROI
ROI = project_and_intersect(sketches, base_NeRF)

# Initialize an edited NeRF model with the same architecture as the base NeRF model
edited_NeRF = copy(base_NeRF)

# Optimize the edited NeRF model using gradient descent
for iteration in range(max_iterations):
  # Sample random rays from the sketches and render them using the edited NeRF model
  rays = sample_rays(sketches)
  rendered_views = render(rays, edited_NeRF)

  # Compute the sketch loss, the text loss, the radiance loss, and the density loss
  sketch_loss = compute_sketch_loss(rendered_views, sketches)
  text_loss = compute_text_loss(rendered_views, text_prompt)
  radiance_loss = compute_radiance_loss(edited_NeRF, base_NeRF, ROI)
  density_loss = compute_density_loss(edited_NeRF, base_NeRF, ROI)

  # Compute the total loss as a weighted sum of the individual losses
  total_loss = sketch_loss + text_loss + radiance_loss + density_loss

  # Update the edited NeRF model parameters using the gradients of the total loss
  edited_NeRF = update(edited_NeRF, total_loss)

# Compute a soft mask from the ROI using a sigmoid function
soft_mask = sigmoid(ROI)

# Return the edited NeRF model and the soft mask
return edited_NeRF, soft_mask
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a base NeRF model, a text prompt, and two sketches from orthogonal views
# Output: an edited NeRF model and a soft mask

# Preprocess the sketches to extract contours and fill holes
def preprocess(sketches):
  # Convert the sketches to grayscale images
  sketches = rgb2gray(sketches)

  # Apply Canny edge detection to extract contours
  sketches = canny(sketches)

  # Apply morphological closing to fill holes
  sketches = closing(sketches)

  # Return the preprocessed sketches
  return sketches

# Project the sketches onto the NeRF volume and compute the ROI
def project_and_intersect(sketches, base_NeRF):
  # Initialize an empty ROI volume with the same resolution as the base NeRF volume
  ROI = zeros(base_NeRF.resolution)

  # For each sketch and its corresponding view direction
  for sketch, view in zip(sketches, views):
    # Project the sketch onto the NeRF volume using ray marching
    projected_sketch = ray_march(sketch, view, base_NeRF)

    # Update the ROI volume by taking the element-wise maximum with the projected sketch
    ROI = max(ROI, projected_sketch)

  # Return the ROI volume
  return ROI

# Render a set of rays using a NeRF model
def render(rays, NeRF):
  # Initialize an empty list of rendered views
  rendered_views = []

  # For each ray in the set of rays
  for ray in rays:
    # Sample points along the ray using stratified sampling
    points = sample_points(ray)

    # Evaluate the NeRF model at each point to get the density and color values
    densities, colors = NeRF(points)

    # Compute the weights for each point using alpha compositing
    weights = alpha_composite(densities)

    # Compute the rendered view by taking the weighted sum of the colors
    rendered_view = sum(weights * colors)

    # Append the rendered view to the list of rendered views
    rendered_views.append(rendered_view)

  # Return the list of rendered views
  return rendered_views

# Compute the sketch loss between a set of rendered views and a set of sketches
def compute_sketch_loss(rendered_views, sketches):
  # Initialize an empty list of sketch losses
  sketch_losses = []

  # For each rendered view and its corresponding sketch
  for rendered_view, sketch in zip(rendered_views, sketches):
    # Convert the rendered view to grayscale
    rendered_view = rgb2gray(rendered_view)

    # Apply Canny edge detection to extract contours
    rendered_view = canny(rendered_view)

    # Compute the mean squared error between the rendered view and the sketch
    sketch_loss = mse(rendered_view, sketch)

    # Append the sketch loss to the list of sketch losses
    sketch_losses.append(sketch_loss)

  # Return the average of the sketch losses
  return mean(sketch_losses)

# Compute the text loss between a set of rendered views and a text prompt
def compute_text_loss(rendered_views, text_prompt):
  # Initialize an empty list of text losses
  text_losses = []

  # For each rendered view
  for rendered_view in rendered_views:
    # Encode the rendered view and the text prompt using a pretrained text-to-image diffusion model
    encoded_view = encode_image(rendered_view)
    encoded_prompt = encode_text(text_prompt)

    # Compute the cosine similarity between the encoded view and the encoded prompt
    similarity = cosine_similarity(encoded_view, encoded_prompt)

    # Compute the text loss as one minus the similarity
    text_loss = 1 - similarity

    # Append the text loss to the list of text losses
    text_losses.append(text_loss)

  # Return the average of the text losses
  return mean(text_losses)

# Compute the radiance loss between an edited NeRF model and a base NeRF model outside the ROI
def compute_radiance_loss(edited_NeRF, base_NeRF, ROI):
  # Sample random rays from outside the ROI using uniform sampling
  rays = sample_rays_outside(ROI)

  # Render the rays using both models and compute their difference in color values
  edited_views = render(rays, edited_NeRF)
  base_views = render(rays, base_NeRF)
  difference = edited_views - base_views

  # Compute the radiance loss as the mean squared error of the difference
  radiance_loss = mse(difference)

  # Return the radiance loss
  return radiance_loss

# Compute the density loss between an edited NeRF model and a base NeRF model outside the ROI
def compute_density_loss(edited_NeRF, base_NeRF, ROI):
  # Sample random points from outside the ROI using uniform sampling
  points = sample_points_outside(ROI)

  # Evaluate both models at the points and compute their difference in density values
  edited_densities = edited_NeRF(points)[0]
  base_densities = base_NeRF(points)[0]
  difference = edited_densities - base_densities

  # Compute the density loss as the mean squared error of the difference
  density_loss = mse(difference)

  # Return the density loss
  return density_loss

# Update the edited NeRF model parameters using the gradients of the total loss
def update(edited_NeRF, total_loss):
  # Compute the gradients of the total loss with respect to the edited NeRF model parameters
  gradients = compute_gradients(total_loss, edited_NeRF.parameters)

  # Apply a learning rate to the gradients
  gradients = gradients * learning_rate

  # Update the edited NeRF model parameters by subtracting the gradients
  edited_NeRF.parameters = edited_NeRF.parameters - gradients

  # Return the updated edited NeRF model
  return edited_NeRF

# Compute a soft mask from the ROI using a sigmoid function
def sigmoid(ROI):
  # Apply a sigmoid function to the ROI volume with a scaling factor
  soft_mask = 1 / (1 + exp(-scaling_factor * ROI))

  # Return the soft mask
  return soft_mask

# Input: a base NeRF model, a text prompt, and two sketches from orthogonal views
# Output: an edited NeRF model and a soft mask

# Preprocess the sketches to extract contours and fill holes
sketches = preprocess(sketches)

# Project the sketches onto the NeRF volume and compute the ROI
ROI = project_and_intersect(sketches, base_NeRF)

# Initialize an edited NeRF model with the same architecture as the base NeRF model
edited_NeRF = copy(base_NeRF)

# Optimize the edited NeRF model using gradient descent
for iteration in range(max_iterations):
  # Sample random rays from the sketches and render them using the edited NeRF model
  rays = sample_rays(sketches)
  rendered_views = render(rays, edited_NeRF)

  # Compute the sketch loss, the text loss, the radiance loss, and the density loss
  sketch_loss = compute_sketch_loss(rendered_views, sketches)
  text_loss = compute_text_loss(rendered_views, text_prompt)
  radiance_loss = compute_radiance_loss(edited_NeRF, base_NeRF, ROI)
  density_loss = compute_density_loss(edited_NeRF, base_NeRF, ROI)

  # Compute the total loss as a weighted sum of the individual losses
  total_loss = sketch_loss + text_loss + radiance_loss + density_loss

  # Update the edited NeRF model parameters using the gradients of the total loss
  edited_NeRF = update(edited_NeRF, total_loss)

# Compute a soft mask from the ROI using a sigmoid function
soft_mask = sigmoid(ROI)

# Return the edited NeRF model and the soft mask
return edited_NeRF, soft_mask
```