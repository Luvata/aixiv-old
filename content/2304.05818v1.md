---
title: 2304.05818v1 Gradient-Free Textual Inversion
date: 2023-04-06
---

# [Gradient-Free Textual Inversion](http://arxiv.org/abs/2304.05818v1)

authors: Zhengcong Fei, Mingyuan Fan, Junshi Huang


## What, Why and How

[1]: https://arxiv.org/abs/2304.05818 "[2304.05818] Gradient-Free Textual Inversion - arXiv.org"
[2]: https://arxiv.org/pdf/2304.05818v1 "arXiv.org"
[3]: https://arxiv-export3.library.cornell.edu/abs/2304.05818 "[2304.05818] Gradient-Free Textual Inversion"

Here is a summary of the paper:

- **What**: The paper introduces a gradient-free framework to optimize the continuous textual inversion in an iterative evolutionary strategy for personalized text-to-image generation[^1^][1].
- **Why**: The paper aims to address the question of whether we can optimize the textual inversions by only accessing the process of model inference, which has the benefits of less GPU memory, simple deployment, and secure access for scalable models[^1^][1].
- **How**: The paper first initializes an appropriate token embedding for textual inversion with the consideration of visual and text vocabulary information. Then, it decomposes the optimization of evolutionary strategy into dimension reduction of searching space and non-convex gradient-free optimization in subspace, which significantly accelerates the optimization process with negligible performance loss[^1^][1]. The paper evaluates the performance of the proposed method on several applications and compares it with gradient-based counterparts[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/2304.05818 "[2304.05818] Gradient-Free Textual Inversion - arXiv.org"
[2]: https://arxiv.org/pdf/2304.05818v1 "arXiv.org"
[3]: https://arxiv-export3.library.cornell.edu/abs/2304.05818 "[2304.05818] Gradient-Free Textual Inversion"

According to the paper[^1^][1], the main contributions are:

- **A gradient-free framework** to optimize the continuous textual inversion in an iterative evolutionary strategy for personalized text-to-image generation, which only requires the forward computation to determine the textual inversion and retains the benefits of less GPU memory, simple deployment, and secure access for scalable models.
- **An initialization method** for textual inversion with the consideration of visual and text vocabulary information, which improves the quality and diversity of the generated images.
- **A dimension reduction technique** for searching space and a non-convex gradient-free optimization method in subspace, which significantly accelerates the optimization process with negligible performance loss.
- **Extensive experiments** on several applications such as text-to-image generation, image editing, and image retrieval, which demonstrate that the proposed method is comparable to gradient-based counterparts with variant GPU/CPU platforms, flexible employment, as well as computational efficiency.

## Method Summary

[1]: https://arxiv.org/abs/2304.05818 "[2304.05818] Gradient-Free Textual Inversion - arXiv.org"
[2]: https://arxiv.org/pdf/2304.05818v1 "arXiv.org"
[3]: https://arxiv-export3.library.cornell.edu/abs/2304.05818 "[2304.05818] Gradient-Free Textual Inversion"

Here is a summary of the method section of the paper:

- The paper proposes a gradient-free framework to optimize the continuous textual inversion in an iterative evolutionary strategy for personalized text-to-image generation[^1^][1].
- The paper defines the textual inversion problem as finding the optimal token embedding that maximizes a similarity score between the generated image and the target image[^1^][1].
- The paper introduces an initialization method for textual inversion that considers both visual and text vocabulary information. The method first extracts visual features from the target image using a pre-trained CNN and then finds the nearest neighbor token embedding in the text vocabulary space using cosine similarity[^1^][1].
- The paper decomposes the optimization of evolutionary strategy into two steps: dimension reduction of searching space and non-convex gradient-free optimization in subspace[^1^][1].
- The paper applies principal component analysis (PCA) to reduce the dimensionality of the searching space and projects the token embedding onto a low-dimensional subspace spanned by the principal components[^1^][1].
- The paper adopts a non-convex gradient-free optimization method called CMA-ES (Covariance Matrix Adaptation Evolution Strategy) to optimize the token embedding in the subspace. CMA-ES is a population-based algorithm that iteratively updates a multivariate normal distribution over the candidate solutions based on their fitness values[^1^][1].
- The paper evaluates the performance of the proposed method on several applications such as text-to-image generation, image editing, and image retrieval using different text-to-image models and datasets[^1^][1].

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a target image I, a text-to-image model M, a text vocabulary V, a pre-trained CNN F
# Output: a token embedding E that maximizes the similarity score S(I, M(E))

# Initialize E with visual and text vocabulary information
E = argmax_e in V cosine_similarity(F(I), e)

# Reduce the dimensionality of the searching space using PCA
P = PCA(V) # compute the principal components of V
E = P.project(E) # project E onto the subspace spanned by P

# Optimize E in the subspace using CMA-ES
C = CMA-ES(E) # initialize CMA-ES with E as the mean
while not converged:
  E_list = C.sample() # sample a population of candidate solutions from C
  S_list = [S(I, M(P.reconstruct(E))) for E in E_list] # compute the similarity scores for each candidate solution
  C.update(E_list, S_list) # update C based on the fitness values of the candidates
E = C.mean # get the optimal solution as the mean of C

# Return E
return E
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a target image I, a text-to-image model M, a text vocabulary V, a pre-trained CNN F
# Output: a token embedding E that maximizes the similarity score S(I, M(E))

# Define some hyperparameters
n = len(V) # the size of the text vocabulary
d = 512 # the dimension of the token embedding
k = 64 # the reduced dimension of the subspace
lambda = 4 + floor(3 * log(k)) # the population size for CMA-ES
sigma = 0.3 # the initial step size for CMA-ES
max_iter = 100 # the maximum number of iterations for CMA-ES

# Initialize E with visual and text vocabulary information
v = F(I) # extract the visual feature vector from I using F
E = argmax_e in V cosine_similarity(v, e) # find the nearest neighbor token embedding in V using cosine similarity

# Reduce the dimensionality of the searching space using PCA
P = PCA(V) # compute the principal components of V using PCA
P = P[:k] # keep only the top k principal components
E = P.project(E) # project E onto the subspace spanned by P

# Optimize E in the subspace using CMA-ES
m = E # initialize the mean vector of CMA-ES with E
C = identity(k) # initialize the covariance matrix of CMA-ES with identity matrix
w = log(lambda / 2 + 0.5) - log(range(1, lambda + 1)) # compute the weights for CMA-ES
w = w / sum(w) # normalize the weights to sum to one
mu_eff = 1 / sum(w ** 2) # compute the effective selection mass for CMA-ES
c_s = (mu_eff + 2) / (k + mu_eff + 5) # compute the step size control parameter for CMA-ES
d_s = 1 + 2 * max(0, sqrt((mu_eff - 1) / (k + 1)) - 1) + c_s # compute the damping parameter for CMA-ES
c_c = (4 + mu_eff / k) / (k + 4 + 2 * mu_eff / k) # compute the covariance matrix adaptation parameter for CMA-ES
c_1 = 2 / ((k + 1.3) ** 2 + mu_eff) # compute the rank-one update parameter for CMA-ES
c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((k + 2) ** 2 + mu_eff)) # compute the rank-mu update parameter for CMA-ES
e_s = normal(0, k) # initialize an evolution path for CMA-ES with standard normal vector
e_c = normal(0, k) # initialize another evolution path for CMA-ES with standard normal vector

for i in range(max_iter):
  E_list = [] # initialize an empty list to store the candidate solutions
  Z_list = [] # initialize an empty list to store the random vectors
  S_list = [] # initialize an empty list to store the similarity scores

  for j in range(lambda):
    z_j = multivariate_normal(0, C) # sample a random vector from multivariate normal distribution with mean zero and covariance matrix C
    e_j = m + sigma * z_j # compute a candidate solution by adding a scaled random vector to the mean vector
    E_list.append(e_j) # append e_j to E_list
    Z_list.append(z_j) # append z_j to Z_list

    i_j = M(P.reconstruct(e_j)) # generate an image from e_j by reconstructing it to original space and passing it to M
    s_j = S(I, i_j) # compute the similarity score between I and i_j using S
    S_list.append(s_j) # append s_j to S_list

  index_list = argsort(S_list)[::-1] # sort the indices of S_list in descending order

  m_old = m # store the old mean vector
  m = sum(w[j] * E_list[index_list[j]] for j in range(lambda)) # update the mean vector by weighted average of the best candidate solutions

  z_w = sum(w[j] * Z_list[index_list[j]] for j in range(lambda)) # compute a weighted average of the best random vectors

  e_s = (1 - c_s) * e_s + sqrt(c_s * (2 - c_s) * mu_eff) * z_w # update the evolution path for step size adaptation

  sigma = sigma * exp(c_s / d_s * (norm(e_s) / norm(normal(0, k)) - 1)) # update the step size by exponential smoothing

  e_c = (1 - c_c) * e_c + sqrt(c_c * (2 - c_c) * mu_eff) * (m - m_old) / sigma # update the evolution path for covariance matrix adaptation

  C = (1 - c_1 - c_mu) * C # update the covariance matrix by decay
  C = C + c_1 * outer(e_c, e_c) # update the covariance matrix by rank-one update
  for j in range(lambda):
    C = C + c_mu * w[j] * outer(Z_list[index_list[j]], Z_list[index_list[j]]) # update the covariance matrix by rank-mu update

E = m # get the optimal solution as the mean vector of CMA-ES

# Return E
return E
```