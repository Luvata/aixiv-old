---
title: 2305.10319v2 Automatic Photo Orientation Detection with Convolutional Neural Networks
date: 2023-05-11
---

# [Automatic Photo Orientation Detection with Convolutional Neural Networks](http://arxiv.org/abs/2305.10319v2)

authors: Ujash Joshi, Michael Guerzhoy


## What, Why and How

[1]: https://arxiv.org/pdf/2305.10319v2.pdf "Automatic Photo Orientation Detection with Convolutional ... - arXiv.org"
[2]: https://arxiv.org/abs/2305.10319 "[2305.10319] Automatic Photo Orientation Detection with Convolutional ..."
[3]: https://arxiv-export2.library.cornell.edu/abs/2302.10319v2 "[2302.10319v2] Differentiable Bootstrap Particle Filters for Regime ..."

Here is a summary of the paper[^1^][1]:

- **What**: The paper applies convolutional neural networks (CNN) to the problem of image orientation detection, which is the task of determining the correct orientation (from 0, 90, 180, and 270 degrees) of a consumer photo. The paper also uses Guided Backpropagation to visualize and explain how the CNN detects photo orientation and what mistakes it makes.
- **Why**: The paper aims to improve on the published state of the art in terms of the performance on one of the standard datasets, and to test the system on a more difficult large dataset of consumer photos. The paper also seeks to gain insights into the inner workings of the CNN and its decision process. The problem is especially important for digitizing analog photographs.
- **How**: The paper modifies the VGG-16 architecture, a common image classification network, to classify input images into four classes: 0, 90, 180, or 270 degrees. The paper trains the classifier on large datasets of photos, such as the Corel stock photo dataset and the SUN-497 database. The paper applies Guided Backpropagation, a technique that highlights the most salient features in an image for a given class, to visualize what the classifier is doing and to explain its mistakes.

## Main Contributions

The paper claims to make the following contributions:

- It applies CNN to the problem of image orientation detection and substantially improves on the published state of the art in terms of the performance on one of the standard datasets.
- It tests the system on a more difficult large dataset of consumer photos that it collected and shows that it performs well on it.
- It uses Guided Backpropagation to obtain insights into how the CNN detects photo orientation and to explain its mistakes. It also provides examples of images where the CNN fails and discusses possible reasons for its failure.

## Method Summary

[1]: https://arxiv.org/pdf/2305.10319v2.pdf "Automatic Photo Orientation Detection with Convolutional ... - arXiv.org"
[2]: https://arxiv.org/abs/2305.10319 "[2305.10319] Automatic Photo Orientation Detection with Convolutional ..."
[3]: https://arxiv-export2.library.cornell.edu/abs/2302.10319v2 "[2302.10319v2] Differentiable Bootstrap Particle Filters for Regime ..."

Here is a summary of the method section of the paper[^1^][1]:

- The paper modifies the VGG-16 architecture, a common image classification network, to classify input images into four classes: 0, 90, 180, or 270 degrees. The paper removes the last three fully connected layers of VGG-16 and replaces them with a single fully connected layer with four output units and a softmax activation function. The paper also resizes the input images to 224x224 pixels and normalizes them by subtracting the mean RGB value computed on the training set.
- The paper trains the classifier on large datasets of photos, such as the Corel stock photo dataset and the SUN-497 database. The paper uses stochastic gradient descent with momentum to optimize the cross-entropy loss function. The paper also uses data augmentation techniques such as random cropping, flipping, and rotating to increase the diversity of the training data and prevent overfitting. The paper also applies dropout and L2 regularization to reduce overfitting.
- The paper applies Guided Backpropagation, a technique that highlights the most salient features in an image for a given class, to visualize what the classifier is doing and to explain its mistakes. The paper computes the Guided Backpropagation maps for each input image and each output class, and displays them as heatmaps overlaid on the original image. The paper also provides examples of images where the classifier fails and discusses possible reasons for its failure.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Import VGG-16 model and modify it
from keras.applications import VGG16
model = VGG16(weights='imagenet', include_top=False)
model.add(Dense(4, activation='softmax'))

# Resize and normalize input images
images = resize(images, (224, 224))
images = images - mean_rgb

# Train the model on large datasets of photos with data augmentation
from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(rotation_range=360, horizontal_flip=True, vertical_flip=True)
model.compile(optimizer='sgd', loss='categorical_crossentropy')
model.fit_generator(datagen.flow(images, labels), epochs=50)

# Apply Guided Backpropagation to visualize and explain the model
from guided_backprop import GuidedBackprop
gb = GuidedBackprop(model)
for image in images:
  for class in [0, 90, 180, 270]:
    # Compute and display the Guided Backpropagation map for each class
    gb_map = gb.compute(image, class)
    display(overlay(gb_map, image))
    # Check if the model makes a mistake and discuss possible reasons
    if model.predict(image) != class:
      print("The model failed to classify this image correctly.")
      print("Possible reasons: ...")
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Import VGG-16 model and modify it
from keras.applications import VGG16
from keras.models import Model
from keras.layers import Dense, Flatten

# Load the pretrained VGG-16 model without the top layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add a flatten layer and a dense layer with four output units and softmax activation
x = Flatten()(base_model.output)
x = Dense(4, activation='softmax')(x)

# Create a new model with the modified architecture
model = Model(inputs=base_model.input, outputs=x)

# Freeze the weights of the base model
for layer in base_model.layers:
  layer.trainable = False

# Resize and normalize input images
from PIL import Image
import numpy as np

# Define a function to resize an image to 224x224 pixels
def resize_image(image):
  return image.resize((224, 224))

# Define a function to normalize an image by subtracting the mean RGB value
def normalize_image(image):
  # Convert the image to a numpy array
  image = np.array(image)
  # Compute the mean RGB value on the training set
  mean_rgb = np.array([123.68, 116.779, 103.939])
  # Subtract the mean RGB value from each pixel
  image = image - mean_rgb
  # Return the normalized image
  return image

# Apply the resize and normalize functions to each image in the dataset
images = [resize_image(image) for image in images]
images = [normalize_image(image) for image in images]

# Train the model on large datasets of photos with data augmentation
from keras.preprocessing.image import ImageDataGenerator

# Define an image data generator with rotation, flipping, and cropping options
datagen = ImageDataGenerator(rotation_range=360, horizontal_flip=True, vertical_flip=True, width_shift_range=0.1, height_shift_range=0.1)

# Compile the model with stochastic gradient descent optimizer and categorical cross-entropy loss function
model.compile(optimizer='sgd', loss='categorical_crossentropy')

# Fit the model on the augmented data generator for 50 epochs
model.fit_generator(datagen.flow(images, labels), epochs=50)

# Apply Guided Backpropagation to visualize and explain the model
from guided_backprop import GuidedBackprop

# Define a function to overlay a heatmap on an image
def overlay(heatmap, image):
  # Convert the heatmap to RGB format
  heatmap = np.uint8(255 * heatmap)
  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
  # Convert the image to RGB format
  image = np.uint8(255 * image)
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  # Overlay the heatmap on the image with some transparency
  overlayed = cv2.addWeighted(heatmap, 0.6, image, 0.4, 0)
  # Return the overlayed image
  return overlayed

# Create a GuidedBackprop object with the model
gb = GuidedBackprop(model)

# Loop over each image in the dataset
for image in images:
  # Loop over each class in [0, 90, 180, 270]
  for class in [0, 90, 180, 270]:
    # Compute and display the Guided Backpropagation map for each class
    gb_map = gb.compute(image, class)
    display(overlay(gb_map, image))
    # Check if the model makes a mistake and discuss possible reasons
    if model.predict(image) != class:
      print("The model failed to classify this image correctly.")
      print("Possible reasons: ...")
```