---
title: 2302.05637v2 Dual Relation Knowledge Distillation for Object Detection
date: 2023-02-06
---

# [Dual Relation Knowledge Distillation for Object Detection](http://arxiv.org/abs/2302.05637v2)

authors: Zhenliang Ni, Fukui Yang, Shengzhao Wen, Gang Zhang


## What, Why and How

[1]: https://arxiv.org/pdf/2302.05637v2.pdf "arXiv:2302.05637v2 [cs.CV] 1 Jun 2023"
[2]: https://arxiv.org/abs/2302.05637 "Dual Relation Knowledge Distillation for Object Detection"
[3]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2302.05637v2 "[2302.05637v2] Dual Relation Knowledge Distillation for Object Detection"

Here is a summary of the paper[^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a new method for knowledge distillation for object detection, called dual relation knowledge distillation (DRKD), which consists of pixel-wise relation distillation and instance-wise relation distillation.
- **Why**: The paper aims to solve two challenges in applying knowledge distillation to detection tasks: the imbalance between foreground and background features, and the lack of feature representation for small objects.
- **How**: The paper uses graph convolution to capture the global pixel relation between features, and distills this relation to the student detector. The paper also calculates the similarity of different instances to obtain a relation matrix, and filters out irrelevant relations using a relation filter module. The paper evaluates the proposed method on COCO 2017 dataset using both one-stage and two-stage detectors, and achieves state-of-the-art performance.

## Main Contributions

The paper claims the following contributions:

- It proposes a novel dual relation knowledge distillation method for object detection, which distills both pixel-wise and instance-wise relations from the teacher to the student detector.
- It designs a relation filter module to select valuable instance relations for distillation, which can improve the performance of small objects and reduce the computational cost.
- It demonstrates the effectiveness and generality of the proposed method on both one-stage and two-stage detectors, and achieves state-of-the-art results on COCO 2017 dataset.

## Method Summary

The method section of the paper can be summarized as follows:

- The paper introduces the problem formulation of knowledge distillation for object detection, and defines the notation and terminology used in the paper.
- The paper presents the pixel-wise relation distillation module, which embeds the pixel-wise features of the teacher and the student detectors into a graph space, and applies graph convolution to capture the global pixel relation. The paper defines a pixel-wise relation loss to measure the discrepancy between the teacher and the student pixel relations, and distills this relation to the student detector.
- The paper presents the instance-wise relation distillation module, which calculates the similarity of different instances (bounding boxes and their features) in the teacher and the student detectors, and obtains a relation matrix for each detector. The paper defines an instance-wise relation loss to measure the difference between the teacher and the student relation matrices, and distills this relation to the student detector.
- The paper introduces a relation filter module, which filters out irrelevant or noisy instance relations based on their confidence scores and feature distances. The paper shows that this module can improve the performance of small objects and reduce the computational cost of distillation.
- The paper summarizes the overall framework of the proposed dual relation knowledge distillation method, and discusses some implementation details and hyperparameters.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: teacher detector T, student detector S, image I
# Output: distillation loss L

# Pixel-wise relation distillation
F_T = T.extract_features(I) # extract pixel-wise features from teacher detector
F_S = S.extract_features(I) # extract pixel-wise features from student detector
G_T = graph_convolution(F_T) # apply graph convolution to teacher features
G_S = graph_convolution(F_S) # apply graph convolution to student features
L_P = pixel_relation_loss(G_T, G_S) # compute pixel-wise relation loss

# Instance-wise relation distillation
B_T, C_T = T.predict_boxes(I) # predict bounding boxes and confidence scores from teacher detector
B_S, C_S = S.predict_boxes(I) # predict bounding boxes and confidence scores from student detector
R_T = calculate_relation_matrix(B_T, C_T, F_T) # calculate relation matrix for teacher detector
R_S = calculate_relation_matrix(B_S, C_S, F_S) # calculate relation matrix for student detector
R_T, R_S = relation_filter(R_T, R_S, C_T, C_S) # filter out irrelevant instance relations
L_I = instance_relation_loss(R_T, R_S) # compute instance-wise relation loss

# Overall distillation loss
L = L_P + L_I # combine pixel-wise and instance-wise relation losses
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: teacher detector T, student detector S, image I
# Output: distillation loss L

# Pixel-wise relation distillation
F_T = T.extract_features(I) # extract pixel-wise features from teacher detector
F_S = S.extract_features(I) # extract pixel-wise features from student detector
F_T = F_T.reshape(-1, C) # reshape teacher features to N x C matrix, where N is the number of pixels and C is the feature dimension
F_S = F_S.reshape(-1, C) # reshape student features to N x C matrix
A_T = F_T @ F_T.T # compute teacher adjacency matrix by matrix multiplication
A_S = F_S @ F_S.T # compute student adjacency matrix by matrix multiplication
A_T = softmax(A_T / sqrt(C)) # apply softmax and scaling to teacher adjacency matrix
A_S = softmax(A_S / sqrt(C)) # apply softmax and scaling to student adjacency matrix
G_T = A_T @ F_T # apply graph convolution to teacher features
G_S = A_S @ F_S # apply graph convolution to student features
L_P = mean_squared_error(G_T, G_S) # compute pixel-wise relation loss as the mean squared error between teacher and student pixel relations

# Instance-wise relation distillation
B_T, C_T = T.predict_boxes(I) # predict bounding boxes and confidence scores from teacher detector
B_S, C_S = S.predict_boxes(I) # predict bounding boxes and confidence scores from student detector
F_T = T.roi_pooling(F_T, B_T) # apply region of interest pooling to teacher features based on teacher bounding boxes
F_S = S.roi_pooling(F_S, B_S) # apply region of interest pooling to student features based on student bounding boxes
R_T = cosine_similarity(F_T) # calculate relation matrix for teacher detector as the cosine similarity between instance features
R_S = cosine_similarity(F_S) # calculate relation matrix for student detector as the cosine similarity between instance features
R_T, R_S = relation_filter(R_T, R_S, C_T, C_S) # filter out irrelevant instance relations based on confidence scores and feature distances
L_I = mean_squared_error(R_T, R_S) # compute instance-wise relation loss as the mean squared error between teacher and student relation matrices

# Overall distillation loss
L = L_P + L_I # combine pixel-wise and instance-wise relation losses

# Relation filter module
def relation_filter(R_T, R_S, C_T, C_S):
  # Input: relation matrices R_T and R_S for teacher and student detectors,
  # confidence scores C_T and C_S for teacher and student detectors
  # Output: filtered relation matrices R_T and R_S
  
  T = threshold(C_T) # determine a threshold for confidence scores based on teacher detector
  M_T = C_T > T # create a mask for teacher instances with high confidence scores
  M_S = C_S > T # create a mask for student instances with high confidence scores
  
  D_T = euclidean_distance(F_T) # calculate feature distance matrix for teacher instances
  D_S = euclidean_distance(F_S) # calculate feature distance matrix for student instances
  
  R_T[M_T == False] = 0 # set low-confidence teacher relations to zero
  R_S[M_S == False] = 0 # set low-confidence student relations to zero
  
  R_T[D_T > alpha] = 0 # set large-distance teacher relations to zero, where alpha is a hyperparameter
  R_S[D_S > alpha] = 0 # set large-distance student relations to zero
  
  return R_T, R_S

```