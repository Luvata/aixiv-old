---
title: 2306.16052v1 SVNR  Spatially-variant Noise Removal with Denoising Diffusion
date: 2023-06-17
---

# [SVNR: Spatially-variant Noise Removal with Denoising Diffusion](http://arxiv.org/abs/2306.16052v1)

authors: Naama Pearl, Yaron Brodsky, Dana Berman, Assaf Zomet, Alex Rav Acha, Daniel Cohen-Or, Dani Lischinski


## What, Why and How

[1]: https://arxiv.org/abs/2306.16052 "SVNR: Spatially-variant Noise Removal with Denoising Diffusion"
[2]: http://export.arxiv.org/abs/2306.16052 "[2306.16052] SVNR: Spatially-variant Noise Removal with Denoising Diffusion"
[3]: https://arxiv.org/pdf/2106.16052v1 "arXiv.org"

Here is a summary of the paper:

```
What: The paper presents SVNR, a novel formulation of denoising diffusion that assumes a more realistic, spatially-variant noise model for single image denoising.

Why: The paper aims to overcome the limitations of existing denoising diffusion models that are based on additive white Gaussian noise, which is unlike noise in real-world images.

How: The paper adapts the diffusion process to allow each pixel to have its own time embedding, and proposes training and inference schemes that support spatially-varying time maps. The paper also accounts for the correlation between the condition image and the samples along the modified diffusion process.
```

Source: [^1^][1]

## Main Contributions

[1]: https://arxiv.org/abs/2306.16052 "SVNR: Spatially-variant Noise Removal with Denoising Diffusion"
[2]: https://arxiv.org/pdf/2306.16098v1.pdf "arXiv:2306.16098v1 [eess.IV] 28 Jun 2023"
[3]: http://export.arxiv.org/abs/2303.16052v1 "[2303.16052v1] Transport Densities and Congested Optimal Transport in ..."

The paper claims to make the following contributions:

- A novel formulation of denoising diffusion that assumes a more realistic, spatially-variant noise model for single image denoising.
- An adaptation of the diffusion process to allow each pixel to have its own time embedding, and a proposal of training and inference schemes that support spatially-varying time maps.
- An accounting for the correlation between the condition image and the samples along the modified diffusion process.
- An experimental demonstration of the advantages of the proposed approach over a strong diffusion model baseline, as well as over a state-of-the-art single image denoising method.

Source: [^1^][1]

## Method Summary

[1]: https://arxiv.org/abs/2306.16052 "SVNR: Spatially-variant Noise Removal with Denoising Diffusion"
[2]: https://arxiv.org/abs/2106.16052v1 "[2106.16052v1] Backward Euler method for the equations of motion ..."
[3]: http://export.arxiv.org/abs/2306.16052 "[2306.16052] SVNR: Spatially-variant Noise Removal with Denoising Diffusion"

Here is a summary of the method section of the paper:

```
The method section of the paper consists of four subsections: 3.1 Denoising Diffusion, 3.2 Spatially-Variant Noise Model, 3.3 Spatially-Variant Denoising Diffusion, and 3.4 Training and Inference.

In 3.1, the paper reviews the basics of denoising diffusion models, which are generative models that learn to transform a noise distribution into a data distribution via a Markov chain of denoising steps.

In 3.2, the paper introduces a spatially-variant noise model that assumes that each pixel in the noisy image is corrupted by an additive Gaussian noise with a different variance, depending on the local image statistics.

In 3.3, the paper proposes SVNR, a novel formulation of denoising diffusion that incorporates the spatially-variant noise model. SVNR modifies the diffusion process to allow each pixel to have its own time embedding, which determines how much noise is added or removed at each step. SVNR also conditions the diffusion process on the noisy input image, and accounts for the correlation between the condition image and the samples along the process.

In 3.4, the paper describes the training and inference schemes for SVNR. The paper uses a U-Net architecture as the denoising model, and trains it using a variational lower bound on the log-likelihood of the data distribution. The paper also introduces a spatially-varying time map that encodes the optimal time embedding for each pixel, and uses it to guide the inference process.
```

Source: [^1^][1]

## Pseudo Code - High level

[1]: https://arxiv.org/abs/2306.16052 "SVNR: Spatially-variant Noise Removal with Denoising Diffusion"
[2]: https://arxiv.org/pdf/2106.16052v1.pdf "arXiv.org"
[3]: http://export.arxiv.org/abs/2303.16052v1 "[2303.16052v1] Transport Densities and Congested Optimal Transport in ..."

Here is a high-level pseudo code for the paper:

```
# Input: a noisy image y, a denoising model f, a spatially-varying time map T
# Output: a denoised image x

# Initialize x as y
x = y

# Loop over the diffusion steps from t = 1 to T
for t in range(1, T):

  # Compute the noise level for each pixel using T
  sigma = sqrt(T - t) / sqrt(T)

  # Add Gaussian noise to x with pixel-wise variance sigma^2
  x = x + sigma * randn(size(x))

  # Compute the denoising prediction for x using f conditioned on y and t
  x_hat = f(x, y, t)

  # Update x by subtracting a fraction of the prediction error
  x = x - beta * (x - x_hat)

# Return the final x as the denoised image
return x
```

Source: [^1^][1]


## Pseudo Code - Detail

[1]: https://arxiv.org/pdf/2006.16052v1.pdf "ElecSus arXiv:2006.16052v1 [physics.atom-ph] 26 Jun 2020"
[2]: https://arxiv.org/pdf/2106.16052v1.pdf "arXiv.org"
[3]: https://arxiv.org/abs/2006.16052v1 "[2006.16052v1] Absorption spectroscopy and Stokes ... - arXiv.org"

Here is a detailed pseudo code to implement the paper:

```
# Define the hyperparameters
num_steps = 1000 # number of diffusion steps
beta = 0.01 # fraction of prediction error to subtract
num_channels = 64 # number of channels in the U-Net
num_layers = 4 # number of layers in the U-Net
learning_rate = 0.0001 # learning rate for the optimizer

# Define the denoising model f as a U-Net with skip connections
def f(x, y, t):

  # Encode x, y and t into a single input tensor
  input = concat(x, y, t)

  # Initialize a list of skip tensors
  skips = []

  # Downsample the input tensor using convolutional layers
  for i in range(num_layers):

    # Apply a convolutional layer with num_channels and a kernel size of 3
    input = conv(input, num_channels, 3)

    # Apply a batch normalization layer
    input = batch_norm(input)

    # Apply a leaky ReLU activation function
    input = leaky_relu(input)

    # Append the input tensor to the skip list
    skips.append(input)

    # Apply a strided convolutional layer with num_channels and a kernel size of 2 and a stride of 2
    input = conv(input, num_channels, 2, stride=2)

  # Upsample the input tensor using transposed convolutional layers
  for i in range(num_layers):

    # Apply a transposed convolutional layer with num_channels and a kernel size of 2 and a stride of 2
    input = conv_transpose(input, num_channels, 2, stride=2)

    # Apply a batch normalization layer
    input = batch_norm(input)

    # Apply a leaky ReLU activation function
    input = leaky_relu(input)

    # Concatenate the input tensor with the corresponding skip tensor from the skip list
    input = concat(input, skips.pop())

    # Apply a convolutional layer with num_channels and a kernel size of 3
    input = conv(input, num_channels, 3)

  # Apply a final convolutional layer with 3 channels and a kernel size of 1 to get the output tensor
  output = conv(input, 3, 1)

  # Return the output tensor as the denoising prediction
  return output

# Define the loss function as the negative log-likelihood of the data distribution
def loss(x, y):

  # Initialize the loss as zero
  loss = 0

  # Loop over the diffusion steps from t = T to t = 1
  for t in range(T, 0, -1):

    # Compute the noise level for each pixel using T
    sigma = sqrt(T - t) / sqrt(T)

    # Compute the denoising prediction for x using f conditioned on y and t
    x_hat = f(x, y, t)

    # Compute the negative log-likelihood of x given x_hat and sigma
    nll = -log_normal(x | x_hat, sigma)

    # Add the negative log-likelihood to the loss
    loss += nll

    # Subtract a fraction of the prediction error from x
    x = x - beta * (x - x_hat)

    # Add Gaussian noise to x with pixel-wise variance sigma^2
    x = x + sigma * randn(size(x))

  # Return the loss divided by T as the average loss per step
  return loss / T

# Define an optimizer as Adam with learning rate learning_rate
optimizer = Adam(learning_rate)

# Define a training loop for N epochs over a dataset of noisy-clean image pairs {y_i, x_i}
for epoch in range(N):

  # Loop over the batches of image pairs in the dataset
  for y_batch, x_batch in dataset:

    # Compute the gradients of the loss function with respect to f's parameters using backpropagation
    gradients = grad(loss(f, y_batch, x_batch))

    # Update f's parameters using the optimizer and the gradients
    optimizer.update(f.parameters, gradients)
```