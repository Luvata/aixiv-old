---
title: 1810.08363v1 Generative Low-Shot Network Expansion
date: 2018-10-09
---

# [Generative Low-Shot Network Expansion](http://arxiv.org/abs/1810.08363v1)

authors: Adi Hayat, Mark Kliger, Shachar Fleishman, Daniel Cohen-Or


## What, Why and How

[1]: https://arxiv.org/abs/1810.08363 "[1810.08363] Generative Low-Shot Network Expansion - arXiv.org"
[2]: https://arxiv.org/pdf/1810.08363v1.pdf "Generative Low-Shot Network Expansion - arXiv.org"
[3]: http://export.arxiv.org/abs/2110.08363v1 "[2110.08363v1] Spatio-temporal extreme event modeling of terror ..."

Here is a summary of the paper[^1^][1]:

- **What**: The paper introduces a learning framework that enables expanding a pre-trained deep network to classify novel classes with a small number of examples, without re-training or affecting the performance on the base classes.
- **Why**: The paper addresses the problem of low-shot network expansion learning, which is challenging for conventional deep learning classifiers that are static and require re-training to learn new classes.
- **How**: The paper presents a hard distillation method that augments the base network with additional weights for the novel classes, while keeping the base network weights unchanged. The paper also shows how to use a compact generative model of the base classes training data to reduce the memory footprint of the expansion. The paper evaluates the proposed method on several datasets and shows its advantages over existing methods.

## Main Contributions

[1]: https://arxiv.org/abs/1810.08363 "[1810.08363] Generative Low-Shot Network Expansion - arXiv.org"
[2]: https://arxiv.org/pdf/1810.08363v1.pdf "Generative Low-Shot Network Expansion - arXiv.org"
[3]: http://export.arxiv.org/abs/2110.08363v1 "[2110.08363v1] Spatio-temporal extreme event modeling of terror ..."

The paper claims the following contributions[^1^][1]:

- A novel learning framework for low-shot network expansion that enables adding new classes to a pre-trained network without re-training or affecting the base classes performance.
- A simple and effective hard distillation method that augments the base network with additional weights for the novel classes, while keeping the base network weights fixed.
- A compact generative model of the base classes training data that reduces the memory footprint of the expansion and allows learning from synthetic data.
- A comprehensive evaluation of the proposed method on several datasets and tasks, showing its superiority over existing methods and its ability to handle various low-shot scenarios.

## Method Summary

[1]: https://arxiv.org/abs/1810.08363 "[1810.08363] Generative Low-Shot Network Expansion - arXiv.org"
[2]: https://arxiv.org/pdf/1810.08363v1.pdf "Generative Low-Shot Network Expansion - arXiv.org"
[3]: http://export.arxiv.org/abs/2110.08363v1 "[2110.08363v1] Spatio-temporal extreme event modeling of terror ..."

Here is a summary of the method section of the paper[^1^][2]:

- The paper proposes a learning framework for low-shot network expansion that consists of two main components: a hard distillation method and a generative model of the base classes training data.
- The hard distillation method augments the base network with additional weights for the novel classes, while keeping the base network weights fixed. The additional weights are trained by minimizing a distillation loss that forces them to mimic the base network outputs on the novel classes data. The paper shows that this method can effectively learn novel classes with a small number of examples, without affecting the base classes performance or requiring re-training.
- The generative model of the base classes training data is a conditional variational autoencoder (CVAE) that learns to generate synthetic data for each base class given a latent code. The paper shows that this model can reduce the memory footprint of the expansion by replacing the base classes training data with a compact representation. The paper also shows that the synthetic data can be used to improve the hard distillation method by augmenting the novel classes data with generated samples from the base classes.

## Pseudo Code - High level

Here is the high-level pseudo code for this paper:

```python
# Input: a base network f_b with C_b base classes, a novel classes dataset D_n with C_n novel classes and N_n examples per class, a base classes training dataset D_b
# Output: an expanded network f_e with C_b + C_n classes

# Train a CVAE to generate synthetic data for each base class
CVAE = train_CVAE(D_b)

# Augment the base network with additional weights for the novel classes
f_e = augment_network(f_b, C_n)

# Train the additional weights by hard distillation
for epoch in range(num_epochs):
  # Sample a batch of novel classes data
  X_n, y_n = sample_batch(D_n)
  # Sample a batch of synthetic base classes data
  X_b, y_b = sample_batch(CVAE)
  # Concatenate the two batches
  X = concatenate(X_n, X_b)
  y = concatenate(y_n, y_b)
  # Compute the base network outputs on the concatenated batch
  z = f_b(X)
  # Compute the distillation loss between the base network outputs and the expanded network outputs on the novel classes data
  L_distill = distillation_loss(z[:N_n], f_e(X[:N_n]))
  # Compute the cross-entropy loss between the expanded network outputs and the labels on the synthetic base classes data
  L_ce = cross_entropy_loss(f_e(X[N_n:]), y[N_n:])
  # Compute the total loss as a weighted sum of the two losses
  L_total = alpha * L_distill + (1 - alpha) * L_ce
  # Update the additional weights by gradient descent
  update_weights(f_e, L_total)
```

## Pseudo Code - Detail

Here is the detailed pseudo code to implement this paper:

```python
# Input: a base network f_b with C_b base classes, a novel classes dataset D_n with C_n novel classes and N_n examples per class, a base classes training dataset D_b
# Output: an expanded network f_e with C_b + C_n classes

# Define the CVAE architecture
CVAE_encoder = ConvNet(input_shape, latent_dim) # a convolutional network that encodes the input image into a latent code
CVAE_decoder = DeconvNet(latent_dim, C_b) # a deconvolutional network that decodes the latent code into an output image
CVAE = CVAE_encoder + CVAE_decoder # a conditional variational autoencoder that takes an input image and a class label and outputs a reconstructed image

# Train the CVAE to generate synthetic data for each base class
for epoch in range(num_epochs):
  # Sample a batch of base classes data
  X_b, y_b = sample_batch(D_b)
  # Compute the CVAE outputs on the batch
  X_hat = CVAE(X_b, y_b)
  # Compute the reconstruction loss between the input and output images
  L_recon = reconstruction_loss(X_b, X_hat)
  # Compute the KL-divergence loss between the latent code distribution and the prior distribution
  L_kl = kl_divergence_loss(CVAE_encoder(X_b))
  # Compute the total loss as a weighted sum of the two losses
  L_total = beta * L_recon + (1 - beta) * L_kl
  # Update the CVAE parameters by gradient descent
  update_parameters(CVAE, L_total)

# Augment the base network with additional weights for the novel classes
f_e = copy_network(f_b) # make a copy of the base network
f_e.add_layer(Dense(C_n)) # add a new layer with C_n units for the novel classes
f_e.add_layer(Softmax()) # add a softmax layer to normalize the outputs

# Train the additional weights by hard distillation
for epoch in range(num_epochs):
  # Sample a batch of novel classes data
  X_n, y_n = sample_batch(D_n)
  # Sample a batch of synthetic base classes data
  X_b, y_b = sample_batch(CVAE)
  # Concatenate the two batches
  X = concatenate(X_n, X_b)
  y = concatenate(y_n, y_b)
  # Compute the base network outputs on the concatenated batch
  z = f_b(X)
  # Compute the distillation loss between the base network outputs and the expanded network outputs on the novel classes data
  L_distill = distillation_loss(z[:N_n], f_e(X[:N_n]))
  # Compute the cross-entropy loss between the expanded network outputs and the labels on the synthetic base classes data
  L_ce = cross_entropy_loss(f_e(X[N_n:]), y[N_n:])
  # Compute the total loss as a weighted sum of the two losses
  L_total = alpha * L_distill + (1 - alpha) * L_ce
  # Update only the additional weights by gradient descent, keeping the base network weights fixed
  update_weights(f_e[C_b:], L_total)
```