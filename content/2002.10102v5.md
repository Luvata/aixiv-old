---
title: 2002.10102v5 GANHopper  Multi-Hop GAN for Unsupervised Image-to-Image Translation
date: 2020-02-11
---

# [GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation](http://arxiv.org/abs/2002.10102v5)

authors: Wallace Lira, Johannes Merz, Daniel Ritchie, Daniel Cohen-Or, Hao Zhang


## What, Why and How

[1]: https://arxiv.org/pdf/2002.10102.pdf "arXiv:2002.10102v5 [cs.CV] 29 Jul 2020"
[2]: https://arxiv.org/abs/2002.10102 "GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation"
[3]: https://www.researcher-app.com/paper/5543668 "GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation"

Here is a summary of the paper:

- **What**: The paper introduces GANHopper, an unsupervised image-to-image translation network that transforms images gradually between two domains, through multiple hops[^1^][1] [^2^][2].
- **Why**: The paper aims to address the limitations of previous methods that perform direct translations, which can fail to produce the necessary geometry variations or alter non-domain-specific features such as general color schemes[^1^][1].
- **How**: The paper proposes to steer the translation by requiring the network to produce in-between images that resemble weighted hybrids between images from the input domains. The network is trained on unpaired images from the two domains only, without any in-between images. The paper introduces a new hybrid discriminator, which is trained to classify the intermediate images produced by the generator as weighted hybrids, with weights based on a predetermined hop count. The paper also adds a smoothness term to constrain the magnitude of each hop, further regularizing the translation[^1^][1].

## Main Contributions

[1]: https://arxiv.org/abs/2002.10102 "GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation"
[2]: https://arxiv.org/pdf/2002.10102 "arXiv:2002.10102v5 [cs.CV] 29 Jul 2020"
[3]: https://dl.acm.org/doi/10.1109/TMM.2020.3009500 "Toward Multi-Modal Conditioned Fashion Image Translation"

According to the paper[^1^][1], the main contributions are:

- **A novel unsupervised image-to-image translation network that transforms images gradually between two domains, through multiple hops, using a single generator along each direction.**
- **A new hybrid discriminator that is trained to classify the intermediate images produced by the generator as weighted hybrids, with weights based on a predetermined hop count.**
- **A smoothness term that constrains the magnitude of each hop, further regularizing the translation.**
- **Extensive experiments and comparisons that demonstrate the advantages of GANHopper over previous methods in terms of domain-specific image features and geometric variations while also preserving non-domain-specific features such as general color schemes.**

## Method Summary

[1]: https://www.researchgate.net/publication/346860414_GANHopper_Multi-hop_GAN_for_Unsupervised_Image-to-Image_Translation "GANHopper: Multi-hop GAN for Unsupervised Image-to-Image Translation ..."
[2]: https://www.sagepub.com/sites/default/files/upm-binaries/14649_Chapter5.pdf "The Method Chapter - SAGE Publications Inc"
[3]: https://www.scribbr.com/apa-style/methods-section/ "How to Write an APA Methods Section | With Examples - Scribbr"

Here is a summary of the method section of the paper:

- **The method section describes the proposed GANHopper network, which consists of two generators and two discriminators for each translation direction.**
- **The method section explains the loss functions used to train the network, which include the cycle-consistency loss, the adversarial loss, the hybrid discriminator loss, and the smoothness loss.**
- **The method section details the implementation details of the network, such as the network architecture, the hop count, the hop weights, and the training parameters.**
- **The method section also describes the datasets and evaluation metrics used to compare GANHopper with previous methods.**

## Pseudo Code - High level

[1]: https://arxiv.org/pdf/2002.10102.pdf "arXiv:2002.10102v5 [cs.CV] 29 Jul 2020"
[2]: https://github.com/wallacemplira/ganhopper "GitHub - wallacemplira/ganhopper"
[3]: https://paperswithcode.com/paper/ganhopper-multi-hop-gan-for-unsupervised "GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation"

Here is a possible high-level pseudo code for this paper:

- Define two generators G_AB and G_BA, and two discriminators D_A and D_B for each translation direction
- Define the hop count h_hops and the hop weights alpha
- Define the loss functions: cycle-consistency loss L_cyc, adversarial loss L_adv, hybrid discriminator loss L_hyb, and smoothness loss L_smooth
- For each epoch:
  - For each batch of unpaired images X_A and X_B from domains A and B:
    - Initialize empty lists H_AB and H_BA for storing intermediate images
    - For i from 0 to h_hops:
      - Generate intermediate images X_AB_i = G_AB(X_A) and X_BA_i = G_BA(X_B) using the generators
      - Append X_AB_i and X_BA_i to H_AB and H_BA respectively
      - Compute the hybrid discriminator loss L_hyb_i for X_AB_i and X_BA_i using D_A and D_B with alpha[i] as the target label
      - Compute the smoothness loss L_smooth_i for X_AB_i and X_BA_i by measuring the difference between X_AB_i and X_AB_(i-1), and between X_BA_i and X_BA_(i-1)
    - Compute the cycle-consistency loss L_cyc for X_A and X_B by applying G_BA(G_AB(X_A)) and G_AB(G_BA(X_B))
    - Compute the adversarial loss L_adv for X_A and X_B by applying D_A(G_AB(X_A)) and D_B(G_BA(X_B))
    - Compute the total generator loss L_G as the weighted sum of L_cyc, L_adv, L_hyb, and L_smooth
    - Compute the total discriminator loss L_D as the weighted sum of L_adv and L_hyb
    - Update the parameters of G_AB, G_BA, D_A, and D_B using gradient descent with L_G and L_D respectively
- Save the trained models and intermediate images

## Pseudo Code - Detail

[1]: https://arxiv.org/pdf/2002.10102.pdf "arXiv:2002.10102v5 [cs.CV] 29 Jul 2020"
[2]: https://arxiv.org/pdf/2002.10102v2.pdf "GANHOPPER: Multi-Hop GAN for Unsupervised Image-to-Image Translation"
[3]: https://github.com/wallacemplira/ganhopper "GitHub - wallacemplira/ganhopper"

Here is a possible detailed pseudo code for this paper:

- Import tensorflow, numpy, scipy, imageio, and other libraries
- Define the network architecture of the generators and discriminators using convolutional, deconvolutional, residual, and normalization layers
- Define the hyperparameters of the network, such as learning rate, batch size, image size, hop count, hop weights, and loss weights
- Define the loss functions using tensorflow operations, such as mean squared error, sigmoid cross entropy, absolute difference, and gradient penalty
- Define the optimizers using Adam optimizer with beta1 = 0.5 and beta2 = 0.999
- Load the datasets using imageio.imread and resize them to the desired image size
- Shuffle the datasets and split them into batches using numpy.random.permutation and numpy.split
- Initialize the tensorflow session and global variables
- For each epoch:
  - For each batch of unpaired images X_A and X_B from domains A and B:
    - Initialize empty lists H_AB and H_BA for storing intermediate images
    - For i from 0 to h_hops:
      - Generate intermediate images X_AB_i = G_AB(X_A) and X_BA_i = G_BA(X_B) using the generators
      - Append X_AB_i and X_BA_i to H_AB and H_BA respectively
      - Compute the hybrid discriminator loss L_hyb_i for X_AB_i and X_BA_i using D_A and D_B with alpha[i] as the target label
      - Compute the smoothness loss L_smooth_i for X_AB_i and X_BA_i by measuring the difference between X_AB_i and X_AB_(i-1), and between X_BA_i and X_BA_(i-1)
    - Compute the cycle-consistency loss L_cyc for X_A and X_B by applying G_BA(G_AB(X_A)) and G_AB(G_BA(X_B))
    - Compute the adversarial loss L_adv for X_A and X_B by applying D_A(G_AB(X_A)) and D_B(G_BA(X_B))
    - Compute the total generator loss L_G as the weighted sum of L_cyc, L_adv, L_hyb, and L_smooth
    - Compute the total discriminator loss L_D as the weighted sum of L_adv and L_hyb
    - Update the parameters of G_AB, G_BA, D_A, and D_B using gradient descent with L_G and L_D respectively
    - Print the current epoch, batch, and losses
  - Save the trained models and intermediate images using tensorflow.Saver.save and imageio.imwrite