---
title: 2306.00112v1 Additional Positive Enables Better Representation Learning for Medical Images
date: 2023-06-01
---

# [Additional Positive Enables Better Representation Learning for Medical Images](http://arxiv.org/abs/2306.00112v1)

authors: Dewen Zeng, Yawen Wu, Xinrong Hu, Xiaowei Xu, Jingtong Hu, Yiyu Shi


## What, Why and How

[1]: https://arxiv.org/pdf/2306.00112.pdf "arXiv:2306.00112v1 [cs.CV] 31 May 2023"
[2]: https://arxiv.org/abs/2306.00111 "[2306.00111] Broadband VLA Spectral Line Survey of a Sample ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.00112 "[2306.00112] Additional Positive Enables Better Representation Learning ..."

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper presents a new way to identify additional positive pairs for BYOL, a state-of-the-art self-supervised learning framework, to improve its representation learning ability for medical images.
- **Why**: The paper argues that conventional BYOL relies on only one positive pair generated by two augmented views of the same image, which limits the diversity and variations of the target features. The paper proposes to use information from different images with the same label as additional positive pairs, without using any label information.
- **How**: The paper uses TracIn, an instance-based and computationally efficient influence function, to estimate the similarity of samples in the mini-batch during training. For each image, the paper selects the most similar sample from other images as the additional positive and pulls their features together with BYOL loss. The paper evaluates the proposed method on two public medical datasets (i.e., ISIC 2019 and ChestX-ray) and shows that it can improve the classification performance compared to other competitive baselines in both semi-supervised and transfer learning settings.

## Main Contributions

[1]: https://arxiv.org/pdf/2306.00112.pdf "arXiv:2306.00112v1 [cs.CV] 31 May 2023"
[2]: https://arxiv.org/abs/2306.00111 "[2306.00111] Broadband VLA Spectral Line Survey of a Sample ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.00112 "[2306.00112] Additional Positive Enables Better Representation Learning ..."

According to the paper at [^1^][1], the main contributions are:

- The paper proposes a novel way to identify additional positive pairs for BYOL without using any label information, by leveraging TracIn, an instance-based and computationally efficient influence function.
- The paper extends TracIn to the self-supervised learning setting and proposes an efficient batch-wise per-sample gradient computation method to estimate the pairwise TracIn for representing the similarity of samples in the mini-batch during training.
- The paper evaluates the proposed method on two public medical datasets (i.e., ISIC 2019 and ChestX-ray) and demonstrates that it can improve the classification performance compared to other competitive baselines in both semi-supervised and transfer learning settings.

## Method Summary

[1]: https://arxiv.org/pdf/2306.00112.pdf "arXiv:2306.00112v1 [cs.CV] 31 May 2023"
[2]: https://arxiv.org/abs/2306.00111 "[2306.00111] Broadband VLA Spectral Line Survey of a Sample ... - arXiv.org"
[3]: http://export.arxiv.org/abs/2306.00112 "[2306.00112] Additional Positive Enables Better Representation Learning ..."

Here is a summary of the method section of the paper at [^1^][1]:

- The paper adopts the BYOL framework, which consists of two siamese neural networks: the online network and the target network. The online network consists of an encoder and a predictor, while the target network consists of an encoder and a projector. The online network is trained to predict the target network representation of the same image under a different augmented view.
- The paper proposes to use TracIn, an instance-based and computationally efficient influence function, to identify additional positive pairs for BYOL without using any label information. TracIn is a gradient-based method that reveals the impact of a training sample on a test sample in supervised learning. The paper extends TracIn to the self-supervised learning setting by treating each sample as both a training and a test sample.
- The paper proposes an efficient batch-wise per-sample gradient computation method to estimate the pairwise TracIn for representing the similarity of samples in the mini-batch during training. For each image, the paper selects the most similar sample from other images as the additional positive and pulls their features together with BYOL loss. The paper also introduces a temperature parameter to control the strength of pulling.
- The paper evaluates the proposed method on two public medical datasets (i.e., ISIC 2019 and ChestX-ray) and compares it with other competitive baselines in both semi-supervised and transfer learning settings. The paper uses standard data augmentation techniques such as random cropping, flipping, rotation, color jittering, and Gaussian blur. The paper also uses a momentum update rule for the target network and a cosine decay learning rate schedule.

## Pseudo Code

Here is a possible pseudo code to implement the paper:

```python
# Define the online network, which consists of an encoder and a predictor
online_encoder = Encoder()
online_predictor = Predictor()

# Define the target network, which consists of an encoder and a projector
target_encoder = Encoder()
target_projector = Projector()

# Initialize the target network with the same weights as the online network
target_encoder.load_state_dict(online_encoder.state_dict())
target_projector.load_state_dict(online_predictor.state_dict())

# Define the BYOL loss function, which is the mean squared error between the online prediction and the target projection
def byol_loss(online_pred, target_proj):
  return torch.mean((online_pred - target_proj) ** 2)

# Define the temperature parameter for additional positive pairs
tau = 0.1

# Define the optimizer for the online network
optimizer = torch.optim.Adam(online_encoder.parameters() + online_predictor.parameters(), lr=0.01)

# Define the momentum update rule for the target network
momentum = 0.99

# Define the cosine decay learning rate schedule
lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)

# Loop over the epochs
for epoch in range(epochs):

  # Loop over the mini-batches
  for batch in dataloader:

    # Get the images and labels from the batch
    images, labels = batch

    # Apply two different augmentations to each image
    images_1 = augment(images)
    images_2 = augment(images)

    # Forward pass the images through the online network
    online_feat_1 = online_encoder(images_1)
    online_feat_2 = online_encoder(images_2)
    online_pred_1 = online_predictor(online_feat_1)
    online_pred_2 = online_predictor(online_feat_2)

    # Forward pass the images through the target network
    with torch.no_grad():
      target_feat_1 = target_encoder(images_1)
      target_feat_2 = target_encoder(images_2)
      target_proj_1 = target_projector(target_feat_1)
      target_proj_2 = target_projector(target_feat_2)

    # Compute the BYOL loss for each positive pair
    loss_1 = byol_loss(online_pred_1, target_proj_2)
    loss_2 = byol_loss(online_pred_2, target_proj_1)

    # Compute the gradients of the online network with respect to each image
    grad_online_feat_1 = torch.autograd.grad(loss_1, online_feat_1)[0]
    grad_online_feat_2 = torch.autograd.grad(loss_2, online_feat_2)[0]

    # Compute the pairwise TracIn between each image and other images in the mini-batch
    tracin_matrix = torch.zeros(batch_size, batch_size)
    for i in range(batch_size):
      for j in range(batch_size):
        if i != j:
          tracin_matrix[i][j] = torch.dot(grad_online_feat_i[i], grad_online_feat_j[j])

    # Normalize the TracIn matrix by row-wise softmax with temperature tau
    tracin_matrix = torch.softmax(tracin_matrix / tau, dim=1)

    # For each image, find the most similar image from other images as the additional positive pair
    additional_pos_index = torch.argmax(tracin_matrix, dim=1)

    # Compute the BYOL loss for each additional positive pair
    loss_additional = 0
    for i in range(batch_size):
      j = additional_pos_index[i]
      loss_additional += byol_loss(online_pred_i[i], target_proj_j[j])

    # Compute the total loss as the average of all losses
    loss_total = (loss_1 + loss_2 + loss_additional) / (batch_size * 3)

    # Backward pass and update the online network parameters
    optimizer.zero_grad()
    loss_total.backward()
    optimizer.step()

    # Update the target network parameters with momentum update rule
    with torch.no_grad():
      for param_q, param_k in zip(online_encoder.parameters(), target_encoder.parameters()):
        param_k.data.copy_(momentum * param_k.data + (1 - momentum) * param_q.data)
      for param_q, param_k in zip(online_predictor.parameters(), target_projector.parameters()):
        param_k.data.copy_(momentum * param_k.data + (1 - momentum) * param_q.data)

  # Update the learning rate with cosine decay schedule
  lr_scheduler.step()
```