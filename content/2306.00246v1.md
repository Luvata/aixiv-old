---
title: 2306.00246v1 Fine-Grained Property Value Assessment using Probabilistic Disaggregation
date: 2023-06-01
---

# [Fine-Grained Property Value Assessment using Probabilistic Disaggregation](http://arxiv.org/abs/2306.00246v1)

authors: Cohen Archbold, Benjamin Brodie, Aram Ansary Ogholbake, Nathan Jacobs


## What, Why and How

[1]: https://arxiv.org/abs/2306.00246 "[2306.00246] Fine-Grained Property Value Assessment using Probabilistic ..."
[2]: https://arxiv.org/pdf/2306.00246.pdf "arXiv:2306.00246v1 [cs.CV] 31 May 2023"
[3]: http://export.arxiv.org/abs/2306.00246 "[2306.00246] Fine-Grained Property Value Assessment using Probabilistic ..."

Here is a summary of the paper:

- **What**: The paper proposes a method to estimate the distribution over property value at the pixel level from remote sensing imagery, using probabilistic disaggregation.
- **Why**: The paper aims to address the problem of estimating fine-grained property values for applications such as insurance and urban planning, where coarse-level labels are often available but not sufficient.
- **How**: The paper uses an analytic approach to derive the fine-level distributions from the coarse-level ones, assuming a linear relationship between pixel values and image features. The paper also introduces a region aggregation layer to train a convolutional neural network to learn the image features that contribute to property value. The paper evaluates the method on a real-world dataset of aerial imagery and property values from Hennepin County, Minnesota.

## Main Contributions

The contributions of this paper are:

- Providing the theoretical motivation for a probabilistic disaggregation method for fine-level estimation from coarse labels
- Formulating a method for probabilistic disaggregation and demonstrating its quantitative and qualitative value
- Showing how the method works on property value estimation from overhead imagery


## Method Summary

The method section of the paper consists of three parts:

- Probabilistic Disaggregation: The paper derives the fine-level distributions from the coarse-level ones, assuming a linear relationship between pixel values and image features. The paper also shows how to compute the expected value and variance of the fine-level distributions.
- Region Aggregation Layer: The paper introduces a region aggregation layer that takes the output of a convolutional neural network and aggregates it over spatial regions to match the coarse-level labels. The paper also explains how to train the network using a maximum likelihood loss function.
- Property Value Estimation: The paper applies the proposed method to the task of property value estimation from aerial imagery. The paper describes the dataset, the network architecture, and the evaluation metrics used in the experiments.

## Pseudo Code

Here is a possible pseudo code to implement this paper:

```python
# Import libraries
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

# Define constants
N = number of pixels in an image
M = number of regions in an image
K = number of features per pixel
L = number of features per region

# Define the linear model for pixel values
def pixel_model(x):
  # x: a tensor of shape (N, K) containing the pixel features
  # returns: a tensor of shape (N,) containing the pixel values
  w = a tensor of shape (K,) containing the model weights
  b = a scalar containing the model bias
  return x @ w + b

# Define the probabilistic disaggregation function
def disaggregate(y, s):
  # y: a tensor of shape (M,) containing the coarse-level labels
  # s: a tensor of shape (M, N) containing the region membership indicators
  # returns: a tensor of shape (N,) containing the fine-level distributions
  mu = pixel_model(x) # a tensor of shape (N,) containing the pixel means
  sigma = a positive scalar containing the pixel standard deviation
  alpha = s @ y / s.sum(dim=1) # a tensor of shape (N,) containing the region means
  beta = s.sum(dim=0) / sigma**2 # a tensor of shape (N,) containing the precision weights
  return torch.distributions.Normal(alpha + beta * (mu - alpha) / (1 + beta), sigma / torch.sqrt(1 + beta)) # a tensor of shape (N,) containing the fine-level distributions

# Define the region aggregation layer
class RegionAggregationLayer(nn.Module):
  def __init__(self, s):
    super().__init__()
    self.s = s # a tensor of shape (M, N) containing the region membership indicators
  
  def forward(self, x):
    # x: a tensor of shape (N, K) containing the pixel features
    # returns: a tensor of shape (M, L) containing the region features
    return self.s @ x # a simple matrix multiplication

# Define the convolutional neural network
class CNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(3, 16, 3, padding=1) # a convolutional layer with 16 filters of size 3x3 and padding 1
    self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # another convolutional layer with 32 filters of size 3x3 and padding 1
    self.pool = nn.MaxPool2d(2, 2) # a max pooling layer with kernel size 2x2 and stride 2x2
    self.fc1 = nn.Linear(32 * N // 4, K) # a fully connected layer with K output units
    self.fc2 = nn.Linear(L, 1) # another fully connected layer with one output unit
  
  def forward(self, x):
    # x: a tensor of shape (3, N) containing the image pixels
    # returns: a tensor of shape (M,) containing the region values
    x = self.pool(torch.relu(self.conv1(x))) # apply the first convolutional layer and max pooling layer with relu activation
    x = self.pool(torch.relu(self.conv2(x))) # apply the second convolutional layer and max pooling layer with relu activation
    x = x.view(-1, 32 * N // 4) # flatten the output to a vector of length 32 * N // 4
    x = self.fc1(x) # apply the first fully connected layer
    x = RegionAggregationLayer(s)(x) # apply the region aggregation layer with s as input
    x = self.fc2(x) # apply the second fully connected layer
    return x.squeeze() # remove any extra dimensions

# Define the loss function
def loss_function(y_pred, y_true):
  # y_pred: a tensor of shape (M,) containing the predicted region values
  # y_true: a tensor of shape (M,) containing the true region values
  return torch.mean((y_pred - y_true)**2) # mean squared error

# Define the optimizer
model = CNN() # instantiate the model
optimizer = optim.Adam(model.parameters(), lr=0.01) # use Adam optimizer with learning rate 0.01

# Define the training loop
for epoch in range(100): # train for 100 epochs
  for x, y in data_loader: # iterate over the data loader
    optimizer.zero_grad() # zero the gradients
    y_pred = model(x) # forward pass
    loss = loss_function(y_pred, y) # compute the loss
    loss.backward() # backward pass
    optimizer.step() # update the parameters
  print(f"Epoch {epoch}, Loss {loss.item()}") # print the epoch and loss

# Define the evaluation metrics
def rmse(y_pred, y_true):
  # y_pred: a tensor of shape (M,) containing the predicted region values
  # y_true: a tensor of shape (M,) containing the true region values
  return torch.sqrt(torch.mean((y_pred - y_true)**2)) # root mean squared error

def r2(y_pred, y_true):
  # y_pred: a tensor of shape (M,) containing the predicted region values
  # y_true: a tensor of shape (M,) containing the true region values
  return 1 - torch.sum((y_pred - y_true)**2) / torch.sum((y_true - torch.mean(y_true))**2) # coefficient of determination

# Evaluate the model on the test set
model.eval() # set the model to evaluation mode
y_pred = model(x_test) # predict on the test set
rmse = rmse(y_pred, y_test) # compute the rmse
r2 = r2(y_pred, y_test) # compute the r2
print(f"RMSE: {rmse.item()}, R2: {r2.item()}") # print the metrics

# Visualize the fine-level distributions
d = disaggregate(y_test, s_test) # disaggregate the test labels using s_test as input
mu = d.mean # get the mean of the fine-level distributions
sigma = d.stddev # get the standard deviation of the fine-level distributions
plot_image(mu.reshape(3, N)) # plot the mean as an image of shape (3, N)
plot_image(sigma.reshape(3, N)) # plot the standard deviation as an image of shape (3, N)
```