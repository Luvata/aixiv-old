---
title: 2204.00923v4 Word separation in continuous sign language using isolated signs and post-processing
date: 2022-04-01
---

# [Word separation in continuous sign language using isolated signs and post-processing](http://arxiv.org/abs/2204.00923v4)

authors: Razieh Rastgoo, Kourosh Kiani, Sergio Escalera


## What, Why and How

[1]: https://arxiv.org/pdf/2204.00923v4.pdf "Word separation in continuous sign language using isolated signs and ..."
[2]: https://arxiv.org/abs/2204.00923 "[2204.00923] Word separation in continuous sign language using isolated ..."
[3]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2212.00923v4 "[2212.00923v4] A Tractable Probability Distribution with Applications ..."

Here is a summary of the paper at [^1^][1] in terms of What, Why, and How:

- **What**: The paper proposes a two-stage model for word separation in continuous sign language using isolated signs and post-processing.
- **Why**: The paper aims to address the challenge of detecting the explicit boundaries between the words in a sign sentence, which is a crucial step for continuous sign language recognition (CSLR) and translation.
- **How**: The paper uses a combination of CNN, SVD, and LSTM to train a predictor model with isolated signs, and then applies a post-processing algorithm to the Softmax outputs to separate the isolated signs in the continuous signs. The paper evaluates the model on two public datasets in isolated sign language recognition (ISLR), RKS-PERSIANSIGN and ASLLVD.

## Main Contributions

[1]: https://arxiv.org/pdf/2204.00923v4.pdf "Word separation in continuous sign language using isolated signs and ..."
[2]: https://arxiv.org/abs/2204.00923 "[2204.00923] Word separation in continuous sign language using isolated ..."
[3]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2212.00923v4 "[2212.00923v4] A Tractable Probability Distribution with Applications ..."

According to the paper at [^1^][1], the main contributions are:

- **A novel two-stage model for word separation in continuous sign language using isolated signs and post-processing**.
- **A predictor model that combines CNN, SVD, and LSTM to learn the features of isolated signs**.
- **A post-processing algorithm that uses a threshold-based method and a sliding window technique to detect the sign boundaries in the continuous signs**.
- **An evaluation of the proposed model on two public datasets in ISLR, RKS-PERSIANSIGN and ASLLVD, showing its effectiveness and robustness**.

## Method Summary

[1]: https://arxiv.org/pdf/2204.00923v4.pdf "Word separation in continuous sign language using isolated signs and ..."
[2]: https://arxiv.org/abs/2204.00923 "[2204.00923] Word separation in continuous sign language using isolated ..."
[3]: https://lib-arxiv-017.serverfarm.cornell.edu/abs/2212.00923v4 "[2212.00923v4] A Tractable Probability Distribution with Applications ..."

Here is a summary of the method section of the paper at [^1^][1]:

- The paper describes a two-stage model for word separation in continuous sign language using isolated signs and post-processing.
- The first stage is the predictor model, which consists of three components: a CNN-based feature extractor, a SVD-based dimensionality reducer, and a LSTM-based classifier. The predictor model is trained with isolated signs from two public datasets in ISLR, RKS-PERSIANSIGN and ASLLVD.
- The second stage is the post-processing algorithm, which takes the Softmax outputs of the predictor model as inputs and applies a threshold-based method and a sliding window technique to detect the sign boundaries in the continuous signs. The post-processing algorithm also uses a dictionary of sign classes to filter out the false positives and improve the accuracy.
- The paper evaluates the proposed model on continuous sign videos from the same two datasets in ISLR, and compares it with several baseline methods. The paper reports the precision, recall, F1-score, and accuracy of the model for word separation in continuous sign language.

## Pseudo Code - High level

Here is the high-level pseudo code for the paper at :

```python
# Define the predictor model
predictor_model = CNN + SVD + LSTM

# Train the predictor model with isolated signs
for each dataset in [RKS-PERSIANSIGN, ASLLVD]:
  for each sign_class in dataset:
    for each sign_video in sign_class:
      features = CNN(sign_video)
      reduced_features = SVD(features)
      softmax_output = LSTM(reduced_features)
      loss = cross_entropy(softmax_output, sign_class)
      update predictor_model parameters

# Define the post-processing algorithm
def post_processing(softmax_outputs):
  # Initialize the output list
  output = []
  # Set the threshold value
  threshold = 0.5
  # Set the sliding window size
  window_size = 10
  # Loop over the softmax outputs
  for i in range(len(softmax_outputs)):
    # Get the current softmax output
    current_output = softmax_outputs[i]
    # Get the maximum probability and the corresponding class
    max_prob, max_class = max(current_output)
    # If the maximum probability is greater than the threshold
    if max_prob > threshold:
      # Append the class to the output list
      output.append(max_class)
    # Else
    else:
      # If the sliding window is not full
      if i < window_size:
        # Get the previous softmax outputs within the window
        previous_outputs = softmax_outputs[:i]
      # Else
      else:
        # Get the previous softmax outputs within the window
        previous_outputs = softmax_outputs[i-window_size:i]
      # Calculate the average probability for each class
      avg_probs = mean(previous_outputs, axis=0)
      # Get the maximum average probability and the corresponding class
      max_avg_prob, max_avg_class = max(avg_probs)
      # If the maximum average probability is greater than the threshold
      if max_avg_prob > threshold:
        # Append the class to the output list
        output.append(max_avg_class)
      # Else
      else:
        # Append a blank symbol to the output list
        output.append("_")
  # Filter out the false positives using a dictionary of sign classes
  output = filter(output, dictionary)
  # Return the output list
  return output

# Evaluate the proposed model on continuous sign videos
for each dataset in [RKS-PERSIANSIGN, ASLLVD]:
  for each sign_sequence in dataset:
    # Get the ground truth labels of the sign sequence
    labels = sign_sequence.labels
    # Get the features of the sign sequence using CNN and SVD
    features = SVD(CNN(sign_sequence))
    # Get the softmax outputs of the sign sequence using LSTM
    softmax_outputs = LSTM(features)
    # Get the predicted labels of the sign sequence using post-processing algorithm
    predictions = post_processing(softmax_outputs)
    # Calculate and report the precision, recall, F1-score, and accuracy of word separation 
    precision, recall, F1_score, accuracy = metrics(labels, predictions)
```


## Pseudo Code - Detail

Here is the detailed pseudo code to implement the paper at :

```python
# Import the necessary libraries
import numpy as np
import tensorflow as tf
import cv2
import sklearn

# Define the hyperparameters
num_classes = 100 # The number of sign classes in the datasets
num_epochs = 50 # The number of epochs for training
batch_size = 32 # The batch size for training
learning_rate = 0.01 # The learning rate for training
threshold = 0.5 # The threshold value for post-processing
window_size = 10 # The sliding window size for post-processing

# Define the CNN model
def CNN_model():
  # Create a sequential model
  model = tf.keras.Sequential()
  # Add a convolutional layer with 32 filters, 3x3 kernel size, ReLU activation, and same padding
  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))
  # Add a max pooling layer with 2x2 pool size and strides
  model.add(tf.keras.layers.MaxPool2D((2, 2), strides=2))
  # Add a convolutional layer with 64 filters, 3x3 kernel size, ReLU activation, and same padding
  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
  # Add a max pooling layer with 2x2 pool size and strides
  model.add(tf.keras.layers.MaxPool2D((2, 2), strides=2))
  # Add a convolutional layer with 128 filters, 3x3 kernel size, ReLU activation, and same padding
  model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
  # Add a max pooling layer with 2x2 pool size and strides
  model.add(tf.keras.layers.MaxPool2D((2, 2), strides=2))
  # Add a flatten layer to convert the output to a vector
  model.add(tf.keras.layers.Flatten())
  # Return the model
  return model

# Define the SVD function
def SVD(X):
  # Perform singular value decomposition on X
  U, S, V = np.linalg.svd(X)
  # Keep only the top k singular values and vectors, where k is the square root of the number of columns of X
  k = int(np.sqrt(X.shape[1]))
  U = U[:, :k]
  S = S[:k]
  V = V[:k, :]
  # Reconstruct X using the truncated U, S, and V
  X_reduced = U @ np.diag(S) @ V
  # Return the reduced X
  return X_reduced

# Define the LSTM model
def LSTM_model():
  # Create a sequential model
  model = tf.keras.Sequential()
  # Add a LSTM layer with 256 units and return sequences
  model.add(tf.keras.layers.LSTM(256, return_sequences=True))
  # Add a dropout layer with 0.2 rate to prevent overfitting
  model.add(tf.keras.layers.Dropout(0.2))
  # Add a dense layer with num_classes units and softmax activation for classification
  model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))
  # Return the model
  return model

# Define the post-processing function
def post_processing(softmax_outputs):
    # Initialize the output list
    output = []
    # Loop over the softmax outputs
    for i in range(len(softmax_outputs)):
      # Get the current softmax output
      current_output = softmax_outputs[i]
      # Get the maximum probability and the corresponding class index
      max_prob = np.max(current_output)
      max_class = np.argmax(current_output)
      # If the maximum probability is greater than the threshold
      if max_prob > threshold:
        # Append the class index to the output list
        output.append(max_class)
      # Else
      else:
        # If the sliding window is not full
        if i < window_size:
          # Get the previous softmax outputs within the window
          previous_outputs = softmax_outputs[:i]
        # Else
        else:
          # Get the previous softmax outputs within the window
          previous_outputs = softmax_outputs[i-window_size:i]
        # Calculate the average probability for each class across the window outputs 
        avg_probs = np.mean(previous_outputs, axis=0)
        # Get the maximum average probability and the corresponding class index 
        max_avg_prob = np.max(avg_probs)
        max_avg_class = np.argmax(avg_probs)
        # If the maximum average probability is greater than the threshold
        if max_avg_prob > threshold:
          # Append the class index to the output list
          output.append(max_avg_class)
        # Else
        else:
          # Append a blank symbol to the output list
          output.append("_")
    # Filter out the false positives using a dictionary of sign classes
    output = filter(output, dictionary)
    # Return the output list
    return output

# Define the filter function
def filter(output, dictionary):
  # Initialize the filtered output list
  filtered_output = []
  # Initialize the current word as an empty string
  current_word = ""
  # Loop over the output list
  for i in range(len(output)):
    # Get the current class index or symbol
    current_class = output[i]
    # If the current class is not a blank symbol
    if current_class != "_":
      # Append the corresponding sign character to the current word
      current_word += dictionary[current_class]
    # Else
    else:
      # If the current word is not empty and is in the dictionary
      if current_word and current_word in dictionary.values():
        # Append the current word to the filtered output list
        filtered_output.append(current_word)
      # Reset the current word as an empty string
      current_word = ""
  # Return the filtered output list
  return filtered_output

# Load the datasets
RKS_PERSIANSIGN = load_dataset("RKS-PERSIANSIGN")
ASLLVD = load_dataset("ASLLVD")

# Create the CNN model
CNN = CNN_model()

# Create the LSTM model
LSTM = LSTM_model()

# Compile the LSTM model with categorical crossentropy loss, Adam optimizer, and accuracy metric
LSTM.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the predictor model with isolated signs
for epoch in range(num_epochs):
  # Shuffle the datasets
  RKS_PERSIANSIGN.shuffle()
  ASLLVD.shuffle()
  # Loop over the datasets
  for dataset in [RKS_PERSIANSIGN, ASLLVD]:
    # Loop over the batches of sign videos and labels in the dataset
    for sign_videos, labels in dataset.batch(batch_size):
      # Get the features of the sign videos using CNN and SVD
      features = SVD(CNN(sign_videos))
      # Get the softmax outputs of the sign videos using LSTM
      softmax_outputs = LSTM(features)
      # Calculate and update the loss and accuracy using labels and softmax outputs
      loss, accuracy = LSTM.train_on_batch(labels, softmax_outputs)
  # Print the epoch number, loss, and accuracy 
  print(f"Epoch {epoch+1}, Loss: {loss}, Accuracy: {accuracy}")

# Evaluate the proposed model on continuous sign videos
for dataset in [RKS_PERSIANSIGN, ASLLVD]:
  # Initialize the lists of true labels and predicted labels 
  true_labels = []
  predicted_labels = []
  # Loop over the sign sequences and labels in the dataset 
  for sign_sequences, labels in dataset:
    # Get the features of the sign sequences using CNN and SVD 
    features = SVD(CNN(sign_sequences))
    # Get the softmax outputs of the sign sequences using LSTM 
    softmax_outputs = LSTM(features)
    # Get the predicted labels of the sign sequences using post-processing algorithm 
    predictions = post_processing(softmax_outputs)
    # Append the labels and predictions to their respective lists 
    true_labels.append(labels)
    predicted_labels.append(predictions)
  # Calculate and report the precision, recall, F1-score, and accuracy of word separation 
  precision, recall, F1_score, accuracy = sklearn.metrics.precision_recall_fscore_support(true_labels, predicted_labels, average='macro')
  print(f"Dataset: {dataset.name}, Precision: {precision}, Recall: {recall}, F1-score: {F1_score}, Accuracy: {accuracy}")
```